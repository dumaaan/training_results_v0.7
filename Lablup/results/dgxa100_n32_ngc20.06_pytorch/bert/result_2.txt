+ echo 'Beginning trial 2 of 4'
Beginning trial 2 of 4
+ '[' 1 -eq 1 ']'
+ srun --ntasks=32 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0016
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0009
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0011
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0010
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0070
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0008
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0066
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0014
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0068
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0061
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0069
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0073
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0111
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0013
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0067
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0015
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0012
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0115
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0063
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0062
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0064
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0116
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0065
Clearing cache on luna-0109
Clearing cache on luna-0075
Clearing cache on luna-0114
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0074
Clearing cache on luna-0110
Clearing cache on luna-0113
Clearing cache on luna-0071
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0072
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0076
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=32 --container-name=language_model python -c '
import mlperf_logger
mlperf_logger.log_event(key=mlperf_logger.constants.CACHE_CLEAR, value=True)'
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
:::MLLOG {"namespace": "", "time_ms": 1592975774729, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774729, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774730, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774730, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774732, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774745, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774745, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774747, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774756, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774758, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774761, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774764, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774768, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774772, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774781, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774782, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774784, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774784, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774786, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774788, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774788, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774794, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774799, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774801, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774808, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774811, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774811, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774812, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774814, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774816, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774829, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975774844, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ srun -l --mpi=none --ntasks=256 --ntasks-per-node=8 --container-name=language_model --container-mounts=/raid/datasets/bert/hdf5/new_2048_shards:/workspace/data,/raid/datasets/bert/hdf5/new_2048_shards:/workspace/data_phase2,/lustre/fsw/mlperf-ci/14138652/ci_checkpoints:/results,/raid/datasets/bert/checkpoints/checkpoint_phase1:/workspace/phase1,/raid/datasets/bert/hdf5/500_shards:/workspace/evaldata sh -c '/workspace/bert/run_and_time.sh "    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=${SLURM_LOCALID}     --bert_config_path=/workspace/phase1/bert_config.json" 28019'
  0: slurmstepd: pyxis: reusing existing container filesystem
  0: slurmstepd: pyxis: starting container ...
 56: slurmstepd: pyxis: reusing existing container filesystem
 56: slurmstepd: pyxis: starting container ...
 24: slurmstepd: pyxis: reusing existing container filesystem
 24: slurmstepd: pyxis: starting container ...
 64: slurmstepd: pyxis: reusing existing container filesystem
 64: slurmstepd: pyxis: starting container ...
 32: slurmstepd: pyxis: reusing existing container filesystem
 32: slurmstepd: pyxis: starting container ...
 40: slurmstepd: pyxis: reusing existing container filesystem
 40: slurmstepd: pyxis: starting container ...
176: slurmstepd: pyxis: reusing existing container filesystem
176: slurmstepd: pyxis: starting container ...
 80: slurmstepd: pyxis: reusing existing container filesystem
 80: slurmstepd: pyxis: starting container ...
144: slurmstepd: pyxis: reusing existing container filesystem
144: slurmstepd: pyxis: starting container ...
 16: slurmstepd: pyxis: reusing existing container filesystem
 16: slurmstepd: pyxis: starting container ...
240: slurmstepd: pyxis: reusing existing container filesystem
240: slurmstepd: pyxis: starting container ...
168: slurmstepd: pyxis: reusing existing container filesystem
168: slurmstepd: pyxis: starting container ...
 96: slurmstepd: pyxis: reusing existing container filesystem
 96: slurmstepd: pyxis: starting container ...
248: slurmstepd: pyxis: reusing existing container filesystem
248: slurmstepd: pyxis: starting container ...
 88: slurmstepd: pyxis: reusing existing container filesystem
 88: slurmstepd: pyxis: starting container ...
 48: slurmstepd: pyxis: reusing existing container filesystem
 48: slurmstepd: pyxis: starting container ...
112: slurmstepd: pyxis: reusing existing container filesystem
112: slurmstepd: pyxis: starting container ...
 72: slurmstepd: pyxis: reusing existing container filesystem
 72: slurmstepd: pyxis: starting container ...
104: slurmstepd: pyxis: reusing existing container filesystem
104: slurmstepd: pyxis: starting container ...
120: slurmstepd: pyxis: reusing existing container filesystem
120: slurmstepd: pyxis: starting container ...
128: slurmstepd: pyxis: reusing existing container filesystem
128: slurmstepd: pyxis: starting container ...
184: slurmstepd: pyxis: reusing existing container filesystem
184: slurmstepd: pyxis: starting container ...
136: slurmstepd: pyxis: reusing existing container filesystem
136: slurmstepd: pyxis: starting container ...
216: slurmstepd: pyxis: reusing existing container filesystem
216: slurmstepd: pyxis: starting container ...
224: slurmstepd: pyxis: reusing existing container filesystem
224: slurmstepd: pyxis: starting container ...
  8: slurmstepd: pyxis: reusing existing container filesystem
  8: slurmstepd: pyxis: starting container ...
208: slurmstepd: pyxis: reusing existing container filesystem
208: slurmstepd: pyxis: starting container ...
200: slurmstepd: pyxis: reusing existing container filesystem
200: slurmstepd: pyxis: starting container ...
192: slurmstepd: pyxis: reusing existing container filesystem
192: slurmstepd: pyxis: starting container ...
232: slurmstepd: pyxis: reusing existing container filesystem
232: slurmstepd: pyxis: starting container ...
160: slurmstepd: pyxis: reusing existing container filesystem
160: slurmstepd: pyxis: starting container ...
152: slurmstepd: pyxis: reusing existing container filesystem
152: slurmstepd: pyxis: starting container ...
  4: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
  0: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
  2: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
  3: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
  5: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
  6: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
  7: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
  1: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 75: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 72: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 77: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 79: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 76: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 73: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 74: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 78: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 59: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 63: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 57: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 62: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 61: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 56: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 60: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 58: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
119: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
116: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 80: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 81: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 82: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 83: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 84: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 85: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 86: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 87: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
112: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
113: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
114: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
115: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
117: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
118: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
179: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
188: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
176: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
177: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
187: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
178: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
180: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
184: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
181: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
182: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
183: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
186: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
190: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
191: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
189: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
185: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
  7: Run vars: id 378151 gpus 8 mparams
  0: Run vars: id 378151 gpus 8 mparams
  5: Run vars: id 378151 gpus 8 mparams
  6: Run vars: id 378151 gpus 8 mparams
  4: Run vars: id 378151 gpus 8 mparams
  0: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
  0: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
  0: son --seed=28019'
  0: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
  2: Run vars: id 378151 gpus 8 mparams
  3: Run vars: id 378151 gpus 8 mparams
  7: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
  5: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
  7: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
134: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
129: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
131: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
128: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
132: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
130: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
133: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
135: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 48: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 50: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 52: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 49: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 51: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 53: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 54: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 55: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 79: Run vars: id 378151 gpus 8 mparams
 78: Run vars: id 378151 gpus 8 mparams
 74: Run vars: id 378151 gpus 8 mparams
 79: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 79: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
 79: son --seed=28019'
 79: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 60: Run vars: id 378151 gpus 8 mparams
 78: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 78: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
 78: son --seed=28019'
 75: Run vars: id 378151 gpus 8 mparams
 78: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 72: Run vars: id 378151 gpus 8 mparams
240: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
245: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
243: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
241: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
244: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
242: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
246: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
247: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 77: Run vars: id 378151 gpus 8 mparams
 74: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 74: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
 56: Run vars: id 378151 gpus 8 mparams
 33: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 34: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 35: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 36: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 37: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 38: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 39: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 60: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 60: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
 60: son --seed=28019'
 87: Run vars: id 378151 gpus 8 mparams
 32: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 74: son --seed=28019'
 60: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 76: Run vars: id 378151 gpus 8 mparams
 74: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 73: Run vars: id 378151 gpus 8 mparams
 75: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 75: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
 75: son --seed=28019'
 75: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 72: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 72: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
 72: son --seed=28019'
 72: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 77: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 77: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
 77: son --seed=28019'
 77: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
119: Run vars: id 378151 gpus 8 mparams
 76: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 76: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
 76: son --seed=28019'
 76: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 73: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 73: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
 73: son --seed=28019'
 73: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 81: Run vars: id 378151 gpus 8 mparams
 58: Run vars: id 378151 gpus 8 mparams
 87: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
116: Run vars: id 378151 gpus 8 mparams
 87: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
 56: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
191: Run vars: id 378151 gpus 8 mparams
179: Run vars: id 378151 gpus 8 mparams
 87: son --seed=28019'
 87: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
219: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 56: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
222: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
220: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 84: Run vars: id 378151 gpus 8 mparams
216: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
221: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
217: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 20: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 19: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 23: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 21: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 17: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 18: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 22: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 16: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
188: Run vars: id 378151 gpus 8 mparams
218: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
187: Run vars: id 378151 gpus 8 mparams
253: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
250: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
119: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
254: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
176: Run vars: id 378151 gpus 8 mparams
252: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
119: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
251: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
119: son --seed=28019'
119: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 85: Run vars: id 378151 gpus 8 mparams
177: Run vars: id 378151 gpus 8 mparams
 81: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 81: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
 81: son --seed=28019'
 81: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
248: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
249: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
255: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
116: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
191: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 56: son --seed=28019'
 61: Run vars: id 378151 gpus 8 mparams
191: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
191: son --seed=28019'
 57: Run vars: id 378151 gpus 8 mparams
 56: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
179: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
116: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
 63: Run vars: id 378151 gpus 8 mparams
 59: Run vars: id 378151 gpus 8 mparams
 62: Run vars: id 378151 gpus 8 mparams
178: Run vars: id 378151 gpus 8 mparams
 58: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
 58: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 58: son --seed=28019'
179: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
116: son --seed=28019'
179: son --seed=28019'
 57: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 58: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
182: Run vars: id 378151 gpus 8 mparams
115: Run vars: id 378151 gpus 8 mparams
191: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
179: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 57: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
116: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 57: son --seed=28019'
 61: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 61: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
114: Run vars: id 378151 gpus 8 mparams
 61: son --seed=28019'
 63: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 57: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 63: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
 63: son --seed=28019'
 61: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
118: Run vars: id 378151 gpus 8 mparams
 63: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 84: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 84: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
 84: son --seed=28019'
186: Run vars: id 378151 gpus 8 mparams
 84: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
188: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
188: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
180: Run vars: id 378151 gpus 8 mparams
188: son --seed=28019'
188: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
187: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
187: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
187: son --seed=28019'
223: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
187: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
181: Run vars: id 378151 gpus 8 mparams
176: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
176: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
176: son --seed=28019'
176: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
113: Run vars: id 378151 gpus 8 mparams
 59: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 59: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
 59: son --seed=28019'
177: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 59: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
177: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
177: son --seed=28019'
183: Run vars: id 378151 gpus 8 mparams
177: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
112: Run vars: id 378151 gpus 8 mparams
117: Run vars: id 378151 gpus 8 mparams
 62: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 86: Run vars: id 378151 gpus 8 mparams
 62: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
 82: Run vars: id 378151 gpus 8 mparams
 62: son --seed=28019'
 62: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
182: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
190: Run vars: id 378151 gpus 8 mparams
182: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
182: son --seed=28019'
178: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
185: Run vars: id 378151 gpus 8 mparams
178: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
178: son --seed=28019'
182: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 85: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
178: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
114: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
115: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 85: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
114: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
114: son --seed=28019'
115: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
115: son --seed=28019'
118: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
114: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
186: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
115: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
189: Run vars: id 378151 gpus 8 mparams
118: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
118: son --seed=28019'
184: Run vars: id 378151 gpus 8 mparams
186: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
118: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
186: son --seed=28019'
186: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
180: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
180: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
180: son --seed=28019'
180: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 68: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 67: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
181: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
181: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
181: son --seed=28019'
181: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
113: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
113: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
113: son --seed=28019'
 64: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 65: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 71: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
113: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
183: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
112: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
183: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
183: son --seed=28019'
190: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
112: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
112: son --seed=28019'
185: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
117: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
190: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
190: son --seed=28019'
112: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
185: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
185: son --seed=28019'
183: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
117: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
190: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
117: son --seed=28019'
117: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
185: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 66: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 69: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 70: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 85: son --seed=28019'
 83: Run vars: id 378151 gpus 8 mparams
 85: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 80: Run vars: id 378151 gpus 8 mparams
 86: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 82: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 86: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
 86: son --seed=28019'
 82: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
 82: son --seed=28019'
 86: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 82: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 83: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
189: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 83: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
189: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
189: son --seed=28019'
 83: son --seed=28019'
189: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 83: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 80: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
184: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 80: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
 80: son --seed=28019'
184: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
 80: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
184: son --seed=28019'
184: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
232: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
233: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
234: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
235: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
236: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
237: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
238: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
239: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
135: Run vars: id 378151 gpus 8 mparams
134: Run vars: id 378151 gpus 8 mparams
128: Run vars: id 378151 gpus 8 mparams
155: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
  9: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
154: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 12: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 14: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
158: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 13: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 10: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 11: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 15: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
247: Run vars: id 378151 gpus 8 mparams
152: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
132: Run vars: id 378151 gpus 8 mparams
153: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
156: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
157: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
159: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
135: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
135: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
135: son --seed=28019'
134: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
134: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
134: son --seed=28019'
135: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
134: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
128: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
128: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
  8: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
104: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
105: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
110: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
111: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
109: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
107: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
128: son --seed=28019'
128: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
130: Run vars: id 378151 gpus 8 mparams
133: Run vars: id 378151 gpus 8 mparams
129: Run vars: id 378151 gpus 8 mparams
132: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
132: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
132: son --seed=28019'
 55: Run vars: id 378151 gpus 8 mparams
132: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
108: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
106: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 54: Run vars: id 378151 gpus 8 mparams
247: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
247: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
247: son --seed=28019'
247: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 48: Run vars: id 378151 gpus 8 mparams
 32: Run vars: id 378151 gpus 8 mparams
130: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
130: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
130: son --seed=28019'
133: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
133: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
133: son --seed=28019'
130: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
133: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
243: Run vars: id 378151 gpus 8 mparams
129: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
129: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
 53: Run vars: id 378151 gpus 8 mparams
129: son --seed=28019'
129: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
131: Run vars: id 378151 gpus 8 mparams
 51: Run vars: id 378151 gpus 8 mparams
 50: Run vars: id 378151 gpus 8 mparams
241: Run vars: id 378151 gpus 8 mparams
 52: Run vars: id 378151 gpus 8 mparams
 54: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 55: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 54: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
 54: son --seed=28019'
 17: Run vars: id 378151 gpus 8 mparams
 55: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
 55: son --seed=28019'
 54: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
246: Run vars: id 378151 gpus 8 mparams
 55: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
240: Run vars: id 378151 gpus 8 mparams
244: Run vars: id 378151 gpus 8 mparams
 32: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 32: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
 32: son --seed=28019'
 49: Run vars: id 378151 gpus 8 mparams
 53: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 32: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 53: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
217: Run vars: id 378151 gpus 8 mparams
 53: son --seed=28019'
 53: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
245: Run vars: id 378151 gpus 8 mparams
243: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 18: Run vars: id 378151 gpus 8 mparams
243: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
243: son --seed=28019'
 48: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 48: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
 48: son --seed=28019'
 48: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
219: Run vars: id 378151 gpus 8 mparams
 34: Run vars: id 378151 gpus 8 mparams
131: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
223: Run vars: id 378151 gpus 8 mparams
131: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
131: son --seed=28019'
131: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 50: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
250: Run vars: id 378151 gpus 8 mparams
243: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
241: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 50: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
246: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 50: son --seed=28019'
 50: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 51: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
241: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
 51: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
 52: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
241: son --seed=28019'
 51: son --seed=28019'
 51: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
246: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
246: son --seed=28019'
 52: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
 52: son --seed=28019'
 52: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
241: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 17: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
242: Run vars: id 378151 gpus 8 mparams
 17: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
246: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 17: son --seed=28019'
216: Run vars: id 378151 gpus 8 mparams
244: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 17: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
244: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
244: son --seed=28019'
244: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 38: Run vars: id 378151 gpus 8 mparams
220: Run vars: id 378151 gpus 8 mparams
217: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
240: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 18: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
245: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 49: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 18: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
 18: son --seed=28019'
217: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
240: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
 49: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
240: son --seed=28019'
245: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
245: son --seed=28019'
 18: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
217: son --seed=28019'
 49: son --seed=28019'
240: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 49: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
245: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
217: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
219: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
221: Run vars: id 378151 gpus 8 mparams
218: Run vars: id 378151 gpus 8 mparams
219: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
219: son --seed=28019'
222: Run vars: id 378151 gpus 8 mparams
 33: Run vars: id 378151 gpus 8 mparams
251: Run vars: id 378151 gpus 8 mparams
228: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 39: Run vars: id 378151 gpus 8 mparams
226: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
231: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
230: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
224: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 34: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 34: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
 34: son --seed=28019'
 34: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
219: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
223: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
223: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
223: son --seed=28019'
223: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
225: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
227: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
229: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
216: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
250: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
242: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
242: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
242: son --seed=28019'
250: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
242: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
216: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
250: son --seed=28019'
250: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
216: son --seed=28019'
216: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
220: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 35: Run vars: id 378151 gpus 8 mparams
220: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
220: son --seed=28019'
252: Run vars: id 378151 gpus 8 mparams
220: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 37: Run vars: id 378151 gpus 8 mparams
 38: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
218: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 38: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
 38: son --seed=28019'
218: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
218: son --seed=28019'
218: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 38: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 33: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 33: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
 33: son --seed=28019'
221: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 39: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 39: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
 39: son --seed=28019'
 33: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
221: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
 39: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
253: Run vars: id 378151 gpus 8 mparams
221: son --seed=28019'
251: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
221: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
251: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
222: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
222: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
222: son --seed=28019'
 36: Run vars: id 378151 gpus 8 mparams
222: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 23: Run vars: id 378151 gpus 8 mparams
 21: Run vars: id 378151 gpus 8 mparams
 71: Run vars: id 378151 gpus 8 mparams
140: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
141: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 22: Run vars: id 378151 gpus 8 mparams
137: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 64: Run vars: id 378151 gpus 8 mparams
142: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
138: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
136: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 16: Run vars: id 378151 gpus 8 mparams
 89: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 92: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 37: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
251: son --seed=28019'
251: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
248: Run vars: id 378151 gpus 8 mparams
249: Run vars: id 378151 gpus 8 mparams
252: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
252: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
139: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 37: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
252: son --seed=28019'
 37: son --seed=28019'
252: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 37: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 35: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 88: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 35: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
 35: son --seed=28019'
 90: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 91: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 93: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 94: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 95: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 35: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 23: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 23: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
 36: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 36: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
 36: son --seed=28019'
253: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 36: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
254: Run vars: id 378151 gpus 8 mparams
253: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
253: son --seed=28019'
253: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
248: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
201: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
248: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
204: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
200: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
206: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
248: son --seed=28019'
248: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
205: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
207: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
202: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
203: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 71: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 23: son --seed=28019'
 23: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 20: Run vars: id 378151 gpus 8 mparams
 21: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 21: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
 21: son --seed=28019'
143: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 71: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
 71: son --seed=28019'
 21: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 19: Run vars: id 378151 gpus 8 mparams
 71: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
  7: son --seed=28019'
  1: Run vars: id 378151 gpus 8 mparams
  5: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
  5: son --seed=28019'
 22: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
  7: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
  5: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
  6: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
  6: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
  6: son --seed=28019'
  6: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
  4: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
  4: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
  4: son --seed=28019'
  4: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
  2: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
  2: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
  2: son --seed=28019'
  2: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
  1: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 22: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
  3: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
  1: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
  1: son --seed=28019'
 22: son --seed=28019'
  3: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
  3: son --seed=28019'
  1: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
  3: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 67: Run vars: id 378151 gpus 8 mparams
 22: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
124: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
121: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
255: Run vars: id 378151 gpus 8 mparams
122: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
126: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 64: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
125: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 16: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 64: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
123: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 64: son --seed=28019'
 16: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
 16: son --seed=28019'
 64: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
239: Run vars: id 378151 gpus 8 mparams
 16: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
120: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
127: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 70: Run vars: id 378151 gpus 8 mparams
249: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
249: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
249: son --seed=28019'
249: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 68: Run vars: id 378151 gpus 8 mparams
254: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
254: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
254: son --seed=28019'
 66: Run vars: id 378151 gpus 8 mparams
254: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 67: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 20: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 67: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
 20: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
 20: son --seed=28019'
232: Run vars: id 378151 gpus 8 mparams
 20: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 19: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 19: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
 19: son --seed=28019'
 19: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 97: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
100: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
255: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
255: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
255: son --seed=28019'
239: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
255: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
239: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
239: son --seed=28019'
239: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 96: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
233: Run vars: id 378151 gpus 8 mparams
 98: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 99: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
101: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
102: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
103: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 67: son --seed=28019'
 67: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 69: Run vars: id 378151 gpus 8 mparams
 65: Run vars: id 378151 gpus 8 mparams
 70: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 70: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
 70: son --seed=28019'
 70: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
  9: Run vars: id 378151 gpus 8 mparams
 68: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 68: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
 68: son --seed=28019'
 66: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 68: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 66: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
 66: son --seed=28019'
232: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
232: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
 66: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
232: son --seed=28019'
232: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
235: Run vars: id 378151 gpus 8 mparams
145: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
146: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
147: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
149: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
150: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
151: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 69: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 69: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
 69: son --seed=28019'
 69: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
237: Run vars: id 378151 gpus 8 mparams
233: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
233: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
 65: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 12: Run vars: id 378151 gpus 8 mparams
 65: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
 65: son --seed=28019'
 65: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
  9: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
  9: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
  9: son --seed=28019'
  9: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
104: Run vars: id 378151 gpus 8 mparams
144: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
148: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 14: Run vars: id 378151 gpus 8 mparams
233: son --seed=28019'
238: Run vars: id 378151 gpus 8 mparams
234: Run vars: id 378151 gpus 8 mparams
233: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
236: Run vars: id 378151 gpus 8 mparams
235: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
235: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
235: son --seed=28019'
235: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
237: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
237: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
237: son --seed=28019'
237: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 13: Run vars: id 378151 gpus 8 mparams
234: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
234: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
234: son --seed=28019'
238: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
234: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
238: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
238: son --seed=28019'
238: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 12: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 11: Run vars: id 378151 gpus 8 mparams
 12: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
 12: son --seed=28019'
110: Run vars: id 378151 gpus 8 mparams
158: Run vars: id 378151 gpus 8 mparams
236: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
236: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
236: son --seed=28019'
 40: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 41: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
236: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 43: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 44: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 45: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 46: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 47: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 42: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
192: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
193: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
194: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
195: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
196: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
197: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
198: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
199: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
105: Run vars: id 378151 gpus 8 mparams
 12: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
104: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
  8: Run vars: id 378151 gpus 8 mparams
 10: Run vars: id 378151 gpus 8 mparams
 14: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 14: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
 14: son --seed=28019'
104: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
104: son --seed=28019'
 14: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
104: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 13: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 13: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
 13: son --seed=28019'
 13: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
152: Run vars: id 378151 gpus 8 mparams
 11: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 11: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
 11: son --seed=28019'
 11: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 15: Run vars: id 378151 gpus 8 mparams
110: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
  8: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
  8: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
110: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
  8: son --seed=28019'
  8: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
157: Run vars: id 378151 gpus 8 mparams
154: Run vars: id 378151 gpus 8 mparams
159: Run vars: id 378151 gpus 8 mparams
 10: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 10: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
 10: son --seed=28019'
 10: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
110: son --seed=28019'
110: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
105: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
105: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
105: son --seed=28019'
105: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
155: Run vars: id 378151 gpus 8 mparams
109: Run vars: id 378151 gpus 8 mparams
156: Run vars: id 378151 gpus 8 mparams
158: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
158: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
111: Run vars: id 378151 gpus 8 mparams
158: son --seed=28019'
158: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 15: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
108: Run vars: id 378151 gpus 8 mparams
 15: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
 15: son --seed=28019'
 15: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
107: Run vars: id 378151 gpus 8 mparams
152: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
152: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
152: son --seed=28019'
106: Run vars: id 378151 gpus 8 mparams
152: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
157: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
157: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
157: son --seed=28019'
157: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
154: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
154: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
154: son --seed=28019'
155: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
111: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
111: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
111: son --seed=28019'
154: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
155: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
155: son --seed=28019'
159: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
153: Run vars: id 378151 gpus 8 mparams
111: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
159: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
159: son --seed=28019'
155: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
159: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
211: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
215: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
214: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
109: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
109: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
109: son --seed=28019'
108: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
156: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
108: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
156: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
156: son --seed=28019'
108: son --seed=28019'
109: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
156: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
108: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
208: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
209: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
210: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
212: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
213: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
228: Run vars: id 378151 gpus 8 mparams
107: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
107: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
107: son --seed=28019'
107: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
106: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
106: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
106: son --seed=28019'
106: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 89: Run vars: id 378151 gpus 8 mparams
226: Run vars: id 378151 gpus 8 mparams
227: Run vars: id 378151 gpus 8 mparams
 88: Run vars: id 378151 gpus 8 mparams
153: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
153: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
153: son --seed=28019'
153: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
141: Run vars: id 378151 gpus 8 mparams
163: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
161: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
231: Run vars: id 378151 gpus 8 mparams
164: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
166: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
228: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
160: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
167: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
228: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
228: son --seed=28019'
165: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
228: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 89: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 89: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
139: Run vars: id 378151 gpus 8 mparams
 89: son --seed=28019'
 89: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
224: Run vars: id 378151 gpus 8 mparams
162: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
226: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
226: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
226: son --seed=28019'
225: Run vars: id 378151 gpus 8 mparams
226: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
229: Run vars: id 378151 gpus 8 mparams
227: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
227: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
227: son --seed=28019'
 88: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
227: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 88: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
 88: son --seed=28019'
 88: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
141: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
141: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
141: son --seed=28019'
141: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
121: Run vars: id 378151 gpus 8 mparams
231: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
231: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
231: son --seed=28019'
231: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
230: Run vars: id 378151 gpus 8 mparams
139: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
139: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
139: son --seed=28019'
139: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
140: Run vars: id 378151 gpus 8 mparams
224: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
224: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
224: son --seed=28019'
137: Run vars: id 378151 gpus 8 mparams
224: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
122: Run vars: id 378151 gpus 8 mparams
225: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
229: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
229: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
229: son --seed=28019'
225: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
225: son --seed=28019'
225: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
229: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 95: Run vars: id 378151 gpus 8 mparams
142: Run vars: id 378151 gpus 8 mparams
150: Run vars: id 378151 gpus 8 mparams
121: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
121: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
121: son --seed=28019'
 91: Run vars: id 378151 gpus 8 mparams
121: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 90: Run vars: id 378151 gpus 8 mparams
 92: Run vars: id 378151 gpus 8 mparams
 94: Run vars: id 378151 gpus 8 mparams
230: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
230: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
230: son --seed=28019'
230: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
143: Run vars: id 378151 gpus 8 mparams
138: Run vars: id 378151 gpus 8 mparams
136: Run vars: id 378151 gpus 8 mparams
126: Run vars: id 378151 gpus 8 mparams
207: Run vars: id 378151 gpus 8 mparams
140: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
140: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
122: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
140: son --seed=28019'
140: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
137: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
137: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
137: son --seed=28019'
 93: Run vars: id 378151 gpus 8 mparams
122: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
137: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
203: Run vars: id 378151 gpus 8 mparams
150: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
142: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 95: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
150: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
142: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
150: son --seed=28019'
142: son --seed=28019'
150: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 95: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
142: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
201: Run vars: id 378151 gpus 8 mparams
 95: son --seed=28019'
 95: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 91: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 91: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
 91: son --seed=28019'
 91: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
143: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
206: Run vars: id 378151 gpus 8 mparams
143: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
143: son --seed=28019'
143: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
207: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
207: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
207: son --seed=28019'
207: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
202: Run vars: id 378151 gpus 8 mparams
138: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 94: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
138: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
138: son --seed=28019'
 94: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
 94: son --seed=28019'
 94: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
138: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
136: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
122: son --seed=28019'
122: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
127: Run vars: id 378151 gpus 8 mparams
125: Run vars: id 378151 gpus 8 mparams
136: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
123: Run vars: id 378151 gpus 8 mparams
 93: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
120: Run vars: id 378151 gpus 8 mparams
136: son --seed=28019'
124: Run vars: id 378151 gpus 8 mparams
126: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
126: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
126: son --seed=28019'
126: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
136: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 93: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
145: Run vars: id 378151 gpus 8 mparams
 93: son --seed=28019'
 93: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
205: Run vars: id 378151 gpus 8 mparams
200: Run vars: id 378151 gpus 8 mparams
127: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
203: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
127: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
127: son --seed=28019'
125: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 90: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
125: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
203: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
125: son --seed=28019'
127: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
125: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 90: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
 90: son --seed=28019'
 92: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 90: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 92: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
 92: son --seed=28019'
 92: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
146: Run vars: id 378151 gpus 8 mparams
148: Run vars: id 378151 gpus 8 mparams
123: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
123: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
123: son --seed=28019'
 46: Run vars: id 378151 gpus 8 mparams
203: son --seed=28019'
203: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
201: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
123: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
201: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
201: son --seed=28019'
204: Run vars: id 378151 gpus 8 mparams
201: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
206: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
124: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
124: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
206: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
124: son --seed=28019'
206: son --seed=28019'
206: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
124: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
202: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
202: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
120: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
202: son --seed=28019'
120: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
202: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
120: son --seed=28019'
120: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
149: Run vars: id 378151 gpus 8 mparams
170: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
171: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
172: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
145: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
173: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
145: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
145: son --seed=28019'
145: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
205: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
205: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
205: son --seed=28019'
205: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
147: Run vars: id 378151 gpus 8 mparams
168: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
200: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
169: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
174: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
175: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
200: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
151: Run vars: id 378151 gpus 8 mparams
144: Run vars: id 378151 gpus 8 mparams
200: son --seed=28019'
200: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
146: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
146: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
146: son --seed=28019'
148: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
146: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
148: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
148: son --seed=28019'
148: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 47: Run vars: id 378151 gpus 8 mparams
204: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
204: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
204: son --seed=28019'
204: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 46: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 46: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
 46: son --seed=28019'
149: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 40: Run vars: id 378151 gpus 8 mparams
149: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
 46: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
149: son --seed=28019'
149: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
198: Run vars: id 378151 gpus 8 mparams
103: Run vars: id 378151 gpus 8 mparams
151: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
193: Run vars: id 378151 gpus 8 mparams
151: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
151: son --seed=28019'
151: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
192: Run vars: id 378151 gpus 8 mparams
144: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
197: Run vars: id 378151 gpus 8 mparams
144: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
 47: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
144: son --seed=28019'
144: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
147: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 47: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
 47: son --seed=28019'
147: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
147: son --seed=28019'
199: Run vars: id 378151 gpus 8 mparams
 47: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
147: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
102: Run vars: id 378151 gpus 8 mparams
 44: Run vars: id 378151 gpus 8 mparams
 40: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 40: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
194: Run vars: id 378151 gpus 8 mparams
195: Run vars: id 378151 gpus 8 mparams
198: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
198: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
198: son --seed=28019'
198: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
103: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
215: Run vars: id 378151 gpus 8 mparams
103: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
103: son --seed=28019'
103: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
193: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
193: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
193: son --seed=28019'
193: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
196: Run vars: id 378151 gpus 8 mparams
192: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 99: Run vars: id 378151 gpus 8 mparams
192: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
208: Run vars: id 378151 gpus 8 mparams
192: son --seed=28019'
197: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
192: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
197: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
197: son --seed=28019'
197: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
199: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
199: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
199: son --seed=28019'
199: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 40: son --seed=28019'
 40: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 45: Run vars: id 378151 gpus 8 mparams
 42: Run vars: id 378151 gpus 8 mparams
 43: Run vars: id 378151 gpus 8 mparams
 41: Run vars: id 378151 gpus 8 mparams
 44: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
102: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 44: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
 44: son --seed=28019'
 44: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
102: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
102: son --seed=28019'
102: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
101: Run vars: id 378151 gpus 8 mparams
 97: Run vars: id 378151 gpus 8 mparams
194: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 45: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
194: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
194: son --seed=28019'
 45: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
194: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 45: son --seed=28019'
 45: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
195: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 43: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 43: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
195: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
 43: son --seed=28019'
195: son --seed=28019'
 96: Run vars: id 378151 gpus 8 mparams
 43: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
195: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
215: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
215: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
215: son --seed=28019'
100: Run vars: id 378151 gpus 8 mparams
215: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 42: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 98: Run vars: id 378151 gpus 8 mparams
 42: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
 42: son --seed=28019'
 42: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
196: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
196: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
196: son --seed=28019'
196: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 99: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 99: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
208: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
163: Run vars: id 378151 gpus 8 mparams
208: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
208: son --seed=28019'
210: Run vars: id 378151 gpus 8 mparams
214: Run vars: id 378151 gpus 8 mparams
208: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 41: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
211: Run vars: id 378151 gpus 8 mparams
 41: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
 41: son --seed=28019'
 99: son --seed=28019'
 99: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 97: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 41: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 97: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
 97: son --seed=28019'
 97: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
101: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
212: Run vars: id 378151 gpus 8 mparams
101: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
101: son --seed=28019'
 96: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
101: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 96: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
 96: son --seed=28019'
 96: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
213: Run vars: id 378151 gpus 8 mparams
 98: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 98: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
 98: son --seed=28019'
100: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 98: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
163: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
163: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
100: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
100: son --seed=28019'
163: son --seed=28019'
100: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
163: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
214: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
214: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
214: son --seed=28019'
214: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
210: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
210: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
210: son --seed=28019'
210: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
211: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
211: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
211: son --seed=28019'
211: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
166: Run vars: id 378151 gpus 8 mparams
212: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
209: Run vars: id 378151 gpus 8 mparams
212: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
212: son --seed=28019'
212: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
213: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
213: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
213: son --seed=28019'
164: Run vars: id 378151 gpus 8 mparams
213: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
165: Run vars: id 378151 gpus 8 mparams
167: Run vars: id 378151 gpus 8 mparams
166: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
166: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
209: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
209: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
209: son --seed=28019'
209: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
166: son --seed=28019'
166: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
160: Run vars: id 378151 gpus 8 mparams
161: Run vars: id 378151 gpus 8 mparams
162: Run vars: id 378151 gpus 8 mparams
164: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
164: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
164: son --seed=28019'
164: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
165: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
165: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
165: son --seed=28019'
165: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
167: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
167: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
167: son --seed=28019'
167: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
160: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
160: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
160: son --seed=28019'
160: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
162: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
162: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
162: son --seed=28019'
162: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
161: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
161: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
161: son --seed=28019'
161: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
168: Run vars: id 378151 gpus 8 mparams
169: Run vars: id 378151 gpus 8 mparams
170: Run vars: id 378151 gpus 8 mparams
168: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
168: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
168: son --seed=28019'
168: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
172: Run vars: id 378151 gpus 8 mparams
173: Run vars: id 378151 gpus 8 mparams
174: Run vars: id 378151 gpus 8 mparams
171: Run vars: id 378151 gpus 8 mparams
169: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
169: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
169: son --seed=28019'
169: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
175: Run vars: id 378151 gpus 8 mparams
170: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
170: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
170: son --seed=28019'
170: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
172: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
174: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
172: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
172: son --seed=28019'
174: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
174: son --seed=28019'
171: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
172: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
174: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
171: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
171: son --seed=28019'
171: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
173: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
173: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
173: son --seed=28019'
173: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
175: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
175: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
175: son --seed=28019'
175: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 28: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 29: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 24: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 26: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 27: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 30: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 31: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 25: slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
 28: Run vars: id 378151 gpus 8 mparams
 25: Run vars: id 378151 gpus 8 mparams
 24: Run vars: id 378151 gpus 8 mparams
 28: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 28: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.j
 28: son --seed=28019'
 30: Run vars: id 378151 gpus 8 mparams
 28: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 25: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 25: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.j
 25: son --seed=28019'
 25: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 26: Run vars: id 378151 gpus 8 mparams
 24: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 24: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.j
 24: son --seed=28019'
 24: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 31: Run vars: id 378151 gpus 8 mparams
 29: Run vars: id 378151 gpus 8 mparams
 27: Run vars: id 378151 gpus 8 mparams
 30: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 30: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.j
 30: son --seed=28019'
 30: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 26: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 26: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.j
 26: son --seed=28019'
 26: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 31: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 31: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.j
 31: son --seed=28019'
 31: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 29: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 29: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.j
 29: son --seed=28019'
 29: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 27: STARTING TIMING RUN AT 2020-06-23 10:16:17 PM
 27: + eval '    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=20     --learning_rate=1.7e-3     --opt_lamb_beta_1=0.87     --opt_lamb_beta_2=0.97     --warmup_proportion=0.0     --max_steps=990     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.712     --max_samples_termination=6500000     --eval_iter_start_samples=3000000 --eval_iter_samples=500000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --dense_seq_output --fused_mha      --allreduce_post_accumulation --allreduce_post_accumulation_fp16     --gradient_accumulation_steps=1     --log_freq=1     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.j
 27: son --seed=28019'
 27: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 18: num_sockets = 2 num_nodes=8 cores_per_socket=64
 18: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
116: num_sockets = 2 num_nodes=8 cores_per_socket=64
116: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 81: num_sockets = 2 num_nodes=8 cores_per_socket=64
 81: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
208: num_sockets = 2 num_nodes=8 cores_per_socket=64
208: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 12: num_sockets = 2 num_nodes=8 cores_per_socket=64
 12: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
239: num_sockets = 2 num_nodes=8 cores_per_socket=64
239: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 74: num_sockets = 2 num_nodes=8 cores_per_socket=64
 74: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
250: num_sockets = 2 num_nodes=8 cores_per_socket=64
250: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
121: num_sockets = 2 num_nodes=8 cores_per_socket=64
121: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
187: num_sockets = 2 num_nodes=8 cores_per_socket=64
187: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
232: num_sockets = 2 num_nodes=8 cores_per_socket=64
 32: num_sockets = 2 num_nodes=8 cores_per_socket=64
232: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 32: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
233: num_sockets = 2 num_nodes=8 cores_per_socket=64
233: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
252: num_sockets = 2 num_nodes=8 cores_per_socket=64
252: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 77: num_sockets = 2 num_nodes=8 cores_per_socket=64
 77: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
216: num_sockets = 2 num_nodes=8 cores_per_socket=64
248: num_sockets = 2 num_nodes=8 cores_per_socket=64
216: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
248: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
220: num_sockets = 2 num_nodes=8 cores_per_socket=64
220: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 64: num_sockets = 2 num_nodes=8 cores_per_socket=64
188: num_sockets = 2 num_nodes=8 cores_per_socket=64
 64: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
188: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
132: num_sockets = 2 num_nodes=8 cores_per_socket=64
132: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 84: num_sockets = 2 num_nodes=8 cores_per_socket=64
 84: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
186: num_sockets = 2 num_nodes=8 cores_per_socket=64
186: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
247: num_sockets = 2 num_nodes=8 cores_per_socket=64
247: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
236: num_sockets = 2 num_nodes=8 cores_per_socket=64
236: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
253: num_sockets = 2 num_nodes=8 cores_per_socket=64
253: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 73: num_sockets = 2 num_nodes=8 cores_per_socket=64
 73: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
122: num_sockets = 2 num_nodes=8 cores_per_socket=64
122: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
243: num_sockets = 2 num_nodes=8 cores_per_socket=64
243: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 72: num_sockets = 2 num_nodes=8 cores_per_socket=64
 76: num_sockets = 2 num_nodes=8 cores_per_socket=64
 75: num_sockets = 2 num_nodes=8 cores_per_socket=64
 72: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 78: num_sockets = 2 num_nodes=8 cores_per_socket=64
 79: num_sockets = 2 num_nodes=8 cores_per_socket=64
133: num_sockets = 2 num_nodes=8 cores_per_socket=64
130: num_sockets = 2 num_nodes=8 cores_per_socket=64
 76: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 78: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 75: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
133: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 79: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
130: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 87: num_sockets = 2 num_nodes=8 cores_per_socket=64
 87: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
  0: num_sockets = 2 num_nodes=8 cores_per_socket=64
  0: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 83: num_sockets = 2 num_nodes=8 cores_per_socket=64
102: num_sockets = 2 num_nodes=8 cores_per_socket=64
 83: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
  9: num_sockets = 2 num_nodes=8 cores_per_socket=64
102: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
150: num_sockets = 2 num_nodes=8 cores_per_socket=64
  9: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
150: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
119: num_sockets = 2 num_nodes=8 cores_per_socket=64
 80: num_sockets = 2 num_nodes=8 cores_per_socket=64
104: num_sockets = 2 num_nodes=8 cores_per_socket=64
119: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 80: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
104: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 13: num_sockets = 2 num_nodes=8 cores_per_socket=64
  7: num_sockets = 2 num_nodes=8 cores_per_socket=64
 13: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
  7: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
242: num_sockets = 2 num_nodes=8 cores_per_socket=64
242: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 55: num_sockets = 2 num_nodes=8 cores_per_socket=64
 55: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
118: num_sockets = 2 num_nodes=8 cores_per_socket=64
118: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
  3: num_sockets = 2 num_nodes=8 cores_per_socket=64
 15: num_sockets = 2 num_nodes=8 cores_per_socket=64
  3: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 15: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
112: num_sockets = 2 num_nodes=8 cores_per_socket=64
112: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 17: num_sockets = 2 num_nodes=8 cores_per_socket=64
 17: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
157: num_sockets = 2 num_nodes=8 cores_per_socket=64
157: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 23: num_sockets = 2 num_nodes=8 cores_per_socket=64
  4: num_sockets = 2 num_nodes=8 cores_per_socket=64
152: num_sockets = 2 num_nodes=8 cores_per_socket=64
 23: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 60: num_sockets = 2 num_nodes=8 cores_per_socket=64
  4: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
152: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 34: num_sockets = 2 num_nodes=8 cores_per_socket=64
176: num_sockets = 2 num_nodes=8 cores_per_socket=64
 60: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 34: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
176: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 54: num_sockets = 2 num_nodes=8 cores_per_socket=64
 54: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
182: num_sockets = 2 num_nodes=8 cores_per_socket=64
182: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
192: num_sockets = 2 num_nodes=8 cores_per_socket=64
 56: num_sockets = 2 num_nodes=8 cores_per_socket=64
155: num_sockets = 2 num_nodes=8 cores_per_socket=64
192: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 56: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
155: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
218: num_sockets = 2 num_nodes=8 cores_per_socket=64
163: num_sockets = 2 num_nodes=8 cores_per_socket=64
218: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
159: num_sockets = 2 num_nodes=8 cores_per_socket=64
163: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
159: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
178: num_sockets = 2 num_nodes=8 cores_per_socket=64
198: num_sockets = 2 num_nodes=8 cores_per_socket=64
178: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
198: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
147: num_sockets = 2 num_nodes=8 cores_per_socket=64
147: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 40: num_sockets = 2 num_nodes=8 cores_per_socket=64
203: num_sockets = 2 num_nodes=8 cores_per_socket=64
 40: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
203: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
128: num_sockets = 2 num_nodes=8 cores_per_socket=64
128: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
249: num_sockets = 2 num_nodes=8 cores_per_socket=64
221: num_sockets = 2 num_nodes=8 cores_per_socket=64
249: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
221: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 65: num_sockets = 2 num_nodes=8 cores_per_socket=64
151: num_sockets = 2 num_nodes=8 cores_per_socket=64
 65: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
151: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 14: num_sockets = 2 num_nodes=8 cores_per_socket=64
 14: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
251: num_sockets = 2 num_nodes=8 cores_per_socket=64
254: num_sockets = 2 num_nodes=8 cores_per_socket=64
201: num_sockets = 2 num_nodes=8 cores_per_socket=64
120: num_sockets = 2 num_nodes=8 cores_per_socket=64
255: num_sockets = 2 num_nodes=8 cores_per_socket=64
124: num_sockets = 2 num_nodes=8 cores_per_socket=64
254: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
251: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
110: num_sockets = 2 num_nodes=8 cores_per_socket=64
201: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
120: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
222: num_sockets = 2 num_nodes=8 cores_per_socket=64
124: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
110: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
222: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
217: num_sockets = 2 num_nodes=8 cores_per_socket=64
246: num_sockets = 2 num_nodes=8 cores_per_socket=64
223: num_sockets = 2 num_nodes=8 cores_per_socket=64
219: num_sockets = 2 num_nodes=8 cores_per_socket=64
255: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
246: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
223: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
217: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
219: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
145: num_sockets = 2 num_nodes=8 cores_per_socket=64
145: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 33: num_sockets = 2 num_nodes=8 cores_per_socket=64
 33: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
215: num_sockets = 2 num_nodes=8 cores_per_socket=64
 85: num_sockets = 2 num_nodes=8 cores_per_socket=64
235: num_sockets = 2 num_nodes=8 cores_per_socket=64
215: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 85: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
235: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 28: num_sockets = 2 num_nodes=8 cores_per_socket=64
 35: num_sockets = 2 num_nodes=8 cores_per_socket=64
237: num_sockets = 2 num_nodes=8 cores_per_socket=64
234: num_sockets = 2 num_nodes=8 cores_per_socket=64
 35: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 28: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 86: num_sockets = 2 num_nodes=8 cores_per_socket=64
238: num_sockets = 2 num_nodes=8 cores_per_socket=64
237: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 82: num_sockets = 2 num_nodes=8 cores_per_socket=64
115: num_sockets = 2 num_nodes=8 cores_per_socket=64
234: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 86: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
238: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 93: num_sockets = 2 num_nodes=8 cores_per_socket=64
  8: num_sockets = 2 num_nodes=8 cores_per_socket=64
115: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 82: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 10: num_sockets = 2 num_nodes=8 cores_per_socket=64
 93: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
  8: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 99: num_sockets = 2 num_nodes=8 cores_per_socket=64
 11: num_sockets = 2 num_nodes=8 cores_per_socket=64
 10: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
127: num_sockets = 2 num_nodes=8 cores_per_socket=64
 99: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 11: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
125: num_sockets = 2 num_nodes=8 cores_per_socket=64
127: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
125: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
123: num_sockets = 2 num_nodes=8 cores_per_socket=64
126: num_sockets = 2 num_nodes=8 cores_per_socket=64
207: num_sockets = 2 num_nodes=8 cores_per_socket=64
109: num_sockets = 2 num_nodes=8 cores_per_socket=64
123: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 44: num_sockets = 2 num_nodes=8 cores_per_socket=64
207: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
109: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
126: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 44: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
114: num_sockets = 2 num_nodes=8 cores_per_socket=64
114: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
199: num_sockets = 2 num_nodes=8 cores_per_socket=64
199: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
241: num_sockets = 2 num_nodes=8 cores_per_socket=64
241: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
240: num_sockets = 2 num_nodes=8 cores_per_socket=64
165: num_sockets = 2 num_nodes=8 cores_per_socket=64
245: num_sockets = 2 num_nodes=8 cores_per_socket=64
 91: num_sockets = 2 num_nodes=8 cores_per_socket=64
117: num_sockets = 2 num_nodes=8 cores_per_socket=64
240: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
165: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
244: num_sockets = 2 num_nodes=8 cores_per_socket=64
245: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 91: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
113: num_sockets = 2 num_nodes=8 cores_per_socket=64
117: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
244: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
113: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
166: num_sockets = 2 num_nodes=8 cores_per_socket=64
166: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 94: num_sockets = 2 num_nodes=8 cores_per_socket=64
141: num_sockets = 2 num_nodes=8 cores_per_socket=64
 94: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
141: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
  6: num_sockets = 2 num_nodes=8 cores_per_socket=64
170: num_sockets = 2 num_nodes=8 cores_per_socket=64
148: num_sockets = 2 num_nodes=8 cores_per_socket=64
  6: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
170: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
148: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 96: num_sockets = 2 num_nodes=8 cores_per_socket=64
  1: num_sockets = 2 num_nodes=8 cores_per_socket=64
  2: num_sockets = 2 num_nodes=8 cores_per_socket=64
 96: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
  5: num_sockets = 2 num_nodes=8 cores_per_socket=64
  1: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
164: num_sockets = 2 num_nodes=8 cores_per_socket=64
164: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
  5: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
140: num_sockets = 2 num_nodes=8 cores_per_socket=64
140: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
174: num_sockets = 2 num_nodes=8 cores_per_socket=64
 42: num_sockets = 2 num_nodes=8 cores_per_socket=64
 97: num_sockets = 2 num_nodes=8 cores_per_socket=64
174: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 42: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 97: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 24: num_sockets = 2 num_nodes=8 cores_per_socket=64
134: num_sockets = 2 num_nodes=8 cores_per_socket=64
 24: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 41: num_sockets = 2 num_nodes=8 cores_per_socket=64
134: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
181: num_sockets = 2 num_nodes=8 cores_per_socket=64
 41: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
181: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 37: num_sockets = 2 num_nodes=8 cores_per_socket=64
 37: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
135: num_sockets = 2 num_nodes=8 cores_per_socket=64
 48: num_sockets = 2 num_nodes=8 cores_per_socket=64
 26: num_sockets = 2 num_nodes=8 cores_per_socket=64
 48: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
135: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 26: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
129: num_sockets = 2 num_nodes=8 cores_per_socket=64
 50: num_sockets = 2 num_nodes=8 cores_per_socket=64
129: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 50: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
131: num_sockets = 2 num_nodes=8 cores_per_socket=64
131: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 20: num_sockets = 2 num_nodes=8 cores_per_socket=64
 20: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
209: num_sockets = 2 num_nodes=8 cores_per_socket=64
209: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
146: num_sockets = 2 num_nodes=8 cores_per_socket=64
185: num_sockets = 2 num_nodes=8 cores_per_socket=64
146: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
185: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
184: num_sockets = 2 num_nodes=8 cores_per_socket=64
 22: num_sockets = 2 num_nodes=8 cores_per_socket=64
190: num_sockets = 2 num_nodes=8 cores_per_socket=64
184: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
189: num_sockets = 2 num_nodes=8 cores_per_socket=64
 22: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
191: num_sockets = 2 num_nodes=8 cores_per_socket=64
144: num_sockets = 2 num_nodes=8 cores_per_socket=64
190: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
189: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
191: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
156: num_sockets = 2 num_nodes=8 cores_per_socket=64
144: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
156: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
149: num_sockets = 2 num_nodes=8 cores_per_socket=64
149: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
171: num_sockets = 2 num_nodes=8 cores_per_socket=64
171: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
  2: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
210: num_sockets = 2 num_nodes=8 cores_per_socket=64
211: num_sockets = 2 num_nodes=8 cores_per_socket=64
212: num_sockets = 2 num_nodes=8 cores_per_socket=64
214: num_sockets = 2 num_nodes=8 cores_per_socket=64
213: num_sockets = 2 num_nodes=8 cores_per_socket=64
210: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
211: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
212: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
214: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 16: num_sockets = 2 num_nodes=8 cores_per_socket=64
213: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 19: num_sockets = 2 num_nodes=8 cores_per_socket=64
 21: num_sockets = 2 num_nodes=8 cores_per_socket=64
 16: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 21: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 19: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
154: num_sockets = 2 num_nodes=8 cores_per_socket=64
 38: num_sockets = 2 num_nodes=8 cores_per_socket=64
 36: num_sockets = 2 num_nodes=8 cores_per_socket=64
154: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 38: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 39: num_sockets = 2 num_nodes=8 cores_per_socket=64
 36: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
158: num_sockets = 2 num_nodes=8 cores_per_socket=64
 39: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
153: num_sockets = 2 num_nodes=8 cores_per_socket=64
158: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
153: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 61: num_sockets = 2 num_nodes=8 cores_per_socket=64
 61: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 45: num_sockets = 2 num_nodes=8 cores_per_socket=64
 45: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 52: num_sockets = 2 num_nodes=8 cores_per_socket=64
 49: num_sockets = 2 num_nodes=8 cores_per_socket=64
 51: num_sockets = 2 num_nodes=8 cores_per_socket=64
 53: num_sockets = 2 num_nodes=8 cores_per_socket=64
 52: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 49: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 51: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 53: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
183: num_sockets = 2 num_nodes=8 cores_per_socket=64
179: num_sockets = 2 num_nodes=8 cores_per_socket=64
183: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
179: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
180: num_sockets = 2 num_nodes=8 cores_per_socket=64
177: num_sockets = 2 num_nodes=8 cores_per_socket=64
180: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
177: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 30: num_sockets = 2 num_nodes=8 cores_per_socket=64
 30: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
111: num_sockets = 2 num_nodes=8 cores_per_socket=64
111: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 59: num_sockets = 2 num_nodes=8 cores_per_socket=64
 89: num_sockets = 2 num_nodes=8 cores_per_socket=64
 59: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 89: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
205: num_sockets = 2 num_nodes=8 cores_per_socket=64
205: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 62: num_sockets = 2 num_nodes=8 cores_per_socket=64
206: num_sockets = 2 num_nodes=8 cores_per_socket=64
202: num_sockets = 2 num_nodes=8 cores_per_socket=64
200: num_sockets = 2 num_nodes=8 cores_per_socket=64
204: num_sockets = 2 num_nodes=8 cores_per_socket=64
 58: num_sockets = 2 num_nodes=8 cores_per_socket=64
 62: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 63: num_sockets = 2 num_nodes=8 cores_per_socket=64
 57: num_sockets = 2 num_nodes=8 cores_per_socket=64
206: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
202: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
200: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 31: num_sockets = 2 num_nodes=8 cores_per_socket=64
 58: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
204: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 63: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 57: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 25: num_sockets = 2 num_nodes=8 cores_per_socket=64
 31: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 25: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 27: num_sockets = 2 num_nodes=8 cores_per_socket=64
 29: num_sockets = 2 num_nodes=8 cores_per_socket=64
160: num_sockets = 2 num_nodes=8 cores_per_socket=64
 29: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 27: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
160: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 67: num_sockets = 2 num_nodes=8 cores_per_socket=64
 67: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 98: num_sockets = 2 num_nodes=8 cores_per_socket=64
 98: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
231: num_sockets = 2 num_nodes=8 cores_per_socket=64
105: num_sockets = 2 num_nodes=8 cores_per_socket=64
231: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
105: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 71: num_sockets = 2 num_nodes=8 cores_per_socket=64
 71: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
107: num_sockets = 2 num_nodes=8 cores_per_socket=64
106: num_sockets = 2 num_nodes=8 cores_per_socket=64
108: num_sockets = 2 num_nodes=8 cores_per_socket=64
107: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
106: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
108: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
162: num_sockets = 2 num_nodes=8 cores_per_socket=64
103: num_sockets = 2 num_nodes=8 cores_per_socket=64
100: num_sockets = 2 num_nodes=8 cores_per_socket=64
167: num_sockets = 2 num_nodes=8 cores_per_socket=64
161: num_sockets = 2 num_nodes=8 cores_per_socket=64
103: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
162: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
100: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
101: num_sockets = 2 num_nodes=8 cores_per_socket=64
167: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 66: num_sockets = 2 num_nodes=8 cores_per_socket=64
 46: num_sockets = 2 num_nodes=8 cores_per_socket=64
 43: num_sockets = 2 num_nodes=8 cores_per_socket=64
 68: num_sockets = 2 num_nodes=8 cores_per_socket=64
 47: num_sockets = 2 num_nodes=8 cores_per_socket=64
 69: num_sockets = 2 num_nodes=8 cores_per_socket=64
101: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
161: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 46: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 66: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 68: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 43: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 69: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 47: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 88: num_sockets = 2 num_nodes=8 cores_per_socket=64
 70: num_sockets = 2 num_nodes=8 cores_per_socket=64
 88: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 70: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 95: num_sockets = 2 num_nodes=8 cores_per_socket=64
 90: num_sockets = 2 num_nodes=8 cores_per_socket=64
 92: num_sockets = 2 num_nodes=8 cores_per_socket=64
 95: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 92: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 90: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
137: num_sockets = 2 num_nodes=8 cores_per_socket=64
137: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
195: num_sockets = 2 num_nodes=8 cores_per_socket=64
195: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
197: num_sockets = 2 num_nodes=8 cores_per_socket=64
197: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
194: num_sockets = 2 num_nodes=8 cores_per_socket=64
196: num_sockets = 2 num_nodes=8 cores_per_socket=64
193: num_sockets = 2 num_nodes=8 cores_per_socket=64
194: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
196: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
193: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
173: num_sockets = 2 num_nodes=8 cores_per_socket=64
173: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
172: num_sockets = 2 num_nodes=8 cores_per_socket=64
224: num_sockets = 2 num_nodes=8 cores_per_socket=64
175: num_sockets = 2 num_nodes=8 cores_per_socket=64
172: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
224: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
175: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
168: num_sockets = 2 num_nodes=8 cores_per_socket=64
169: num_sockets = 2 num_nodes=8 cores_per_socket=64
168: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
169: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
143: num_sockets = 2 num_nodes=8 cores_per_socket=64
143: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
139: num_sockets = 2 num_nodes=8 cores_per_socket=64
138: num_sockets = 2 num_nodes=8 cores_per_socket=64
136: num_sockets = 2 num_nodes=8 cores_per_socket=64
142: num_sockets = 2 num_nodes=8 cores_per_socket=64
139: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
138: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
142: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
136: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
229: num_sockets = 2 num_nodes=8 cores_per_socket=64
229: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
227: num_sockets = 2 num_nodes=8 cores_per_socket=64
225: num_sockets = 2 num_nodes=8 cores_per_socket=64
227: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
225: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
226: num_sockets = 2 num_nodes=8 cores_per_socket=64
230: num_sockets = 2 num_nodes=8 cores_per_socket=64
228: num_sockets = 2 num_nodes=8 cores_per_socket=64
226: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
230: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
228: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=20 --learning_rate=1.7e-3 --opt_lamb_beta_1=0.87 --opt_lamb_beta_2=0.97 --warmup_proportion=0.0 --max_steps=990 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.712 --max_samples_termination=6500000 --eval_iter_start_samples=3000000 --eval_iter_samples=500000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --dense_seq_output --fused_mha --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --gradient_accumulation_steps=1 --log_freq=1 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --seed=28019
 18: :::MLLOG {"namespace": "", "time_ms": 1592975778010, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
116: :::MLLOG {"namespace": "", "time_ms": 1592975778058, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 12: :::MLLOG {"namespace": "", "time_ms": 1592975778076, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
208: :::MLLOG {"namespace": "", "time_ms": 1592975778112, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 81: :::MLLOG {"namespace": "", "time_ms": 1592975778137, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 74: :::MLLOG {"namespace": "", "time_ms": 1592975778175, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
239: :::MLLOG {"namespace": "", "time_ms": 1592975778176, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
121: :::MLLOG {"namespace": "", "time_ms": 1592975778213, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
250: :::MLLOG {"namespace": "", "time_ms": 1592975778213, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
187: :::MLLOG {"namespace": "", "time_ms": 1592975778244, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 32: :::MLLOG {"namespace": "", "time_ms": 1592975778262, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
232: :::MLLOG {"namespace": "", "time_ms": 1592975778282, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
132: :::MLLOG {"namespace": "", "time_ms": 1592975778283, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
233: :::MLLOG {"namespace": "", "time_ms": 1592975778290, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
216: :::MLLOG {"namespace": "", "time_ms": 1592975778294, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
252: :::MLLOG {"namespace": "", "time_ms": 1592975778294, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 84: :::MLLOG {"namespace": "", "time_ms": 1592975778296, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
188: :::MLLOG {"namespace": "", "time_ms": 1592975778298, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 64: :::MLLOG {"namespace": "", "time_ms": 1592975778299, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
186: :::MLLOG {"namespace": "", "time_ms": 1592975778303, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 77: :::MLLOG {"namespace": "", "time_ms": 1592975778304, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
220: :::MLLOG {"namespace": "", "time_ms": 1592975778306, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
247: :::MLLOG {"namespace": "", "time_ms": 1592975778310, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 13: :::MLLOG {"namespace": "", "time_ms": 1592975778318, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
236: :::MLLOG {"namespace": "", "time_ms": 1592975778319, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
133: :::MLLOG {"namespace": "", "time_ms": 1592975778322, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
102: :::MLLOG {"namespace": "", "time_ms": 1592975778324, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
  0: :::MLLOG {"namespace": "", "time_ms": 1592975778328, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
150: :::MLLOG {"namespace": "", "time_ms": 1592975778328, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
248: :::MLLOG {"namespace": "", "time_ms": 1592975778328, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
122: :::MLLOG {"namespace": "", "time_ms": 1592975778329, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 87: :::MLLOG {"namespace": "", "time_ms": 1592975778331, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
243: :::MLLOG {"namespace": "", "time_ms": 1592975778340, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
104: :::MLLOG {"namespace": "", "time_ms": 1592975778344, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 83: :::MLLOG {"namespace": "", "time_ms": 1592975778347, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 60: :::MLLOG {"namespace": "", "time_ms": 1592975778351, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 17: :::MLLOG {"namespace": "", "time_ms": 1592975778351, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 73: :::MLLOG {"namespace": "", "time_ms": 1592975778348, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
118: :::MLLOG {"namespace": "", "time_ms": 1592975778350, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
242: :::MLLOG {"namespace": "", "time_ms": 1592975778351, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
  7: :::MLLOG {"namespace": "", "time_ms": 1592975778353, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 80: :::MLLOG {"namespace": "", "time_ms": 1592975778356, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 55: :::MLLOG {"namespace": "", "time_ms": 1592975778357, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
253: :::MLLOG {"namespace": "", "time_ms": 1592975778359, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
  3: :::MLLOG {"namespace": "", "time_ms": 1592975778361, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
203: :::MLLOG {"namespace": "", "time_ms": 1592975778362, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
  9: :::MLLOG {"namespace": "", "time_ms": 1592975778361, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 23: :::MLLOG {"namespace": "", "time_ms": 1592975778365, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
157: :::MLLOG {"namespace": "", "time_ms": 1592975778364, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
130: :::MLLOG {"namespace": "", "time_ms": 1592975778366, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 75: :::MLLOG {"namespace": "", "time_ms": 1592975778364, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 79: :::MLLOG {"namespace": "", "time_ms": 1592975778364, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 76: :::MLLOG {"namespace": "", "time_ms": 1592975778365, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 54: :::MLLOG {"namespace": "", "time_ms": 1592975778368, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 15: :::MLLOG {"namespace": "", "time_ms": 1592975778377, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
112: :::MLLOG {"namespace": "", "time_ms": 1592975778380, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 78: :::MLLOG {"namespace": "", "time_ms": 1592975778379, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
119: :::MLLOG {"namespace": "", "time_ms": 1592975778381, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
163: :::MLLOG {"namespace": "", "time_ms": 1592975778382, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 72: :::MLLOG {"namespace": "", "time_ms": 1592975778384, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
218: :::MLLOG {"namespace": "", "time_ms": 1592975778386, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 14: :::MLLOG {"namespace": "", "time_ms": 1592975778388, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
  4: :::MLLOG {"namespace": "", "time_ms": 1592975778390, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
201: :::MLLOG {"namespace": "", "time_ms": 1592975778390, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 34: :::MLLOG {"namespace": "", "time_ms": 1592975778391, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
192: :::MLLOG {"namespace": "", "time_ms": 1592975778389, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
198: :::MLLOG {"namespace": "", "time_ms": 1592975778391, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
221: :::MLLOG {"namespace": "", "time_ms": 1592975778394, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
110: :::MLLOG {"namespace": "", "time_ms": 1592975778396, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
222: :::MLLOG {"namespace": "", "time_ms": 1592975778397, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
151: :::MLLOG {"namespace": "", "time_ms": 1592975778401, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
159: :::MLLOG {"namespace": "", "time_ms": 1592975778401, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
155: :::MLLOG {"namespace": "", "time_ms": 1592975778401, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 40: :::MLLOG {"namespace": "", "time_ms": 1592975778407, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
178: :::MLLOG {"namespace": "", "time_ms": 1592975778410, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 65: :::MLLOG {"namespace": "", "time_ms": 1592975778411, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
152: :::MLLOG {"namespace": "", "time_ms": 1592975778412, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
219: :::MLLOG {"namespace": "", "time_ms": 1592975778415, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
182: :::MLLOG {"namespace": "", "time_ms": 1592975778416, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 33: :::MLLOG {"namespace": "", "time_ms": 1592975778419, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 35: :::MLLOG {"namespace": "", "time_ms": 1592975778422, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
249: :::MLLOG {"namespace": "", "time_ms": 1592975778422, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
246: :::MLLOG {"namespace": "", "time_ms": 1592975778423, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 93: :::MLLOG {"namespace": "", "time_ms": 1592975778426, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 99: :::MLLOG {"namespace": "", "time_ms": 1592975778429, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 44: :::MLLOG {"namespace": "", "time_ms": 1592975778432, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
176: :::MLLOG {"namespace": "", "time_ms": 1592975778429, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
124: :::MLLOG {"namespace": "", "time_ms": 1592975778430, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 28: :::MLLOG {"namespace": "", "time_ms": 1592975778433, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
109: :::MLLOG {"namespace": "", "time_ms": 1592975778434, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
255: :::MLLOG {"namespace": "", "time_ms": 1592975778432, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
217: :::MLLOG {"namespace": "", "time_ms": 1592975778437, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
254: :::MLLOG {"namespace": "", "time_ms": 1592975778437, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
251: :::MLLOG {"namespace": "", "time_ms": 1592975778437, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
128: :::MLLOG {"namespace": "", "time_ms": 1592975778440, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
147: :::MLLOG {"namespace": "", "time_ms": 1592975778440, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 86: :::MLLOG {"namespace": "", "time_ms": 1592975778442, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
  8: :::MLLOG {"namespace": "", "time_ms": 1592975778442, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
145: :::MLLOG {"namespace": "", "time_ms": 1592975778441, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
238: :::MLLOG {"namespace": "", "time_ms": 1592975778443, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
120: :::MLLOG {"namespace": "", "time_ms": 1592975778442, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 10: :::MLLOG {"namespace": "", "time_ms": 1592975778444, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 11: :::MLLOG {"namespace": "", "time_ms": 1592975778446, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
199: :::MLLOG {"namespace": "", "time_ms": 1592975778450, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
114: :::MLLOG {"namespace": "", "time_ms": 1592975778448, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 56: :::MLLOG {"namespace": "", "time_ms": 1592975778452, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 91: :::MLLOG {"namespace": "", "time_ms": 1592975778454, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
223: :::MLLOG {"namespace": "", "time_ms": 1592975778457, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
215: :::MLLOG {"namespace": "", "time_ms": 1592975778455, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
115: :::MLLOG {"namespace": "", "time_ms": 1592975778452, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
235: :::MLLOG {"namespace": "", "time_ms": 1592975778455, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
165: :::MLLOG {"namespace": "", "time_ms": 1592975778457, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
166: :::MLLOG {"namespace": "", "time_ms": 1592975778457, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
234: :::MLLOG {"namespace": "", "time_ms": 1592975778457, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 85: :::MLLOG {"namespace": "", "time_ms": 1592975778461, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
237: :::MLLOG {"namespace": "", "time_ms": 1592975778462, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
127: :::MLLOG {"namespace": "", "time_ms": 1592975778461, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
125: :::MLLOG {"namespace": "", "time_ms": 1592975778463, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
117: :::MLLOG {"namespace": "", "time_ms": 1592975778464, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 20: :::MLLOG {"namespace": "", "time_ms": 1592975778472, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
164: :::MLLOG {"namespace": "", "time_ms": 1592975778467, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
  2: :::MLLOG {"namespace": "", "time_ms": 1592975778472, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
126: :::MLLOG {"namespace": "", "time_ms": 1592975778469, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 94: :::MLLOG {"namespace": "", "time_ms": 1592975778471, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
123: :::MLLOG {"namespace": "", "time_ms": 1592975778468, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
170: :::MLLOG {"namespace": "", "time_ms": 1592975778472, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 26: :::MLLOG {"namespace": "", "time_ms": 1592975778474, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
241: :::MLLOG {"namespace": "", "time_ms": 1592975778474, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 24: :::MLLOG {"namespace": "", "time_ms": 1592975778477, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
148: :::MLLOG {"namespace": "", "time_ms": 1592975778475, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
134: :::MLLOG {"namespace": "", "time_ms": 1592975778476, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
141: :::MLLOG {"namespace": "", "time_ms": 1592975778475, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 82: :::MLLOG {"namespace": "", "time_ms": 1592975778480, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
113: :::MLLOG {"namespace": "", "time_ms": 1592975778478, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 42: :::MLLOG {"namespace": "", "time_ms": 1592975778479, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
  5: :::MLLOG {"namespace": "", "time_ms": 1592975778480, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 48: :::MLLOG {"namespace": "", "time_ms": 1592975778479, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 37: :::MLLOG {"namespace": "", "time_ms": 1592975778482, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
  6: :::MLLOG {"namespace": "", "time_ms": 1592975778484, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
245: :::MLLOG {"namespace": "", "time_ms": 1592975778483, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
174: :::MLLOG {"namespace": "", "time_ms": 1592975778484, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
244: :::MLLOG {"namespace": "", "time_ms": 1592975778486, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 97: :::MLLOG {"namespace": "", "time_ms": 1592975778487, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 96: :::MLLOG {"namespace": "", "time_ms": 1592975778487, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
  1: :::MLLOG {"namespace": "", "time_ms": 1592975778488, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 50: :::MLLOG {"namespace": "", "time_ms": 1592975778489, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 41: :::MLLOG {"namespace": "", "time_ms": 1592975778492, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
140: :::MLLOG {"namespace": "", "time_ms": 1592975778497, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
129: :::MLLOG {"namespace": "", "time_ms": 1592975778497, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
240: :::MLLOG {"namespace": "", "time_ms": 1592975778501, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
181: :::MLLOG {"namespace": "", "time_ms": 1592975778502, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
207: :::MLLOG {"namespace": "", "time_ms": 1592975778506, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 61: :::MLLOG {"namespace": "", "time_ms": 1592975778507, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
171: :::MLLOG {"namespace": "", "time_ms": 1592975778504, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
156: :::MLLOG {"namespace": "", "time_ms": 1592975778506, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
131: :::MLLOG {"namespace": "", "time_ms": 1592975778506, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
185: :::MLLOG {"namespace": "", "time_ms": 1592975778509, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
146: :::MLLOG {"namespace": "", "time_ms": 1592975778510, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 36: :::MLLOG {"namespace": "", "time_ms": 1592975778514, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
135: :::MLLOG {"namespace": "", "time_ms": 1592975778510, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 19: :::MLLOG {"namespace": "", "time_ms": 1592975778515, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 38: :::MLLOG {"namespace": "", "time_ms": 1592975778518, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 22: :::MLLOG {"namespace": "", "time_ms": 1592975778518, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
191: :::MLLOG {"namespace": "", "time_ms": 1592975778521, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
184: :::MLLOG {"namespace": "", "time_ms": 1592975778521, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 21: :::MLLOG {"namespace": "", "time_ms": 1592975778526, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
154: :::MLLOG {"namespace": "", "time_ms": 1592975778526, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
144: :::MLLOG {"namespace": "", "time_ms": 1592975778532, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 39: :::MLLOG {"namespace": "", "time_ms": 1592975778536, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
149: :::MLLOG {"namespace": "", "time_ms": 1592975778533, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 16: :::MLLOG {"namespace": "", "time_ms": 1592975778536, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
189: :::MLLOG {"namespace": "", "time_ms": 1592975778536, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
212: :::MLLOG {"namespace": "", "time_ms": 1592975778539, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
213: :::MLLOG {"namespace": "", "time_ms": 1592975778538, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 45: :::MLLOG {"namespace": "", "time_ms": 1592975778550, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
210: :::MLLOG {"namespace": "", "time_ms": 1592975778553, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
153: :::MLLOG {"namespace": "", "time_ms": 1592975778554, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 52: :::MLLOG {"namespace": "", "time_ms": 1592975778556, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
111: :::MLLOG {"namespace": "", "time_ms": 1592975778557, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
158: :::MLLOG {"namespace": "", "time_ms": 1592975778557, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
214: :::MLLOG {"namespace": "", "time_ms": 1592975778562, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 51: :::MLLOG {"namespace": "", "time_ms": 1592975778563, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 59: :::MLLOG {"namespace": "", "time_ms": 1592975778566, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
206: :::MLLOG {"namespace": "", "time_ms": 1592975778571, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
180: :::MLLOG {"namespace": "", "time_ms": 1592975778571, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
183: :::MLLOG {"namespace": "", "time_ms": 1592975778572, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 30: :::MLLOG {"namespace": "", "time_ms": 1592975778574, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
211: :::MLLOG {"namespace": "", "time_ms": 1592975778571, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
204: :::MLLOG {"namespace": "", "time_ms": 1592975778576, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
231: :::MLLOG {"namespace": "", "time_ms": 1592975778578, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
200: :::MLLOG {"namespace": "", "time_ms": 1592975778580, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
202: :::MLLOG {"namespace": "", "time_ms": 1592975778581, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 62: :::MLLOG {"namespace": "", "time_ms": 1592975778583, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 63: :::MLLOG {"namespace": "", "time_ms": 1592975778583, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
205: :::MLLOG {"namespace": "", "time_ms": 1592975778584, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 57: :::MLLOG {"namespace": "", "time_ms": 1592975778586, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 58: :::MLLOG {"namespace": "", "time_ms": 1592975778586, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
179: :::MLLOG {"namespace": "", "time_ms": 1592975778586, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 49: :::MLLOG {"namespace": "", "time_ms": 1592975778589, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 71: :::MLLOG {"namespace": "", "time_ms": 1592975778595, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
177: :::MLLOG {"namespace": "", "time_ms": 1592975778594, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 53: :::MLLOG {"namespace": "", "time_ms": 1592975778596, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 46: :::MLLOG {"namespace": "", "time_ms": 1592975778601, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 47: :::MLLOG {"namespace": "", "time_ms": 1592975778602, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
108: :::MLLOG {"namespace": "", "time_ms": 1592975778601, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
190: :::MLLOG {"namespace": "", "time_ms": 1592975778604, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 89: :::MLLOG {"namespace": "", "time_ms": 1592975778604, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
209: :::MLLOG {"namespace": "", "time_ms": 1592975778603, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
105: :::MLLOG {"namespace": "", "time_ms": 1592975778603, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 68: :::MLLOG {"namespace": "", "time_ms": 1592975778607, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 98: :::MLLOG {"namespace": "", "time_ms": 1592975778607, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 31: :::MLLOG {"namespace": "", "time_ms": 1592975778610, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
167: :::MLLOG {"namespace": "", "time_ms": 1592975778611, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 29: :::MLLOG {"namespace": "", "time_ms": 1592975778617, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 43: :::MLLOG {"namespace": "", "time_ms": 1592975778621, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 25: :::MLLOG {"namespace": "", "time_ms": 1592975778619, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 27: :::MLLOG {"namespace": "", "time_ms": 1592975778621, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
100: :::MLLOG {"namespace": "", "time_ms": 1592975778622, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 69: :::MLLOG {"namespace": "", "time_ms": 1592975778621, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
101: :::MLLOG {"namespace": "", "time_ms": 1592975778624, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
162: :::MLLOG {"namespace": "", "time_ms": 1592975778627, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
160: :::MLLOG {"namespace": "", "time_ms": 1592975778627, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
195: :::MLLOG {"namespace": "", "time_ms": 1592975778629, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
103: :::MLLOG {"namespace": "", "time_ms": 1592975778632, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 66: :::MLLOG {"namespace": "", "time_ms": 1592975778630, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
106: :::MLLOG {"namespace": "", "time_ms": 1592975778633, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 90: :::MLLOG {"namespace": "", "time_ms": 1592975778637, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
173: :::MLLOG {"namespace": "", "time_ms": 1592975778638, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
161: :::MLLOG {"namespace": "", "time_ms": 1592975778637, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 95: :::MLLOG {"namespace": "", "time_ms": 1592975778644, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
194: :::MLLOG {"namespace": "", "time_ms": 1592975778644, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 92: :::MLLOG {"namespace": "", "time_ms": 1592975778644, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 70: :::MLLOG {"namespace": "", "time_ms": 1592975778646, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
172: :::MLLOG {"namespace": "", "time_ms": 1592975778650, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 88: :::MLLOG {"namespace": "", "time_ms": 1592975778652, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
 67: :::MLLOG {"namespace": "", "time_ms": 1592975778652, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
137: :::MLLOG {"namespace": "", "time_ms": 1592975778655, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
197: :::MLLOG {"namespace": "", "time_ms": 1592975778654, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
196: :::MLLOG {"namespace": "", "time_ms": 1592975778654, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
169: :::MLLOG {"namespace": "", "time_ms": 1592975778665, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
107: :::MLLOG {"namespace": "", "time_ms": 1592975778670, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
224: :::MLLOG {"namespace": "", "time_ms": 1592975778671, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
175: :::MLLOG {"namespace": "", "time_ms": 1592975778677, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
193: :::MLLOG {"namespace": "", "time_ms": 1592975778678, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
229: :::MLLOG {"namespace": "", "time_ms": 1592975778679, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
168: :::MLLOG {"namespace": "", "time_ms": 1592975778682, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
136: :::MLLOG {"namespace": "", "time_ms": 1592975778696, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
143: :::MLLOG {"namespace": "", "time_ms": 1592975778696, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
139: :::MLLOG {"namespace": "", "time_ms": 1592975778707, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
138: :::MLLOG {"namespace": "", "time_ms": 1592975778734, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
142: :::MLLOG {"namespace": "", "time_ms": 1592975778738, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
228: :::MLLOG {"namespace": "", "time_ms": 1592975778738, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
230: :::MLLOG {"namespace": "", "time_ms": 1592975778740, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
226: :::MLLOG {"namespace": "", "time_ms": 1592975778753, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
227: :::MLLOG {"namespace": "", "time_ms": 1592975778756, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
225: :::MLLOG {"namespace": "", "time_ms": 1592975778782, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 657}}
127: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
127: Torch distributed is available.
127: Torch distributed is initialized.
238: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
238: Torch distributed is available.
238: Torch distributed is initialized.
 33: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
 33: Torch distributed is available.
 33: Torch distributed is initialized.
237: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
237: Torch distributed is available.
237: Torch distributed is initialized.
254: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
254: Torch distributed is available.
254: Torch distributed is initialized.
170: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
170: Torch distributed is available.
170: Torch distributed is initialized.
235: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
235: Torch distributed is available.
235: Torch distributed is initialized.
125: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
125: Torch distributed is available.
125: Torch distributed is initialized.
234: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
234: Torch distributed is available.
234: Torch distributed is initialized.
145: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
191: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
145: Torch distributed is available.
145: Torch distributed is initialized.
191: Torch distributed is available.
191: Torch distributed is initialized.
251: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
251: Torch distributed is available.
251: Torch distributed is initialized.
120: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
120: Torch distributed is available.
120: Torch distributed is initialized.
141: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
141: Torch distributed is available.
141: Torch distributed is initialized.
184: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
184: Torch distributed is available.
184: Torch distributed is initialized.
 40: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
 40: Torch distributed is available.
 40: Torch distributed is initialized.
 24: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
 24: Torch distributed is available.
 24: Torch distributed is initialized.
109: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
130: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
109: Torch distributed is available.
109: Torch distributed is initialized.
130: Torch distributed is available.
130: Torch distributed is initialized.
253: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
253: Torch distributed is available.
253: Torch distributed is initialized.
255: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
255: Torch distributed is available.
255: Torch distributed is initialized.
140: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
140: Torch distributed is available.
140: Torch distributed is initialized.
 39: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
 39: Torch distributed is available.
 39: Torch distributed is initialized.
243: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
243: Torch distributed is available.
243: Torch distributed is initialized.
 71: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
 71: Torch distributed is available.
 71: Torch distributed is initialized.
134: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
134: Torch distributed is available.
134: Torch distributed is initialized.
 36: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
 36: Torch distributed is available.
 36: Torch distributed is initialized.
189: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
189: Torch distributed is available.
189: Torch distributed is initialized.
242: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
242: Torch distributed is available.
242: Torch distributed is initialized.
165: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
165: Torch distributed is available.
165: Torch distributed is initialized.
219: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
219: Torch distributed is available.
219: Torch distributed is initialized.
 91: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
 91: Torch distributed is available.
 91: Torch distributed is initialized.
 68: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
 68: Torch distributed is available.
 68: Torch distributed is initialized.
 93: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
 93: Torch distributed is available.
 93: Torch distributed is initialized.
123: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
123: Torch distributed is available.
123: Torch distributed is initialized.
217: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
217: Torch distributed is available.
217: Torch distributed is initialized.
190: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
190: Torch distributed is available.
190: Torch distributed is initialized.
129: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
129: Torch distributed is available.
129: Torch distributed is initialized.
  4: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
  4: Torch distributed is available.
  4: Torch distributed is initialized.
185: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
185: Torch distributed is available.
185: Torch distributed is initialized.
231: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
231: Torch distributed is available.
231: Torch distributed is initialized.
200: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
195: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
200: Torch distributed is available.
200: Torch distributed is initialized.
195: Torch distributed is available.
195: Torch distributed is initialized.
 61: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
 61: Torch distributed is available.
 61: Torch distributed is initialized.
 69: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
 69: Torch distributed is available.
 69: Torch distributed is initialized.
  2: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
 35: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
  2: Torch distributed is available.
  2: Torch distributed is initialized.
 35: Torch distributed is available.
 35: Torch distributed is initialized.
182: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
182: Torch distributed is available.
182: Torch distributed is initialized.
126: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
126: Torch distributed is available.
126: Torch distributed is initialized.
 97: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
 97: Torch distributed is available.
 97: Torch distributed is initialized.
151: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
151: Torch distributed is available.
151: Torch distributed is initialized.
 96: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
 96: Torch distributed is available.
 96: Torch distributed is initialized.
174: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
223: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
174: Torch distributed is available.
174: Torch distributed is initialized.
223: Torch distributed is available.
223: Torch distributed is initialized.
111: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
111: Torch distributed is available.
111: Torch distributed is initialized.
 59: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
 59: Torch distributed is available.
 59: Torch distributed is initialized.
147: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
147: Torch distributed is available.
147: Torch distributed is initialized.
159: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
159: Torch distributed is available.
159: Torch distributed is initialized.
218: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
218: Torch distributed is available.
218: Torch distributed is initialized.
 37: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
 37: Torch distributed is available.
 37: Torch distributed is initialized.
154: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
154: Torch distributed is available.
154: Torch distributed is initialized.
 98: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
 98: Torch distributed is available.
 98: Torch distributed is initialized.
241: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
241: Torch distributed is available.
241: Torch distributed is initialized.
 38: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
 38: Torch distributed is available.
 38: Torch distributed is initialized.
155: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
155: Torch distributed is available.
155: Torch distributed is initialized.
 26: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
176: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
 26: Torch distributed is available.
 26: Torch distributed is initialized.
176: Torch distributed is available.
176: Torch distributed is initialized.
222: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
222: Torch distributed is available.
222: Torch distributed is initialized.
 51: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
 51: Torch distributed is available.
 51: Torch distributed is initialized.
 57: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
 57: Torch distributed is available.
 57: Torch distributed is initialized.
135: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
135: Torch distributed is available.
135: Torch distributed is initialized.
206: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
206: Torch distributed is available.
206: Torch distributed is initialized.
221: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
221: Torch distributed is available.
221: Torch distributed is initialized.
128: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
128: Torch distributed is available.
128: Torch distributed is initialized.
 49: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
 49: Torch distributed is available.
 49: Torch distributed is initialized.
 70: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
 70: Torch distributed is available.
 70: Torch distributed is initialized.
131: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
131: Torch distributed is available.
131: Torch distributed is initialized.
202: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
202: Torch distributed is available.
202: Torch distributed is initialized.
199: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
199: Torch distributed is available.
199: Torch distributed is initialized.
146: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
146: Torch distributed is available.
146: Torch distributed is initialized.
166: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
166: Torch distributed is available.
166: Torch distributed is initialized.
 58: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
 58: Torch distributed is available.
 58: Torch distributed is initialized.
 67: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
 67: Torch distributed is available.
 67: Torch distributed is initialized.
  5: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
  5: Torch distributed is available.
  5: Torch distributed is initialized.
100: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
100: Torch distributed is available.
100: Torch distributed is initialized.
  6: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
 66: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
  6: Torch distributed is available.
  6: Torch distributed is initialized.
 66: Torch distributed is available.
 66: Torch distributed is initialized.
108: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
108: Torch distributed is available.
108: Torch distributed is initialized.
164: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
164: Torch distributed is available.
164: Torch distributed is initialized.
  1: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
  1: Torch distributed is available.
  1: Torch distributed is initialized.
 53: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
 53: Torch distributed is available.
 53: Torch distributed is initialized.
 48: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
 48: Torch distributed is available.
 48: Torch distributed is initialized.
 63: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
 63: Torch distributed is available.
 63: Torch distributed is initialized.
105: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
240: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
105: Torch distributed is available.
105: Torch distributed is initialized.
240: Torch distributed is available.
240: Torch distributed is initialized.
152: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
152: Torch distributed is available.
152: Torch distributed is initialized.
205: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
205: Torch distributed is available.
205: Torch distributed is initialized.
246: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
246: Torch distributed is available.
246: Torch distributed is initialized.
101: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
101: Torch distributed is available.
101: Torch distributed is initialized.
244: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
244: Torch distributed is available.
244: Torch distributed is initialized.
 50: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
 50: Torch distributed is available.
 50: Torch distributed is initialized.
204: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
204: Torch distributed is available.
204: Torch distributed is initialized.
 52: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
 52: Torch distributed is available.
 52: Torch distributed is initialized.
167: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
167: Torch distributed is available.
167: Torch distributed is initialized.
 46: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
 46: Torch distributed is available.
 46: Torch distributed is initialized.
245: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
 62: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
 62: Torch distributed is available.
 62: Torch distributed is initialized.
245: Torch distributed is available.
245: Torch distributed is initialized.
207: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
207: Torch distributed is available.
207: Torch distributed is initialized.
194: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
194: Torch distributed is available.
194: Torch distributed is initialized.
106: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
106: Torch distributed is available.
106: Torch distributed is initialized.
 89: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
 89: Torch distributed is available.
 89: Torch distributed is initialized.
103: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
103: Torch distributed is available.
103: Torch distributed is initialized.
144: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
144: Torch distributed is available.
144: Torch distributed is initialized.
229: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
229: Torch distributed is available.
229: Torch distributed is initialized.
148: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
148: Torch distributed is available.
148: Torch distributed is initialized.
196: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
196: Torch distributed is available.
196: Torch distributed is initialized.
149: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
149: Torch distributed is available.
149: Torch distributed is initialized.
107: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
107: Torch distributed is available.
107: Torch distributed is initialized.
153: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
153: Torch distributed is available.
153: Torch distributed is initialized.
 43: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
 43: Torch distributed is available.
 43: Torch distributed is initialized.
197: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
197: Torch distributed is available.
197: Torch distributed is initialized.
179: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
179: Torch distributed is available.
179: Torch distributed is initialized.
 42: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
 42: Torch distributed is available.
 42: Torch distributed is initialized.
193: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
193: Torch distributed is available.
193: Torch distributed is initialized.
181: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
181: Torch distributed is available.
181: Torch distributed is initialized.
171: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
171: Torch distributed is available.
171: Torch distributed is initialized.
156: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
156: Torch distributed is available.
156: Torch distributed is initialized.
 41: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
 41: Torch distributed is available.
 41: Torch distributed is initialized.
183: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
160: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
183: Torch distributed is available.
183: Torch distributed is initialized.
160: Torch distributed is available.
160: Torch distributed is initialized.
 27: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
 27: Torch distributed is available.
 27: Torch distributed is initialized.
158: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
158: Torch distributed is available.
158: Torch distributed is initialized.
 45: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
 45: Torch distributed is available.
 45: Torch distributed is initialized.
 30: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
 30: Torch distributed is available.
 30: Torch distributed is initialized.
180: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
180: Torch distributed is available.
180: Torch distributed is initialized.
 25: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
 25: Torch distributed is available.
 25: Torch distributed is initialized.
161: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
161: Torch distributed is available.
161: Torch distributed is initialized.
143: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
143: Torch distributed is available.
143: Torch distributed is initialized.
 31: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
 31: Torch distributed is available.
 31: Torch distributed is initialized.
 47: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
162: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
 47: Torch distributed is available.
 47: Torch distributed is initialized.
162: Torch distributed is available.
162: Torch distributed is initialized.
177: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
177: Torch distributed is available.
177: Torch distributed is initialized.
 88: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
 88: Torch distributed is available.
 88: Torch distributed is initialized.
 29: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
 29: Torch distributed is available.
 29: Torch distributed is initialized.
 90: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
 90: Torch distributed is available.
 90: Torch distributed is initialized.
 95: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
 95: Torch distributed is available.
 95: Torch distributed is initialized.
 92: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
 92: Torch distributed is available.
 92: Torch distributed is initialized.
224: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
224: Torch distributed is available.
224: Torch distributed is initialized.
138: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
138: Torch distributed is available.
138: Torch distributed is initialized.
175: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
175: Torch distributed is available.
175: Torch distributed is initialized.
 18: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
 18: Torch distributed is available.
 18: Torch distributed is initialized.
142: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
142: Torch distributed is available.
142: Torch distributed is initialized.
168: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
168: Torch distributed is available.
168: Torch distributed is initialized.
137: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
137: Torch distributed is available.
137: Torch distributed is initialized.
173: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
173: Torch distributed is available.
173: Torch distributed is initialized.
136: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
136: Torch distributed is available.
136: Torch distributed is initialized.
172: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
172: Torch distributed is available.
172: Torch distributed is initialized.
139: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
139: Torch distributed is available.
139: Torch distributed is initialized.
226: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
226: Torch distributed is available.
226: Torch distributed is initialized.
169: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
169: Torch distributed is available.
169: Torch distributed is initialized.
227: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
227: Torch distributed is available.
227: Torch distributed is initialized.
225: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
225: Torch distributed is available.
225: Torch distributed is initialized.
116: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
116: Torch distributed is available.
116: Torch distributed is initialized.
228: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
228: Torch distributed is available.
228: Torch distributed is initialized.
 12: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
 12: Torch distributed is available.
 12: Torch distributed is initialized.
230: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
230: Torch distributed is available.
230: Torch distributed is initialized.
 17: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
 17: Torch distributed is available.
 17: Torch distributed is initialized.
 23: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
 23: Torch distributed is available.
 23: Torch distributed is initialized.
 11: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
 11: Torch distributed is available.
 11: Torch distributed is initialized.
208: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
208: Torch distributed is available.
208: Torch distributed is initialized.
 81: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
 81: Torch distributed is available.
 81: Torch distributed is initialized.
215: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
215: Torch distributed is available.
215: Torch distributed is initialized.
 20: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
 20: Torch distributed is available.
 20: Torch distributed is initialized.
 74: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
 74: Torch distributed is available.
 74: Torch distributed is initialized.
112: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
112: Torch distributed is available.
112: Torch distributed is initialized.
118: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
118: Torch distributed is available.
118: Torch distributed is initialized.
121: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
121: Torch distributed is available.
121: Torch distributed is initialized.
250: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
250: Torch distributed is available.
250: Torch distributed is initialized.
 21: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
 21: Torch distributed is available.
 21: Torch distributed is initialized.
187: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
187: Torch distributed is available.
187: Torch distributed is initialized.
239: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
239: Torch distributed is available.
239: Torch distributed is initialized.
 32: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
 32: Torch distributed is available.
 32: Torch distributed is initialized.
132: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
132: Torch distributed is available.
132: Torch distributed is initialized.
 19: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
 19: Torch distributed is available.
 19: Torch distributed is initialized.
216: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
216: Torch distributed is available.
216: Torch distributed is initialized.
 22: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
 22: Torch distributed is available.
 22: Torch distributed is initialized.
 16: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
 16: Torch distributed is available.
 16: Torch distributed is initialized.
114: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
114: Torch distributed is available.
114: Torch distributed is initialized.
 13: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
 64: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
 13: Torch distributed is available.
 13: Torch distributed is initialized.
 64: Torch distributed is available.
 64: Torch distributed is initialized.
212: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
212: Torch distributed is available.
212: Torch distributed is initialized.
247: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
247: Torch distributed is available.
247: Torch distributed is initialized.
213: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
213: Torch distributed is available.
213: Torch distributed is initialized.
  9: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
  9: Torch distributed is available.
  9: Torch distributed is initialized.
 60: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
 60: Torch distributed is available.
 60: Torch distributed is initialized.
119: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
 15: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
119: Torch distributed is available.
 15: Torch distributed is available.
 15: Torch distributed is initialized.
119: Torch distributed is initialized.
232: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
232: Torch distributed is available.
232: Torch distributed is initialized.
150: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
115: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
150: Torch distributed is available.
150: Torch distributed is initialized.
115: Torch distributed is available.
115: Torch distributed is initialized.
 65: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
 65: Torch distributed is available.
 65: Torch distributed is initialized.
 79: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
 79: Torch distributed is available.
 79: Torch distributed is initialized.
 14: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
 14: Torch distributed is available.
 14: Torch distributed is initialized.
248: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
248: Torch distributed is available.
248: Torch distributed is initialized.
113: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
113: Torch distributed is available.
113: Torch distributed is initialized.
117: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
117: Torch distributed is available.
117: Torch distributed is initialized.
220: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
220: Torch distributed is available.
220: Torch distributed is initialized.
  8: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
  8: Torch distributed is available.
  8: Torch distributed is initialized.
 10: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
104: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
 10: Torch distributed is available.
 10: Torch distributed is initialized.
104: Torch distributed is available.
104: Torch distributed is initialized.
  3: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
  3: Torch distributed is available.
  3: Torch distributed is initialized.
 99: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
 99: Torch distributed is available.
 99: Torch distributed is initialized.
122: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
122: Torch distributed is available.
122: Torch distributed is initialized.
157: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
157: Torch distributed is available.
157: Torch distributed is initialized.
188: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
188: Torch distributed is available.
188: Torch distributed is initialized.
 55: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
 55: Torch distributed is available.
 55: Torch distributed is initialized.
186: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
163: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
186: Torch distributed is available.
186: Torch distributed is initialized.
163: Torch distributed is available.
163: Torch distributed is initialized.
 77: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
 86: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
233: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
102: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
 87: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
210: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
201: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
110: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
 83: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
133: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
 77: Torch distributed is available.
 77: Torch distributed is initialized.
209: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
211: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
 86: Torch distributed is available.
 86: Torch distributed is initialized.
 80: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
214: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
102: Torch distributed is available.
102: Torch distributed is initialized.
233: Torch distributed is available.
233: Torch distributed is initialized.
178: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
 87: Torch distributed is available.
 87: Torch distributed is initialized.
210: Torch distributed is available.
210: Torch distributed is initialized.
110: Torch distributed is available.
110: Torch distributed is initialized.
 83: Torch distributed is available.
 83: Torch distributed is initialized.
133: Torch distributed is available.
133: Torch distributed is initialized.
201: Torch distributed is available.
201: Torch distributed is initialized.
211: Torch distributed is available.
211: Torch distributed is initialized.
 84: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
178: Torch distributed is available.
178: Torch distributed is initialized.
214: Torch distributed is available.
214: Torch distributed is initialized.
 80: Torch distributed is available.
 80: Torch distributed is initialized.
209: Torch distributed is available.
209: Torch distributed is initialized.
 84: Torch distributed is available.
 84: Torch distributed is initialized.
 54: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
 54: Torch distributed is available.
 54: Torch distributed is initialized.
 44: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
 44: Torch distributed is available.
 44: Torch distributed is initialized.
 76: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
 76: Torch distributed is available.
 76: Torch distributed is initialized.
 85: device: cuda:5 n_gpu: 256, distributed training: True, 16-bits training: True
 85: Torch distributed is available.
 85: Torch distributed is initialized.
 82: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
 82: Torch distributed is available.
 82: Torch distributed is initialized.
236: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
236: Torch distributed is available.
236: Torch distributed is initialized.
198: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
198: Torch distributed is available.
198: Torch distributed is initialized.
252: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
252: Torch distributed is available.
252: Torch distributed is initialized.
 34: device: cuda:2 n_gpu: 256, distributed training: True, 16-bits training: True
 34: Torch distributed is available.
 34: Torch distributed is initialized.
192: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
192: Torch distributed is available.
192: Torch distributed is initialized.
 28: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
 28: Torch distributed is available.
 28: Torch distributed is initialized.
 72: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
 72: Torch distributed is available.
 72: Torch distributed is initialized.
203: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
203: Torch distributed is available.
203: Torch distributed is initialized.
 73: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
 73: Torch distributed is available.
 73: Torch distributed is initialized.
 94: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
 94: Torch distributed is available.
 94: Torch distributed is initialized.
 56: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
 56: Torch distributed is available.
 56: Torch distributed is initialized.
 75: device: cuda:3 n_gpu: 256, distributed training: True, 16-bits training: True
 75: Torch distributed is available.
 75: Torch distributed is initialized.
 78: device: cuda:6 n_gpu: 256, distributed training: True, 16-bits training: True
 78: Torch distributed is available.
 78: Torch distributed is initialized.
  7: device: cuda:7 n_gpu: 256, distributed training: True, 16-bits training: True
  7: Torch distributed is available.
  7: Torch distributed is initialized.
124: device: cuda:4 n_gpu: 256, distributed training: True, 16-bits training: True
249: device: cuda:1 n_gpu: 256, distributed training: True, 16-bits training: True
124: Torch distributed is available.
124: Torch distributed is initialized.
249: Torch distributed is available.
249: Torch distributed is initialized.
  0: device: cuda:0 n_gpu: 256, distributed training: True, 16-bits training: True
  0: :::MLLOG {"namespace": "", "time_ms": 1592975780801, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "bert", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 68}}
  0: :::MLLOG {"namespace": "", "time_ms": 1592975780801, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "NVIDIA", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 73}}
  0: :::MLLOG {"namespace": "", "time_ms": 1592975780802, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 77}}
  0: :::MLLOG {"namespace": "", "time_ms": 1592975780802, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 81}}
  0: :::MLLOG {"namespace": "", "time_ms": 1592975780802, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "32xNVIDIA DGX A100", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 85}}
  0: Torch distributed is available.
  0: Torch distributed is initialized.
  0: :::MLLOG {"namespace": "", "time_ms": 1592975786620, "event_type": "POINT_IN_TIME", "key": "seed", "value": 28019, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 675}}
  0: :::MLLOG {"namespace": "", "time_ms": 1592975786620, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 5120, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 677}}
  0: :::MLLOG {"namespace": "", "time_ms": 1592975786620, "event_type": "POINT_IN_TIME", "key": "opt_gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 679}}
  0: :::MLLOG {"namespace": "", "time_ms": 1592975786621, "event_type": "POINT_IN_TIME", "key": "max_predictions_per_seq", "value": 76, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 681}}
  0: :::MLLOG {"namespace": "", "time_ms": 1592975786621, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_training_steps", "value": 990.0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 683}}
  0: :::MLLOG {"namespace": "", "time_ms": 1592975786621, "event_type": "POINT_IN_TIME", "key": "num_warmup_steps", "value": 0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 686}}
  0: parsed args:
  0: Namespace(allreduce_post_accumulation=True, allreduce_post_accumulation_fp16=True, bert_config_path='/workspace/phase1/bert_config.json', bert_model='bert-large-uncased', cache_eval_data=True, checkpoint_activations=False, dense_seq_output=True, disable_apex_softmax=False, disable_fuse_mask=False, disable_fuse_qkv=False, disable_fuse_scale=False, do_train=True, enable_fuse_dropout=False, enable_stream=False, eval_batch_size=16, eval_dir='/workspace/evaldata', eval_iter_samples=500000, eval_iter_start_samples=3000000, fp16=True, fused_gelu_bias=True, fused_mha=True, gradient_accumulation_steps=1, init_checkpoint='/workspace/phase1/model.ckpt-28252.pt', init_tf_checkpoint=None, input_dir='/workspace/data_phase2', keep_n_most_recent_checkpoints=20, learning_rate=0.0017, local_rank=0, log_freq=1.0, loss_scale=0.0, max_predictions_per_seq=76, max_samples_termination=6500000.0, max_seq_length=512, max_steps=990.0, min_samples_to_start_checkpoints=3000000, n_gpu=256, num_epochs_to_generate_seeds_for=2, num_eval_exam
  0: ples=10000, num_samples_per_checkpoint=500000, opt_lamb_beta_1=0.87, opt_lamb_beta_2=0.97, output_dir='/results', pad=False, phase2=True, resume_from_checkpoint=False, seed=28019, skip_checkpoint=True, target_mlm_accuracy=0.712, train_batch_size=20, train_mlm_accuracy_window_size=0, unpad=False, use_env=False, warmup_proportion=0.0)
  0: :::MLLOG {"namespace": "", "time_ms": 1592975792375, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.0017, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 512}}
  0: :::MLLOG {"namespace": "", "time_ms": 1592975792376, "event_type": "POINT_IN_TIME", "key": "opt_epsilon", "value": 1e-06, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 517}}
  0: :::MLLOG {"namespace": "", "time_ms": 1592975792376, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_1", "value": 0.87, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 519}}
  0: :::MLLOG {"namespace": "", "time_ms": 1592975792376, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_2", "value": 0.97, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 520}}
  0: :::MLLOG {"namespace": "", "time_ms": 1592975792376, "event_type": "POINT_IN_TIME", "key": "opt_lamb_weight_decay_rate", "value": 0.01, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 523}}
  0: :::MLLOG {"namespace": "", "time_ms": 1592975792376, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 85}}
  0: :::MLLOG {"namespace": "", "time_ms": 1592975792376, "event_type": "POINT_IN_TIME", "key": "opt_lamb_learning_rate_decay_poly_power", "value": 1.0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 86}}
  0: :::MLLOG {"namespace": "", "time_ms": 1592975792376, "event_type": "POINT_IN_TIME", "key": "start_warmup_step", "value": 0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 531}}
  0: Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.
  0:
  0: Defaults for this optimization level are:
  0: enabled                : True
  0: opt_level              : O2
  0: cast_model_type        : torch.float16
  0: patch_torch_functions  : False
  0: keep_batchnorm_fp32    : True
  0: master_weights         : True
  0: loss_scale             : dynamic
  0: Processing user overrides (additional kwargs that are not None)...
  0: After processing overrides, optimization options are:
  0: enabled                : True
  0: opt_level              : O2
  0: cast_model_type        : torch.float16
  0: patch_torch_functions  : False
  0: keep_batchnorm_fp32    : True
  0: master_weights         : True
  0: loss_scale             : dynamic
  0: :::MLLOG {"namespace": "", "time_ms": 1592975792435, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 735}}
  0: :::MLLOG {"namespace": "", "time_ms": 1592975793544, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 736}}
  0: :::MLLOG {"namespace": "", "time_ms": 1592975793572, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 745, "epoch_num": 1}}
  0: :::MLLOG {"namespace": "", "time_ms": 1592975793574, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 749, "first_epoch_num": 1, "epoch_count": 1}}
  0: parsed args:
  0: Namespace(allreduce_post_accumulation=True, allreduce_post_accumulation_fp16=True, bert_config_path='/workspace/phase1/bert_config.json', bert_model='bert-large-uncased', cache_eval_data=True, checkpoint_activations=False, dense_seq_output=True, disable_apex_softmax=False, disable_fuse_mask=False, disable_fuse_qkv=False, disable_fuse_scale=False, do_train=True, enable_fuse_dropout=False, enable_stream=False, eval_batch_size=16, eval_dir='/workspace/evaldata', eval_iter_samples=500000, eval_iter_start_samples=3000000, fp16=True, fused_gelu_bias=True, fused_mha=True, gradient_accumulation_steps=1, init_checkpoint='/workspace/phase1/model.ckpt-28252.pt', init_tf_checkpoint=None, input_dir='/workspace/data_phase2', keep_n_most_recent_checkpoints=20, learning_rate=0.0017, local_rank=0, log_freq=1.0, loss_scale=0.0, max_predictions_per_seq=76, max_samples_termination=6500000.0, max_seq_length=512, max_steps=990.0, min_samples_to_start_checkpoints=3000000, n_gpu=256, num_epochs_to_generate_seeds_for=2, num_eval_exam
  0: ples=10000, num_samples_per_checkpoint=500000, opt_lamb_beta_1=0.87, opt_lamb_beta_2=0.97, output_dir='/results', pad=False, phase2=True, resume_from_checkpoint=False, resume_step=0, seed=28019, skip_checkpoint=True, target_mlm_accuracy=0.712, train_batch_size=20, train_mlm_accuracy_window_size=0, unpad=False, use_env=False, warmup_proportion=0.0)
  0: epoch: 1
  0: {'training_steps': 1, 'average_loss': 6.2109375, 'step_loss': 6.2109375, 'learning_rate': 0.0016982828282828281, 'seq/s': 1703.9355840001015, 'global_steps': 0, 'samples_trained': 0, 'skipped_steps': 1, 'timestamp': 1592975796.5796185}
  0: {'training_steps': 2, 'average_loss': 7.015625, 'step_loss': 7.015625, 'learning_rate': 0.0016982828282828281, 'seq/s': 25712.82415766661, 'global_steps': 0, 'samples_trained': 0, 'skipped_steps': 2, 'timestamp': 1592975796.7787416}
  0: {'training_steps': 3, 'average_loss': 5.0859375, 'step_loss': 5.0859375, 'learning_rate': 0.0016982828282828281, 'seq/s': 24660.08042864656, 'global_steps': 0, 'samples_trained': 0, 'skipped_steps': 3, 'timestamp': 1592975796.9863656}
  0: {'training_steps': 4, 'average_loss': 6.27734375, 'step_loss': 6.27734375, 'learning_rate': 0.0016982828282828281, 'seq/s': 24103.842591449386, 'global_steps': 0, 'samples_trained': 0, 'skipped_steps': 4, 'timestamp': 1592975797.1987803}
  0: {'training_steps': 5, 'average_loss': 5.91015625, 'step_loss': 5.91015625, 'learning_rate': 0.0016982828282828281, 'seq/s': 25876.196344891658, 'global_steps': 0, 'samples_trained': 0, 'skipped_steps': 5, 'timestamp': 1592975797.3966463}
  0: {'training_steps': 6, 'average_loss': 5.06640625, 'step_loss': 5.06640625, 'learning_rate': 0.0016982828282828281, 'seq/s': 25012.18470139475, 'global_steps': 0, 'samples_trained': 0, 'skipped_steps': 6, 'timestamp': 1592975797.601347}
  0: {'training_steps': 7, 'average_loss': 6.2109375, 'step_loss': 6.2109375, 'learning_rate': 0.0016982828282828281, 'seq/s': 26071.218345536414, 'global_steps': 0, 'samples_trained': 0, 'skipped_steps': 7, 'timestamp': 1592975797.7977326}
  0: {'training_steps': 8, 'average_loss': 5.58984375, 'step_loss': 5.58984375, 'learning_rate': 0.0016982828282828281, 'seq/s': 25792.346286654538, 'global_steps': 0, 'samples_trained': 0, 'skipped_steps': 8, 'timestamp': 1592975797.9962416}
  0: {'training_steps': 9, 'average_loss': 4.83984375, 'step_loss': 4.83984375, 'learning_rate': 0.0016982828282828281, 'seq/s': 23607.723472576905, 'global_steps': 1, 'samples_trained': 5120, 'skipped_steps': 8, 'timestamp': 1592975798.2131205}
  0: {'training_steps': 10, 'average_loss': 5.71875, 'step_loss': 5.71875, 'learning_rate': 0.0016965656565656564, 'seq/s': 19792.00174005047, 'global_steps': 2, 'samples_trained': 10240, 'skipped_steps': 8, 'timestamp': 1592975798.4718115}
  0: {'training_steps': 11, 'average_loss': 4.1171875, 'step_loss': 4.1171875, 'learning_rate': 0.0016948484848484848, 'seq/s': 24335.471108844693, 'global_steps': 3, 'samples_trained': 15360, 'skipped_steps': 8, 'timestamp': 1592975798.6822045}
  0: {'training_steps': 12, 'average_loss': 4.6796875, 'step_loss': 4.6796875, 'learning_rate': 0.001693131313131313, 'seq/s': 24314.613086173456, 'global_steps': 4, 'samples_trained': 20480, 'skipped_steps': 8, 'timestamp': 1592975798.892778}
  0: {'training_steps': 13, 'average_loss': 3.28515625, 'step_loss': 3.28515625, 'learning_rate': 0.0016914141414141413, 'seq/s': 24351.890594258693, 'global_steps': 5, 'samples_trained': 25600, 'skipped_steps': 8, 'timestamp': 1592975799.103029}
  0: {'training_steps': 14, 'average_loss': 4.1953125, 'step_loss': 4.1953125, 'learning_rate': 0.0016896969696969695, 'seq/s': 23321.882967239428, 'global_steps': 6, 'samples_trained': 30720, 'skipped_steps': 8, 'timestamp': 1592975799.3225658}
  0: {'training_steps': 15, 'average_loss': 4.73828125, 'step_loss': 4.73828125, 'learning_rate': 0.0016879797979797977, 'seq/s': 24296.869249602874, 'global_steps': 7, 'samples_trained': 35840, 'skipped_steps': 8, 'timestamp': 1592975799.533293}
  0: {'training_steps': 16, 'average_loss': 4.46875, 'step_loss': 4.46875, 'learning_rate': 0.0016862626262626262, 'seq/s': 22889.79185319724, 'global_steps': 8, 'samples_trained': 40960, 'skipped_steps': 8, 'timestamp': 1592975799.7569742}
  0: {'training_steps': 17, 'average_loss': 4.28125, 'step_loss': 4.28125, 'learning_rate': 0.0016845454545454546, 'seq/s': 24276.81829383822, 'global_steps': 9, 'samples_trained': 46080, 'skipped_steps': 8, 'timestamp': 1592975799.9678755}
  0: {'training_steps': 18, 'average_loss': 3.7890625, 'step_loss': 3.7890625, 'learning_rate': 0.0016828282828282829, 'seq/s': 24288.789950980947, 'global_steps': 10, 'samples_trained': 51200, 'skipped_steps': 8, 'timestamp': 1592975800.1786728}
  0: {'training_steps': 19, 'average_loss': 4.5390625, 'step_loss': 4.5390625, 'learning_rate': 0.001681111111111111, 'seq/s': 24328.633892905615, 'global_steps': 11, 'samples_trained': 56320, 'skipped_steps': 8, 'timestamp': 1592975800.3891249}
  0: {'training_steps': 20, 'average_loss': 4.59375, 'step_loss': 4.59375, 'learning_rate': 0.0016793939393939393, 'seq/s': 24326.346489106585, 'global_steps': 12, 'samples_trained': 61440, 'skipped_steps': 8, 'timestamp': 1592975800.5995967}
  0: {'training_steps': 21, 'average_loss': 3.64453125, 'step_loss': 3.64453125, 'learning_rate': 0.0016776767676767675, 'seq/s': 24269.35571291987, 'global_steps': 13, 'samples_trained': 66560, 'skipped_steps': 8, 'timestamp': 1592975800.8105628}
  0: {'training_steps': 22, 'average_loss': 3.798828125, 'step_loss': 3.798828125, 'learning_rate': 0.001675959595959596, 'seq/s': 24377.43305661851, 'global_steps': 14, 'samples_trained': 71680, 'skipped_steps': 8, 'timestamp': 1592975801.0205936}
  0: {'training_steps': 23, 'average_loss': 4.140625, 'step_loss': 4.140625, 'learning_rate': 0.0016742424242424242, 'seq/s': 24313.484412079055, 'global_steps': 15, 'samples_trained': 76800, 'skipped_steps': 8, 'timestamp': 1592975801.2311769}
  0: {'training_steps': 24, 'average_loss': 4.125, 'step_loss': 4.125, 'learning_rate': 0.0016725252525252525, 'seq/s': 20669.312050757864, 'global_steps': 16, 'samples_trained': 81920, 'skipped_steps': 8, 'timestamp': 1592975801.478888}
  0: {'training_steps': 25, 'average_loss': 4.16796875, 'step_loss': 4.16796875, 'learning_rate': 0.0016708080808080807, 'seq/s': 24297.14415019879, 'global_steps': 17, 'samples_trained': 87040, 'skipped_steps': 8, 'timestamp': 1592975801.6896129}
  0: {'training_steps': 26, 'average_loss': 3.015625, 'step_loss': 3.015625, 'learning_rate': 0.001669090909090909, 'seq/s': 24336.90520604081, 'global_steps': 18, 'samples_trained': 92160, 'skipped_steps': 8, 'timestamp': 1592975801.8999934}
  0: {'training_steps': 27, 'average_loss': 4.08984375, 'step_loss': 4.08984375, 'learning_rate': 0.0016673737373737374, 'seq/s': 24299.783512457198, 'global_steps': 19, 'samples_trained': 97280, 'skipped_steps': 8, 'timestamp': 1592975802.1106954}
  0: {'training_steps': 28, 'average_loss': 3.9375, 'step_loss': 3.9375, 'learning_rate': 0.0016656565656565656, 'seq/s': 24319.679645943535, 'global_steps': 20, 'samples_trained': 102400, 'skipped_steps': 8, 'timestamp': 1592975802.321225}
  0: {'training_steps': 29, 'average_loss': 4.40234375, 'step_loss': 4.40234375, 'learning_rate': 0.0016639393939393938, 'seq/s': 24308.062731692407, 'global_steps': 21, 'samples_trained': 107520, 'skipped_steps': 8, 'timestamp': 1592975802.531855}
  0: {'training_steps': 30, 'average_loss': 3.478515625, 'step_loss': 3.478515625, 'learning_rate': 0.001662222222222222, 'seq/s': 24295.274948807004, 'global_steps': 22, 'samples_trained': 112640, 'skipped_steps': 8, 'timestamp': 1592975802.7425961}
  0: {'training_steps': 31, 'average_loss': 4.3671875, 'step_loss': 4.3671875, 'learning_rate': 0.0016605050505050503, 'seq/s': 24226.480088445656, 'global_steps': 23, 'samples_trained': 117760, 'skipped_steps': 8, 'timestamp': 1592975802.9539356}
  0: {'training_steps': 32, 'average_loss': 3.939453125, 'step_loss': 3.939453125, 'learning_rate': 0.0016587878787878785, 'seq/s': 22484.62080013402, 'global_steps': 24, 'samples_trained': 122880, 'skipped_steps': 8, 'timestamp': 1592975803.1816473}
  0: {'training_steps': 33, 'average_loss': 3.919921875, 'step_loss': 3.919921875, 'learning_rate': 0.001657070707070707, 'seq/s': 24300.608430762823, 'global_steps': 25, 'samples_trained': 128000, 'skipped_steps': 8, 'timestamp': 1592975803.392342}
  0: {'training_steps': 34, 'average_loss': 3.9453125, 'step_loss': 3.9453125, 'learning_rate': 0.0016553535353535354, 'seq/s': 24340.905023842366, 'global_steps': 26, 'samples_trained': 133120, 'skipped_steps': 8, 'timestamp': 1592975803.602688}
  0: {'training_steps': 35, 'average_loss': 3.42578125, 'step_loss': 3.42578125, 'learning_rate': 0.0016536363636363636, 'seq/s': 24313.677105116272, 'global_steps': 27, 'samples_trained': 138240, 'skipped_steps': 8, 'timestamp': 1592975803.8132699}
  0: {'training_steps': 36, 'average_loss': 3.87109375, 'step_loss': 3.87109375, 'learning_rate': 0.0016519191919191919, 'seq/s': 24323.81155613548, 'global_steps': 28, 'samples_trained': 143360, 'skipped_steps': 8, 'timestamp': 1592975804.0237637}
  0: {'training_steps': 37, 'average_loss': 3.73828125, 'step_loss': 3.73828125, 'learning_rate': 0.00165020202020202, 'seq/s': 24228.44805877601, 'global_steps': 29, 'samples_trained': 148480, 'skipped_steps': 8, 'timestamp': 1592975804.235086}
  0: {'training_steps': 38, 'average_loss': 4.7578125, 'step_loss': 4.7578125, 'learning_rate': 0.0016484848484848485, 'seq/s': 24262.583004651446, 'global_steps': 30, 'samples_trained': 153600, 'skipped_steps': 8, 'timestamp': 1592975804.446111}
  0: {'training_steps': 39, 'average_loss': 3.66015625, 'step_loss': 3.66015625, 'learning_rate': 0.0016467676767676768, 'seq/s': 24281.457282966217, 'global_steps': 31, 'samples_trained': 158720, 'skipped_steps': 8, 'timestamp': 1592975804.6569722}
  0: {'training_steps': 40, 'average_loss': 3.9140625, 'step_loss': 3.9140625, 'learning_rate': 0.001645050505050505, 'seq/s': 22867.903420574563, 'global_steps': 32, 'samples_trained': 163840, 'skipped_steps': 8, 'timestamp': 1592975804.8808672}
  0: {'training_steps': 41, 'average_loss': 4.15625, 'step_loss': 4.15625, 'learning_rate': 0.0016433333333333332, 'seq/s': 24279.64539576406, 'global_steps': 33, 'samples_trained': 168960, 'skipped_steps': 8, 'timestamp': 1592975805.091744}
  0: {'training_steps': 42, 'average_loss': 3.814453125, 'step_loss': 3.814453125, 'learning_rate': 0.0016416161616161615, 'seq/s': 24240.508857024495, 'global_steps': 34, 'samples_trained': 174080, 'skipped_steps': 8, 'timestamp': 1592975805.302961}
  0: {'training_steps': 43, 'average_loss': 3.603515625, 'step_loss': 3.603515625, 'learning_rate': 0.0016398989898989897, 'seq/s': 24225.7148529863, 'global_steps': 35, 'samples_trained': 179200, 'skipped_steps': 8, 'timestamp': 1592975805.5143073}
  0: {'training_steps': 44, 'average_loss': 3.9375, 'step_loss': 3.9375, 'learning_rate': 0.0016381818181818181, 'seq/s': 24198.607546867905, 'global_steps': 36, 'samples_trained': 184320, 'skipped_steps': 8, 'timestamp': 1592975805.7258906}
  0: {'training_steps': 45, 'average_loss': 2.91796875, 'step_loss': 2.91796875, 'learning_rate': 0.0016364646464646464, 'seq/s': 24228.912765095658, 'global_steps': 37, 'samples_trained': 189440, 'skipped_steps': 8, 'timestamp': 1592975805.937209}
  0: {'training_steps': 46, 'average_loss': 3.015625, 'step_loss': 3.015625, 'learning_rate': 0.0016347474747474746, 'seq/s': 24329.984489870832, 'global_steps': 38, 'samples_trained': 194560, 'skipped_steps': 8, 'timestamp': 1592975806.1476493}
  0: {'training_steps': 47, 'average_loss': 3.41015625, 'step_loss': 3.41015625, 'learning_rate': 0.0016330303030303028, 'seq/s': 24217.628176790597, 'global_steps': 39, 'samples_trained': 199680, 'skipped_steps': 8, 'timestamp': 1592975806.359066}
  0: {'training_steps': 48, 'average_loss': 3.328125, 'step_loss': 3.328125, 'learning_rate': 0.001631313131313131, 'seq/s': 24329.322954253726, 'global_steps': 40, 'samples_trained': 204800, 'skipped_steps': 8, 'timestamp': 1592975806.5695121}
  0: {'training_steps': 49, 'average_loss': 4.01953125, 'step_loss': 4.01953125, 'learning_rate': 0.0016295959595959595, 'seq/s': 24313.016455989993, 'global_steps': 41, 'samples_trained': 209920, 'skipped_steps': 8, 'timestamp': 1592975806.7800994}
  0: {'training_steps': 50, 'average_loss': 3.43359375, 'step_loss': 3.43359375, 'learning_rate': 0.0016278787878787877, 'seq/s': 24314.39284885334, 'global_steps': 42, 'samples_trained': 215040, 'skipped_steps': 8, 'timestamp': 1592975806.9906747}
  0: {'training_steps': 51, 'average_loss': 3.95703125, 'step_loss': 3.95703125, 'learning_rate': 0.0016261616161616162, 'seq/s': 24267.98441412854, 'global_steps': 43, 'samples_trained': 220160, 'skipped_steps': 8, 'timestamp': 1592975807.2016528}
  0: {'training_steps': 52, 'average_loss': 3.48828125, 'step_loss': 3.48828125, 'learning_rate': 0.0016244444444444444, 'seq/s': 24355.17715053032, 'global_steps': 44, 'samples_trained': 225280, 'skipped_steps': 8, 'timestamp': 1592975807.4118755}
  0: {'training_steps': 53, 'average_loss': 3.40234375, 'step_loss': 3.40234375, 'learning_rate': 0.0016227272727272726, 'seq/s': 24238.101208246095, 'global_steps': 45, 'samples_trained': 230400, 'skipped_steps': 8, 'timestamp': 1592975807.6231136}
  0: {'training_steps': 54, 'average_loss': 4.04296875, 'step_loss': 4.04296875, 'learning_rate': 0.0016210101010101009, 'seq/s': 24055.48483792809, 'global_steps': 46, 'samples_trained': 235520, 'skipped_steps': 8, 'timestamp': 1592975807.8359554}
  0: {'training_steps': 55, 'average_loss': 3.84375, 'step_loss': 3.84375, 'learning_rate': 0.0016192929292929293, 'seq/s': 15054.752381613363, 'global_steps': 47, 'samples_trained': 240640, 'skipped_steps': 8, 'timestamp': 1592975808.1760478}
  0: {'training_steps': 56, 'average_loss': 4.12109375, 'step_loss': 4.12109375, 'learning_rate': 0.0016175757575757576, 'seq/s': 13205.499728201381, 'global_steps': 48, 'samples_trained': 245760, 'skipped_steps': 8, 'timestamp': 1592975808.5637655}
  0: {'training_steps': 57, 'average_loss': 3.66015625, 'step_loss': 3.66015625, 'learning_rate': 0.0016158585858585858, 'seq/s': 9403.93548610287, 'global_steps': 49, 'samples_trained': 250880, 'skipped_steps': 8, 'timestamp': 1592975809.1082191}
  0: {'training_steps': 58, 'average_loss': 3.939453125, 'step_loss': 3.939453125, 'learning_rate': 0.001614141414141414, 'seq/s': 22650.511267330807, 'global_steps': 50, 'samples_trained': 256000, 'skipped_steps': 8, 'timestamp': 1592975809.334263}
  0: {'training_steps': 59, 'average_loss': 4.09765625, 'step_loss': 4.09765625, 'learning_rate': 0.0016124242424242422, 'seq/s': 13494.07574459903, 'global_steps': 51, 'samples_trained': 261120, 'skipped_steps': 8, 'timestamp': 1592975809.7136893}
  0: {'training_steps': 60, 'average_loss': 3.568359375, 'step_loss': 3.568359375, 'learning_rate': 0.0016107070707070707, 'seq/s': 20955.312375584508, 'global_steps': 52, 'samples_trained': 266240, 'skipped_steps': 8, 'timestamp': 1592975809.9580193}
  0: {'training_steps': 61, 'average_loss': 3.708984375, 'step_loss': 3.708984375, 'learning_rate': 0.001608989898989899, 'seq/s': 24314.915919003255, 'global_steps': 53, 'samples_trained': 271360, 'skipped_steps': 8, 'timestamp': 1592975810.16859}
  0: {'training_steps': 62, 'average_loss': 3.984375, 'step_loss': 3.984375, 'learning_rate': 0.0016072727272727272, 'seq/s': 24284.752316257167, 'global_steps': 54, 'samples_trained': 276480, 'skipped_steps': 8, 'timestamp': 1592975810.3794224}
  0: {'training_steps': 63, 'average_loss': 3.599609375, 'step_loss': 3.599609375, 'learning_rate': 0.0016055555555555554, 'seq/s': 24267.27139999774, 'global_steps': 55, 'samples_trained': 281600, 'skipped_steps': 8, 'timestamp': 1592975810.590407}
  0: {'training_steps': 64, 'average_loss': 3.279296875, 'step_loss': 3.279296875, 'learning_rate': 0.0016038383838383836, 'seq/s': 24274.046726341527, 'global_steps': 56, 'samples_trained': 286720, 'skipped_steps': 8, 'timestamp': 1592975810.8013322}
  0: {'training_steps': 65, 'average_loss': 3.21484375, 'step_loss': 3.21484375, 'learning_rate': 0.001602121212121212, 'seq/s': 24180.324643738626, 'global_steps': 57, 'samples_trained': 291840, 'skipped_steps': 8, 'timestamp': 1592975811.0130754}
  0: {'training_steps': 66, 'average_loss': 4.10546875, 'step_loss': 4.10546875, 'learning_rate': 0.0016004040404040403, 'seq/s': 23324.13735876435, 'global_steps': 58, 'samples_trained': 296960, 'skipped_steps': 8, 'timestamp': 1592975811.232591}
  0: {'training_steps': 67, 'average_loss': 3.962890625, 'step_loss': 3.962890625, 'learning_rate': 0.0015986868686868685, 'seq/s': 24248.829870720852, 'global_steps': 59, 'samples_trained': 302080, 'skipped_steps': 8, 'timestamp': 1592975811.4437358}
  0: {'training_steps': 68, 'average_loss': 3.859375, 'step_loss': 3.859375, 'learning_rate': 0.001596969696969697, 'seq/s': 24182.50297286584, 'global_steps': 60, 'samples_trained': 307200, 'skipped_steps': 8, 'timestamp': 1592975811.6554596}
  0: {'training_steps': 69, 'average_loss': 3.501953125, 'step_loss': 3.501953125, 'learning_rate': 0.0015952525252525252, 'seq/s': 24221.506921933404, 'global_steps': 61, 'samples_trained': 312320, 'skipped_steps': 8, 'timestamp': 1592975811.866843}
  0: {'training_steps': 70, 'average_loss': 3.63671875, 'step_loss': 3.63671875, 'learning_rate': 0.0015935353535353534, 'seq/s': 24325.051402991296, 'global_steps': 62, 'samples_trained': 317440, 'skipped_steps': 8, 'timestamp': 1592975812.0773263}
  0: {'training_steps': 71, 'average_loss': 3.70703125, 'step_loss': 3.70703125, 'learning_rate': 0.0015918181818181819, 'seq/s': 24150.358046544476, 'global_steps': 63, 'samples_trained': 322560, 'skipped_steps': 8, 'timestamp': 1592975812.289332}
  0: {'training_steps': 72, 'average_loss': 3.7265625, 'step_loss': 3.7265625, 'learning_rate': 0.00159010101010101, 'seq/s': 24260.006529634713, 'global_steps': 64, 'samples_trained': 327680, 'skipped_steps': 8, 'timestamp': 1592975812.5003793}
  0: {'training_steps': 73, 'average_loss': 3.89453125, 'step_loss': 3.89453125, 'learning_rate': 0.0015883838383838383, 'seq/s': 24186.561157269596, 'global_steps': 65, 'samples_trained': 332800, 'skipped_steps': 8, 'timestamp': 1592975812.7120676}
  0: {'training_steps': 74, 'average_loss': 3.27734375, 'step_loss': 3.27734375, 'learning_rate': 0.0015866666666666666, 'seq/s': 24260.033936063734, 'global_steps': 66, 'samples_trained': 337920, 'skipped_steps': 8, 'timestamp': 1592975812.923115}
  0: {'training_steps': 75, 'average_loss': 3.6328125, 'step_loss': 3.6328125, 'learning_rate': 0.0015849494949494948, 'seq/s': 24292.55412558017, 'global_steps': 67, 'samples_trained': 343040, 'skipped_steps': 8, 'timestamp': 1592975813.13388}
  0: {'training_steps': 76, 'average_loss': 3.759765625, 'step_loss': 3.759765625, 'learning_rate': 0.0015832323232323232, 'seq/s': 24251.95172384976, 'global_steps': 68, 'samples_trained': 348160, 'skipped_steps': 8, 'timestamp': 1592975813.3449974}
  0: {'training_steps': 77, 'average_loss': 4.0859375, 'step_loss': 4.0859375, 'learning_rate': 0.0015815151515151515, 'seq/s': 24336.243294024855, 'global_steps': 69, 'samples_trained': 353280, 'skipped_steps': 8, 'timestamp': 1592975813.555384}
  0: {'training_steps': 78, 'average_loss': 3.587890625, 'step_loss': 3.587890625, 'learning_rate': 0.0015797979797979797, 'seq/s': 23416.127079389727, 'global_steps': 70, 'samples_trained': 358400, 'skipped_steps': 8, 'timestamp': 1592975813.7740374}
  0: {'training_steps': 79, 'average_loss': 4.0546875, 'step_loss': 4.0546875, 'learning_rate': 0.001578080808080808, 'seq/s': 23539.09764826456, 'global_steps': 71, 'samples_trained': 363520, 'skipped_steps': 8, 'timestamp': 1592975813.9915483}
  0: {'training_steps': 80, 'average_loss': 3.654296875, 'step_loss': 3.654296875, 'learning_rate': 0.0015763636363636362, 'seq/s': 24375.689823086195, 'global_steps': 72, 'samples_trained': 368640, 'skipped_steps': 8, 'timestamp': 1592975814.201594}
  0: {'training_steps': 81, 'average_loss': 4.19921875, 'step_loss': 4.19921875, 'learning_rate': 0.0015746464646464646, 'seq/s': 22963.269695096784, 'global_steps': 73, 'samples_trained': 373760, 'skipped_steps': 8, 'timestamp': 1592975814.4245596}
  0: {'training_steps': 82, 'average_loss': 4.1328125, 'step_loss': 4.1328125, 'learning_rate': 0.0015729292929292928, 'seq/s': 24342.53291226193, 'global_steps': 74, 'samples_trained': 378880, 'skipped_steps': 8, 'timestamp': 1592975814.6348915}
  0: {'training_steps': 83, 'average_loss': 4.1484375, 'step_loss': 4.1484375, 'learning_rate': 0.001571212121212121, 'seq/s': 24176.377422300076, 'global_steps': 75, 'samples_trained': 384000, 'skipped_steps': 8, 'timestamp': 1592975814.846669}
  0: {'training_steps': 84, 'average_loss': 3.732421875, 'step_loss': 3.732421875, 'learning_rate': 0.0015694949494949493, 'seq/s': 24226.316105348895, 'global_steps': 76, 'samples_trained': 389120, 'skipped_steps': 8, 'timestamp': 1592975815.0580099}
  0: {'training_steps': 85, 'average_loss': 4.34765625, 'step_loss': 4.34765625, 'learning_rate': 0.0015677777777777777, 'seq/s': 24331.1973986098, 'global_steps': 77, 'samples_trained': 394240, 'skipped_steps': 8, 'timestamp': 1592975815.2684398}
  0: {'training_steps': 86, 'average_loss': 3.16796875, 'step_loss': 3.16796875, 'learning_rate': 0.001566060606060606, 'seq/s': 24254.33473156826, 'global_steps': 78, 'samples_trained': 399360, 'skipped_steps': 8, 'timestamp': 1592975815.4795365}
  0: {'training_steps': 87, 'average_loss': 4.0703125, 'step_loss': 4.0703125, 'learning_rate': 0.0015643434343434344, 'seq/s': 24376.381552585844, 'global_steps': 79, 'samples_trained': 404480, 'skipped_steps': 8, 'timestamp': 1592975815.6895761}
  0: {'training_steps': 88, 'average_loss': 3.451171875, 'step_loss': 3.451171875, 'learning_rate': 0.0015626262626262627, 'seq/s': 24207.363693750565, 'global_steps': 80, 'samples_trained': 409600, 'skipped_steps': 8, 'timestamp': 1592975815.9010825}
  0: {'training_steps': 89, 'average_loss': 2.974609375, 'step_loss': 2.974609375, 'learning_rate': 0.0015609090909090909, 'seq/s': 24249.815632244652, 'global_steps': 81, 'samples_trained': 414720, 'skipped_steps': 8, 'timestamp': 1592975816.1122186}
  0: {'training_steps': 90, 'average_loss': 3.55859375, 'step_loss': 3.55859375, 'learning_rate': 0.0015591919191919191, 'seq/s': 24272.290813079897, 'global_steps': 82, 'samples_trained': 419840, 'skipped_steps': 8, 'timestamp': 1592975816.3231592}
  0: {'training_steps': 91, 'average_loss': 2.177734375, 'step_loss': 2.177734375, 'learning_rate': 0.0015574747474747473, 'seq/s': 24239.49649187759, 'global_steps': 83, 'samples_trained': 424960, 'skipped_steps': 8, 'timestamp': 1592975816.5343852}
  0: {'training_steps': 92, 'average_loss': 3.435546875, 'step_loss': 3.435546875, 'learning_rate': 0.0015557575757575758, 'seq/s': 24211.04807860336, 'global_steps': 84, 'samples_trained': 430080, 'skipped_steps': 8, 'timestamp': 1592975816.7458594}
  0: {'training_steps': 93, 'average_loss': 4.01171875, 'step_loss': 4.01171875, 'learning_rate': 0.001554040404040404, 'seq/s': 24277.91611930242, 'global_steps': 85, 'samples_trained': 435200, 'skipped_steps': 8, 'timestamp': 1592975816.956751}
  0: {'training_steps': 94, 'average_loss': 4.07421875, 'step_loss': 4.07421875, 'learning_rate': 0.0015523232323232323, 'seq/s': 24272.098775478833, 'global_steps': 86, 'samples_trained': 440320, 'skipped_steps': 8, 'timestamp': 1592975817.1676934}
  0: {'training_steps': 95, 'average_loss': 4.078125, 'step_loss': 4.078125, 'learning_rate': 0.0015506060606060605, 'seq/s': 24322.406549148058, 'global_steps': 87, 'samples_trained': 445440, 'skipped_steps': 8, 'timestamp': 1592975817.3781993}
  0: {'training_steps': 96, 'average_loss': 3.564453125, 'step_loss': 3.564453125, 'learning_rate': 0.0015488888888888887, 'seq/s': 24195.44488973666, 'global_steps': 88, 'samples_trained': 450560, 'skipped_steps': 8, 'timestamp': 1592975817.58981}
  0: {'training_steps': 97, 'average_loss': 3.751953125, 'step_loss': 3.751953125, 'learning_rate': 0.001547171717171717, 'seq/s': 24148.37558628429, 'global_steps': 89, 'samples_trained': 455680, 'skipped_steps': 8, 'timestamp': 1592975817.801833}
  0: {'training_steps': 98, 'average_loss': 3.8125, 'step_loss': 3.8125, 'learning_rate': 0.0015454545454545454, 'seq/s': 24159.813155188745, 'global_steps': 90, 'samples_trained': 460800, 'skipped_steps': 8, 'timestamp': 1592975818.0137556}
  0: {'training_steps': 99, 'average_loss': 3.11328125, 'step_loss': 3.11328125, 'learning_rate': 0.0015437373737373736, 'seq/s': 24309.521118597408, 'global_steps': 91, 'samples_trained': 465920, 'skipped_steps': 8, 'timestamp': 1592975818.2243733}
  0: {'training_steps': 100, 'average_loss': 3.603515625, 'step_loss': 3.603515625, 'learning_rate': 0.0015420202020202018, 'seq/s': 24183.8101587416, 'global_steps': 92, 'samples_trained': 471040, 'skipped_steps': 8, 'timestamp': 1592975818.4360857}
  0: {'training_steps': 101, 'average_loss': 4.265625, 'step_loss': 4.265625, 'learning_rate': 0.00154030303030303, 'seq/s': 24284.532619549227, 'global_steps': 93, 'samples_trained': 476160, 'skipped_steps': 8, 'timestamp': 1592975818.64692}
  0: {'training_steps': 102, 'average_loss': 3.080078125, 'step_loss': 3.080078125, 'learning_rate': 0.0015385858585858585, 'seq/s': 23278.097587731183, 'global_steps': 94, 'samples_trained': 481280, 'skipped_steps': 8, 'timestamp': 1592975818.86687}
  0: {'training_steps': 103, 'average_loss': 3.78125, 'step_loss': 3.78125, 'learning_rate': 0.001536868686868687, 'seq/s': 24276.571296791397, 'global_steps': 95, 'samples_trained': 486400, 'skipped_steps': 8, 'timestamp': 1592975819.0777733}
  0: {'training_steps': 104, 'average_loss': 3.548828125, 'step_loss': 3.548828125, 'learning_rate': 0.0015351515151515152, 'seq/s': 24254.718247819037, 'global_steps': 96, 'samples_trained': 491520, 'skipped_steps': 8, 'timestamp': 1592975819.288867}
  0: {'training_steps': 105, 'average_loss': 3.970703125, 'step_loss': 3.970703125, 'learning_rate': 0.0015334343434343434, 'seq/s': 24249.295359231062, 'global_steps': 97, 'samples_trained': 496640, 'skipped_steps': 8, 'timestamp': 1592975819.5000076}
  0: {'training_steps': 106, 'average_loss': 3.560546875, 'step_loss': 3.560546875, 'learning_rate': 0.0015317171717171717, 'seq/s': 23022.772595455448, 'global_steps': 98, 'samples_trained': 501760, 'skipped_steps': 8, 'timestamp': 1592975819.7223966}
  0: {'training_steps': 107, 'average_loss': 3.90625, 'step_loss': 3.90625, 'learning_rate': 0.00153, 'seq/s': 24358.630370991286, 'global_steps': 99, 'samples_trained': 506880, 'skipped_steps': 8, 'timestamp': 1592975819.9325898}
  0: {'training_steps': 108, 'average_loss': 3.888671875, 'step_loss': 3.888671875, 'learning_rate': 0.0015282828282828281, 'seq/s': 24241.68549574201, 'global_steps': 100, 'samples_trained': 512000, 'skipped_steps': 8, 'timestamp': 1592975820.143797}
  0: {'training_steps': 109, 'average_loss': 3.310546875, 'step_loss': 3.310546875, 'learning_rate': 0.0015265656565656566, 'seq/s': 24302.368443685977, 'global_steps': 101, 'samples_trained': 517120, 'skipped_steps': 8, 'timestamp': 1592975820.3544767}
  0: {'training_steps': 110, 'average_loss': 3.759765625, 'step_loss': 3.759765625, 'learning_rate': 0.0015248484848484848, 'seq/s': 23085.11563607906, 'global_steps': 102, 'samples_trained': 522240, 'skipped_steps': 8, 'timestamp': 1592975820.5762653}
  0: {'training_steps': 111, 'average_loss': 2.818359375, 'step_loss': 2.818359375, 'learning_rate': 0.001523131313131313, 'seq/s': 24290.932914662673, 'global_steps': 103, 'samples_trained': 527360, 'skipped_steps': 8, 'timestamp': 1592975820.787044}
  0: {'training_steps': 112, 'average_loss': 3.146484375, 'step_loss': 3.146484375, 'learning_rate': 0.0015214141414141413, 'seq/s': 24268.889453943004, 'global_steps': 104, 'samples_trained': 532480, 'skipped_steps': 8, 'timestamp': 1592975820.9980142}
  0: {'training_steps': 113, 'average_loss': 3.27734375, 'step_loss': 3.27734375, 'learning_rate': 0.0015196969696969695, 'seq/s': 24251.07533305252, 'global_steps': 105, 'samples_trained': 537600, 'skipped_steps': 8, 'timestamp': 1592975821.2091393}
  0: {'training_steps': 114, 'average_loss': 3.158203125, 'step_loss': 3.158203125, 'learning_rate': 0.001517979797979798, 'seq/s': 24281.73183492141, 'global_steps': 106, 'samples_trained': 542720, 'skipped_steps': 8, 'timestamp': 1592975821.419998}
  0: {'training_steps': 115, 'average_loss': 3.6171875, 'step_loss': 3.6171875, 'learning_rate': 0.0015162626262626262, 'seq/s': 24202.61658480729, 'global_steps': 107, 'samples_trained': 547840, 'skipped_steps': 8, 'timestamp': 1592975821.6315458}
  0: {'training_steps': 116, 'average_loss': 3.662109375, 'step_loss': 3.662109375, 'learning_rate': 0.0015145454545454544, 'seq/s': 24225.769511058767, 'global_steps': 108, 'samples_trained': 552960, 'skipped_steps': 8, 'timestamp': 1592975821.8428915}
  0: {'training_steps': 117, 'average_loss': 3.681640625, 'step_loss': 3.681640625, 'learning_rate': 0.0015128282828282826, 'seq/s': 24280.825837030603, 'global_steps': 109, 'samples_trained': 558080, 'skipped_steps': 8, 'timestamp': 1592975822.053758}
  0: {'training_steps': 118, 'average_loss': 3.529296875, 'step_loss': 3.529296875, 'learning_rate': 0.0015111111111111109, 'seq/s': 24253.56773545057, 'global_steps': 110, 'samples_trained': 563200, 'skipped_steps': 8, 'timestamp': 1592975822.2648613}
  0: {'training_steps': 119, 'average_loss': 3.615234375, 'step_loss': 3.615234375, 'learning_rate': 0.0015093939393939393, 'seq/s': 24150.385205794337, 'global_steps': 111, 'samples_trained': 568320, 'skipped_steps': 8, 'timestamp': 1592975822.4768667}
  0: {'training_steps': 120, 'average_loss': 2.83203125, 'step_loss': 2.83203125, 'learning_rate': 0.0015076767676767675, 'seq/s': 24310.346698182624, 'global_steps': 112, 'samples_trained': 573440, 'skipped_steps': 8, 'timestamp': 1592975822.6874774}
  0: {'training_steps': 121, 'average_loss': 3.1796875, 'step_loss': 3.1796875, 'learning_rate': 0.001505959595959596, 'seq/s': 24145.82330857079, 'global_steps': 113, 'samples_trained': 578560, 'skipped_steps': 8, 'timestamp': 1592975822.8995228}
  0: {'training_steps': 122, 'average_loss': 3.583984375, 'step_loss': 3.583984375, 'learning_rate': 0.0015042424242424242, 'seq/s': 24246.11943972126, 'global_steps': 114, 'samples_trained': 583680, 'skipped_steps': 8, 'timestamp': 1592975823.110691}
  0: {'training_steps': 123, 'average_loss': 3.447265625, 'step_loss': 3.447265625, 'learning_rate': 0.0015025252525252524, 'seq/s': 24219.10304616044, 'global_steps': 115, 'samples_trained': 588800, 'skipped_steps': 8, 'timestamp': 1592975823.322095}
  0: {'training_steps': 124, 'average_loss': 3.796875, 'step_loss': 3.796875, 'learning_rate': 0.0015008080808080807, 'seq/s': 24240.700395078453, 'global_steps': 116, 'samples_trained': 593920, 'skipped_steps': 8, 'timestamp': 1592975823.5333107}
  0: {'training_steps': 125, 'average_loss': 3.306640625, 'step_loss': 3.306640625, 'learning_rate': 0.0014990909090909091, 'seq/s': 24246.146814782867, 'global_steps': 117, 'samples_trained': 599040, 'skipped_steps': 8, 'timestamp': 1592975823.744479}
  0: {'training_steps': 126, 'average_loss': 3.69140625, 'step_loss': 3.69140625, 'learning_rate': 0.0014973737373737373, 'seq/s': 23170.0500196367, 'global_steps': 118, 'samples_trained': 604160, 'skipped_steps': 8, 'timestamp': 1592975823.9654546}
  0: {'training_steps': 127, 'average_loss': 3.255859375, 'step_loss': 3.255859375, 'learning_rate': 0.0014956565656565656, 'seq/s': 24182.63913146785, 'global_steps': 119, 'samples_trained': 609280, 'skipped_steps': 8, 'timestamp': 1592975824.1771774}
  0: {'training_steps': 128, 'average_loss': 4.05859375, 'step_loss': 4.05859375, 'learning_rate': 0.0014939393939393938, 'seq/s': 24158.046552544572, 'global_steps': 120, 'samples_trained': 614400, 'skipped_steps': 8, 'timestamp': 1592975824.3891156}
  0: {'training_steps': 129, 'average_loss': 4.12890625, 'step_loss': 4.12890625, 'learning_rate': 0.001492222222222222, 'seq/s': 24234.654725483313, 'global_steps': 121, 'samples_trained': 619520, 'skipped_steps': 8, 'timestamp': 1592975824.6003838}
  0: {'training_steps': 130, 'average_loss': 3.208984375, 'step_loss': 3.208984375, 'learning_rate': 0.0014905050505050505, 'seq/s': 22860.81937632868, 'global_steps': 122, 'samples_trained': 624640, 'skipped_steps': 8, 'timestamp': 1592975824.8243482}
  0: {'training_steps': 131, 'average_loss': 3.84765625, 'step_loss': 3.84765625, 'learning_rate': 0.0014887878787878787, 'seq/s': 24356.696446900864, 'global_steps': 123, 'samples_trained': 629760, 'skipped_steps': 8, 'timestamp': 1592975825.0345583}
  0: {'training_steps': 132, 'average_loss': 3.552734375, 'step_loss': 3.552734375, 'learning_rate': 0.001487070707070707, 'seq/s': 24333.623578922557, 'global_steps': 124, 'samples_trained': 634880, 'skipped_steps': 8, 'timestamp': 1592975825.2449672}
  0: {'training_steps': 133, 'average_loss': 3.48046875, 'step_loss': 3.48046875, 'learning_rate': 0.0014853535353535352, 'seq/s': 24276.434078381542, 'global_steps': 125, 'samples_trained': 640000, 'skipped_steps': 8, 'timestamp': 1592975825.4558718}
  0: {'training_steps': 134, 'average_loss': 3.486328125, 'step_loss': 3.486328125, 'learning_rate': 0.0014836363636363636, 'seq/s': 22932.298725499095, 'global_steps': 126, 'samples_trained': 645120, 'skipped_steps': 8, 'timestamp': 1592975825.6791384}
  0: {'training_steps': 135, 'average_loss': 3.478515625, 'step_loss': 3.478515625, 'learning_rate': 0.0014819191919191919, 'seq/s': 21779.09037250388, 'global_steps': 127, 'samples_trained': 650240, 'skipped_steps': 8, 'timestamp': 1592975825.9142268}
  0: {'training_steps': 136, 'average_loss': 3.09765625, 'step_loss': 3.09765625, 'learning_rate': 0.0014802020202020203, 'seq/s': 21444.87798545432, 'global_steps': 128, 'samples_trained': 655360, 'skipped_steps': 8, 'timestamp': 1592975826.152979}
  0: {'training_steps': 137, 'average_loss': 2.81640625, 'step_loss': 2.81640625, 'learning_rate': 0.0014784848484848483, 'seq/s': 24253.403385450783, 'global_steps': 129, 'samples_trained': 660480, 'skipped_steps': 8, 'timestamp': 1592975826.3640838}
  0: {'training_steps': 138, 'average_loss': 3.0546875, 'step_loss': 3.0546875, 'learning_rate': 0.0014767676767676768, 'seq/s': 24252.252997815867, 'global_steps': 130, 'samples_trained': 665600, 'skipped_steps': 8, 'timestamp': 1592975826.5751987}
  0: {'training_steps': 139, 'average_loss': 3.224609375, 'step_loss': 3.224609375, 'learning_rate': 0.001475050505050505, 'seq/s': 21619.731923350293, 'global_steps': 131, 'samples_trained': 670720, 'skipped_steps': 8, 'timestamp': 1592975826.8120198}
  0: {'training_steps': 140, 'average_loss': 3.53515625, 'step_loss': 3.53515625, 'learning_rate': 0.0014733333333333332, 'seq/s': 21807.222160165238, 'global_steps': 132, 'samples_trained': 675840, 'skipped_steps': 8, 'timestamp': 1592975827.046805}
  0: {'training_steps': 141, 'average_loss': 3.203125, 'step_loss': 3.203125, 'learning_rate': 0.0014716161616161617, 'seq/s': 24258.060831433715, 'global_steps': 133, 'samples_trained': 680960, 'skipped_steps': 8, 'timestamp': 1592975827.2578692}
  0: {'training_steps': 142, 'average_loss': 4.04296875, 'step_loss': 4.04296875, 'learning_rate': 0.00146989898989899, 'seq/s': 24308.420433038424, 'global_steps': 134, 'samples_trained': 686080, 'skipped_steps': 8, 'timestamp': 1592975827.4684963}
  0: {'training_steps': 143, 'average_loss': 3.212890625, 'step_loss': 3.212890625, 'learning_rate': 0.0014681818181818181, 'seq/s': 21281.873730882093, 'global_steps': 135, 'samples_trained': 691200, 'skipped_steps': 8, 'timestamp': 1592975827.7090776}
  0: {'training_steps': 144, 'average_loss': 3.8046875, 'step_loss': 3.8046875, 'learning_rate': 0.0014664646464646464, 'seq/s': 21557.14164680751, 'global_steps': 136, 'samples_trained': 696320, 'skipped_steps': 8, 'timestamp': 1592975827.9465864}
  0: {'training_steps': 145, 'average_loss': 2.845703125, 'step_loss': 2.845703125, 'learning_rate': 0.0014647474747474746, 'seq/s': 24293.653374722417, 'global_steps': 137, 'samples_trained': 701440, 'skipped_steps': 8, 'timestamp': 1592975828.1573415}
  0: {'training_steps': 146, 'average_loss': 3.234375, 'step_loss': 3.234375, 'learning_rate': 0.001463030303030303, 'seq/s': 24283.57149318811, 'global_steps': 138, 'samples_trained': 706560, 'skipped_steps': 8, 'timestamp': 1592975828.368184}
  0: {'training_steps': 147, 'average_loss': 2.8359375, 'step_loss': 2.8359375, 'learning_rate': 0.0014613131313131313, 'seq/s': 24184.899588262324, 'global_steps': 139, 'samples_trained': 711680, 'skipped_steps': 8, 'timestamp': 1592975828.579887}
  0: {'training_steps': 148, 'average_loss': 3.244140625, 'step_loss': 3.244140625, 'learning_rate': 0.0014595959595959595, 'seq/s': 24299.453560816422, 'global_steps': 140, 'samples_trained': 716800, 'skipped_steps': 8, 'timestamp': 1592975828.7905917}
  0: {'training_steps': 149, 'average_loss': 3.53125, 'step_loss': 3.53125, 'learning_rate': 0.0014578787878787877, 'seq/s': 24253.2116465995, 'global_steps': 141, 'samples_trained': 721920, 'skipped_steps': 8, 'timestamp': 1592975829.0016983}
  0: {'training_steps': 150, 'average_loss': 3.25, 'step_loss': 3.25, 'learning_rate': 0.001456161616161616, 'seq/s': 24272.784638007797, 'global_steps': 142, 'samples_trained': 727040, 'skipped_steps': 8, 'timestamp': 1592975829.2126346}
  0: {'training_steps': 151, 'average_loss': 3.51171875, 'step_loss': 3.51171875, 'learning_rate': 0.0014544444444444444, 'seq/s': 24180.35187043061, 'global_steps': 143, 'samples_trained': 732160, 'skipped_steps': 8, 'timestamp': 1592975829.4243777}
  0: {'training_steps': 152, 'average_loss': 3.638671875, 'step_loss': 3.638671875, 'learning_rate': 0.0014527272727272726, 'seq/s': 24142.593007307478, 'global_steps': 144, 'samples_trained': 737280, 'skipped_steps': 8, 'timestamp': 1592975829.6364515}
  0: {'training_steps': 153, 'average_loss': 3.13671875, 'step_loss': 3.13671875, 'learning_rate': 0.001451010101010101, 'seq/s': 23052.033564445817, 'global_steps': 145, 'samples_trained': 742400, 'skipped_steps': 8, 'timestamp': 1592975829.8585582}
  0: {'training_steps': 154, 'average_loss': 2.681640625, 'step_loss': 2.681640625, 'learning_rate': 0.001449292929292929, 'seq/s': 24324.445239848217, 'global_steps': 146, 'samples_trained': 747520, 'skipped_steps': 8, 'timestamp': 1592975830.0690465}
  0: {'training_steps': 155, 'average_loss': 3.408203125, 'step_loss': 3.408203125, 'learning_rate': 0.0014475757575757575, 'seq/s': 24217.409692901736, 'global_steps': 147, 'samples_trained': 752640, 'skipped_steps': 8, 'timestamp': 1592975830.2804651}
  0: {'training_steps': 156, 'average_loss': 3.71484375, 'step_loss': 3.71484375, 'learning_rate': 0.0014458585858585858, 'seq/s': 24136.86745471282, 'global_steps': 148, 'samples_trained': 757760, 'skipped_steps': 8, 'timestamp': 1592975830.4925895}
  0: {'training_steps': 157, 'average_loss': 3.400390625, 'step_loss': 3.400390625, 'learning_rate': 0.0014441414141414142, 'seq/s': 24238.019137740717, 'global_steps': 149, 'samples_trained': 762880, 'skipped_steps': 8, 'timestamp': 1592975830.7038286}
  0: {'training_steps': 158, 'average_loss': 3.513671875, 'step_loss': 3.513671875, 'learning_rate': 0.0014424242424242424, 'seq/s': 24146.013353212486, 'global_steps': 150, 'samples_trained': 768000, 'skipped_steps': 8, 'timestamp': 1592975830.9158723}
  0: {'training_steps': 159, 'average_loss': 4.21484375, 'step_loss': 4.21484375, 'learning_rate': 0.0014407070707070707, 'seq/s': 24229.48683869075, 'global_steps': 151, 'samples_trained': 773120, 'skipped_steps': 8, 'timestamp': 1592975831.1271858}
  0: {'training_steps': 160, 'average_loss': 2.740234375, 'step_loss': 2.740234375, 'learning_rate': 0.001438989898989899, 'seq/s': 23947.833448938036, 'global_steps': 152, 'samples_trained': 778240, 'skipped_steps': 8, 'timestamp': 1592975831.3409843}
  0: {'training_steps': 161, 'average_loss': 3.748046875, 'step_loss': 3.748046875, 'learning_rate': 0.0014372727272727271, 'seq/s': 23180.37924360686, 'global_steps': 153, 'samples_trained': 783360, 'skipped_steps': 8, 'timestamp': 1592975831.5618613}
  0: {'training_steps': 162, 'average_loss': 3.21484375, 'step_loss': 3.21484375, 'learning_rate': 0.0014355555555555554, 'seq/s': 24319.98260499291, 'global_steps': 154, 'samples_trained': 788480, 'skipped_steps': 8, 'timestamp': 1592975831.7723885}
  0: {'training_steps': 163, 'average_loss': 3.7109375, 'step_loss': 3.7109375, 'learning_rate': 0.0014338383838383838, 'seq/s': 24297.061679366856, 'global_steps': 155, 'samples_trained': 793600, 'skipped_steps': 8, 'timestamp': 1592975831.983114}
  0: {'training_steps': 164, 'average_loss': 3.302734375, 'step_loss': 3.302734375, 'learning_rate': 0.001432121212121212, 'seq/s': 24141.507385839872, 'global_steps': 156, 'samples_trained': 798720, 'skipped_steps': 8, 'timestamp': 1592975832.1951973}
  0: {'training_steps': 165, 'average_loss': 2.75390625, 'step_loss': 2.75390625, 'learning_rate': 0.0014304040404040403, 'seq/s': 24278.190591182683, 'global_steps': 157, 'samples_trained': 803840, 'skipped_steps': 8, 'timestamp': 1592975832.4060867}
  0: {'training_steps': 166, 'average_loss': 3.412109375, 'step_loss': 3.412109375, 'learning_rate': 0.0014286868686868685, 'seq/s': 24184.70893101083, 'global_steps': 158, 'samples_trained': 808960, 'skipped_steps': 8, 'timestamp': 1592975832.6177912}
  0: {'training_steps': 167, 'average_loss': 3.890625, 'step_loss': 3.890625, 'learning_rate': 0.0014269696969696967, 'seq/s': 24122.416416173543, 'global_steps': 159, 'samples_trained': 814080, 'skipped_steps': 8, 'timestamp': 1592975832.8300426}
  0: {'training_steps': 168, 'average_loss': 3.712890625, 'step_loss': 3.712890625, 'learning_rate': 0.0014252525252525252, 'seq/s': 24239.33233252441, 'global_steps': 160, 'samples_trained': 819200, 'skipped_steps': 8, 'timestamp': 1592975833.0412703}
  0: {'training_steps': 169, 'average_loss': 3.90625, 'step_loss': 3.90625, 'learning_rate': 0.0014235353535353534, 'seq/s': 24081.894180155246, 'global_steps': 161, 'samples_trained': 824320, 'skipped_steps': 8, 'timestamp': 1592975833.2538786}
  0: {'training_steps': 170, 'average_loss': 3.37109375, 'step_loss': 3.37109375, 'learning_rate': 0.0014218181818181819, 'seq/s': 24264.52942838096, 'global_steps': 162, 'samples_trained': 829440, 'skipped_steps': 8, 'timestamp': 1592975833.4648867}
  0: {'training_steps': 171, 'average_loss': 2.953125, 'step_loss': 2.953125, 'learning_rate': 0.0014201010101010099, 'seq/s': 24221.042499653176, 'global_steps': 163, 'samples_trained': 834560, 'skipped_steps': 8, 'timestamp': 1592975833.6762736}
  0: {'training_steps': 172, 'average_loss': 3.421875, 'step_loss': 3.421875, 'learning_rate': 0.0014183838383838383, 'seq/s': 24196.589894255307, 'global_steps': 164, 'samples_trained': 839680, 'skipped_steps': 8, 'timestamp': 1592975833.8878741}
  0: {'training_steps': 173, 'average_loss': 3.4375, 'step_loss': 3.4375, 'learning_rate': 0.0014166666666666666, 'seq/s': 24289.421811218574, 'global_steps': 165, 'samples_trained': 844800, 'skipped_steps': 8, 'timestamp': 1592975834.098666}
  0: {'training_steps': 174, 'average_loss': 2.34765625, 'step_loss': 2.34765625, 'learning_rate': 0.001414949494949495, 'seq/s': 24309.68623002855, 'global_steps': 166, 'samples_trained': 849920, 'skipped_steps': 8, 'timestamp': 1592975834.3092823}
  0: {'training_steps': 175, 'average_loss': 3.44921875, 'step_loss': 3.44921875, 'learning_rate': 0.0014132323232323232, 'seq/s': 24250.50023601365, 'global_steps': 167, 'samples_trained': 855040, 'skipped_steps': 8, 'timestamp': 1592975834.5204124}
  0: {'training_steps': 176, 'average_loss': 3.6953125, 'step_loss': 3.6953125, 'learning_rate': 0.0014115151515151515, 'seq/s': 23957.531513179252, 'global_steps': 168, 'samples_trained': 860160, 'skipped_steps': 8, 'timestamp': 1592975834.7341247}
  0: {'training_steps': 177, 'average_loss': 3.15234375, 'step_loss': 3.15234375, 'learning_rate': 0.0014097979797979797, 'seq/s': 23598.17683328187, 'global_steps': 169, 'samples_trained': 865280, 'skipped_steps': 8, 'timestamp': 1592975834.9510913}
  0: {'training_steps': 178, 'average_loss': 3.314453125, 'step_loss': 3.314453125, 'learning_rate': 0.001408080808080808, 'seq/s': 24308.64056217626, 'global_steps': 170, 'samples_trained': 870400, 'skipped_steps': 8, 'timestamp': 1592975835.1617165}
  0: {'training_steps': 179, 'average_loss': 3.0546875, 'step_loss': 3.0546875, 'learning_rate': 0.0014063636363636364, 'seq/s': 24250.965788656446, 'global_steps': 171, 'samples_trained': 875520, 'skipped_steps': 8, 'timestamp': 1592975835.3728426}
  0: {'training_steps': 180, 'average_loss': 3.478515625, 'step_loss': 3.478515625, 'learning_rate': 0.0014046464646464646, 'seq/s': 24261.760665935326, 'global_steps': 172, 'samples_trained': 880640, 'skipped_steps': 8, 'timestamp': 1592975835.5838747}
  0: {'training_steps': 181, 'average_loss': 2.75390625, 'step_loss': 2.75390625, 'learning_rate': 0.0014029292929292928, 'seq/s': 24228.83075680274, 'global_steps': 173, 'samples_trained': 885760, 'skipped_steps': 8, 'timestamp': 1592975835.7951937}
  0: {'training_steps': 182, 'average_loss': 2.958984375, 'step_loss': 2.958984375, 'learning_rate': 0.001401212121212121, 'seq/s': 24182.91145327173, 'global_steps': 174, 'samples_trained': 890880, 'skipped_steps': 8, 'timestamp': 1592975836.0069141}
  0: {'training_steps': 183, 'average_loss': 3.455078125, 'step_loss': 3.455078125, 'learning_rate': 0.0013994949494949493, 'seq/s': 24170.33658645843, 'global_steps': 175, 'samples_trained': 896000, 'skipped_steps': 8, 'timestamp': 1592975836.2187448}
  0: {'training_steps': 184, 'average_loss': 2.89453125, 'step_loss': 2.89453125, 'learning_rate': 0.0013977777777777777, 'seq/s': 24220.35955806389, 'global_steps': 176, 'samples_trained': 901120, 'skipped_steps': 8, 'timestamp': 1592975836.4301376}
  0: {'training_steps': 185, 'average_loss': 3.13671875, 'step_loss': 3.13671875, 'learning_rate': 0.001396060606060606, 'seq/s': 23435.266858515388, 'global_steps': 177, 'samples_trained': 906240, 'skipped_steps': 8, 'timestamp': 1592975836.6486123}
  0: {'training_steps': 186, 'average_loss': 3.4453125, 'step_loss': 3.4453125, 'learning_rate': 0.0013943434343434342, 'seq/s': 24357.912020480086, 'global_steps': 178, 'samples_trained': 911360, 'skipped_steps': 8, 'timestamp': 1592975836.8588114}
  0: {'training_steps': 187, 'average_loss': 3.015625, 'step_loss': 3.015625, 'learning_rate': 0.0013926262626262626, 'seq/s': 24160.65577975665, 'global_steps': 179, 'samples_trained': 916480, 'skipped_steps': 8, 'timestamp': 1592975837.0707269}
  0: {'training_steps': 188, 'average_loss': 3.0, 'step_loss': 3.0, 'learning_rate': 0.0013909090909090907, 'seq/s': 24152.367996041117, 'global_steps': 180, 'samples_trained': 921600, 'skipped_steps': 8, 'timestamp': 1592975837.2827148}
  0: {'training_steps': 189, 'average_loss': 3.58984375, 'step_loss': 3.58984375, 'learning_rate': 0.001389191919191919, 'seq/s': 24196.453578510907, 'global_steps': 181, 'samples_trained': 926720, 'skipped_steps': 8, 'timestamp': 1592975837.4943166}
  0: {'training_steps': 190, 'average_loss': 3.220703125, 'step_loss': 3.220703125, 'learning_rate': 0.0013874747474747475, 'seq/s': 24313.869801207835, 'global_steps': 182, 'samples_trained': 931840, 'skipped_steps': 8, 'timestamp': 1592975837.7048965}
  0: {'training_steps': 191, 'average_loss': 2.939453125, 'step_loss': 2.939453125, 'learning_rate': 0.0013857575757575758, 'seq/s': 24222.517784933985, 'global_steps': 183, 'samples_trained': 936960, 'skipped_steps': 8, 'timestamp': 1592975837.9162705}
  0: {'training_steps': 192, 'average_loss': 3.31640625, 'step_loss': 3.31640625, 'learning_rate': 0.001384040404040404, 'seq/s': 24274.760138675214, 'global_steps': 184, 'samples_trained': 942080, 'skipped_steps': 8, 'timestamp': 1592975838.1271894}
  0: {'training_steps': 193, 'average_loss': 2.7421875, 'step_loss': 2.7421875, 'learning_rate': 0.0013823232323232322, 'seq/s': 24127.91824196863, 'global_steps': 185, 'samples_trained': 947200, 'skipped_steps': 8, 'timestamp': 1592975838.3393922}
  0: {'training_steps': 194, 'average_loss': 3.41796875, 'step_loss': 3.41796875, 'learning_rate': 0.0013806060606060605, 'seq/s': 24124.069410447064, 'global_steps': 186, 'samples_trained': 952320, 'skipped_steps': 8, 'timestamp': 1592975838.5516288}
  0: {'training_steps': 195, 'average_loss': 3.59375, 'step_loss': 3.59375, 'learning_rate': 0.001378888888888889, 'seq/s': 24218.201715755655, 'global_steps': 187, 'samples_trained': 957440, 'skipped_steps': 8, 'timestamp': 1592975838.7630405}
  0: {'training_steps': 196, 'average_loss': 2.662109375, 'step_loss': 2.662109375, 'learning_rate': 0.0013771717171717171, 'seq/s': 24263.54247027905, 'global_steps': 188, 'samples_trained': 962560, 'skipped_steps': 8, 'timestamp': 1592975838.9740572}
  0: {'training_steps': 197, 'average_loss': 2.951171875, 'step_loss': 2.951171875, 'learning_rate': 0.0013754545454545454, 'seq/s': 24201.116449108526, 'global_steps': 189, 'samples_trained': 967680, 'skipped_steps': 8, 'timestamp': 1592975839.1856182}
  0: {'training_steps': 198, 'average_loss': 2.7734375, 'step_loss': 2.7734375, 'learning_rate': 0.0013737373737373736, 'seq/s': 24272.318247270967, 'global_steps': 190, 'samples_trained': 972800, 'skipped_steps': 8, 'timestamp': 1592975839.3965585}
  0: {'training_steps': 199, 'average_loss': 3.3671875, 'step_loss': 3.3671875, 'learning_rate': 0.0013720202020202018, 'seq/s': 24194.35450998595, 'global_steps': 191, 'samples_trained': 977920, 'skipped_steps': 8, 'timestamp': 1592975839.6081786}
  0: {'training_steps': 200, 'average_loss': 3.158203125, 'step_loss': 3.158203125, 'learning_rate': 0.0013703030303030303, 'seq/s': 24236.45990373058, 'global_steps': 192, 'samples_trained': 983040, 'skipped_steps': 8, 'timestamp': 1592975839.819431}
  0: {'training_steps': 201, 'average_loss': 3.12109375, 'step_loss': 3.12109375, 'learning_rate': 0.0013685858585858585, 'seq/s': 24122.66028632889, 'global_steps': 193, 'samples_trained': 988160, 'skipped_steps': 8, 'timestamp': 1592975840.0316803}
  0: {'training_steps': 202, 'average_loss': 3.359375, 'step_loss': 3.359375, 'learning_rate': 0.0013668686868686867, 'seq/s': 23501.64154881101, 'global_steps': 194, 'samples_trained': 993280, 'skipped_steps': 8, 'timestamp': 1592975840.249538}
  0: {'training_steps': 203, 'average_loss': 2.982421875, 'step_loss': 2.982421875, 'learning_rate': 0.001365151515151515, 'seq/s': 24248.22750035286, 'global_steps': 195, 'samples_trained': 998400, 'skipped_steps': 8, 'timestamp': 1592975840.4606879}
  0: {'training_steps': 204, 'average_loss': 3.220703125, 'step_loss': 3.220703125, 'learning_rate': 0.0013634343434343434, 'seq/s': 23988.38772232015, 'global_steps': 196, 'samples_trained': 1003520, 'skipped_steps': 8, 'timestamp': 1592975840.674125}
  0: {'training_steps': 205, 'average_loss': 3.072265625, 'step_loss': 3.072265625, 'learning_rate': 0.0013617171717171714, 'seq/s': 23490.63865489227, 'global_steps': 197, 'samples_trained': 1008640, 'skipped_steps': 8, 'timestamp': 1592975840.892085}
  0: {'training_steps': 206, 'average_loss': 2.71875, 'step_loss': 2.71875, 'learning_rate': 0.00136, 'seq/s': 24342.284576225655, 'global_steps': 198, 'samples_trained': 1013760, 'skipped_steps': 8, 'timestamp': 1592975841.1024191}
  0: {'training_steps': 207, 'average_loss': 2.802734375, 'step_loss': 2.802734375, 'learning_rate': 0.0013582828282828283, 'seq/s': 24180.89641714644, 'global_steps': 199, 'samples_trained': 1018880, 'skipped_steps': 8, 'timestamp': 1592975841.3141568}
  0: {'training_steps': 208, 'average_loss': 3.166015625, 'step_loss': 3.166015625, 'learning_rate': 0.0013565656565656566, 'seq/s': 21427.887977441427, 'global_steps': 200, 'samples_trained': 1024000, 'skipped_steps': 8, 'timestamp': 1592975841.5530982}
  0: {'training_steps': 209, 'average_loss': 3.28125, 'step_loss': 3.28125, 'learning_rate': 0.0013548484848484848, 'seq/s': 24127.02368567108, 'global_steps': 201, 'samples_trained': 1029120, 'skipped_steps': 8, 'timestamp': 1592975841.7653089}
  0: {'training_steps': 210, 'average_loss': 3.0546875, 'step_loss': 3.0546875, 'learning_rate': 0.001353131313131313, 'seq/s': 24292.141932798204, 'global_steps': 202, 'samples_trained': 1034240, 'skipped_steps': 8, 'timestamp': 1592975841.976077}
  0: {'training_steps': 211, 'average_loss': 3.28125, 'step_loss': 3.28125, 'learning_rate': 0.0013514141414141415, 'seq/s': 24124.828237778813, 'global_steps': 203, 'samples_trained': 1039360, 'skipped_steps': 8, 'timestamp': 1592975842.1883073}
  0: {'training_steps': 212, 'average_loss': 2.333984375, 'step_loss': 2.333984375, 'learning_rate': 0.0013496969696969697, 'seq/s': 21764.54432957092, 'global_steps': 204, 'samples_trained': 1044480, 'skipped_steps': 8, 'timestamp': 1592975842.423553}
  0: {'training_steps': 213, 'average_loss': 3.150390625, 'step_loss': 3.150390625, 'learning_rate': 0.001347979797979798, 'seq/s': 24213.368451911152, 'global_steps': 205, 'samples_trained': 1049600, 'skipped_steps': 8, 'timestamp': 1592975842.635007}
  0: {'training_steps': 214, 'average_loss': 2.927734375, 'step_loss': 2.927734375, 'learning_rate': 0.0013462626262626262, 'seq/s': 24176.159682076857, 'global_steps': 206, 'samples_trained': 1054720, 'skipped_steps': 8, 'timestamp': 1592975842.8467863}
  0: {'training_steps': 215, 'average_loss': 2.59765625, 'step_loss': 2.59765625, 'learning_rate': 0.0013445454545454544, 'seq/s': 24232.6584021106, 'global_steps': 207, 'samples_trained': 1059840, 'skipped_steps': 8, 'timestamp': 1592975843.0580719}
  0: {'training_steps': 216, 'average_loss': 3.392578125, 'step_loss': 3.392578125, 'learning_rate': 0.0013428282828282826, 'seq/s': 21433.21318000443, 'global_steps': 208, 'samples_trained': 1064960, 'skipped_steps': 8, 'timestamp': 1592975843.2969537}
  0: {'training_steps': 217, 'average_loss': 2.833984375, 'step_loss': 2.833984375, 'learning_rate': 0.001341111111111111, 'seq/s': 24238.538926994883, 'global_steps': 209, 'samples_trained': 1070080, 'skipped_steps': 8, 'timestamp': 1592975843.5081882}
  0: {'training_steps': 218, 'average_loss': 3.283203125, 'step_loss': 3.283203125, 'learning_rate': 0.0013393939393939393, 'seq/s': 24132.961527439864, 'global_steps': 210, 'samples_trained': 1075200, 'skipped_steps': 8, 'timestamp': 1592975843.7203467}
  0: {'training_steps': 219, 'average_loss': 2.755859375, 'step_loss': 2.755859375, 'learning_rate': 0.0013376767676767675, 'seq/s': 24239.359692262195, 'global_steps': 211, 'samples_trained': 1080320, 'skipped_steps': 8, 'timestamp': 1592975843.931574}
  0: {'training_steps': 220, 'average_loss': 2.8671875, 'step_loss': 2.8671875, 'learning_rate': 0.0013359595959595958, 'seq/s': 24158.861875506947, 'global_steps': 212, 'samples_trained': 1085440, 'skipped_steps': 8, 'timestamp': 1592975844.143505}
  0: {'training_steps': 221, 'average_loss': 3.0078125, 'step_loss': 3.0078125, 'learning_rate': 0.0013342424242424242, 'seq/s': 24245.51720400486, 'global_steps': 213, 'samples_trained': 1090560, 'skipped_steps': 8, 'timestamp': 1592975844.3546789}
  0: {'training_steps': 222, 'average_loss': 3.359375, 'step_loss': 3.359375, 'learning_rate': 0.0013325252525252524, 'seq/s': 24140.530409993076, 'global_steps': 214, 'samples_trained': 1095680, 'skipped_steps': 8, 'timestamp': 1592975844.566771}
  0: {'training_steps': 223, 'average_loss': 2.072265625, 'step_loss': 2.072265625, 'learning_rate': 0.0013308080808080809, 'seq/s': 24213.559561299953, 'global_steps': 215, 'samples_trained': 1100800, 'skipped_steps': 8, 'timestamp': 1592975844.7782233}
  0: {'training_steps': 224, 'average_loss': 3.11328125, 'step_loss': 3.11328125, 'learning_rate': 0.001329090909090909, 'seq/s': 24184.02803679379, 'global_steps': 216, 'samples_trained': 1105920, 'skipped_steps': 8, 'timestamp': 1592975844.9899337}
  0: {'training_steps': 225, 'average_loss': 3.125, 'step_loss': 3.125, 'learning_rate': 0.0013273737373737373, 'seq/s': 24219.567394067486, 'global_steps': 217, 'samples_trained': 1111040, 'skipped_steps': 8, 'timestamp': 1592975845.2013335}
  0: {'training_steps': 226, 'average_loss': 3.357421875, 'step_loss': 3.357421875, 'learning_rate': 0.0013256565656565656, 'seq/s': 24266.092276261537, 'global_steps': 218, 'samples_trained': 1116160, 'skipped_steps': 8, 'timestamp': 1592975845.412328}
  0: {'training_steps': 227, 'average_loss': 2.0859375, 'step_loss': 2.0859375, 'learning_rate': 0.0013239393939393938, 'seq/s': 23260.599201930618, 'global_steps': 219, 'samples_trained': 1121280, 'skipped_steps': 8, 'timestamp': 1592975845.6324432}
  0: {'training_steps': 228, 'average_loss': 3.146484375, 'step_loss': 3.146484375, 'learning_rate': 0.0013222222222222222, 'seq/s': 24218.556777300357, 'global_steps': 220, 'samples_trained': 1126400, 'skipped_steps': 8, 'timestamp': 1592975845.8438518}
  0: {'training_steps': 229, 'average_loss': 3.48046875, 'step_loss': 3.48046875, 'learning_rate': 0.0013205050505050505, 'seq/s': 23976.09459660123, 'global_steps': 221, 'samples_trained': 1131520, 'skipped_steps': 8, 'timestamp': 1592975846.0573986}
  0: {'training_steps': 230, 'average_loss': 2.634765625, 'step_loss': 2.634765625, 'learning_rate': 0.0013187878787878787, 'seq/s': 24219.540078991828, 'global_steps': 222, 'samples_trained': 1136640, 'skipped_steps': 8, 'timestamp': 1592975846.2687988}
  0: {'training_steps': 231, 'average_loss': 2.7421875, 'step_loss': 2.7421875, 'learning_rate': 0.001317070707070707, 'seq/s': 24306.05429657347, 'global_steps': 223, 'samples_trained': 1141760, 'skipped_steps': 8, 'timestamp': 1592975846.4794464}
  0: {'training_steps': 232, 'average_loss': 2.50390625, 'step_loss': 2.50390625, 'learning_rate': 0.0013153535353535352, 'seq/s': 22918.201918633626, 'global_steps': 224, 'samples_trained': 1146880, 'skipped_steps': 8, 'timestamp': 1592975846.70285}
  0: {'training_steps': 233, 'average_loss': 2.685546875, 'step_loss': 2.685546875, 'learning_rate': 0.0013136363636363636, 'seq/s': 24269.410568095005, 'global_steps': 225, 'samples_trained': 1152000, 'skipped_steps': 8, 'timestamp': 1592975846.9138157}
  0: {'training_steps': 234, 'average_loss': 2.6796875, 'step_loss': 2.6796875, 'learning_rate': 0.0013119191919191918, 'seq/s': 24288.927309105675, 'global_steps': 226, 'samples_trained': 1157120, 'skipped_steps': 8, 'timestamp': 1592975847.1246119}
  0: {'training_steps': 235, 'average_loss': 3.26953125, 'step_loss': 3.26953125, 'learning_rate': 0.00131020202020202, 'seq/s': 24289.229502448736, 'global_steps': 227, 'samples_trained': 1162240, 'skipped_steps': 8, 'timestamp': 1592975847.3354053}
  0: {'training_steps': 236, 'average_loss': 3.001953125, 'step_loss': 3.001953125, 'learning_rate': 0.0013084848484848483, 'seq/s': 24238.42949582554, 'global_steps': 228, 'samples_trained': 1167360, 'skipped_steps': 8, 'timestamp': 1592975847.5466406}
  0: {'training_steps': 237, 'average_loss': 2.91796875, 'step_loss': 2.91796875, 'learning_rate': 0.0013067676767676765, 'seq/s': 24194.29999357818, 'global_steps': 229, 'samples_trained': 1172480, 'skipped_steps': 8, 'timestamp': 1592975847.7582612}
  0: {'training_steps': 238, 'average_loss': 2.396484375, 'step_loss': 2.396484375, 'learning_rate': 0.001305050505050505, 'seq/s': 23935.28838480435, 'global_steps': 230, 'samples_trained': 1177600, 'skipped_steps': 8, 'timestamp': 1592975847.972172}
  0: {'training_steps': 239, 'average_loss': 1.931640625, 'step_loss': 1.931640625, 'learning_rate': 0.0013033333333333332, 'seq/s': 24110.09384764101, 'global_steps': 231, 'samples_trained': 1182720, 'skipped_steps': 8, 'timestamp': 1592975848.1845317}
  0: {'training_steps': 240, 'average_loss': 3.037109375, 'step_loss': 3.037109375, 'learning_rate': 0.0013016161616161617, 'seq/s': 24147.968271745707, 'global_steps': 232, 'samples_trained': 1187840, 'skipped_steps': 8, 'timestamp': 1592975848.3965583}
  0: {'training_steps': 241, 'average_loss': 3.244140625, 'step_loss': 3.244140625, 'learning_rate': 0.0012998989898989899, 'seq/s': 24197.05337927522, 'global_steps': 233, 'samples_trained': 1192960, 'skipped_steps': 8, 'timestamp': 1592975848.6081553}
  0: {'training_steps': 242, 'average_loss': 3.005859375, 'step_loss': 3.005859375, 'learning_rate': 0.0012981818181818181, 'seq/s': 24213.914486740032, 'global_steps': 234, 'samples_trained': 1198080, 'skipped_steps': 8, 'timestamp': 1592975848.8196044}
  0: {'training_steps': 243, 'average_loss': 3.03515625, 'step_loss': 3.03515625, 'learning_rate': 0.0012964646464646463, 'seq/s': 24180.188511198412, 'global_steps': 235, 'samples_trained': 1203200, 'skipped_steps': 8, 'timestamp': 1592975849.0313485}
  0: {'training_steps': 244, 'average_loss': 3.046875, 'step_loss': 3.046875, 'learning_rate': 0.0012947474747474748, 'seq/s': 24144.737396575976, 'global_steps': 236, 'samples_trained': 1208320, 'skipped_steps': 8, 'timestamp': 1592975849.2434034}
  0: {'training_steps': 245, 'average_loss': 3.181640625, 'step_loss': 3.181640625, 'learning_rate': 0.001293030303030303, 'seq/s': 24262.555592462788, 'global_steps': 237, 'samples_trained': 1213440, 'skipped_steps': 8, 'timestamp': 1592975849.4544287}
  0: {'training_steps': 246, 'average_loss': 2.896484375, 'step_loss': 2.896484375, 'learning_rate': 0.0012913131313131313, 'seq/s': 24213.25924790056, 'global_steps': 238, 'samples_trained': 1218560, 'skipped_steps': 8, 'timestamp': 1592975849.6658835}
  0: {'training_steps': 247, 'average_loss': 2.833984375, 'step_loss': 2.833984375, 'learning_rate': 0.0012895959595959595, 'seq/s': 24266.832642895726, 'global_steps': 239, 'samples_trained': 1223680, 'skipped_steps': 8, 'timestamp': 1592975849.8768718}
  0: {'training_steps': 248, 'average_loss': 2.93359375, 'step_loss': 2.93359375, 'learning_rate': 0.0012878787878787877, 'seq/s': 24179.072282184025, 'global_steps': 240, 'samples_trained': 1228800, 'skipped_steps': 8, 'timestamp': 1592975850.088626}
  0: {'training_steps': 249, 'average_loss': 2.8671875, 'step_loss': 2.8671875, 'learning_rate': 0.0012861616161616162, 'seq/s': 24203.325804604698, 'global_steps': 241, 'samples_trained': 1233920, 'skipped_steps': 8, 'timestamp': 1592975850.3001678}
  0: {'training_steps': 250, 'average_loss': 2.919921875, 'step_loss': 2.919921875, 'learning_rate': 0.0012844444444444444, 'seq/s': 24177.629504701024, 'global_steps': 242, 'samples_trained': 1239040, 'skipped_steps': 8, 'timestamp': 1592975850.5119343}
  0: {'training_steps': 251, 'average_loss': 2.716796875, 'step_loss': 2.716796875, 'learning_rate': 0.0012827272727272726, 'seq/s': 24155.193355499665, 'global_steps': 243, 'samples_trained': 1244160, 'skipped_steps': 8, 'timestamp': 1592975850.7238977}
  0: {'training_steps': 252, 'average_loss': 2.75, 'step_loss': 2.75, 'learning_rate': 0.0012810101010101009, 'seq/s': 24186.506675977183, 'global_steps': 244, 'samples_trained': 1249280, 'skipped_steps': 8, 'timestamp': 1592975850.9355865}
  0: {'training_steps': 253, 'average_loss': 2.64453125, 'step_loss': 2.64453125, 'learning_rate': 0.001279292929292929, 'seq/s': 22911.9911232029, 'global_steps': 245, 'samples_trained': 1254400, 'skipped_steps': 8, 'timestamp': 1592975851.159051}
  0: {'training_steps': 254, 'average_loss': 2.443359375, 'step_loss': 2.443359375, 'learning_rate': 0.0012775757575757575, 'seq/s': 24137.355784523425, 'global_steps': 246, 'samples_trained': 1259520, 'skipped_steps': 8, 'timestamp': 1592975851.3711708}
  0: {'training_steps': 255, 'average_loss': 2.642578125, 'step_loss': 2.642578125, 'learning_rate': 0.001275858585858586, 'seq/s': 24238.757792297944, 'global_steps': 247, 'samples_trained': 1264640, 'skipped_steps': 8, 'timestamp': 1592975851.5824034}
  0: {'training_steps': 256, 'average_loss': 2.50390625, 'step_loss': 2.50390625, 'learning_rate': 0.001274141414141414, 'seq/s': 23071.326103725605, 'global_steps': 248, 'samples_trained': 1269760, 'skipped_steps': 8, 'timestamp': 1592975851.8043242}
  0: {'training_steps': 257, 'average_loss': 2.439453125, 'step_loss': 2.439453125, 'learning_rate': 0.0012724242424242424, 'seq/s': 24112.09710035088, 'global_steps': 249, 'samples_trained': 1274880, 'skipped_steps': 8, 'timestamp': 1592975852.0166662}
  0: {'training_steps': 258, 'average_loss': 2.65234375, 'step_loss': 2.65234375, 'learning_rate': 0.0012707070707070705, 'seq/s': 24251.07533305252, 'global_steps': 250, 'samples_trained': 1280000, 'skipped_steps': 8, 'timestamp': 1592975852.2277913}
  0: {'training_steps': 259, 'average_loss': 2.474609375, 'step_loss': 2.474609375, 'learning_rate': 0.001268989898989899, 'seq/s': 24208.100481009318, 'global_steps': 251, 'samples_trained': 1285120, 'skipped_steps': 8, 'timestamp': 1592975852.4392915}
  0: {'training_steps': 260, 'average_loss': 1.4775390625, 'step_loss': 1.4775390625, 'learning_rate': 0.0012672727272727273, 'seq/s': 21486.654139776878, 'global_steps': 252, 'samples_trained': 1290240, 'skipped_steps': 8, 'timestamp': 1592975852.6775794}
  0: {'training_steps': 261, 'average_loss': 2.626953125, 'step_loss': 2.626953125, 'learning_rate': 0.0012655555555555556, 'seq/s': 24080.381969907983, 'global_steps': 253, 'samples_trained': 1295360, 'skipped_steps': 8, 'timestamp': 1592975852.890201}
  0: {'training_steps': 262, 'average_loss': 3.01171875, 'step_loss': 3.01171875, 'learning_rate': 0.0012638383838383838, 'seq/s': 24227.163375244672, 'global_steps': 254, 'samples_trained': 1300480, 'skipped_steps': 8, 'timestamp': 1592975853.1015346}
  0: {'training_steps': 263, 'average_loss': 2.728515625, 'step_loss': 2.728515625, 'learning_rate': 0.001262121212121212, 'seq/s': 24103.382670349638, 'global_steps': 255, 'samples_trained': 1305600, 'skipped_steps': 8, 'timestamp': 1592975853.3139536}
  0: {'training_steps': 264, 'average_loss': 2.525390625, 'step_loss': 2.525390625, 'learning_rate': 0.0012604040404040403, 'seq/s': 21681.942393745052, 'global_steps': 256, 'samples_trained': 1310720, 'skipped_steps': 8, 'timestamp': 1592975853.5500953}
  0: {'training_steps': 265, 'average_loss': 3.11328125, 'step_loss': 3.11328125, 'learning_rate': 0.0012586868686868687, 'seq/s': 24210.092760027957, 'global_steps': 257, 'samples_trained': 1315840, 'skipped_steps': 8, 'timestamp': 1592975853.761578}
  0: {'training_steps': 266, 'average_loss': 2.1796875, 'step_loss': 2.1796875, 'learning_rate': 0.001256969696969697, 'seq/s': 24117.32336663552, 'global_steps': 258, 'samples_trained': 1320960, 'skipped_steps': 8, 'timestamp': 1592975853.973874}
  0: {'training_steps': 267, 'average_loss': 2.869140625, 'step_loss': 2.869140625, 'learning_rate': 0.0012552525252525252, 'seq/s': 21395.118269328483, 'global_steps': 259, 'samples_trained': 1326080, 'skipped_steps': 8, 'timestamp': 1592975854.213182}
  0: {'training_steps': 268, 'average_loss': 2.712890625, 'step_loss': 2.712890625, 'learning_rate': 0.0012535353535353534, 'seq/s': 23941.47919890476, 'global_steps': 260, 'samples_trained': 1331200, 'skipped_steps': 8, 'timestamp': 1592975854.4270375}
  0: {'training_steps': 269, 'average_loss': 2.435546875, 'step_loss': 2.435546875, 'learning_rate': 0.0012518181818181816, 'seq/s': 24207.581996410827, 'global_steps': 261, 'samples_trained': 1336320, 'skipped_steps': 8, 'timestamp': 1592975854.6385422}
  0: {'training_steps': 270, 'average_loss': 2.30859375, 'step_loss': 2.30859375, 'learning_rate': 0.00125010101010101, 'seq/s': 24141.778782053443, 'global_steps': 262, 'samples_trained': 1341440, 'skipped_steps': 8, 'timestamp': 1592975854.8506231}
  0: {'training_steps': 271, 'average_loss': 2.03125, 'step_loss': 2.03125, 'learning_rate': 0.0012483838383838383, 'seq/s': 24205.8356853657, 'global_steps': 263, 'samples_trained': 1346560, 'skipped_steps': 8, 'timestamp': 1592975855.0621433}
  0: {'training_steps': 272, 'average_loss': 2.1015625, 'step_loss': 2.1015625, 'learning_rate': 0.0012466666666666668, 'seq/s': 24218.22902781255, 'global_steps': 264, 'samples_trained': 1351680, 'skipped_steps': 8, 'timestamp': 1592975855.273555}
  0: {'training_steps': 273, 'average_loss': 2.18359375, 'step_loss': 2.18359375, 'learning_rate': 0.0012449494949494948, 'seq/s': 24190.32095928448, 'global_steps': 265, 'samples_trained': 1356800, 'skipped_steps': 8, 'timestamp': 1592975855.4852104}
  0: {'training_steps': 274, 'average_loss': 2.392578125, 'step_loss': 2.392578125, 'learning_rate': 0.0012432323232323232, 'seq/s': 24161.3081746288, 'global_steps': 266, 'samples_trained': 1361920, 'skipped_steps': 8, 'timestamp': 1592975855.69712}
  0: {'training_steps': 275, 'average_loss': 2.833984375, 'step_loss': 2.833984375, 'learning_rate': 0.0012415151515151512, 'seq/s': 23950.931701125784, 'global_steps': 267, 'samples_trained': 1367040, 'skipped_steps': 8, 'timestamp': 1592975855.9108908}
  0: {'training_steps': 276, 'average_loss': 2.658203125, 'step_loss': 2.658203125, 'learning_rate': 0.00123979797979798, 'seq/s': 24345.78934241494, 'global_steps': 268, 'samples_trained': 1372160, 'skipped_steps': 8, 'timestamp': 1592975856.1211948}
  0: {'training_steps': 277, 'average_loss': 2.462890625, 'step_loss': 2.462890625, 'learning_rate': 0.0012380808080808081, 'seq/s': 24163.347135707343, 'global_steps': 269, 'samples_trained': 1377280, 'skipped_steps': 8, 'timestamp': 1592975856.3330867}
  0: {'training_steps': 278, 'average_loss': 2.5859375, 'step_loss': 2.5859375, 'learning_rate': 0.0012363636363636364, 'seq/s': 24142.1044655645, 'global_steps': 270, 'samples_trained': 1382400, 'skipped_steps': 8, 'timestamp': 1592975856.5451648}
  0: {'training_steps': 279, 'average_loss': 2.44921875, 'step_loss': 2.44921875, 'learning_rate': 0.0012346464646464646, 'seq/s': 24229.51417620717, 'global_steps': 271, 'samples_trained': 1387520, 'skipped_steps': 8, 'timestamp': 1592975856.7564778}
  0: {'training_steps': 280, 'average_loss': 2.42578125, 'step_loss': 2.42578125, 'learning_rate': 0.0012329292929292928, 'seq/s': 24182.91145327173, 'global_steps': 272, 'samples_trained': 1392640, 'skipped_steps': 8, 'timestamp': 1592975856.968198}
  0: {'training_steps': 281, 'average_loss': 2.091796875, 'step_loss': 2.091796875, 'learning_rate': 0.001231212121212121, 'seq/s': 24057.04782207843, 'global_steps': 273, 'samples_trained': 1397760, 'skipped_steps': 8, 'timestamp': 1592975857.1810262}
  0: {'training_steps': 282, 'average_loss': 2.2421875, 'step_loss': 2.2421875, 'learning_rate': 0.0012294949494949495, 'seq/s': 23069.1450977022, 'global_steps': 274, 'samples_trained': 1402880, 'skipped_steps': 8, 'timestamp': 1592975857.4029684}
  0: {'training_steps': 283, 'average_loss': 2.533203125, 'step_loss': 2.533203125, 'learning_rate': 0.0012277777777777777, 'seq/s': 24384.546926558523, 'global_steps': 275, 'samples_trained': 1408000, 'skipped_steps': 8, 'timestamp': 1592975857.612938}
  0: {'training_steps': 284, 'average_loss': 1.9453125, 'step_loss': 1.9453125, 'learning_rate': 0.001226060606060606, 'seq/s': 24213.341150816155, 'global_steps': 276, 'samples_trained': 1413120, 'skipped_steps': 8, 'timestamp': 1592975857.824392}
  0: {'training_steps': 285, 'average_loss': 2.34375, 'step_loss': 2.34375, 'learning_rate': 0.0012243434343434342, 'seq/s': 24136.243506486207, 'global_steps': 277, 'samples_trained': 1418240, 'skipped_steps': 8, 'timestamp': 1592975858.0365217}
  0: {'training_steps': 286, 'average_loss': 2.865234375, 'step_loss': 2.865234375, 'learning_rate': 0.0012226262626262624, 'seq/s': 24211.129966560766, 'global_steps': 278, 'samples_trained': 1423360, 'skipped_steps': 8, 'timestamp': 1592975858.2479954}
  0: {'training_steps': 287, 'average_loss': 1.7939453125, 'step_loss': 1.7939453125, 'learning_rate': 0.0012209090909090909, 'seq/s': 24188.522647275153, 'global_steps': 279, 'samples_trained': 1428480, 'skipped_steps': 8, 'timestamp': 1592975858.4596665}
  0: {'training_steps': 288, 'average_loss': 2.361328125, 'step_loss': 2.361328125, 'learning_rate': 0.001219191919191919, 'seq/s': 24128.162223380732, 'global_steps': 280, 'samples_trained': 1433600, 'skipped_steps': 8, 'timestamp': 1592975858.6718674}
  0: {'training_steps': 289, 'average_loss': 2.494140625, 'step_loss': 2.494140625, 'learning_rate': 0.0012174747474747475, 'seq/s': 24107.333152971314, 'global_steps': 281, 'samples_trained': 1438720, 'skipped_steps': 8, 'timestamp': 1592975858.8842516}
  0: {'training_steps': 290, 'average_loss': 2.5546875, 'step_loss': 2.5546875, 'learning_rate': 0.0012157575757575755, 'seq/s': 24220.742000609047, 'global_steps': 282, 'samples_trained': 1443840, 'skipped_steps': 8, 'timestamp': 1592975859.0956411}
  0: {'training_steps': 291, 'average_loss': 2.166015625, 'step_loss': 2.166015625, 'learning_rate': 0.001214040404040404, 'seq/s': 24230.08827830231, 'global_steps': 283, 'samples_trained': 1448960, 'skipped_steps': 8, 'timestamp': 1592975859.3069491}
  0: {'training_steps': 292, 'average_loss': 2.451171875, 'step_loss': 2.451171875, 'learning_rate': 0.0012123232323232322, 'seq/s': 24226.75339854018, 'global_steps': 284, 'samples_trained': 1454080, 'skipped_steps': 8, 'timestamp': 1592975859.5182862}
  0: {'training_steps': 293, 'average_loss': 2.228515625, 'step_loss': 2.228515625, 'learning_rate': 0.0012106060606060607, 'seq/s': 24244.69602169451, 'global_steps': 285, 'samples_trained': 1459200, 'skipped_steps': 8, 'timestamp': 1592975859.729467}
  0: {'training_steps': 294, 'average_loss': 2.451171875, 'step_loss': 2.451171875, 'learning_rate': 0.001208888888888889, 'seq/s': 24173.54710528715, 'global_steps': 286, 'samples_trained': 1464320, 'skipped_steps': 8, 'timestamp': 1592975859.9412692}
  0: {'training_steps': 295, 'average_loss': 2.548828125, 'step_loss': 2.548828125, 'learning_rate': 0.0012071717171717171, 'seq/s': 24223.993249942752, 'global_steps': 287, 'samples_trained': 1469440, 'skipped_steps': 8, 'timestamp': 1592975860.1526306}
  0: {'training_steps': 296, 'average_loss': 2.064453125, 'step_loss': 2.064453125, 'learning_rate': 0.0012054545454545454, 'seq/s': 24117.43170699933, 'global_steps': 288, 'samples_trained': 1474560, 'skipped_steps': 8, 'timestamp': 1592975860.3649256}
  0: {'training_steps': 297, 'average_loss': 2.59765625, 'step_loss': 2.59765625, 'learning_rate': 0.0012037373737373736, 'seq/s': 23989.70080509937, 'global_steps': 289, 'samples_trained': 1479680, 'skipped_steps': 8, 'timestamp': 1592975860.578351}
  0: {'training_steps': 298, 'average_loss': 2.529296875, 'step_loss': 2.529296875, 'learning_rate': 0.001202020202020202, 'seq/s': 23583.016672413756, 'global_steps': 290, 'samples_trained': 1484800, 'skipped_steps': 8, 'timestamp': 1592975860.7954571}
  0: {'training_steps': 299, 'average_loss': 2.12890625, 'step_loss': 2.12890625, 'learning_rate': 0.0012003030303030303, 'seq/s': 24238.18327930726, 'global_steps': 291, 'samples_trained': 1489920, 'skipped_steps': 8, 'timestamp': 1592975861.0066946}
  0: {'training_steps': 300, 'average_loss': 2.072265625, 'step_loss': 2.072265625, 'learning_rate': 0.0011985858585858585, 'seq/s': 24278.135696310146, 'global_steps': 292, 'samples_trained': 1495040, 'skipped_steps': 8, 'timestamp': 1592975861.2175844}
  0: {'training_steps': 301, 'average_loss': 1.9677734375, 'step_loss': 1.9677734375, 'learning_rate': 0.0011968686868686867, 'seq/s': 24210.611352185624, 'global_steps': 293, 'samples_trained': 1500160, 'skipped_steps': 8, 'timestamp': 1592975861.4290624}
  0: {'training_steps': 302, 'average_loss': 2.126953125, 'step_loss': 2.126953125, 'learning_rate': 0.001195151515151515, 'seq/s': 24160.65577975665, 'global_steps': 294, 'samples_trained': 1505280, 'skipped_steps': 8, 'timestamp': 1592975861.6409776}
  0: {'training_steps': 303, 'average_loss': 2.3203125, 'step_loss': 2.3203125, 'learning_rate': 0.0011934343434343434, 'seq/s': 24147.968271745707, 'global_steps': 295, 'samples_trained': 1510400, 'skipped_steps': 8, 'timestamp': 1592975861.8530042}
  0: {'training_steps': 304, 'average_loss': 1.9912109375, 'step_loss': 1.9912109375, 'learning_rate': 0.0011917171717171719, 'seq/s': 24140.61182162678, 'global_steps': 296, 'samples_trained': 1515520, 'skipped_steps': 8, 'timestamp': 1592975862.0650954}
  0: {'training_steps': 305, 'average_loss': 1.947265625, 'step_loss': 1.947265625, 'learning_rate': 0.0011899999999999999, 'seq/s': 24234.791471996894, 'global_steps': 297, 'samples_trained': 1520640, 'skipped_steps': 8, 'timestamp': 1592975862.2763624}
  0: {'training_steps': 306, 'average_loss': 2.001953125, 'step_loss': 2.001953125, 'learning_rate': 0.0011882828282828283, 'seq/s': 24214.84280247078, 'global_steps': 298, 'samples_trained': 1525760, 'skipped_steps': 8, 'timestamp': 1592975862.4878037}
  0: {'training_steps': 307, 'average_loss': 2.00390625, 'step_loss': 2.00390625, 'learning_rate': 0.0011865656565656563, 'seq/s': 24102.868661654877, 'global_steps': 299, 'samples_trained': 1530880, 'skipped_steps': 8, 'timestamp': 1592975862.700227}
  0: {'training_steps': 308, 'average_loss': 2.2890625, 'step_loss': 2.2890625, 'learning_rate': 0.0011848484848484848, 'seq/s': 23718.53912567111, 'global_steps': 300, 'samples_trained': 1536000, 'skipped_steps': 8, 'timestamp': 1592975862.9160926}
  0: {'training_steps': 309, 'average_loss': 2.158203125, 'step_loss': 2.158203125, 'learning_rate': 0.001183131313131313, 'seq/s': 24262.80230439061, 'global_steps': 301, 'samples_trained': 1541120, 'skipped_steps': 8, 'timestamp': 1592975863.1271157}
  0: {'training_steps': 310, 'average_loss': 2.30859375, 'step_loss': 2.30859375, 'learning_rate': 0.0011814141414141415, 'seq/s': 24277.971013181992, 'global_steps': 302, 'samples_trained': 1546240, 'skipped_steps': 8, 'timestamp': 1592975863.338007}
  0: {'training_steps': 311, 'average_loss': 2.171875, 'step_loss': 2.171875, 'learning_rate': 0.0011796969696969697, 'seq/s': 24173.166151681442, 'global_steps': 303, 'samples_trained': 1551360, 'skipped_steps': 8, 'timestamp': 1592975863.5498126}
  0: {'training_steps': 312, 'average_loss': 2.181640625, 'step_loss': 2.181640625, 'learning_rate': 0.001177979797979798, 'seq/s': 24203.980505926218, 'global_steps': 304, 'samples_trained': 1556480, 'skipped_steps': 8, 'timestamp': 1592975863.7613487}
  0: {'training_steps': 313, 'average_loss': 2.251953125, 'step_loss': 2.251953125, 'learning_rate': 0.0011762626262626261, 'seq/s': 24142.728716856192, 'global_steps': 305, 'samples_trained': 1561600, 'skipped_steps': 8, 'timestamp': 1592975863.9734216}
  0: {'training_steps': 314, 'average_loss': 1.9638671875, 'step_loss': 1.9638671875, 'learning_rate': 0.0011745454545454546, 'seq/s': 24342.615692066684, 'global_steps': 306, 'samples_trained': 1566720, 'skipped_steps': 8, 'timestamp': 1592975864.1837528}
  0: {'training_steps': 315, 'average_loss': 2.076171875, 'step_loss': 2.076171875, 'learning_rate': 0.0011728282828282828, 'seq/s': 23698.515595342145, 'global_steps': 307, 'samples_trained': 1571840, 'skipped_steps': 8, 'timestamp': 1592975864.3998005}
  0: {'training_steps': 316, 'average_loss': 2.087890625, 'step_loss': 2.087890625, 'learning_rate': 0.001171111111111111, 'seq/s': 24103.6532100474, 'global_steps': 308, 'samples_trained': 1576960, 'skipped_steps': 8, 'timestamp': 1592975864.6122172}
  0: {'training_steps': 317, 'average_loss': 1.9560546875, 'step_loss': 1.9560546875, 'learning_rate': 0.0011693939393939393, 'seq/s': 24217.46431350437, 'global_steps': 309, 'samples_trained': 1582080, 'skipped_steps': 8, 'timestamp': 1592975864.8236358}
  0: {'training_steps': 318, 'average_loss': 1.5947265625, 'step_loss': 1.5947265625, 'learning_rate': 0.0011676767676767675, 'seq/s': 24178.010598999997, 'global_steps': 310, 'samples_trained': 1587200, 'skipped_steps': 8, 'timestamp': 1592975865.035399}
  0: {'training_steps': 319, 'average_loss': 2.189453125, 'step_loss': 2.189453125, 'learning_rate': 0.001165959595959596, 'seq/s': 24186.670120590756, 'global_steps': 311, 'samples_trained': 1592320, 'skipped_steps': 8, 'timestamp': 1592975865.2470863}
  0: {'training_steps': 320, 'average_loss': 1.9580078125, 'step_loss': 1.9580078125, 'learning_rate': 0.0011642424242424242, 'seq/s': 24186.533916592707, 'global_steps': 312, 'samples_trained': 1597440, 'skipped_steps': 8, 'timestamp': 1592975865.4587748}
  0: {'training_steps': 321, 'average_loss': 1.9326171875, 'step_loss': 1.9326171875, 'learning_rate': 0.0011625252525252526, 'seq/s': 24117.64839064711, 'global_steps': 313, 'samples_trained': 1602560, 'skipped_steps': 8, 'timestamp': 1592975865.671068}
  0: {'training_steps': 322, 'average_loss': 1.9306640625, 'step_loss': 1.9306640625, 'learning_rate': 0.0011608080808080806, 'seq/s': 22902.632388354818, 'global_steps': 314, 'samples_trained': 1607680, 'skipped_steps': 8, 'timestamp': 1592975865.8946235}
  0: {'training_steps': 323, 'average_loss': 1.4541015625, 'step_loss': 1.4541015625, 'learning_rate': 0.001159090909090909, 'seq/s': 24365.401524451816, 'global_steps': 315, 'samples_trained': 1612800, 'skipped_steps': 8, 'timestamp': 1592975866.104758}
  0: {'training_steps': 324, 'average_loss': 1.7998046875, 'step_loss': 1.7998046875, 'learning_rate': 0.0011573737373737371, 'seq/s': 24260.36281804194, 'global_steps': 316, 'samples_trained': 1617920, 'skipped_steps': 8, 'timestamp': 1592975866.3158026}
  0: {'training_steps': 325, 'average_loss': 2.314453125, 'step_loss': 2.314453125, 'learning_rate': 0.0011556565656565658, 'seq/s': 24100.298946985673, 'global_steps': 317, 'samples_trained': 1623040, 'skipped_steps': 8, 'timestamp': 1592975866.5282485}
  0: {'training_steps': 326, 'average_loss': 1.904296875, 'step_loss': 1.904296875, 'learning_rate': 0.0011539393939393938, 'seq/s': 24129.59910290018, 'global_steps': 318, 'samples_trained': 1628160, 'skipped_steps': 8, 'timestamp': 1592975866.7404366}
  0: {'training_steps': 327, 'average_loss': 2.04296875, 'step_loss': 2.04296875, 'learning_rate': 0.0011522222222222222, 'seq/s': 24264.063354827485, 'global_steps': 319, 'samples_trained': 1633280, 'skipped_steps': 8, 'timestamp': 1592975866.951449}
  0: {'training_steps': 328, 'average_loss': 2.01171875, 'step_loss': 2.01171875, 'learning_rate': 0.0011505050505050502, 'seq/s': 24180.841961371163, 'global_steps': 320, 'samples_trained': 1638400, 'skipped_steps': 8, 'timestamp': 1592975867.1631873}
  0: {'training_steps': 329, 'average_loss': 1.6591796875, 'step_loss': 1.6591796875, 'learning_rate': 0.0011487878787878787, 'seq/s': 22686.475778371252, 'global_steps': 321, 'samples_trained': 1643520, 'skipped_steps': 8, 'timestamp': 1592975867.3888729}
  0: {'training_steps': 330, 'average_loss': 1.9453125, 'step_loss': 1.9453125, 'learning_rate': 0.0011470707070707071, 'seq/s': 24084.081820333064, 'global_steps': 322, 'samples_trained': 1648640, 'skipped_steps': 8, 'timestamp': 1592975867.6014621}
  0: {'training_steps': 331, 'average_loss': 1.5576171875, 'step_loss': 1.5576171875, 'learning_rate': 0.0011453535353535354, 'seq/s': 24221.78011982964, 'global_steps': 323, 'samples_trained': 1653760, 'skipped_steps': 8, 'timestamp': 1592975867.8128428}
  0: {'training_steps': 332, 'average_loss': 2.10546875, 'step_loss': 2.10546875, 'learning_rate': 0.0011436363636363636, 'seq/s': 21468.288651961153, 'global_steps': 324, 'samples_trained': 1658880, 'skipped_steps': 8, 'timestamp': 1592975868.0513349}
  0: {'training_steps': 333, 'average_loss': 2.169921875, 'step_loss': 2.169921875, 'learning_rate': 0.0011419191919191918, 'seq/s': 24110.635234467187, 'global_steps': 325, 'samples_trained': 1664000, 'skipped_steps': 8, 'timestamp': 1592975868.2636898}
  0: {'training_steps': 334, 'average_loss': 1.8740234375, 'step_loss': 1.8740234375, 'learning_rate': 0.00114020202020202, 'seq/s': 24191.056709450524, 'global_steps': 326, 'samples_trained': 1669120, 'skipped_steps': 8, 'timestamp': 1592975868.4753387}
  0: {'training_steps': 335, 'average_loss': 2.171875, 'step_loss': 2.171875, 'learning_rate': 0.0011384848484848483, 'seq/s': 22891.695053650652, 'global_steps': 327, 'samples_trained': 1674240, 'skipped_steps': 8, 'timestamp': 1592975868.6990013}
  0: {'training_steps': 336, 'average_loss': 1.5498046875, 'step_loss': 1.5498046875, 'learning_rate': 0.0011367676767676767, 'seq/s': 21630.29339865614, 'global_steps': 328, 'samples_trained': 1679360, 'skipped_steps': 8, 'timestamp': 1592975868.9357069}
  0: {'training_steps': 337, 'average_loss': 1.90234375, 'step_loss': 1.90234375, 'learning_rate': 0.001135050505050505, 'seq/s': 24270.041420432648, 'global_steps': 329, 'samples_trained': 1684480, 'skipped_steps': 8, 'timestamp': 1592975869.146667}
  0: {'training_steps': 338, 'average_loss': 1.6533203125, 'step_loss': 1.6533203125, 'learning_rate': 0.0011333333333333334, 'seq/s': 24294.395424134163, 'global_steps': 330, 'samples_trained': 1689600, 'skipped_steps': 8, 'timestamp': 1592975869.357416}
  0: {'training_steps': 339, 'average_loss': 2.166015625, 'step_loss': 2.166015625, 'learning_rate': 0.0011316161616161614, 'seq/s': 24223.44676046297, 'global_steps': 331, 'samples_trained': 1694720, 'skipped_steps': 8, 'timestamp': 1592975869.5687819}
  0: {'training_steps': 340, 'average_loss': 1.4248046875, 'step_loss': 1.4248046875, 'learning_rate': 0.0011298989898989899, 'seq/s': 21227.87142385487, 'global_steps': 332, 'samples_trained': 1699840, 'skipped_steps': 8, 'timestamp': 1592975869.8099747}
  0: {'training_steps': 341, 'average_loss': 1.8544921875, 'step_loss': 1.8544921875, 'learning_rate': 0.001128181818181818, 'seq/s': 23906.96360881564, 'global_steps': 333, 'samples_trained': 1704960, 'skipped_steps': 8, 'timestamp': 1592975870.0241385}
  0: {'training_steps': 342, 'average_loss': 1.92578125, 'step_loss': 1.92578125, 'learning_rate': 0.0011264646464646466, 'seq/s': 24194.163703633603, 'global_steps': 334, 'samples_trained': 1710080, 'skipped_steps': 8, 'timestamp': 1592975870.2357602}
  0: {'training_steps': 343, 'average_loss': 1.8046875, 'step_loss': 1.8046875, 'learning_rate': 0.0011247474747474746, 'seq/s': 24095.025985799813, 'global_steps': 335, 'samples_trained': 1715200, 'skipped_steps': 8, 'timestamp': 1592975870.4482527}
  0: {'training_steps': 344, 'average_loss': 1.8203125, 'step_loss': 1.8203125, 'learning_rate': 0.001123030303030303, 'seq/s': 24166.175064593666, 'global_steps': 336, 'samples_trained': 1720320, 'skipped_steps': 8, 'timestamp': 1592975870.6601198}
  0: {'training_steps': 345, 'average_loss': 1.8798828125, 'step_loss': 1.8798828125, 'learning_rate': 0.001121313131313131, 'seq/s': 24255.348336561758, 'global_steps': 337, 'samples_trained': 1725440, 'skipped_steps': 8, 'timestamp': 1592975870.8712077}
  0: {'training_steps': 346, 'average_loss': 1.763671875, 'step_loss': 1.763671875, 'learning_rate': 0.0011195959595959595, 'seq/s': 23172.475184490995, 'global_steps': 338, 'samples_trained': 1730560, 'skipped_steps': 8, 'timestamp': 1592975871.09216}
  0: {'training_steps': 347, 'average_loss': 2.125, 'step_loss': 2.125, 'learning_rate': 0.001117878787878788, 'seq/s': 24183.5650506254, 'global_steps': 339, 'samples_trained': 1735680, 'skipped_steps': 8, 'timestamp': 1592975871.3038745}
  0: {'training_steps': 348, 'average_loss': 1.5166015625, 'step_loss': 1.5166015625, 'learning_rate': 0.0011161616161616161, 'seq/s': 24262.637829214586, 'global_steps': 340, 'samples_trained': 1740800, 'skipped_steps': 8, 'timestamp': 1592975871.514899}
  0: {'training_steps': 349, 'average_loss': 2.013671875, 'step_loss': 2.013671875, 'learning_rate': 0.0011144444444444444, 'seq/s': 24242.095977982703, 'global_steps': 341, 'samples_trained': 1745920, 'skipped_steps': 8, 'timestamp': 1592975871.7261024}
  0: {'training_steps': 350, 'average_loss': 1.9853515625, 'step_loss': 1.9853515625, 'learning_rate': 0.0011127272727272726, 'seq/s': 24121.007485151007, 'global_steps': 342, 'samples_trained': 1751040, 'skipped_steps': 8, 'timestamp': 1592975871.9383662}
  0: {'training_steps': 351, 'average_loss': 1.3525390625, 'step_loss': 1.3525390625, 'learning_rate': 0.0011110101010101008, 'seq/s': 24111.393216871704, 'global_steps': 343, 'samples_trained': 1756160, 'skipped_steps': 8, 'timestamp': 1592975872.1507146}
  0: {'training_steps': 352, 'average_loss': 1.6494140625, 'step_loss': 1.6494140625, 'learning_rate': 0.0011092929292929293, 'seq/s': 24222.763683286787, 'global_steps': 344, 'samples_trained': 1761280, 'skipped_steps': 8, 'timestamp': 1592975872.3620868}
  0: {'training_steps': 353, 'average_loss': 1.5185546875, 'step_loss': 1.5185546875, 'learning_rate': 0.0011075757575757575, 'seq/s': 24202.534754428336, 'global_steps': 345, 'samples_trained': 1766400, 'skipped_steps': 8, 'timestamp': 1592975872.5736353}
  0: {'training_steps': 354, 'average_loss': 1.27734375, 'step_loss': 1.27734375, 'learning_rate': 0.0011058585858585857, 'seq/s': 24275.22662325918, 'global_steps': 346, 'samples_trained': 1771520, 'skipped_steps': 8, 'timestamp': 1592975872.7845507}
  0: {'training_steps': 355, 'average_loss': 1.7763671875, 'step_loss': 1.7763671875, 'learning_rate': 0.0011041414141414142, 'seq/s': 22578.54341789706, 'global_steps': 347, 'samples_trained': 1776640, 'skipped_steps': 8, 'timestamp': 1592975873.0113153}
  0: {'training_steps': 356, 'average_loss': 1.52734375, 'step_loss': 1.52734375, 'learning_rate': 0.0011024242424242422, 'seq/s': 24282.418241973453, 'global_steps': 348, 'samples_trained': 1781760, 'skipped_steps': 8, 'timestamp': 1592975873.222168}
  0: {'training_steps': 357, 'average_loss': 1.5615234375, 'step_loss': 1.5615234375, 'learning_rate': 0.0011007070707070707, 'seq/s': 24212.440249218093, 'global_steps': 349, 'samples_trained': 1786880, 'skipped_steps': 8, 'timestamp': 1592975873.43363}
  0: {'training_steps': 358, 'average_loss': 1.4384765625, 'step_loss': 1.4384765625, 'learning_rate': 0.0010989898989898989, 'seq/s': 24144.357350452814, 'global_steps': 350, 'samples_trained': 1792000, 'skipped_steps': 8, 'timestamp': 1592975873.6456883}
  0: {'training_steps': 359, 'average_loss': 1.8349609375, 'step_loss': 1.8349609375, 'learning_rate': 0.0010972727272727273, 'seq/s': 24228.366053628866, 'global_steps': 351, 'samples_trained': 1797120, 'skipped_steps': 8, 'timestamp': 1592975873.8570116}
  0: {'training_steps': 360, 'average_loss': 1.60546875, 'step_loss': 1.60546875, 'learning_rate': 0.0010955555555555553, 'seq/s': 24190.81145442236, 'global_steps': 352, 'samples_trained': 1802240, 'skipped_steps': 8, 'timestamp': 1592975874.068663}
  0: {'training_steps': 361, 'average_loss': 1.51953125, 'step_loss': 1.51953125, 'learning_rate': 0.0010938383838383838, 'seq/s': 24307.51244248499, 'global_steps': 353, 'samples_trained': 1807360, 'skipped_steps': 8, 'timestamp': 1592975874.2792978}
  0: {'training_steps': 362, 'average_loss': 1.70703125, 'step_loss': 1.70703125, 'learning_rate': 0.001092121212121212, 'seq/s': 23039.667668367878, 'global_steps': 354, 'samples_trained': 1812480, 'skipped_steps': 8, 'timestamp': 1592975874.501524}
  0: {'training_steps': 363, 'average_loss': 1.7734375, 'step_loss': 1.7734375, 'learning_rate': 0.0010904040404040405, 'seq/s': 24333.07213181997, 'global_steps': 355, 'samples_trained': 1817600, 'skipped_steps': 8, 'timestamp': 1592975874.711938}
  0: {'training_steps': 364, 'average_loss': 1.5478515625, 'step_loss': 1.5478515625, 'learning_rate': 0.0010886868686868687, 'seq/s': 24172.866839414397, 'global_steps': 356, 'samples_trained': 1822720, 'skipped_steps': 8, 'timestamp': 1592975874.923746}
  0: {'training_steps': 365, 'average_loss': 1.841796875, 'step_loss': 1.841796875, 'learning_rate': 0.001086969696969697, 'seq/s': 24170.82627149644, 'global_steps': 357, 'samples_trained': 1827840, 'skipped_steps': 8, 'timestamp': 1592975875.1355722}
  0: {'training_steps': 366, 'average_loss': 1.4521484375, 'step_loss': 1.4521484375, 'learning_rate': 0.0010852525252525252, 'seq/s': 23978.34337695806, 'global_steps': 358, 'samples_trained': 1832960, 'skipped_steps': 8, 'timestamp': 1592975875.3490987}
  0: {'training_steps': 367, 'average_loss': 1.5537109375, 'step_loss': 1.5537109375, 'learning_rate': 0.0010835353535353534, 'seq/s': 24140.96461171815, 'global_steps': 359, 'samples_trained': 1838080, 'skipped_steps': 8, 'timestamp': 1592975875.561187}
  0: {'training_steps': 368, 'average_loss': 1.5625, 'step_loss': 1.5625, 'learning_rate': 0.0010818181818181818, 'seq/s': 24230.170295108233, 'global_steps': 360, 'samples_trained': 1843200, 'skipped_steps': 8, 'timestamp': 1592975875.7724943}
  0: {'training_steps': 369, 'average_loss': 1.49609375, 'step_loss': 1.49609375, 'learning_rate': 0.00108010101010101, 'seq/s': 24261.760665935326, 'global_steps': 361, 'samples_trained': 1848320, 'skipped_steps': 8, 'timestamp': 1592975875.9835265}
  0: {'training_steps': 370, 'average_loss': 1.5595703125, 'step_loss': 1.5595703125, 'learning_rate': 0.0010783838383838383, 'seq/s': 24186.479435423014, 'global_steps': 362, 'samples_trained': 1853440, 'skipped_steps': 8, 'timestamp': 1592975876.1952157}
  0: {'training_steps': 371, 'average_loss': 1.3740234375, 'step_loss': 1.3740234375, 'learning_rate': 0.0010766666666666665, 'seq/s': 24179.616771267527, 'global_steps': 363, 'samples_trained': 1858560, 'skipped_steps': 8, 'timestamp': 1592975876.4069648}
  0: {'training_steps': 372, 'average_loss': 1.6513671875, 'step_loss': 1.6513671875, 'learning_rate': 0.001074949494949495, 'seq/s': 22862.936826483096, 'global_steps': 364, 'samples_trained': 1863680, 'skipped_steps': 8, 'timestamp': 1592975876.6309085}
  0: {'training_steps': 373, 'average_loss': 1.7080078125, 'step_loss': 1.7080078125, 'learning_rate': 0.0010732323232323232, 'seq/s': 24252.143442780318, 'global_steps': 365, 'samples_trained': 1868800, 'skipped_steps': 8, 'timestamp': 1592975876.8420248}
  0: {'training_steps': 374, 'average_loss': 1.51171875, 'step_loss': 1.51171875, 'learning_rate': 0.0010715151515151517, 'seq/s': 24111.176645607353, 'global_steps': 366, 'samples_trained': 1873920, 'skipped_steps': 8, 'timestamp': 1592975877.054375}
  0: {'training_steps': 375, 'average_loss': 1.396484375, 'step_loss': 1.396484375, 'learning_rate': 0.0010697979797979797, 'seq/s': 24234.982919708524, 'global_steps': 367, 'samples_trained': 1879040, 'skipped_steps': 8, 'timestamp': 1592975877.2656403}
  0: {'training_steps': 376, 'average_loss': 1.5341796875, 'step_loss': 1.5341796875, 'learning_rate': 0.0010680808080808081, 'seq/s': 24140.77464654152, 'global_steps': 368, 'samples_trained': 1884160, 'skipped_steps': 8, 'timestamp': 1592975877.47773}
  0: {'training_steps': 377, 'average_loss': 1.6064453125, 'step_loss': 1.6064453125, 'learning_rate': 0.0010663636363636361, 'seq/s': 24093.674316115903, 'global_steps': 369, 'samples_trained': 1889280, 'skipped_steps': 8, 'timestamp': 1592975877.6902347}
  0: {'training_steps': 378, 'average_loss': 1.5224609375, 'step_loss': 1.5224609375, 'learning_rate': 0.0010646464646464646, 'seq/s': 24202.64386172324, 'global_steps': 370, 'samples_trained': 1894400, 'skipped_steps': 8, 'timestamp': 1592975877.9017823}
  0: {'training_steps': 379, 'average_loss': 1.6865234375, 'step_loss': 1.6865234375, 'learning_rate': 0.0010629292929292928, 'seq/s': 24219.40350453772, 'global_steps': 371, 'samples_trained': 1899520, 'skipped_steps': 8, 'timestamp': 1592975878.1131835}
  0: {'training_steps': 380, 'average_loss': 1.5517578125, 'step_loss': 1.5517578125, 'learning_rate': 0.0010612121212121212, 'seq/s': 24212.877041620533, 'global_steps': 372, 'samples_trained': 1904640, 'skipped_steps': 8, 'timestamp': 1592975878.3246417}
  0: {'training_steps': 381, 'average_loss': 1.8271484375, 'step_loss': 1.8271484375, 'learning_rate': 0.0010594949494949495, 'seq/s': 23399.51694748117, 'global_steps': 373, 'samples_trained': 1909760, 'skipped_steps': 8, 'timestamp': 1592975878.54345}
  0: {'training_steps': 382, 'average_loss': 1.634765625, 'step_loss': 1.634765625, 'learning_rate': 0.0010577777777777777, 'seq/s': 24227.163375244672, 'global_steps': 374, 'samples_trained': 1914880, 'skipped_steps': 8, 'timestamp': 1592975878.7547836}
  0: {'training_steps': 383, 'average_loss': 1.283203125, 'step_loss': 1.283203125, 'learning_rate': 0.001056060606060606, 'seq/s': 24033.651262629654, 'global_steps': 375, 'samples_trained': 1920000, 'skipped_steps': 8, 'timestamp': 1592975878.9678187}
  0: {'training_steps': 384, 'average_loss': 1.6123046875, 'step_loss': 1.6123046875, 'learning_rate': 0.0010543434343434344, 'seq/s': 24254.91001049266, 'global_steps': 376, 'samples_trained': 1925120, 'skipped_steps': 8, 'timestamp': 1592975879.1789105}
  0: {'training_steps': 385, 'average_loss': 1.587890625, 'step_loss': 1.587890625, 'learning_rate': 0.0010526262626262626, 'seq/s': 24212.46754828155, 'global_steps': 377, 'samples_trained': 1930240, 'skipped_steps': 8, 'timestamp': 1592975879.3903723}
  0: {'training_steps': 386, 'average_loss': 1.3828125, 'step_loss': 1.3828125, 'learning_rate': 0.0010509090909090908, 'seq/s': 24171.071121456196, 'global_steps': 378, 'samples_trained': 1935360, 'skipped_steps': 8, 'timestamp': 1592975879.6021962}
  0: {'training_steps': 387, 'average_loss': 1.498046875, 'step_loss': 1.498046875, 'learning_rate': 0.001049191919191919, 'seq/s': 24142.53872391518, 'global_steps': 379, 'samples_trained': 1940480, 'skipped_steps': 8, 'timestamp': 1592975879.8142705}
  0: {'training_steps': 388, 'average_loss': 1.2890625, 'step_loss': 1.2890625, 'learning_rate': 0.0010474747474747473, 'seq/s': 24226.917387556914, 'global_steps': 380, 'samples_trained': 1945600, 'skipped_steps': 8, 'timestamp': 1592975880.0256062}
  0: {'training_steps': 389, 'average_loss': 1.615234375, 'step_loss': 1.615234375, 'learning_rate': 0.0010457575757575758, 'seq/s': 24192.773633900557, 'global_steps': 381, 'samples_trained': 1950720, 'skipped_steps': 8, 'timestamp': 1592975880.2372403}
  0: {'training_steps': 390, 'average_loss': 1.7685546875, 'step_loss': 1.7685546875, 'learning_rate': 0.001044040404040404, 'seq/s': 24220.113708519566, 'global_steps': 382, 'samples_trained': 1955840, 'skipped_steps': 8, 'timestamp': 1592975880.4486353}
  0: {'training_steps': 391, 'average_loss': 1.3125, 'step_loss': 1.3125, 'learning_rate': 0.0010423232323232324, 'seq/s': 24156.470417519227, 'global_steps': 383, 'samples_trained': 1960960, 'skipped_steps': 8, 'timestamp': 1592975880.6605875}
  0: {'training_steps': 392, 'average_loss': 1.642578125, 'step_loss': 1.642578125, 'learning_rate': 0.0010406060606060604, 'seq/s': 24237.5540820415, 'global_steps': 384, 'samples_trained': 1966080, 'skipped_steps': 8, 'timestamp': 1592975880.8718305}
  0: {'training_steps': 393, 'average_loss': 1.859375, 'step_loss': 1.859375, 'learning_rate': 0.0010388888888888889, 'seq/s': 23976.60321238687, 'global_steps': 385, 'samples_trained': 1971200, 'skipped_steps': 8, 'timestamp': 1592975881.0853724}
  0: {'training_steps': 394, 'average_loss': 1.3193359375, 'step_loss': 1.3193359375, 'learning_rate': 0.001037171717171717, 'seq/s': 24013.602571012594, 'global_steps': 386, 'samples_trained': 1976320, 'skipped_steps': 8, 'timestamp': 1592975881.2985854}
  0: {'training_steps': 395, 'average_loss': 1.45703125, 'step_loss': 1.45703125, 'learning_rate': 0.0010354545454545454, 'seq/s': 24227.10871088237, 'global_steps': 387, 'samples_trained': 1981440, 'skipped_steps': 8, 'timestamp': 1592975881.5099194}
  0: {'training_steps': 396, 'average_loss': 1.615234375, 'step_loss': 1.615234375, 'learning_rate': 0.0010337373737373736, 'seq/s': 24166.50140667552, 'global_steps': 388, 'samples_trained': 1986560, 'skipped_steps': 8, 'timestamp': 1592975881.7217836}
  0: {'training_steps': 397, 'average_loss': 1.4169921875, 'step_loss': 1.4169921875, 'learning_rate': 0.001032020202020202, 'seq/s': 24203.707709404523, 'global_steps': 389, 'samples_trained': 1991680, 'skipped_steps': 8, 'timestamp': 1592975881.933322}
  0: {'training_steps': 398, 'average_loss': 1.5947265625, 'step_loss': 1.5947265625, 'learning_rate': 0.0010303030303030303, 'seq/s': 24171.2887700294, 'global_steps': 390, 'samples_trained': 1996800, 'skipped_steps': 8, 'timestamp': 1592975882.1451442}
  0: {'training_steps': 399, 'average_loss': 1.45703125, 'step_loss': 1.45703125, 'learning_rate': 0.0010285858585858585, 'seq/s': 23897.62555390611, 'global_steps': 391, 'samples_trained': 2001920, 'skipped_steps': 8, 'timestamp': 1592975882.3593922}
  0: {'training_steps': 400, 'average_loss': 1.4619140625, 'step_loss': 1.4619140625, 'learning_rate': 0.0010268686868686867, 'seq/s': 24262.007361697033, 'global_steps': 392, 'samples_trained': 2007040, 'skipped_steps': 8, 'timestamp': 1592975882.5704222}
  0: {'training_steps': 401, 'average_loss': 1.595703125, 'step_loss': 1.595703125, 'learning_rate': 0.0010251515151515152, 'seq/s': 24148.97300579692, 'global_steps': 393, 'samples_trained': 2012160, 'skipped_steps': 8, 'timestamp': 1592975882.78244}
  0: {'training_steps': 402, 'average_loss': 1.4970703125, 'step_loss': 1.4970703125, 'learning_rate': 0.0010234343434343434, 'seq/s': 24191.819756897115, 'global_steps': 394, 'samples_trained': 2017280, 'skipped_steps': 8, 'timestamp': 1592975882.9940825}
  0: {'training_steps': 403, 'average_loss': 1.4365234375, 'step_loss': 1.4365234375, 'learning_rate': 0.0010217171717171716, 'seq/s': 24247.296623192447, 'global_steps': 395, 'samples_trained': 2022400, 'skipped_steps': 8, 'timestamp': 1592975883.2052405}
  0: {'training_steps': 404, 'average_loss': 1.6865234375, 'step_loss': 1.6865234375, 'learning_rate': 0.0010199999999999999, 'seq/s': 24243.847525076628, 'global_steps': 396, 'samples_trained': 2027520, 'skipped_steps': 8, 'timestamp': 1592975883.4164286}
  0: {'training_steps': 405, 'average_loss': 1.3154296875, 'step_loss': 1.3154296875, 'learning_rate': 0.001018282828282828, 'seq/s': 24141.181718438045, 'global_steps': 397, 'samples_trained': 2032640, 'skipped_steps': 8, 'timestamp': 1592975883.6285148}
  0: {'training_steps': 406, 'average_loss': 1.486328125, 'step_loss': 1.486328125, 'learning_rate': 0.0010165656565656565, 'seq/s': 24119.273642122287, 'global_steps': 398, 'samples_trained': 2037760, 'skipped_steps': 8, 'timestamp': 1592975883.8407936}
  0: {'training_steps': 407, 'average_loss': 1.505859375, 'step_loss': 1.505859375, 'learning_rate': 0.0010148484848484848, 'seq/s': 24190.075719174456, 'global_steps': 399, 'samples_trained': 2042880, 'skipped_steps': 8, 'timestamp': 1592975884.0524511}
  0: {'training_steps': 408, 'average_loss': 1.5712890625, 'step_loss': 1.5712890625, 'learning_rate': 0.0010131313131313132, 'seq/s': 24056.077670076924, 'global_steps': 400, 'samples_trained': 2048000, 'skipped_steps': 8, 'timestamp': 1592975884.2652876}
  0: {'training_steps': 409, 'average_loss': 1.572265625, 'step_loss': 1.572265625, 'learning_rate': 0.0010114141414141412, 'seq/s': 24145.959054438168, 'global_steps': 401, 'samples_trained': 2053120, 'skipped_steps': 8, 'timestamp': 1592975884.4773319}
  0: {'training_steps': 410, 'average_loss': 1.37890625, 'step_loss': 1.37890625, 'learning_rate': 0.0010096969696969697, 'seq/s': 24148.239813244694, 'global_steps': 402, 'samples_trained': 2058240, 'skipped_steps': 8, 'timestamp': 1592975884.6893563}
  0: {'training_steps': 411, 'average_loss': 1.4345703125, 'step_loss': 1.4345703125, 'learning_rate': 0.001007979797979798, 'seq/s': 23380.079128153204, 'global_steps': 403, 'samples_trained': 2063360, 'skipped_steps': 8, 'timestamp': 1592975884.9083467}
  0: {'training_steps': 412, 'average_loss': 1.2734375, 'step_loss': 1.2734375, 'learning_rate': 0.0010062626262626263, 'seq/s': 24235.28377222384, 'global_steps': 404, 'samples_trained': 2068480, 'skipped_steps': 8, 'timestamp': 1592975885.1196094}
  0: {'training_steps': 413, 'average_loss': 1.4716796875, 'step_loss': 1.4716796875, 'learning_rate': 0.0010045454545454544, 'seq/s': 24316.843213765645, 'global_steps': 405, 'samples_trained': 2073600, 'skipped_steps': 8, 'timestamp': 1592975885.3301635}
  0: {'training_steps': 414, 'average_loss': 1.28125, 'step_loss': 1.28125, 'learning_rate': 0.0010028282828282828, 'seq/s': 24287.965834856408, 'global_steps': 406, 'samples_trained': 2078720, 'skipped_steps': 8, 'timestamp': 1592975885.540968}
  0: {'training_steps': 415, 'average_loss': 1.130859375, 'step_loss': 1.130859375, 'learning_rate': 0.001001111111111111, 'seq/s': 24144.9274241242, 'global_steps': 407, 'samples_trained': 2083840, 'skipped_steps': 8, 'timestamp': 1592975885.7530212}
  0: {'training_steps': 416, 'average_loss': 1.318359375, 'step_loss': 1.318359375, 'learning_rate': 0.0009993939393939393, 'seq/s': 24228.33871870318, 'global_steps': 408, 'samples_trained': 2088960, 'skipped_steps': 8, 'timestamp': 1592975885.9643445}
  0: {'training_steps': 417, 'average_loss': 1.576171875, 'step_loss': 1.576171875, 'learning_rate': 0.0009976767676767677, 'seq/s': 24178.282816569033, 'global_steps': 409, 'samples_trained': 2094080, 'skipped_steps': 8, 'timestamp': 1592975886.1761055}
  0: {'training_steps': 418, 'average_loss': 1.5654296875, 'step_loss': 1.5654296875, 'learning_rate': 0.000995959595959596, 'seq/s': 24033.97403527621, 'global_steps': 410, 'samples_trained': 2099200, 'skipped_steps': 8, 'timestamp': 1592975886.3891377}
  0: {'training_steps': 419, 'average_loss': 1.51171875, 'step_loss': 1.51171875, 'learning_rate': 0.0009942424242424242, 'seq/s': 24233.806931542218, 'global_steps': 411, 'samples_trained': 2104320, 'skipped_steps': 8, 'timestamp': 1592975886.6004133}
  0: {'training_steps': 420, 'average_loss': 1.412109375, 'step_loss': 1.412109375, 'learning_rate': 0.0009925252525252524, 'seq/s': 24150.928403619913, 'global_steps': 412, 'samples_trained': 2109440, 'skipped_steps': 8, 'timestamp': 1592975886.812414}
  0: {'training_steps': 421, 'average_loss': 1.4912109375, 'step_loss': 1.4912109375, 'learning_rate': 0.0009908080808080806, 'seq/s': 24096.350769237673, 'global_steps': 413, 'samples_trained': 2114560, 'skipped_steps': 8, 'timestamp': 1592975887.024895}
  0: {'training_steps': 422, 'average_loss': 1.322265625, 'step_loss': 1.322265625, 'learning_rate': 0.000989090909090909, 'seq/s': 24170.254974214447, 'global_steps': 414, 'samples_trained': 2119680, 'skipped_steps': 8, 'timestamp': 1592975887.236726}
  0: {'training_steps': 423, 'average_loss': 1.59765625, 'step_loss': 1.59765625, 'learning_rate': 0.0009873737373737375, 'seq/s': 24058.422338037133, 'global_steps': 415, 'samples_trained': 2124800, 'skipped_steps': 8, 'timestamp': 1592975887.4495418}
  0: {'training_steps': 424, 'average_loss': 1.48046875, 'step_loss': 1.48046875, 'learning_rate': 0.0009856565656565655, 'seq/s': 24165.250476556997, 'global_steps': 416, 'samples_trained': 2129920, 'skipped_steps': 8, 'timestamp': 1592975887.6614165}
  0: {'training_steps': 425, 'average_loss': 1.6982421875, 'step_loss': 1.6982421875, 'learning_rate': 0.000983939393939394, 'seq/s': 24126.45445710851, 'global_steps': 417, 'samples_trained': 2135040, 'skipped_steps': 8, 'timestamp': 1592975887.8736322}
  0: {'training_steps': 426, 'average_loss': 1.439453125, 'step_loss': 1.439453125, 'learning_rate': 0.000982222222222222, 'seq/s': 24088.025978250505, 'global_steps': 418, 'samples_trained': 2140160, 'skipped_steps': 8, 'timestamp': 1592975888.0861864}
  0: {'training_steps': 427, 'average_loss': 1.392578125, 'step_loss': 1.392578125, 'learning_rate': 0.0009805050505050505, 'seq/s': 24205.53556352832, 'global_steps': 419, 'samples_trained': 2145280, 'skipped_steps': 8, 'timestamp': 1592975888.2977087}
  0: {'training_steps': 428, 'average_loss': 1.5732421875, 'step_loss': 1.5732421875, 'learning_rate': 0.0009787878787878787, 'seq/s': 24243.68330678456, 'global_steps': 420, 'samples_trained': 2150400, 'skipped_steps': 8, 'timestamp': 1592975888.5088983}
  0: {'training_steps': 429, 'average_loss': 1.4404296875, 'step_loss': 1.4404296875, 'learning_rate': 0.0009770707070707071, 'seq/s': 24224.157201595026, 'global_steps': 421, 'samples_trained': 2155520, 'skipped_steps': 8, 'timestamp': 1592975888.720258}
  0: {'training_steps': 430, 'average_loss': 1.58203125, 'step_loss': 1.58203125, 'learning_rate': 0.0009753535353535351, 'seq/s': 24234.025711396793, 'global_steps': 422, 'samples_trained': 2160640, 'skipped_steps': 8, 'timestamp': 1592975888.9315317}
  0: {'training_steps': 431, 'average_loss': 1.48828125, 'step_loss': 1.48828125, 'learning_rate': 0.0009736363636363636, 'seq/s': 24157.693263017693, 'global_steps': 423, 'samples_trained': 2165760, 'skipped_steps': 8, 'timestamp': 1592975889.143473}
  0: {'training_steps': 432, 'average_loss': 1.1513671875, 'step_loss': 1.1513671875, 'learning_rate': 0.0009719191919191919, 'seq/s': 24192.255805622335, 'global_steps': 424, 'samples_trained': 2170880, 'skipped_steps': 8, 'timestamp': 1592975889.3551114}
  0: {'training_steps': 433, 'average_loss': 1.6708984375, 'step_loss': 1.6708984375, 'learning_rate': 0.0009702020202020202, 'seq/s': 22871.727219958997, 'global_steps': 425, 'samples_trained': 2176000, 'skipped_steps': 8, 'timestamp': 1592975889.5789692}
  0: {'training_steps': 434, 'average_loss': 1.576171875, 'step_loss': 1.576171875, 'learning_rate': 0.0009684848484848484, 'seq/s': 24177.683946008205, 'global_steps': 426, 'samples_trained': 2181120, 'skipped_steps': 8, 'timestamp': 1592975889.7907352}
  0: {'training_steps': 435, 'average_loss': 1.5634765625, 'step_loss': 1.5634765625, 'learning_rate': 0.0009667676767676767, 'seq/s': 24227.35470245536, 'global_steps': 427, 'samples_trained': 2186240, 'skipped_steps': 8, 'timestamp': 1592975890.002067}
  0: {'training_steps': 436, 'average_loss': 1.2939453125, 'step_loss': 1.2939453125, 'learning_rate': 0.000965050505050505, 'seq/s': 24165.440827133916, 'global_steps': 428, 'samples_trained': 2191360, 'skipped_steps': 8, 'timestamp': 1592975890.2139404}
  0: {'training_steps': 437, 'average_loss': 1.384765625, 'step_loss': 1.384765625, 'learning_rate': 0.0009633333333333333, 'seq/s': 23669.547977078666, 'global_steps': 429, 'samples_trained': 2196480, 'skipped_steps': 8, 'timestamp': 1592975890.4302528}
  0: {'training_steps': 438, 'average_loss': 1.4912109375, 'step_loss': 1.4912109375, 'learning_rate': 0.0009616161616161615, 'seq/s': 24081.489105215882, 'global_steps': 430, 'samples_trained': 2201600, 'skipped_steps': 8, 'timestamp': 1592975890.642865}
  0: {'training_steps': 439, 'average_loss': 1.52734375, 'step_loss': 1.52734375, 'learning_rate': 0.0009598989898989898, 'seq/s': 24316.512798679254, 'global_steps': 431, 'samples_trained': 2206720, 'skipped_steps': 8, 'timestamp': 1592975890.8534224}
  0: {'training_steps': 440, 'average_loss': 1.439453125, 'step_loss': 1.439453125, 'learning_rate': 0.0009581818181818183, 'seq/s': 24267.381091752304, 'global_steps': 432, 'samples_trained': 2211840, 'skipped_steps': 8, 'timestamp': 1592975891.0644054}
  0: {'training_steps': 441, 'average_loss': 1.4189453125, 'step_loss': 1.4189453125, 'learning_rate': 0.0009564646464646463, 'seq/s': 24105.871864669334, 'global_steps': 433, 'samples_trained': 2216960, 'skipped_steps': 8, 'timestamp': 1592975891.2768023}
  0: {'training_steps': 442, 'average_loss': 1.5234375, 'step_loss': 1.5234375, 'learning_rate': 0.0009547474747474748, 'seq/s': 24245.544577706572, 'global_steps': 434, 'samples_trained': 2222080, 'skipped_steps': 8, 'timestamp': 1592975891.4879756}
  0: {'training_steps': 443, 'average_loss': 1.68359375, 'step_loss': 1.68359375, 'learning_rate': 0.0009530303030303029, 'seq/s': 24220.98786290873, 'global_steps': 435, 'samples_trained': 2227200, 'skipped_steps': 8, 'timestamp': 1592975891.6993632}
  0: {'training_steps': 444, 'average_loss': 1.376953125, 'step_loss': 1.376953125, 'learning_rate': 0.0009513131313131313, 'seq/s': 24138.57669550204, 'global_steps': 436, 'samples_trained': 2232320, 'skipped_steps': 8, 'timestamp': 1592975891.9114723}
  0: {'training_steps': 445, 'average_loss': 1.623046875, 'step_loss': 1.623046875, 'learning_rate': 0.0009495959595959595, 'seq/s': 24147.262292427542, 'global_steps': 437, 'samples_trained': 2237440, 'skipped_steps': 8, 'timestamp': 1592975892.123505}
  0: {'training_steps': 446, 'average_loss': 1.26171875, 'step_loss': 1.26171875, 'learning_rate': 0.0009478787878787879, 'seq/s': 24180.8147335755, 'global_steps': 438, 'samples_trained': 2242560, 'skipped_steps': 8, 'timestamp': 1592975892.3352437}
  0: {'training_steps': 447, 'average_loss': 1.4365234375, 'step_loss': 1.4365234375, 'learning_rate': 0.0009461616161616159, 'seq/s': 24220.386874988017, 'global_steps': 439, 'samples_trained': 2247680, 'skipped_steps': 8, 'timestamp': 1592975892.5466363}
  0: {'training_steps': 448, 'average_loss': 1.6982421875, 'step_loss': 1.6982421875, 'learning_rate': 0.0009444444444444445, 'seq/s': 24282.83010483252, 'global_steps': 440, 'samples_trained': 2252800, 'skipped_steps': 8, 'timestamp': 1592975892.7574854}
  0: {'training_steps': 449, 'average_loss': 1.5556640625, 'step_loss': 1.5556640625, 'learning_rate': 0.0009427272727272727, 'seq/s': 24112.53027984222, 'global_steps': 441, 'samples_trained': 2257920, 'skipped_steps': 8, 'timestamp': 1592975892.9698238}
  0: {'training_steps': 450, 'average_loss': 1.447265625, 'step_loss': 1.447265625, 'learning_rate': 0.0009410101010101009, 'seq/s': 24161.96060473432, 'global_steps': 442, 'samples_trained': 2263040, 'skipped_steps': 8, 'timestamp': 1592975893.181728}
  0: {'training_steps': 451, 'average_loss': 1.203125, 'step_loss': 1.203125, 'learning_rate': 0.0009392929292929293, 'seq/s': 24170.200566357977, 'global_steps': 443, 'samples_trained': 2268160, 'skipped_steps': 8, 'timestamp': 1592975893.3935595}
  0: {'training_steps': 452, 'average_loss': 1.3203125, 'step_loss': 1.3203125, 'learning_rate': 0.0009375757575757575, 'seq/s': 24131.280198040942, 'global_steps': 444, 'samples_trained': 2273280, 'skipped_steps': 8, 'timestamp': 1592975893.6057327}
  0: {'training_steps': 453, 'average_loss': 1.615234375, 'step_loss': 1.615234375, 'learning_rate': 0.0009358585858585858, 'seq/s': 24153.481760748804, 'global_steps': 445, 'samples_trained': 2278400, 'skipped_steps': 8, 'timestamp': 1592975893.8177109}
  0: {'training_steps': 454, 'average_loss': 1.634765625, 'step_loss': 1.634765625, 'learning_rate': 0.0009341414141414141, 'seq/s': 24191.329220869924, 'global_steps': 446, 'samples_trained': 2283520, 'skipped_steps': 8, 'timestamp': 1592975894.029358}
  0: {'training_steps': 455, 'average_loss': 1.3876953125, 'step_loss': 1.3876953125, 'learning_rate': 0.0009324242424242423, 'seq/s': 24175.58813265097, 'global_steps': 447, 'samples_trained': 2288640, 'skipped_steps': 8, 'timestamp': 1592975894.2411425}
  0: {'training_steps': 456, 'average_loss': 1.4892578125, 'step_loss': 1.4892578125, 'learning_rate': 0.0009307070707070706, 'seq/s': 21736.8304979923, 'global_steps': 448, 'samples_trained': 2293760, 'skipped_steps': 8, 'timestamp': 1592975894.476688}
  0: {'training_steps': 457, 'average_loss': 1.3447265625, 'step_loss': 1.3447265625, 'learning_rate': 0.0009289898989898991, 'seq/s': 21333.883511638604, 'global_steps': 449, 'samples_trained': 2298880, 'skipped_steps': 8, 'timestamp': 1592975894.7166822}
  0: {'training_steps': 458, 'average_loss': 1.3671875, 'step_loss': 1.3671875, 'learning_rate': 0.0009272727272727271, 'seq/s': 24144.845983380124, 'global_steps': 450, 'samples_trained': 2304000, 'skipped_steps': 8, 'timestamp': 1592975894.9287362}
  0: {'training_steps': 459, 'average_loss': 1.4111328125, 'step_loss': 1.4111328125, 'learning_rate': 0.0009255555555555557, 'seq/s': 22757.1326324401, 'global_steps': 451, 'samples_trained': 2309120, 'skipped_steps': 8, 'timestamp': 1592975895.153721}
  0: {'training_steps': 460, 'average_loss': 1.43359375, 'step_loss': 1.43359375, 'learning_rate': 0.0009238383838383837, 'seq/s': 21713.22598812361, 'global_steps': 452, 'samples_trained': 2314240, 'skipped_steps': 8, 'timestamp': 1592975895.3895228}
  0: {'training_steps': 461, 'average_loss': 1.6181640625, 'step_loss': 1.6181640625, 'learning_rate': 0.0009221212121212121, 'seq/s': 21812.250178003538, 'global_steps': 453, 'samples_trained': 2319360, 'skipped_steps': 8, 'timestamp': 1592975895.6242537}
  0: {'training_steps': 462, 'average_loss': 1.5654296875, 'step_loss': 1.5654296875, 'learning_rate': 0.0009204040404040402, 'seq/s': 23520.27740448066, 'global_steps': 454, 'samples_trained': 2324480, 'skipped_steps': 8, 'timestamp': 1592975895.8419387}
  0: {'training_steps': 463, 'average_loss': 1.447265625, 'step_loss': 1.447265625, 'learning_rate': 0.0009186868686868687, 'seq/s': 24311.33746770728, 'global_steps': 455, 'samples_trained': 2329600, 'skipped_steps': 8, 'timestamp': 1592975896.0525408}
  0: {'training_steps': 464, 'average_loss': 1.2685546875, 'step_loss': 1.2685546875, 'learning_rate': 0.0009169696969696968, 'seq/s': 21287.88626283974, 'global_steps': 456, 'samples_trained': 2334720, 'skipped_steps': 8, 'timestamp': 1592975896.293054}
  0: {'training_steps': 465, 'average_loss': 1.3720703125, 'step_loss': 1.3720703125, 'learning_rate': 0.0009152525252525253, 'seq/s': 21615.357921849947, 'global_steps': 457, 'samples_trained': 2339840, 'skipped_steps': 8, 'timestamp': 1592975896.5299234}
  0: {'training_steps': 466, 'average_loss': 1.544921875, 'step_loss': 1.544921875, 'learning_rate': 0.0009135353535353535, 'seq/s': 24213.641466247223, 'global_steps': 458, 'samples_trained': 2344960, 'skipped_steps': 8, 'timestamp': 1592975896.741375}
  0: {'training_steps': 467, 'average_loss': 1.193359375, 'step_loss': 1.193359375, 'learning_rate': 0.0009118181818181818, 'seq/s': 24112.47613155463, 'global_steps': 459, 'samples_trained': 2350080, 'skipped_steps': 8, 'timestamp': 1592975896.9537137}
  0: {'training_steps': 468, 'average_loss': 1.5625, 'step_loss': 1.5625, 'learning_rate': 0.0009101010101010101, 'seq/s': 24117.21502724508, 'global_steps': 460, 'samples_trained': 2355200, 'skipped_steps': 8, 'timestamp': 1592975897.1660106}
  0: {'training_steps': 469, 'average_loss': 1.2685546875, 'step_loss': 1.2685546875, 'learning_rate': 0.0009083838383838383, 'seq/s': 23895.07282628289, 'global_steps': 461, 'samples_trained': 2360320, 'skipped_steps': 8, 'timestamp': 1592975897.3802814}
  0: {'training_steps': 470, 'average_loss': 1.349609375, 'step_loss': 1.349609375, 'learning_rate': 0.0009066666666666666, 'seq/s': 24137.68134870813, 'global_steps': 462, 'samples_trained': 2365440, 'skipped_steps': 8, 'timestamp': 1592975897.5923984}
  0: {'training_steps': 471, 'average_loss': 1.279296875, 'step_loss': 1.279296875, 'learning_rate': 0.0009049494949494949, 'seq/s': 24209.055642359348, 'global_steps': 463, 'samples_trained': 2370560, 'skipped_steps': 8, 'timestamp': 1592975897.80389}
  0: {'training_steps': 472, 'average_loss': 1.328125, 'step_loss': 1.328125, 'learning_rate': 0.0009032323232323232, 'seq/s': 24141.534525186642, 'global_steps': 464, 'samples_trained': 2375680, 'skipped_steps': 8, 'timestamp': 1592975898.015973}
  0: {'training_steps': 473, 'average_loss': 1.439453125, 'step_loss': 1.439453125, 'learning_rate': 0.0009015151515151514, 'seq/s': 24071.528550899762, 'global_steps': 465, 'samples_trained': 2380800, 'skipped_steps': 8, 'timestamp': 1592975898.228673}
  0: {'training_steps': 474, 'average_loss': 1.4794921875, 'step_loss': 1.4794921875, 'learning_rate': 0.0008997979797979799, 'seq/s': 23285.215407502506, 'global_steps': 466, 'samples_trained': 2385920, 'skipped_steps': 8, 'timestamp': 1592975898.4485555}
  0: {'training_steps': 475, 'average_loss': 1.197265625, 'step_loss': 1.197265625, 'learning_rate': 0.000898080808080808, 'seq/s': 24145.280340363908, 'global_steps': 467, 'samples_trained': 2391040, 'skipped_steps': 8, 'timestamp': 1592975898.6606057}
  0: {'training_steps': 476, 'average_loss': 1.2255859375, 'step_loss': 1.2255859375, 'learning_rate': 0.0008963636363636364, 'seq/s': 24241.22029934043, 'global_steps': 468, 'samples_trained': 2396160, 'skipped_steps': 8, 'timestamp': 1592975898.8718169}
  0: {'training_steps': 477, 'average_loss': 1.57421875, 'step_loss': 1.57421875, 'learning_rate': 0.0008946464646464646, 'seq/s': 24135.429709451044, 'global_steps': 469, 'samples_trained': 2401280, 'skipped_steps': 8, 'timestamp': 1592975899.0839539}
  0: {'training_steps': 478, 'average_loss': 1.1953125, 'step_loss': 1.1953125, 'learning_rate': 0.000892929292929293, 'seq/s': 24198.144002307716, 'global_steps': 470, 'samples_trained': 2406400, 'skipped_steps': 8, 'timestamp': 1592975899.2955408}
  0: {'training_steps': 479, 'average_loss': 1.3271484375, 'step_loss': 1.3271484375, 'learning_rate': 0.000891212121212121, 'seq/s': 24255.18396242931, 'global_steps': 471, 'samples_trained': 2411520, 'skipped_steps': 8, 'timestamp': 1592975899.5066302}
  0: {'training_steps': 480, 'average_loss': 1.5966796875, 'step_loss': 1.5966796875, 'learning_rate': 0.0008894949494949495, 'seq/s': 24157.013889123242, 'global_steps': 472, 'samples_trained': 2416640, 'skipped_steps': 8, 'timestamp': 1592975899.7185774}
  0: {'training_steps': 481, 'average_loss': 1.4609375, 'step_loss': 1.4609375, 'learning_rate': 0.0008877777777777776, 'seq/s': 24197.65320977694, 'global_steps': 473, 'samples_trained': 2421760, 'skipped_steps': 8, 'timestamp': 1592975899.9301686}
  0: {'training_steps': 482, 'average_loss': 1.4384765625, 'step_loss': 1.4384765625, 'learning_rate': 0.000886060606060606, 'seq/s': 24161.851863936517, 'global_steps': 474, 'samples_trained': 2426880, 'skipped_steps': 8, 'timestamp': 1592975900.1420734}
  0: {'training_steps': 483, 'average_loss': 1.53125, 'step_loss': 1.53125, 'learning_rate': 0.0008843434343434344, 'seq/s': 24210.747827498657, 'global_steps': 475, 'samples_trained': 2432000, 'skipped_steps': 8, 'timestamp': 1592975900.3535504}
  0: {'training_steps': 484, 'average_loss': 1.5361328125, 'step_loss': 1.5361328125, 'learning_rate': 0.0008826262626262626, 'seq/s': 24279.288540766902, 'global_steps': 476, 'samples_trained': 2437120, 'skipped_steps': 8, 'timestamp': 1592975900.5644302}
  0: {'training_steps': 485, 'average_loss': 1.3955078125, 'step_loss': 1.3955078125, 'learning_rate': 0.0008809090909090908, 'seq/s': 24225.03164789001, 'global_steps': 477, 'samples_trained': 2442240, 'skipped_steps': 8, 'timestamp': 1592975900.7757823}
  0: {'training_steps': 486, 'average_loss': 1.2294921875, 'step_loss': 1.2294921875, 'learning_rate': 0.0008791919191919192, 'seq/s': 24257.046999727776, 'global_steps': 478, 'samples_trained': 2447360, 'skipped_steps': 8, 'timestamp': 1592975900.9868553}
  0: {'training_steps': 487, 'average_loss': 1.81640625, 'step_loss': 1.81640625, 'learning_rate': 0.0008774747474747474, 'seq/s': 24188.30468823037, 'global_steps': 479, 'samples_trained': 2452480, 'skipped_steps': 8, 'timestamp': 1592975901.1985283}
  0: {'training_steps': 488, 'average_loss': 1.47265625, 'step_loss': 1.47265625, 'learning_rate': 0.0008757575757575756, 'seq/s': 23710.892165684916, 'global_steps': 480, 'samples_trained': 2457600, 'skipped_steps': 8, 'timestamp': 1592975901.4144633}
  0: {'training_steps': 489, 'average_loss': 1.732421875, 'step_loss': 1.732421875, 'learning_rate': 0.000874040404040404, 'seq/s': 24311.94297772907, 'global_steps': 481, 'samples_trained': 2462720, 'skipped_steps': 8, 'timestamp': 1592975901.6250598}
  0: {'training_steps': 490, 'average_loss': 1.4521484375, 'step_loss': 1.4521484375, 'learning_rate': 0.0008723232323232322, 'seq/s': 24190.32095928448, 'global_steps': 482, 'samples_trained': 2467840, 'skipped_steps': 8, 'timestamp': 1592975901.8367152}
  0: {'training_steps': 491, 'average_loss': 1.34375, 'step_loss': 1.34375, 'learning_rate': 0.0008706060606060606, 'seq/s': 24181.549905581447, 'global_steps': 483, 'samples_trained': 2472960, 'skipped_steps': 8, 'timestamp': 1592975902.0484474}
  0: {'training_steps': 492, 'average_loss': 1.583984375, 'step_loss': 1.583984375, 'learning_rate': 0.0008688888888888888, 'seq/s': 24227.05404676675, 'global_steps': 484, 'samples_trained': 2478080, 'skipped_steps': 8, 'timestamp': 1592975902.2597818}
  0: {'training_steps': 493, 'average_loss': 1.2685546875, 'step_loss': 1.2685546875, 'learning_rate': 0.0008671717171717172, 'seq/s': 23999.96924404271, 'global_steps': 485, 'samples_trained': 2483200, 'skipped_steps': 8, 'timestamp': 1592975902.473116}
  0: {'training_steps': 494, 'average_loss': 1.2880859375, 'step_loss': 1.2880859375, 'learning_rate': 0.0008654545454545453, 'seq/s': 24167.426090440316, 'global_steps': 486, 'samples_trained': 2488320, 'skipped_steps': 8, 'timestamp': 1592975902.6849718}
  0: {'training_steps': 495, 'average_loss': 1.2734375, 'step_loss': 1.2734375, 'learning_rate': 0.0008637373737373738, 'seq/s': 24155.818283872115, 'global_steps': 487, 'samples_trained': 2493440, 'skipped_steps': 8, 'timestamp': 1592975902.8969295}
  0: {'training_steps': 496, 'average_loss': 1.638671875, 'step_loss': 1.638671875, 'learning_rate': 0.0008620202020202019, 'seq/s': 24265.077773132507, 'global_steps': 488, 'samples_trained': 2498560, 'skipped_steps': 8, 'timestamp': 1592975903.107933}
  0: {'training_steps': 497, 'average_loss': 1.341796875, 'step_loss': 1.341796875, 'learning_rate': 0.0008603030303030304, 'seq/s': 24113.207153957403, 'global_steps': 489, 'samples_trained': 2503680, 'skipped_steps': 8, 'timestamp': 1592975903.3202653}
  0: {'training_steps': 498, 'average_loss': 1.4326171875, 'step_loss': 1.4326171875, 'learning_rate': 0.0008585858585858584, 'seq/s': 24144.194477205347, 'global_steps': 490, 'samples_trained': 2508800, 'skipped_steps': 8, 'timestamp': 1592975903.532325}
  0: {'training_steps': 499, 'average_loss': 1.681640625, 'step_loss': 1.681640625, 'learning_rate': 0.0008568686868686868, 'seq/s': 24132.988647575894, 'global_steps': 491, 'samples_trained': 2513920, 'skipped_steps': 8, 'timestamp': 1592975903.7444835}
  0: {'training_steps': 500, 'average_loss': 1.212890625, 'step_loss': 1.212890625, 'learning_rate': 0.0008551515151515152, 'seq/s': 24080.733001788547, 'global_steps': 492, 'samples_trained': 2519040, 'skipped_steps': 8, 'timestamp': 1592975903.9571023}
  0: {'training_steps': 501, 'average_loss': 1.4736328125, 'step_loss': 1.4736328125, 'learning_rate': 0.0008534343434343434, 'seq/s': 22937.883503503996, 'global_steps': 493, 'samples_trained': 2524160, 'skipped_steps': 8, 'timestamp': 1592975904.1803143}
  0: {'training_steps': 502, 'average_loss': 1.4794921875, 'step_loss': 1.4794921875, 'learning_rate': 0.0008517171717171717, 'seq/s': 24324.16972113359, 'global_steps': 494, 'samples_trained': 2529280, 'skipped_steps': 8, 'timestamp': 1592975904.390805}
  0: {'training_steps': 503, 'average_loss': 1.2333984375, 'step_loss': 1.2333984375, 'learning_rate': 0.00085, 'seq/s': 24161.66156989552, 'global_steps': 495, 'samples_trained': 2534400, 'skipped_steps': 8, 'timestamp': 1592975904.6027114}
  0: {'training_steps': 504, 'average_loss': 1.3173828125, 'step_loss': 1.3173828125, 'learning_rate': 0.0008482828282828282, 'seq/s': 24121.061671762363, 'global_steps': 496, 'samples_trained': 2539520, 'skipped_steps': 8, 'timestamp': 1592975904.8149743}
  0: {'training_steps': 505, 'average_loss': 1.494140625, 'step_loss': 1.494140625, 'learning_rate': 0.0008465656565656565, 'seq/s': 24165.440827133916, 'global_steps': 497, 'samples_trained': 2544640, 'skipped_steps': 8, 'timestamp': 1592975905.026848}
  0: {'training_steps': 506, 'average_loss': 1.130859375, 'step_loss': 1.130859375, 'learning_rate': 0.0008448484848484848, 'seq/s': 24165.11451369517, 'global_steps': 498, 'samples_trained': 2549760, 'skipped_steps': 8, 'timestamp': 1592975905.2387245}
  0: {'training_steps': 507, 'average_loss': 1.330078125, 'step_loss': 1.330078125, 'learning_rate': 0.0008431313131313131, 'seq/s': 24245.79094380353, 'global_steps': 499, 'samples_trained': 2554880, 'skipped_steps': 8, 'timestamp': 1592975905.4498954}
  0: {'training_steps': 508, 'average_loss': 1.515625, 'step_loss': 1.515625, 'learning_rate': 0.0008414141414141413, 'seq/s': 24263.87144739191, 'global_steps': 500, 'samples_trained': 2560000, 'skipped_steps': 8, 'timestamp': 1592975905.6609094}
  0: {'training_steps': 509, 'average_loss': 1.54296875, 'step_loss': 1.54296875, 'learning_rate': 0.0008396969696969696, 'seq/s': 24224.84035736847, 'global_steps': 501, 'samples_trained': 2565120, 'skipped_steps': 8, 'timestamp': 1592975905.8722632}
  0: {'training_steps': 510, 'average_loss': 1.4248046875, 'step_loss': 1.4248046875, 'learning_rate': 0.0008379797979797979, 'seq/s': 24149.217413208346, 'global_steps': 502, 'samples_trained': 2570240, 'skipped_steps': 8, 'timestamp': 1592975906.0842788}
  0: {'training_steps': 511, 'average_loss': 1.541015625, 'step_loss': 1.541015625, 'learning_rate': 0.0008362626262626261, 'seq/s': 24084.730086346797, 'global_steps': 503, 'samples_trained': 2575360, 'skipped_steps': 8, 'timestamp': 1592975906.2968621}
  0: {'training_steps': 512, 'average_loss': 1.287109375, 'step_loss': 1.287109375, 'learning_rate': 0.0008345454545454546, 'seq/s': 24117.404621817124, 'global_steps': 504, 'samples_trained': 2580480, 'skipped_steps': 8, 'timestamp': 1592975906.5091574}
  0: {'training_steps': 513, 'average_loss': 1.375, 'step_loss': 1.375, 'learning_rate': 0.0008328282828282829, 'seq/s': 24251.86955952171, 'global_steps': 505, 'samples_trained': 2585600, 'skipped_steps': 8, 'timestamp': 1592975906.7202756}
  0: {'training_steps': 514, 'average_loss': 1.5390625, 'step_loss': 1.5390625, 'learning_rate': 0.0008311111111111111, 'seq/s': 23667.721918957137, 'global_steps': 506, 'samples_trained': 2590720, 'skipped_steps': 8, 'timestamp': 1592975906.9366045}
  0: {'training_steps': 515, 'average_loss': 1.3798828125, 'step_loss': 1.3798828125, 'learning_rate': 0.0008293939393939394, 'seq/s': 24222.381176895226, 'global_steps': 507, 'samples_trained': 2595840, 'skipped_steps': 8, 'timestamp': 1592975907.1479797}
  0: {'training_steps': 516, 'average_loss': 1.4716796875, 'step_loss': 1.4716796875, 'learning_rate': 0.0008276767676767677, 'seq/s': 24203.76226821692, 'global_steps': 508, 'samples_trained': 2600960, 'skipped_steps': 8, 'timestamp': 1592975907.3595178}
  0: {'training_steps': 517, 'average_loss': 1.345703125, 'step_loss': 1.345703125, 'learning_rate': 0.0008259595959595959, 'seq/s': 24162.042160974994, 'global_steps': 509, 'samples_trained': 2606080, 'skipped_steps': 8, 'timestamp': 1592975907.571421}
  0: {'training_steps': 518, 'average_loss': 1.087890625, 'step_loss': 1.087890625, 'learning_rate': 0.0008242424242424243, 'seq/s': 24159.05212545028, 'global_steps': 510, 'samples_trained': 2611200, 'skipped_steps': 8, 'timestamp': 1592975907.7833502}
  0: {'training_steps': 519, 'average_loss': 1.5048828125, 'step_loss': 1.5048828125, 'learning_rate': 0.0008225252525252525, 'seq/s': 24258.554077501445, 'global_steps': 511, 'samples_trained': 2616320, 'skipped_steps': 8, 'timestamp': 1592975907.9944103}
  0: {'training_steps': 520, 'average_loss': 1.3486328125, 'step_loss': 1.3486328125, 'learning_rate': 0.0008208080808080807, 'seq/s': 24223.720002120648, 'global_steps': 512, 'samples_trained': 2621440, 'skipped_steps': 8, 'timestamp': 1592975908.2057738}
  0: {'training_steps': 521, 'average_loss': 1.26953125, 'step_loss': 1.26953125, 'learning_rate': 0.0008190909090909091, 'seq/s': 23960.899620081564, 'global_steps': 513, 'samples_trained': 2626560, 'skipped_steps': 8, 'timestamp': 1592975908.4194558}
  0: {'training_steps': 522, 'average_loss': 1.5849609375, 'step_loss': 1.5849609375, 'learning_rate': 0.0008173737373737373, 'seq/s': 24128.053786588407, 'global_steps': 514, 'samples_trained': 2631680, 'skipped_steps': 8, 'timestamp': 1592975908.6316574}
  0: {'training_steps': 523, 'average_loss': 1.2958984375, 'step_loss': 1.2958984375, 'learning_rate': 0.0008156565656565655, 'seq/s': 24226.50741917761, 'global_steps': 515, 'samples_trained': 2636800, 'skipped_steps': 8, 'timestamp': 1592975908.8429968}
  0: {'training_steps': 524, 'average_loss': 1.443359375, 'step_loss': 1.443359375, 'learning_rate': 0.0008139393939393939, 'seq/s': 24159.84033570902, 'global_steps': 516, 'samples_trained': 2641920, 'skipped_steps': 8, 'timestamp': 1592975909.0549192}
  0: {'training_steps': 525, 'average_loss': 1.65234375, 'step_loss': 1.65234375, 'learning_rate': 0.0008122222222222221, 'seq/s': 24146.149101216706, 'global_steps': 517, 'samples_trained': 2647040, 'skipped_steps': 8, 'timestamp': 1592975909.2669618}
  0: {'training_steps': 526, 'average_loss': 1.5390625, 'step_loss': 1.5390625, 'learning_rate': 0.0008105050505050504, 'seq/s': 22925.664214126802, 'global_steps': 518, 'samples_trained': 2652160, 'skipped_steps': 8, 'timestamp': 1592975909.4902928}
  0: {'training_steps': 527, 'average_loss': 1.4921875, 'step_loss': 1.4921875, 'learning_rate': 0.0008087878787878787, 'seq/s': 24333.237563326387, 'global_steps': 519, 'samples_trained': 2657280, 'skipped_steps': 8, 'timestamp': 1592975909.7007053}
  0: {'training_steps': 528, 'average_loss': 1.6591796875, 'step_loss': 1.6591796875, 'learning_rate': 0.0008070707070707069, 'seq/s': 24182.748059453414, 'global_steps': 520, 'samples_trained': 2662400, 'skipped_steps': 8, 'timestamp': 1592975909.912427}
  0: {'training_steps': 529, 'average_loss': 1.4833984375, 'step_loss': 1.4833984375, 'learning_rate': 0.0008053535353535353, 'seq/s': 21337.97471020872, 'global_steps': 521, 'samples_trained': 2667520, 'skipped_steps': 8, 'timestamp': 1592975910.1523752}
  0: {'training_steps': 530, 'average_loss': 1.4990234375, 'step_loss': 1.4990234375, 'learning_rate': 0.0008036363636363637, 'seq/s': 23367.562290397625, 'global_steps': 522, 'samples_trained': 2672640, 'skipped_steps': 8, 'timestamp': 1592975910.371483}
  0: {'training_steps': 531, 'average_loss': 1.333984375, 'step_loss': 1.333984375, 'learning_rate': 0.0008019191919191919, 'seq/s': 24119.598718703248, 'global_steps': 523, 'samples_trained': 2677760, 'skipped_steps': 8, 'timestamp': 1592975910.583759}
  0: {'training_steps': 532, 'average_loss': 1.3740234375, 'step_loss': 1.3740234375, 'learning_rate': 0.0008002020202020203, 'seq/s': 24194.027415224497, 'global_steps': 524, 'samples_trained': 2682880, 'skipped_steps': 8, 'timestamp': 1592975910.795382}
  0: {'training_steps': 533, 'average_loss': 1.55078125, 'step_loss': 1.55078125, 'learning_rate': 0.0007984848484848485, 'seq/s': 21738.766848305273, 'global_steps': 525, 'samples_trained': 2688000, 'skipped_steps': 8, 'timestamp': 1592975911.0309064}
  0: {'training_steps': 534, 'average_loss': 1.4296875, 'step_loss': 1.4296875, 'learning_rate': 0.0007967676767676767, 'seq/s': 23374.1497676717, 'global_steps': 526, 'samples_trained': 2693120, 'skipped_steps': 8, 'timestamp': 1592975911.2499523}
  0: {'training_steps': 535, 'average_loss': 1.31640625, 'step_loss': 1.31640625, 'learning_rate': 0.000795050505050505, 'seq/s': 24175.941945775678, 'global_steps': 527, 'samples_trained': 2698240, 'skipped_steps': 8, 'timestamp': 1592975911.4617336}
  0: {'training_steps': 536, 'average_loss': 1.3203125, 'step_loss': 1.3203125, 'learning_rate': 0.0007933333333333333, 'seq/s': 24064.623087422202, 'global_steps': 528, 'samples_trained': 2703360, 'skipped_steps': 8, 'timestamp': 1592975911.6744945}
  0: {'training_steps': 537, 'average_loss': 1.1806640625, 'step_loss': 1.1806640625, 'learning_rate': 0.0007916161616161616, 'seq/s': 21157.70365984262, 'global_steps': 529, 'samples_trained': 2708480, 'skipped_steps': 8, 'timestamp': 1592975911.9164872}
  0: {'training_steps': 538, 'average_loss': 1.5322265625, 'step_loss': 1.5322265625, 'learning_rate': 0.0007898989898989899, 'seq/s': 24224.86768440087, 'global_steps': 530, 'samples_trained': 2713600, 'skipped_steps': 8, 'timestamp': 1592975912.127841}
  0: {'training_steps': 539, 'average_loss': 1.4150390625, 'step_loss': 1.4150390625, 'learning_rate': 0.0007881818181818181, 'seq/s': 24124.584323787527, 'global_steps': 531, 'samples_trained': 2718720, 'skipped_steps': 8, 'timestamp': 1592975912.340073}
  0: {'training_steps': 540, 'average_loss': 1.1640625, 'step_loss': 1.1640625, 'learning_rate': 0.0007864646464646464, 'seq/s': 24046.272748955, 'global_steps': 532, 'samples_trained': 2723840, 'skipped_steps': 8, 'timestamp': 1592975912.5529964}
  0: {'training_steps': 541, 'average_loss': 1.5263671875, 'step_loss': 1.5263671875, 'learning_rate': 0.0007847474747474746, 'seq/s': 24288.70753685182, 'global_steps': 533, 'samples_trained': 2728960, 'skipped_steps': 8, 'timestamp': 1592975912.7637944}
  0: {'training_steps': 542, 'average_loss': 1.2900390625, 'step_loss': 1.2900390625, 'learning_rate': 0.0007830303030303029, 'seq/s': 24259.348793914276, 'global_steps': 534, 'samples_trained': 2734080, 'skipped_steps': 8, 'timestamp': 1592975912.9748478}
  0: {'training_steps': 543, 'average_loss': 1.2041015625, 'step_loss': 1.2041015625, 'learning_rate': 0.0007813131313131312, 'seq/s': 24260.636893168787, 'global_steps': 535, 'samples_trained': 2739200, 'skipped_steps': 8, 'timestamp': 1592975913.1858897}
  0: {'training_steps': 544, 'average_loss': 1.4248046875, 'step_loss': 1.4248046875, 'learning_rate': 0.0007795959595959594, 'seq/s': 24258.499271392262, 'global_steps': 536, 'samples_trained': 2744320, 'skipped_steps': 8, 'timestamp': 1592975913.3969502}
  0: {'training_steps': 545, 'average_loss': 1.4296875, 'step_loss': 1.4296875, 'learning_rate': 0.0007778787878787878, 'seq/s': 24161.60720072007, 'global_steps': 537, 'samples_trained': 2749440, 'skipped_steps': 8, 'timestamp': 1592975913.6088572}
  0: {'training_steps': 546, 'average_loss': 1.5205078125, 'step_loss': 1.5205078125, 'learning_rate': 0.0007761616161616162, 'seq/s': 24189.340028678245, 'global_steps': 538, 'samples_trained': 2754560, 'skipped_steps': 8, 'timestamp': 1592975913.820521}
  0: {'training_steps': 547, 'average_loss': 1.4306640625, 'step_loss': 1.4306640625, 'learning_rate': 0.0007744444444444445, 'seq/s': 23910.397377685833, 'global_steps': 539, 'samples_trained': 2759680, 'skipped_steps': 8, 'timestamp': 1592975914.0346541}
  0: {'training_steps': 548, 'average_loss': 1.5859375, 'step_loss': 1.5859375, 'learning_rate': 0.0007727272727272728, 'seq/s': 24265.54388565785, 'global_steps': 540, 'samples_trained': 2764800, 'skipped_steps': 8, 'timestamp': 1592975914.2456534}
  0: {'training_steps': 549, 'average_loss': 1.3857421875, 'step_loss': 1.3857421875, 'learning_rate': 0.000771010101010101, 'seq/s': 24177.193983069643, 'global_steps': 541, 'samples_trained': 2769920, 'skipped_steps': 8, 'timestamp': 1592975914.4574237}
  0: {'training_steps': 550, 'average_loss': 1.248046875, 'step_loss': 1.248046875, 'learning_rate': 0.0007692929292929293, 'seq/s': 24171.506422522274, 'global_steps': 542, 'samples_trained': 2775040, 'skipped_steps': 8, 'timestamp': 1592975914.6692438}
  0: {'training_steps': 551, 'average_loss': 1.71484375, 'step_loss': 1.71484375, 'learning_rate': 0.0007675757575757576, 'seq/s': 24210.474878411194, 'global_steps': 543, 'samples_trained': 2780160, 'skipped_steps': 8, 'timestamp': 1592975914.880723}
  0: {'training_steps': 552, 'average_loss': 1.2138671875, 'step_loss': 1.2138671875, 'learning_rate': 0.0007658585858585858, 'seq/s': 24179.48064669766, 'global_steps': 544, 'samples_trained': 2785280, 'skipped_steps': 8, 'timestamp': 1592975915.0924733}
  0: {'training_steps': 553, 'average_loss': 1.5927734375, 'step_loss': 1.5927734375, 'learning_rate': 0.0007641414141414141, 'seq/s': 24211.62130593801, 'global_steps': 545, 'samples_trained': 2790400, 'skipped_steps': 8, 'timestamp': 1592975915.3039424}
  0: {'training_steps': 554, 'average_loss': 1.470703125, 'step_loss': 1.470703125, 'learning_rate': 0.0007624242424242424, 'seq/s': 24311.530126715264, 'global_steps': 546, 'samples_trained': 2795520, 'skipped_steps': 8, 'timestamp': 1592975915.5145426}
  0: {'training_steps': 555, 'average_loss': 1.3203125, 'step_loss': 1.3203125, 'learning_rate': 0.0007607070707070706, 'seq/s': 24202.371095330458, 'global_steps': 547, 'samples_trained': 2800640, 'skipped_steps': 8, 'timestamp': 1592975915.7260926}
  0: {'training_steps': 556, 'average_loss': 1.6123046875, 'step_loss': 1.6123046875, 'learning_rate': 0.000758989898989899, 'seq/s': 24133.286973095255, 'global_steps': 548, 'samples_trained': 2805760, 'skipped_steps': 8, 'timestamp': 1592975915.9382482}
  0: {'training_steps': 557, 'average_loss': 1.357421875, 'step_loss': 1.357421875, 'learning_rate': 0.0007572727272727272, 'seq/s': 24085.621509100452, 'global_steps': 549, 'samples_trained': 2810880, 'skipped_steps': 8, 'timestamp': 1592975916.1508236}
  0: {'training_steps': 558, 'average_loss': 1.185546875, 'step_loss': 1.185546875, 'learning_rate': 0.0007555555555555554, 'seq/s': 24225.22294143261, 'global_steps': 550, 'samples_trained': 2816000, 'skipped_steps': 8, 'timestamp': 1592975916.362174}
  0: {'training_steps': 559, 'average_loss': 1.431640625, 'step_loss': 1.431640625, 'learning_rate': 0.0007538383838383838, 'seq/s': 24177.820050348793, 'global_steps': 551, 'samples_trained': 2821120, 'skipped_steps': 8, 'timestamp': 1592975916.5739388}
  0: {'training_steps': 560, 'average_loss': 1.111328125, 'step_loss': 1.111328125, 'learning_rate': 0.000752121212121212, 'seq/s': 24251.705232535816, 'global_steps': 552, 'samples_trained': 2826240, 'skipped_steps': 8, 'timestamp': 1592975916.7850585}
  0: {'training_steps': 561, 'average_loss': 1.4521484375, 'step_loss': 1.4521484375, 'learning_rate': 0.0007504040404040403, 'seq/s': 24183.8646278866, 'global_steps': 553, 'samples_trained': 2831360, 'skipped_steps': 8, 'timestamp': 1592975916.9967704}
  0: {'training_steps': 562, 'average_loss': 1.169921875, 'step_loss': 1.169921875, 'learning_rate': 0.0007486868686868686, 'seq/s': 24134.344732098303, 'global_steps': 554, 'samples_trained': 2836480, 'skipped_steps': 8, 'timestamp': 1592975917.2089167}
  0: {'training_steps': 563, 'average_loss': 1.4150390625, 'step_loss': 1.4150390625, 'learning_rate': 0.000746969696969697, 'seq/s': 24172.295445668482, 'global_steps': 555, 'samples_trained': 2841600, 'skipped_steps': 8, 'timestamp': 1592975917.4207299}
  0: {'training_steps': 564, 'average_loss': 1.49609375, 'step_loss': 1.49609375, 'learning_rate': 0.0007452525252525252, 'seq/s': 24113.47791424407, 'global_steps': 556, 'samples_trained': 2846720, 'skipped_steps': 8, 'timestamp': 1592975917.6330597}
  0: {'training_steps': 565, 'average_loss': 1.4111328125, 'step_loss': 1.4111328125, 'learning_rate': 0.0007435353535353536, 'seq/s': 23762.052879960607, 'global_steps': 557, 'samples_trained': 2851840, 'skipped_steps': 8, 'timestamp': 1592975917.8485298}
  0: {'training_steps': 566, 'average_loss': 1.513671875, 'step_loss': 1.513671875, 'learning_rate': 0.0007418181818181818, 'seq/s': 24287.05937170963, 'global_steps': 558, 'samples_trained': 2856960, 'skipped_steps': 8, 'timestamp': 1592975918.0593421}
  0: {'training_steps': 567, 'average_loss': 1.1220703125, 'step_loss': 1.1220703125, 'learning_rate': 0.0007401010101010102, 'seq/s': 24206.981673569044, 'global_steps': 559, 'samples_trained': 2862080, 'skipped_steps': 8, 'timestamp': 1592975918.2708519}
  0: {'training_steps': 568, 'average_loss': 1.142578125, 'step_loss': 1.142578125, 'learning_rate': 0.0007383838383838384, 'seq/s': 24085.621509100452, 'global_steps': 560, 'samples_trained': 2867200, 'skipped_steps': 8, 'timestamp': 1592975918.4834273}
  0: {'training_steps': 569, 'average_loss': 1.7265625, 'step_loss': 1.7265625, 'learning_rate': 0.0007366666666666666, 'seq/s': 24152.014872580985, 'global_steps': 561, 'samples_trained': 2872320, 'skipped_steps': 8, 'timestamp': 1592975918.6954184}
  0: {'training_steps': 570, 'average_loss': 1.509765625, 'step_loss': 1.509765625, 'learning_rate': 0.000734949494949495, 'seq/s': 24237.52672637966, 'global_steps': 562, 'samples_trained': 2877440, 'skipped_steps': 8, 'timestamp': 1592975918.906662}
  0: {'training_steps': 571, 'average_loss': 1.3935546875, 'step_loss': 1.3935546875, 'learning_rate': 0.0007332323232323232, 'seq/s': 24067.400981083272, 'global_steps': 563, 'samples_trained': 2882560, 'skipped_steps': 8, 'timestamp': 1592975919.1193984}
  0: {'training_steps': 572, 'average_loss': 1.55078125, 'step_loss': 1.55078125, 'learning_rate': 0.0007315151515151515, 'seq/s': 24080.651993523123, 'global_steps': 564, 'samples_trained': 2887680, 'skipped_steps': 8, 'timestamp': 1592975919.3320177}
  0: {'training_steps': 573, 'average_loss': 1.5927734375, 'step_loss': 1.5927734375, 'learning_rate': 0.0007297979797979797, 'seq/s': 24204.362431387577, 'global_steps': 565, 'samples_trained': 2892800, 'skipped_steps': 8, 'timestamp': 1592975919.5435503}
  0: {'training_steps': 574, 'average_loss': 1.185546875, 'step_loss': 1.185546875, 'learning_rate': 0.000728080808080808, 'seq/s': 24179.48064669766, 'global_steps': 566, 'samples_trained': 2897920, 'skipped_steps': 8, 'timestamp': 1592975919.7553005}
  0: {'training_steps': 575, 'average_loss': 1.5126953125, 'step_loss': 1.5126953125, 'learning_rate': 0.0007263636363636363, 'seq/s': 24116.18585158017, 'global_steps': 567, 'samples_trained': 2903040, 'skipped_steps': 8, 'timestamp': 1592975919.9676065}
  0: {'training_steps': 576, 'average_loss': 1.5244140625, 'step_loss': 1.5244140625, 'learning_rate': 0.0007246464646464645, 'seq/s': 24194.19096149968, 'global_steps': 568, 'samples_trained': 2908160, 'skipped_steps': 8, 'timestamp': 1592975920.179228}
  0: {'training_steps': 577, 'average_loss': 1.3271484375, 'step_loss': 1.3271484375, 'learning_rate': 0.0007229292929292928, 'seq/s': 23025.611408352543, 'global_steps': 569, 'samples_trained': 2913280, 'skipped_steps': 8, 'timestamp': 1592975920.4015899}
  0: {'training_steps': 578, 'average_loss': 1.0283203125, 'step_loss': 1.0283203125, 'learning_rate': 0.0007212121212121211, 'seq/s': 24256.389424472538, 'global_steps': 570, 'samples_trained': 2918400, 'skipped_steps': 8, 'timestamp': 1592975920.6126688}
  0: {'training_steps': 579, 'average_loss': 1.4072265625, 'step_loss': 1.4072265625, 'learning_rate': 0.0007194949494949493, 'seq/s': 24089.377014240603, 'global_steps': 571, 'samples_trained': 2923520, 'skipped_steps': 8, 'timestamp': 1592975920.825211}
  0: {'training_steps': 580, 'average_loss': 1.4013671875, 'step_loss': 1.4013671875, 'learning_rate': 0.0007177777777777778, 'seq/s': 24065.08153053963, 'global_steps': 572, 'samples_trained': 2928640, 'skipped_steps': 8, 'timestamp': 1592975921.037968}
  0: {'training_steps': 581, 'average_loss': 1.15234375, 'step_loss': 1.15234375, 'learning_rate': 0.0007160606060606061, 'seq/s': 21543.819790970687, 'global_steps': 573, 'samples_trained': 2933760, 'skipped_steps': 8, 'timestamp': 1592975921.2756238}
  0: {'training_steps': 582, 'average_loss': 1.30078125, 'step_loss': 1.30078125, 'learning_rate': 0.0007143434343434344, 'seq/s': 24183.755689841957, 'global_steps': 574, 'samples_trained': 2938880, 'skipped_steps': 8, 'timestamp': 1592975921.4873369}
  0: {'training_steps': 583, 'average_loss': 1.3828125, 'step_loss': 1.3828125, 'learning_rate': 0.0007126262626262626, 'seq/s': 24193.400508318762, 'global_steps': 575, 'samples_trained': 2944000, 'skipped_steps': 8, 'timestamp': 1592975921.6989653}
  0: {'training_steps': 584, 'average_loss': 1.1337890625, 'step_loss': 1.1337890625, 'learning_rate': 0.0007109090909090909, 'seq/s': 24214.78819369272, 'global_steps': 576, 'samples_trained': 2949120, 'skipped_steps': 8, 'timestamp': 1592975921.9104068}
  0: {'training_steps': 585, 'average_loss': 1.4814453125, 'step_loss': 1.4814453125, 'learning_rate': 0.0007091919191919192, 'seq/s': 21620.97263403343, 'global_steps': 577, 'samples_trained': 2954240, 'skipped_steps': 8, 'timestamp': 1592975922.1472144}
  0: {'training_steps': 586, 'average_loss': 1.34765625, 'step_loss': 1.34765625, 'learning_rate': 0.0007074747474747475, 'seq/s': 24187.26943640699, 'global_steps': 578, 'samples_trained': 2959360, 'skipped_steps': 8, 'timestamp': 1592975922.3588967}
  0: {'training_steps': 587, 'average_loss': 1.5263671875, 'step_loss': 1.5263671875, 'learning_rate': 0.0007057575757575757, 'seq/s': 23278.476085587397, 'global_steps': 579, 'samples_trained': 2964480, 'skipped_steps': 8, 'timestamp': 1592975922.5788429}
  0: {'training_steps': 588, 'average_loss': 1.35546875, 'step_loss': 1.35546875, 'learning_rate': 0.000704040404040404, 'seq/s': 21408.342169222396, 'global_steps': 580, 'samples_trained': 2969600, 'skipped_steps': 8, 'timestamp': 1592975922.818003}
  0: {'training_steps': 589, 'average_loss': 1.3662109375, 'step_loss': 1.3662109375, 'learning_rate': 0.0007023232323232323, 'seq/s': 24142.94585530761, 'global_steps': 581, 'samples_trained': 2974720, 'skipped_steps': 8, 'timestamp': 1592975923.0300736}
  0: {'training_steps': 590, 'average_loss': 1.4970703125, 'step_loss': 1.4970703125, 'learning_rate': 0.0007006060606060605, 'seq/s': 24323.425851779448, 'global_steps': 582, 'samples_trained': 2979840, 'skipped_steps': 8, 'timestamp': 1592975923.2405708}
  0: {'training_steps': 591, 'average_loss': 1.5654296875, 'step_loss': 1.5654296875, 'learning_rate': 0.0006988888888888889, 'seq/s': 23634.172665591796, 'global_steps': 583, 'samples_trained': 2984960, 'skipped_steps': 8, 'timestamp': 1592975923.4572067}
  0: {'training_steps': 592, 'average_loss': 1.4404296875, 'step_loss': 1.4404296875, 'learning_rate': 0.0006971717171717171, 'seq/s': 24353.078071062766, 'global_steps': 584, 'samples_trained': 2990080, 'skipped_steps': 8, 'timestamp': 1592975923.6674476}
  0: {'training_steps': 593, 'average_loss': 1.1064453125, 'step_loss': 1.1064453125, 'learning_rate': 0.0006954545454545453, 'seq/s': 24131.68694979897, 'global_steps': 585, 'samples_trained': 2995200, 'skipped_steps': 8, 'timestamp': 1592975923.8796172}
  0: :::MLLOG {"namespace": "", "time_ms": 1592975924386, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7052384614944458, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 843, "epoch_num": 1}}
  0: {'global_steps': 586, 'eval_loss': 1.3806931972503662, 'eval_mlm_accuracy': 0.7052384614944458}
  0: {'training_steps': 594, 'average_loss': 1.4599609375, 'step_loss': 1.4599609375, 'learning_rate': 0.0006937373737373737, 'seq/s': 10084.890525860017, 'global_steps': 586, 'samples_trained': 3000320, 'skipped_steps': 8, 'timestamp': 1592975924.3873084}
  0: {'training_steps': 595, 'average_loss': 1.513671875, 'step_loss': 1.513671875, 'learning_rate': 0.0006920202020202019, 'seq/s': 25493.41437471509, 'global_steps': 587, 'samples_trained': 3005440, 'skipped_steps': 8, 'timestamp': 1592975924.5881453}
  0: {'training_steps': 596, 'average_loss': 1.291015625, 'step_loss': 1.291015625, 'learning_rate': 0.0006903030303030301, 'seq/s': 24199.807391731098, 'global_steps': 588, 'samples_trained': 3010560, 'skipped_steps': 8, 'timestamp': 1592975924.7997177}
  0: {'training_steps': 597, 'average_loss': 1.173828125, 'step_loss': 1.173828125, 'learning_rate': 0.0006885858585858587, 'seq/s': 24149.842032403205, 'global_steps': 589, 'samples_trained': 3015680, 'skipped_steps': 8, 'timestamp': 1592975925.0117278}
  0: {'training_steps': 598, 'average_loss': 1.33203125, 'step_loss': 1.33203125, 'learning_rate': 0.0006868686868686869, 'seq/s': 24145.253192594573, 'global_steps': 590, 'samples_trained': 3020800, 'skipped_steps': 8, 'timestamp': 1592975925.2237785}
  0: {'training_steps': 599, 'average_loss': 1.3642578125, 'step_loss': 1.3642578125, 'learning_rate': 0.0006851515151515151, 'seq/s': 24098.35173874158, 'global_steps': 591, 'samples_trained': 3025920, 'skipped_steps': 8, 'timestamp': 1592975925.4362416}
  0: {'training_steps': 600, 'average_loss': 1.341796875, 'step_loss': 1.341796875, 'learning_rate': 0.0006834343434343435, 'seq/s': 24108.767552663605, 'global_steps': 592, 'samples_trained': 3031040, 'skipped_steps': 8, 'timestamp': 1592975925.6486135}
  0: {'training_steps': 601, 'average_loss': 1.3984375, 'step_loss': 1.3984375, 'learning_rate': 0.0006817171717171717, 'seq/s': 24142.728716856192, 'global_steps': 593, 'samples_trained': 3036160, 'skipped_steps': 8, 'timestamp': 1592975925.860686}
  0: {'training_steps': 602, 'average_loss': 1.4296875, 'step_loss': 1.4296875, 'learning_rate': 0.00068, 'seq/s': 24117.07960437581, 'global_steps': 594, 'samples_trained': 3041280, 'skipped_steps': 8, 'timestamp': 1592975926.0729842}
  0: {'training_steps': 603, 'average_loss': 1.470703125, 'step_loss': 1.470703125, 'learning_rate': 0.0006782828282828283, 'seq/s': 24240.83720982735, 'global_steps': 595, 'samples_trained': 3046400, 'skipped_steps': 8, 'timestamp': 1592975926.2841988}
  0: {'training_steps': 604, 'average_loss': 1.486328125, 'step_loss': 1.486328125, 'learning_rate': 0.0006765656565656565, 'seq/s': 24004.449357771296, 'global_steps': 596, 'samples_trained': 3051520, 'skipped_steps': 8, 'timestamp': 1592975926.4974933}
  0: {'training_steps': 605, 'average_loss': 1.3427734375, 'step_loss': 1.3427734375, 'learning_rate': 0.0006748484848484848, 'seq/s': 24228.748749064973, 'global_steps': 597, 'samples_trained': 3056640, 'skipped_steps': 8, 'timestamp': 1592975926.708813}
  0: {'training_steps': 606, 'average_loss': 1.3759765625, 'step_loss': 1.3759765625, 'learning_rate': 0.0006731313131313131, 'seq/s': 24153.101439299615, 'global_steps': 598, 'samples_trained': 3061760, 'skipped_steps': 8, 'timestamp': 1592975926.9207947}
  0: {'training_steps': 607, 'average_loss': 1.265625, 'step_loss': 1.265625, 'learning_rate': 0.0006714141414141413, 'seq/s': 24223.501408301363, 'global_steps': 599, 'samples_trained': 3066880, 'skipped_steps': 8, 'timestamp': 1592975927.1321604}
  0: {'training_steps': 608, 'average_loss': 1.62890625, 'step_loss': 1.62890625, 'learning_rate': 0.0006696969696969696, 'seq/s': 24242.94435200007, 'global_steps': 600, 'samples_trained': 3072000, 'skipped_steps': 8, 'timestamp': 1592975927.3433566}
  0: {'training_steps': 609, 'average_loss': 1.5263671875, 'step_loss': 1.5263671875, 'learning_rate': 0.0006679797979797979, 'seq/s': 24214.760889396053, 'global_steps': 601, 'samples_trained': 3077120, 'skipped_steps': 8, 'timestamp': 1592975927.5547984}
  0: {'training_steps': 610, 'average_loss': 1.291015625, 'step_loss': 1.291015625, 'learning_rate': 0.0006662626262626262, 'seq/s': 24213.39575306771, 'global_steps': 602, 'samples_trained': 3082240, 'skipped_steps': 8, 'timestamp': 1592975927.766252}
  0: {'training_steps': 611, 'average_loss': 1.2529296875, 'step_loss': 1.2529296875, 'learning_rate': 0.0006645454545454544, 'seq/s': 24127.86402454713, 'global_steps': 603, 'samples_trained': 3087360, 'skipped_steps': 8, 'timestamp': 1592975927.9784555}
  0: {'training_steps': 612, 'average_loss': 1.4111328125, 'step_loss': 1.4111328125, 'learning_rate': 0.0006628282828282827, 'seq/s': 23423.84055742075, 'global_steps': 604, 'samples_trained': 3092480, 'skipped_steps': 8, 'timestamp': 1592975928.1970367}
  0: {'training_steps': 613, 'average_loss': 1.4345703125, 'step_loss': 1.4345703125, 'learning_rate': 0.000661111111111111, 'seq/s': 24261.65102498489, 'global_steps': 605, 'samples_trained': 3097600, 'skipped_steps': 8, 'timestamp': 1592975928.4080698}
  0: {'training_steps': 614, 'average_loss': 1.6865234375, 'step_loss': 1.6865234375, 'learning_rate': 0.0006593939393939395, 'seq/s': 23278.375151622236, 'global_steps': 606, 'samples_trained': 3102720, 'skipped_steps': 8, 'timestamp': 1592975928.628017}
  0: {'training_steps': 615, 'average_loss': 1.4501953125, 'step_loss': 1.4501953125, 'learning_rate': 0.0006576767676767677, 'seq/s': 23282.18601605426, 'global_steps': 607, 'samples_trained': 3107840, 'skipped_steps': 8, 'timestamp': 1592975928.847928}
  0: {'training_steps': 616, 'average_loss': 1.3330078125, 'step_loss': 1.3330078125, 'learning_rate': 0.000655959595959596, 'seq/s': 24224.43045928065, 'global_steps': 608, 'samples_trained': 3112960, 'skipped_steps': 8, 'timestamp': 1592975929.0592854}
  0: {'training_steps': 617, 'average_loss': 1.142578125, 'step_loss': 1.142578125, 'learning_rate': 0.0006542424242424243, 'seq/s': 24308.943246250623, 'global_steps': 609, 'samples_trained': 3118080, 'skipped_steps': 8, 'timestamp': 1592975929.269908}
  0: {'training_steps': 618, 'average_loss': 1.544921875, 'step_loss': 1.544921875, 'learning_rate': 0.0006525252525252525, 'seq/s': 24307.29233377817, 'global_steps': 610, 'samples_trained': 3123200, 'skipped_steps': 8, 'timestamp': 1592975929.4805448}
  0: {'training_steps': 619, 'average_loss': 1.591796875, 'step_loss': 1.591796875, 'learning_rate': 0.0006508080808080808, 'seq/s': 24247.92632639143, 'global_steps': 611, 'samples_trained': 3128320, 'skipped_steps': 8, 'timestamp': 1592975929.6916976}
  0: {'training_steps': 620, 'average_loss': 1.3642578125, 'step_loss': 1.3642578125, 'learning_rate': 0.0006490909090909091, 'seq/s': 24228.612070735675, 'global_steps': 612, 'samples_trained': 3133440, 'skipped_steps': 8, 'timestamp': 1592975929.9030185}
  0: {'training_steps': 621, 'average_loss': 1.390625, 'step_loss': 1.390625, 'learning_rate': 0.0006473737373737374, 'seq/s': 24142.15874700399, 'global_steps': 613, 'samples_trained': 3138560, 'skipped_steps': 8, 'timestamp': 1592975930.115096}
  0: {'training_steps': 622, 'average_loss': 1.4970703125, 'step_loss': 1.4970703125, 'learning_rate': 0.0006456565656565656, 'seq/s': 24192.937163225553, 'global_steps': 614, 'samples_trained': 3143680, 'skipped_steps': 8, 'timestamp': 1592975930.3267288}
  0: {'training_steps': 623, 'average_loss': 1.556640625, 'step_loss': 1.556640625, 'learning_rate': 0.0006439393939393939, 'seq/s': 24124.80113598066, 'global_steps': 615, 'samples_trained': 3148800, 'skipped_steps': 8, 'timestamp': 1592975930.538959}
  0: {'training_steps': 624, 'average_loss': 1.484375, 'step_loss': 1.484375, 'learning_rate': 0.0006422222222222222, 'seq/s': 24091.133587614986, 'global_steps': 616, 'samples_trained': 3153920, 'skipped_steps': 8, 'timestamp': 1592975930.7514856}
  0: {'training_steps': 625, 'average_loss': 1.646484375, 'step_loss': 1.646484375, 'learning_rate': 0.0006405050505050504, 'seq/s': 24130.276935661845, 'global_steps': 617, 'samples_trained': 3159040, 'skipped_steps': 8, 'timestamp': 1592975930.9636676}
  0: {'training_steps': 626, 'average_loss': 1.7119140625, 'step_loss': 1.7119140625, 'learning_rate': 0.0006387878787878788, 'seq/s': 24253.62251927881, 'global_steps': 618, 'samples_trained': 3164160, 'skipped_steps': 8, 'timestamp': 1592975931.1747704}
  0: {'training_steps': 627, 'average_loss': 1.0986328125, 'step_loss': 1.0986328125, 'learning_rate': 0.000637070707070707, 'seq/s': 24223.419436636243, 'global_steps': 619, 'samples_trained': 3169280, 'skipped_steps': 8, 'timestamp': 1592975931.3861368}
  0: {'training_steps': 628, 'average_loss': 1.3291015625, 'step_loss': 1.3291015625, 'learning_rate': 0.0006353535353535352, 'seq/s': 24144.058751177698, 'global_steps': 620, 'samples_trained': 3174400, 'skipped_steps': 8, 'timestamp': 1592975931.5981977}
  0: {'training_steps': 629, 'average_loss': 1.4384765625, 'step_loss': 1.4384765625, 'learning_rate': 0.0006336363636363636, 'seq/s': 24144.81883658752, 'global_steps': 621, 'samples_trained': 3179520, 'skipped_steps': 8, 'timestamp': 1592975931.810252}
  0: {'training_steps': 630, 'average_loss': 1.498046875, 'step_loss': 1.498046875, 'learning_rate': 0.0006319191919191918, 'seq/s': 24157.231284612037, 'global_steps': 622, 'samples_trained': 3184640, 'skipped_steps': 8, 'timestamp': 1592975932.0221975}
  0: {'training_steps': 631, 'average_loss': 1.3466796875, 'step_loss': 1.3466796875, 'learning_rate': 0.00063020202020202, 'seq/s': 24100.02848257883, 'global_steps': 623, 'samples_trained': 3189760, 'skipped_steps': 8, 'timestamp': 1592975932.2346458}
  0: {'training_steps': 632, 'average_loss': 1.5595703125, 'step_loss': 1.5595703125, 'learning_rate': 0.0006284848484848486, 'seq/s': 24174.771680347985, 'global_steps': 624, 'samples_trained': 3194880, 'skipped_steps': 8, 'timestamp': 1592975932.4464374}
  0: {'training_steps': 633, 'average_loss': 1.185546875, 'step_loss': 1.185546875, 'learning_rate': 0.0006267676767676768, 'seq/s': 21672.48958501534, 'global_steps': 625, 'samples_trained': 3200000, 'skipped_steps': 8, 'timestamp': 1592975932.682682}
  0: {'training_steps': 634, 'average_loss': 1.3740234375, 'step_loss': 1.3740234375, 'learning_rate': 0.000625050505050505, 'seq/s': 24252.41733222507, 'global_steps': 626, 'samples_trained': 3205120, 'skipped_steps': 8, 'timestamp': 1592975932.8937955}
  0: {'training_steps': 635, 'average_loss': 1.208984375, 'step_loss': 1.208984375, 'learning_rate': 0.0006233333333333334, 'seq/s': 24173.166151681442, 'global_steps': 627, 'samples_trained': 3210240, 'skipped_steps': 8, 'timestamp': 1592975933.105601}
  0: {'training_steps': 636, 'average_loss': 1.26953125, 'step_loss': 1.26953125, 'learning_rate': 0.0006216161616161616, 'seq/s': 24219.813232521, 'global_steps': 628, 'samples_trained': 3215360, 'skipped_steps': 8, 'timestamp': 1592975933.3169987}
  0: {'training_steps': 637, 'average_loss': 1.455078125, 'step_loss': 1.455078125, 'learning_rate': 0.00061989898989899, 'seq/s': 24185.335387553947, 'global_steps': 629, 'samples_trained': 3220480, 'skipped_steps': 8, 'timestamp': 1592975933.528698}
  0: {'training_steps': 638, 'average_loss': 1.4912109375, 'step_loss': 1.4912109375, 'learning_rate': 0.0006181818181818182, 'seq/s': 23389.781261674558, 'global_steps': 630, 'samples_trained': 3225600, 'skipped_steps': 8, 'timestamp': 1592975933.7475975}
  0: {'training_steps': 639, 'average_loss': 1.4541015625, 'step_loss': 1.4541015625, 'learning_rate': 0.0006164646464646464, 'seq/s': 24159.622893259217, 'global_steps': 631, 'samples_trained': 3230720, 'skipped_steps': 8, 'timestamp': 1592975933.9595218}
  0: {'training_steps': 640, 'average_loss': 1.609375, 'step_loss': 1.609375, 'learning_rate': 0.0006147474747474747, 'seq/s': 24169.98293738154, 'global_steps': 632, 'samples_trained': 3235840, 'skipped_steps': 8, 'timestamp': 1592975934.1713555}
  0: {'training_steps': 641, 'average_loss': 1.2421875, 'step_loss': 1.2421875, 'learning_rate': 0.000613030303030303, 'seq/s': 24205.50828009396, 'global_steps': 633, 'samples_trained': 3240960, 'skipped_steps': 8, 'timestamp': 1592975934.3828785}
  0: {'training_steps': 642, 'average_loss': 1.216796875, 'step_loss': 1.216796875, 'learning_rate': 0.0006113131313131312, 'seq/s': 24051.416642027078, 'global_steps': 634, 'samples_trained': 3246080, 'skipped_steps': 8, 'timestamp': 1592975934.5957563}
  0: {'training_steps': 643, 'average_loss': 1.095703125, 'step_loss': 1.095703125, 'learning_rate': 0.0006095959595959595, 'seq/s': 23163.15232679547, 'global_steps': 635, 'samples_trained': 3251200, 'skipped_steps': 8, 'timestamp': 1592975934.8167975}
  0: {'training_steps': 644, 'average_loss': 1.37109375, 'step_loss': 1.37109375, 'learning_rate': 0.0006078787878787878, 'seq/s': 24189.912228530233, 'global_steps': 636, 'samples_trained': 3256320, 'skipped_steps': 8, 'timestamp': 1592975935.0284564}
  0: {'training_steps': 645, 'average_loss': 1.3544921875, 'step_loss': 1.3544921875, 'learning_rate': 0.0006061616161616161, 'seq/s': 24228.12004151812, 'global_steps': 637, 'samples_trained': 3261440, 'skipped_steps': 8, 'timestamp': 1592975935.2397816}
  0: {'training_steps': 646, 'average_loss': 1.462890625, 'step_loss': 1.462890625, 'learning_rate': 0.0006044444444444443, 'seq/s': 24193.645815847492, 'global_steps': 638, 'samples_trained': 3266560, 'skipped_steps': 8, 'timestamp': 1592975935.451408}
  0: {'training_steps': 647, 'average_loss': 1.3310546875, 'step_loss': 1.3310546875, 'learning_rate': 0.0006027272727272726, 'seq/s': 24227.10871088237, 'global_steps': 639, 'samples_trained': 3271680, 'skipped_steps': 8, 'timestamp': 1592975935.662742}
  0: {'training_steps': 648, 'average_loss': 1.4384765625, 'step_loss': 1.4384765625, 'learning_rate': 0.0006010101010101009, 'seq/s': 24242.31490752855, 'global_steps': 640, 'samples_trained': 3276800, 'skipped_steps': 8, 'timestamp': 1592975935.873943}
  0: {'training_steps': 649, 'average_loss': 1.7001953125, 'step_loss': 1.7001953125, 'learning_rate': 0.0005992929292929294, 'seq/s': 21352.062122793934, 'global_steps': 641, 'samples_trained': 3281920, 'skipped_steps': 8, 'timestamp': 1592975936.113733}
  0: {'training_steps': 650, 'average_loss': 1.23828125, 'step_loss': 1.23828125, 'learning_rate': 0.0005975757575757576, 'seq/s': 24250.062085148573, 'global_steps': 642, 'samples_trained': 3287040, 'skipped_steps': 8, 'timestamp': 1592975936.324867}
  0: {'training_steps': 651, 'average_loss': 1.6474609375, 'step_loss': 1.6474609375, 'learning_rate': 0.0005958585858585859, 'seq/s': 24186.016355390173, 'global_steps': 643, 'samples_trained': 3292160, 'skipped_steps': 8, 'timestamp': 1592975936.53656}
  0: {'training_steps': 652, 'average_loss': 1.455078125, 'step_loss': 1.455078125, 'learning_rate': 0.0005941414141414142, 'seq/s': 24175.56091668571, 'global_steps': 644, 'samples_trained': 3297280, 'skipped_steps': 8, 'timestamp': 1592975936.748345}
  0: {'training_steps': 653, 'average_loss': 1.1572265625, 'step_loss': 1.1572265625, 'learning_rate': 0.0005924242424242424, 'seq/s': 21201.632246866873, 'global_steps': 645, 'samples_trained': 3302400, 'skipped_steps': 8, 'timestamp': 1592975936.9898362}
  0: {'training_steps': 654, 'average_loss': 1.3974609375, 'step_loss': 1.3974609375, 'learning_rate': 0.0005907070707070707, 'seq/s': 24176.595166445444, 'global_steps': 646, 'samples_trained': 3307520, 'skipped_steps': 8, 'timestamp': 1592975937.2016118}
  0: {'training_steps': 655, 'average_loss': 1.203125, 'step_loss': 1.203125, 'learning_rate': 0.000588989898989899, 'seq/s': 24223.22817157508, 'global_steps': 647, 'samples_trained': 3312640, 'skipped_steps': 8, 'timestamp': 1592975937.4129796}
  0: {'training_steps': 656, 'average_loss': 1.3701171875, 'step_loss': 1.3701171875, 'learning_rate': 0.0005872727272727273, 'seq/s': 24104.356641684746, 'global_steps': 648, 'samples_trained': 3317760, 'skipped_steps': 8, 'timestamp': 1592975937.6253898}
  0: {'training_steps': 657, 'average_loss': 1.1845703125, 'step_loss': 1.1845703125, 'learning_rate': 0.0005855555555555555, 'seq/s': 21443.63598963508, 'global_steps': 649, 'samples_trained': 3322880, 'skipped_steps': 8, 'timestamp': 1592975937.864156}
  0: {'training_steps': 658, 'average_loss': 1.345703125, 'step_loss': 1.345703125, 'learning_rate': 0.0005838383838383838, 'seq/s': 24238.56628494161, 'global_steps': 650, 'samples_trained': 3328000, 'skipped_steps': 8, 'timestamp': 1592975938.07539}
  0: {'training_steps': 659, 'average_loss': 1.416015625, 'step_loss': 1.416015625, 'learning_rate': 0.0005821212121212121, 'seq/s': 24221.39764450049, 'global_steps': 651, 'samples_trained': 3333120, 'skipped_steps': 8, 'timestamp': 1592975938.286774}
  0: {'training_steps': 660, 'average_loss': 1.4423828125, 'step_loss': 1.4423828125, 'learning_rate': 0.0005804040404040403, 'seq/s': 24194.43628505826, 'global_steps': 652, 'samples_trained': 3338240, 'skipped_steps': 8, 'timestamp': 1592975938.4983933}
  0: {'training_steps': 661, 'average_loss': 1.458984375, 'step_loss': 1.458984375, 'learning_rate': 0.0005786868686868686, 'seq/s': 21015.68577714102, 'global_steps': 653, 'samples_trained': 3343360, 'skipped_steps': 8, 'timestamp': 1592975938.7420213}
  0: {'training_steps': 662, 'average_loss': 1.1494140625, 'step_loss': 1.1494140625, 'learning_rate': 0.0005769696969696969, 'seq/s': 24296.676822886908, 'global_steps': 654, 'samples_trained': 3348480, 'skipped_steps': 8, 'timestamp': 1592975938.9527504}
  0: {'training_steps': 663, 'average_loss': 1.1552734375, 'step_loss': 1.1552734375, 'learning_rate': 0.0005752525252525251, 'seq/s': 22824.93115799543, 'global_steps': 655, 'samples_trained': 3353600, 'skipped_steps': 8, 'timestamp': 1592975939.177067}
  0: {'training_steps': 664, 'average_loss': 1.4375, 'step_loss': 1.4375, 'learning_rate': 0.0005735353535353535, 'seq/s': 24264.255265298743, 'global_steps': 656, 'samples_trained': 3358720, 'skipped_steps': 8, 'timestamp': 1592975939.3880775}
  0: {'training_steps': 665, 'average_loss': 1.2275390625, 'step_loss': 1.2275390625, 'learning_rate': 0.0005718181818181817, 'seq/s': 24115.508810228872, 'global_steps': 657, 'samples_trained': 3363840, 'skipped_steps': 8, 'timestamp': 1592975939.6003897}
  0: {'training_steps': 666, 'average_loss': 1.5009765625, 'step_loss': 1.5009765625, 'learning_rate': 0.0005701010101010101, 'seq/s': 24233.04123315805, 'global_steps': 658, 'samples_trained': 3368960, 'skipped_steps': 8, 'timestamp': 1592975939.811672}
  0: {'training_steps': 667, 'average_loss': 1.4931640625, 'step_loss': 1.4931640625, 'learning_rate': 0.0005683838383838385, 'seq/s': 24283.818632700346, 'global_steps': 659, 'samples_trained': 3374080, 'skipped_steps': 8, 'timestamp': 1592975940.0225124}
  0: {'training_steps': 668, 'average_loss': 1.458984375, 'step_loss': 1.458984375, 'learning_rate': 0.0005666666666666667, 'seq/s': 24107.928543443435, 'global_steps': 660, 'samples_trained': 3379200, 'skipped_steps': 8, 'timestamp': 1592975940.2348912}
  0: {'training_steps': 669, 'average_loss': 1.1865234375, 'step_loss': 1.1865234375, 'learning_rate': 0.0005649494949494949, 'seq/s': 24231.892776302102, 'global_steps': 661, 'samples_trained': 3384320, 'skipped_steps': 8, 'timestamp': 1592975940.4461834}
  0: {'training_steps': 670, 'average_loss': 1.5126953125, 'step_loss': 1.5126953125, 'learning_rate': 0.0005632323232323233, 'seq/s': 24185.30814963809, 'global_steps': 662, 'samples_trained': 3389440, 'skipped_steps': 8, 'timestamp': 1592975940.6578827}
  0: {'training_steps': 671, 'average_loss': 1.5595703125, 'step_loss': 1.5595703125, 'learning_rate': 0.0005615151515151515, 'seq/s': 24141.833062028403, 'global_steps': 663, 'samples_trained': 3394560, 'skipped_steps': 8, 'timestamp': 1592975940.8699632}
  0: {'training_steps': 672, 'average_loss': 1.2392578125, 'step_loss': 1.2392578125, 'learning_rate': 0.0005597979797979797, 'seq/s': 24116.104604610788, 'global_steps': 664, 'samples_trained': 3399680, 'skipped_steps': 8, 'timestamp': 1592975941.08227}
  0: {'training_steps': 673, 'average_loss': 1.6923828125, 'step_loss': 1.6923828125, 'learning_rate': 0.0005580808080808081, 'seq/s': 24239.0587385435, 'global_steps': 665, 'samples_trained': 3404800, 'skipped_steps': 8, 'timestamp': 1592975941.2934997}
  0: {'training_steps': 674, 'average_loss': 1.328125, 'step_loss': 1.328125, 'learning_rate': 0.0005563636363636363, 'seq/s': 24220.496143300712, 'global_steps': 666, 'samples_trained': 3409920, 'skipped_steps': 8, 'timestamp': 1592975941.5048914}
  0: {'training_steps': 675, 'average_loss': 1.396484375, 'step_loss': 1.396484375, 'learning_rate': 0.0005546464646464646, 'seq/s': 24243.491721588896, 'global_steps': 667, 'samples_trained': 3415040, 'skipped_steps': 8, 'timestamp': 1592975941.7160826}
  0: {'training_steps': 676, 'average_loss': 1.4326171875, 'step_loss': 1.4326171875, 'learning_rate': 0.0005529292929292929, 'seq/s': 24134.968582156733, 'global_steps': 668, 'samples_trained': 3420160, 'skipped_steps': 8, 'timestamp': 1592975941.9282234}
  0: {'training_steps': 677, 'average_loss': 1.4365234375, 'step_loss': 1.4365234375, 'learning_rate': 0.0005512121212121211, 'seq/s': 24168.89485128279, 'global_steps': 669, 'samples_trained': 3425280, 'skipped_steps': 8, 'timestamp': 1592975942.1400664}
  0: {'training_steps': 678, 'average_loss': 1.4228515625, 'step_loss': 1.4228515625, 'learning_rate': 0.0005494949494949494, 'seq/s': 24102.841609172956, 'global_steps': 670, 'samples_trained': 3430400, 'skipped_steps': 8, 'timestamp': 1592975942.35249}
  0: {'training_steps': 679, 'average_loss': 1.2001953125, 'step_loss': 1.2001953125, 'learning_rate': 0.0005477777777777777, 'seq/s': 24201.771030907505, 'global_steps': 671, 'samples_trained': 3435520, 'skipped_steps': 8, 'timestamp': 1592975942.5640454}
  0: {'training_steps': 680, 'average_loss': 1.2607421875, 'step_loss': 1.2607421875, 'learning_rate': 0.000546060606060606, 'seq/s': 24139.22789852792, 'global_steps': 672, 'samples_trained': 3440640, 'skipped_steps': 8, 'timestamp': 1592975942.776149}
  0: {'training_steps': 681, 'average_loss': 1.5244140625, 'step_loss': 1.5244140625, 'learning_rate': 0.0005443434343434342, 'seq/s': 24250.472851120725, 'global_steps': 673, 'samples_trained': 3445760, 'skipped_steps': 8, 'timestamp': 1592975942.9872794}
  0: {'training_steps': 682, 'average_loss': 1.3134765625, 'step_loss': 1.3134765625, 'learning_rate': 0.0005426262626262625, 'seq/s': 24101.326767098042, 'global_steps': 674, 'samples_trained': 3450880, 'skipped_steps': 8, 'timestamp': 1592975943.1997163}
  0: {'training_steps': 683, 'average_loss': 1.4091796875, 'step_loss': 1.4091796875, 'learning_rate': 0.0005409090909090909, 'seq/s': 24237.22581817484, 'global_steps': 675, 'samples_trained': 3456000, 'skipped_steps': 8, 'timestamp': 1592975943.410962}
  0: {'training_steps': 684, 'average_loss': 1.3251953125, 'step_loss': 1.3251953125, 'learning_rate': 0.0005391919191919193, 'seq/s': 24114.940124870864, 'global_steps': 676, 'samples_trained': 3461120, 'skipped_steps': 8, 'timestamp': 1592975943.623279}
  0: {'training_steps': 685, 'average_loss': 1.16796875, 'step_loss': 1.16796875, 'learning_rate': 0.0005374747474747475, 'seq/s': 24091.83628869588, 'global_steps': 677, 'samples_trained': 3466240, 'skipped_steps': 8, 'timestamp': 1592975943.8357997}
  0: {'training_steps': 686, 'average_loss': 1.4501953125, 'step_loss': 1.4501953125, 'learning_rate': 0.0005357575757575758, 'seq/s': 24233.150615679053, 'global_steps': 678, 'samples_trained': 3471360, 'skipped_steps': 8, 'timestamp': 1592975944.047081}
  0: {'training_steps': 687, 'average_loss': 1.384765625, 'step_loss': 1.384765625, 'learning_rate': 0.0005340404040404041, 'seq/s': 24134.58884349766, 'global_steps': 679, 'samples_trained': 3476480, 'skipped_steps': 8, 'timestamp': 1592975944.2592251}
  0: {'training_steps': 688, 'average_loss': 1.66015625, 'step_loss': 1.66015625, 'learning_rate': 0.0005323232323232323, 'seq/s': 24244.887625924785, 'global_steps': 680, 'samples_trained': 3481600, 'skipped_steps': 8, 'timestamp': 1592975944.4704041}
  0: {'training_steps': 689, 'average_loss': 1.232421875, 'step_loss': 1.232421875, 'learning_rate': 0.0005306060606060606, 'seq/s': 24126.617091099877, 'global_steps': 681, 'samples_trained': 3486720, 'skipped_steps': 8, 'timestamp': 1592975944.6826184}
  0: {'training_steps': 690, 'average_loss': 1.2841796875, 'step_loss': 1.2841796875, 'learning_rate': 0.0005288888888888889, 'seq/s': 24248.665584925177, 'global_steps': 682, 'samples_trained': 3491840, 'skipped_steps': 8, 'timestamp': 1592975944.8937645}
  0: {'training_steps': 691, 'average_loss': 1.2978515625, 'step_loss': 1.2978515625, 'learning_rate': 0.0005271717171717172, 'seq/s': 24161.11788915166, 'global_steps': 683, 'samples_trained': 3496960, 'skipped_steps': 8, 'timestamp': 1592975945.105676}
  0: :::MLLOG {"namespace": "", "time_ms": 1592975945451, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7076681852340698, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 843, "epoch_num": 1}}
  0: {'global_steps': 684, 'eval_loss': 1.3632012605667114, 'eval_mlm_accuracy': 0.7076681852340698}
  0: {'training_steps': 692, 'average_loss': 1.3935546875, 'step_loss': 1.3935546875, 'learning_rate': 0.0005254545454545454, 'seq/s': 14786.899347787767, 'global_steps': 684, 'samples_trained': 3502080, 'skipped_steps': 8, 'timestamp': 1592975945.4519286}
  0: {'training_steps': 693, 'average_loss': 1.5703125, 'step_loss': 1.5703125, 'learning_rate': 0.0005237373737373737, 'seq/s': 25396.065123220636, 'global_steps': 685, 'samples_trained': 3507200, 'skipped_steps': 8, 'timestamp': 1592975945.6535351}
  0: {'training_steps': 694, 'average_loss': 1.4072265625, 'step_loss': 1.4072265625, 'learning_rate': 0.000522020202020202, 'seq/s': 24176.704039988967, 'global_steps': 686, 'samples_trained': 3512320, 'skipped_steps': 8, 'timestamp': 1592975945.8653097}
  0: {'training_steps': 695, 'average_loss': 1.4091796875, 'step_loss': 1.4091796875, 'learning_rate': 0.0005203030303030302, 'seq/s': 24262.08959473246, 'global_steps': 687, 'samples_trained': 3517440, 'skipped_steps': 8, 'timestamp': 1592975946.0763392}
  0: {'training_steps': 696, 'average_loss': 1.44140625, 'step_loss': 1.44140625, 'learning_rate': 0.0005185858585858585, 'seq/s': 24205.89025377209, 'global_steps': 688, 'samples_trained': 3522560, 'skipped_steps': 8, 'timestamp': 1592975946.2878585}
  0: {'training_steps': 697, 'average_loss': 1.9189453125, 'step_loss': 1.9189453125, 'learning_rate': 0.0005168686868686868, 'seq/s': 23602.248775641194, 'global_steps': 689, 'samples_trained': 3527680, 'skipped_steps': 8, 'timestamp': 1592975946.5047874}
  0: {'training_steps': 698, 'average_loss': 1.197265625, 'step_loss': 1.197265625, 'learning_rate': 0.000515151515151515, 'seq/s': 24341.843102449617, 'global_steps': 690, 'samples_trained': 3532800, 'skipped_steps': 8, 'timestamp': 1592975946.715125}
  0: {'training_steps': 699, 'average_loss': 1.537109375, 'step_loss': 1.537109375, 'learning_rate': 0.0005134343434343434, 'seq/s': 24171.887323816834, 'global_steps': 691, 'samples_trained': 3537920, 'skipped_steps': 8, 'timestamp': 1592975946.9269419}
  0: {'training_steps': 700, 'average_loss': 1.310546875, 'step_loss': 1.310546875, 'learning_rate': 0.0005117171717171718, 'seq/s': 24209.465020297775, 'global_steps': 692, 'samples_trained': 3543040, 'skipped_steps': 8, 'timestamp': 1592975947.1384299}
  0: {'training_steps': 701, 'average_loss': 1.1796875, 'step_loss': 1.1796875, 'learning_rate': 0.00051, 'seq/s': 24173.683163056252, 'global_steps': 693, 'samples_trained': 3548160, 'skipped_steps': 8, 'timestamp': 1592975947.350231}
  0: {'training_steps': 702, 'average_loss': 1.1865234375, 'step_loss': 1.1865234375, 'learning_rate': 0.0005082828282828283, 'seq/s': 24137.87126520501, 'global_steps': 694, 'samples_trained': 3553280, 'skipped_steps': 8, 'timestamp': 1592975947.5623462}
  0: {'training_steps': 703, 'average_loss': 1.318359375, 'step_loss': 1.318359375, 'learning_rate': 0.0005065656565656566, 'seq/s': 24114.831806891223, 'global_steps': 695, 'samples_trained': 3558400, 'skipped_steps': 8, 'timestamp': 1592975947.7746642}
  0: {'training_steps': 704, 'average_loss': 1.3095703125, 'step_loss': 1.3095703125, 'learning_rate': 0.0005048484848484848, 'seq/s': 24134.778711333485, 'global_steps': 696, 'samples_trained': 3563520, 'skipped_steps': 8, 'timestamp': 1592975947.9868069}
  0: {'training_steps': 705, 'average_loss': 1.3857421875, 'step_loss': 1.3857421875, 'learning_rate': 0.0005031313131313132, 'seq/s': 24124.530121348154, 'global_steps': 697, 'samples_trained': 3568640, 'skipped_steps': 8, 'timestamp': 1592975948.1990395}
  0: {'training_steps': 706, 'average_loss': 1.4755859375, 'step_loss': 1.4755859375, 'learning_rate': 0.0005014141414141414, 'seq/s': 24153.101439299615, 'global_steps': 698, 'samples_trained': 3573760, 'skipped_steps': 8, 'timestamp': 1592975948.411021}
  0: {'training_steps': 707, 'average_loss': 1.453125, 'step_loss': 1.453125, 'learning_rate': 0.0004996969696969696, 'seq/s': 24197.10790809198, 'global_steps': 699, 'samples_trained': 3578880, 'skipped_steps': 8, 'timestamp': 1592975948.622617}
  0: {'training_steps': 708, 'average_loss': 1.16796875, 'step_loss': 1.16796875, 'learning_rate': 0.000497979797979798, 'seq/s': 24160.22086941456, 'global_steps': 700, 'samples_trained': 3584000, 'skipped_steps': 8, 'timestamp': 1592975948.834536}
  0: {'training_steps': 709, 'average_loss': 1.3525390625, 'step_loss': 1.3525390625, 'learning_rate': 0.0004962626262626262, 'seq/s': 21562.163241126564, 'global_steps': 701, 'samples_trained': 3589120, 'skipped_steps': 8, 'timestamp': 1592975949.0719895}
  0: {'training_steps': 710, 'average_loss': 1.3193359375, 'step_loss': 1.3193359375, 'learning_rate': 0.0004945454545454545, 'seq/s': 24240.125789997077, 'global_steps': 702, 'samples_trained': 3594240, 'skipped_steps': 8, 'timestamp': 1592975949.28321}
  0: {'training_steps': 711, 'average_loss': 1.2421875, 'step_loss': 1.2421875, 'learning_rate': 0.0004928282828282828, 'seq/s': 24224.12987616553, 'global_steps': 703, 'samples_trained': 3599360, 'skipped_steps': 8, 'timestamp': 1592975949.49457}
  0: {'training_steps': 712, 'average_loss': 1.2099609375, 'step_loss': 1.2099609375, 'learning_rate': 0.000491111111111111, 'seq/s': 24173.08452032806, 'global_steps': 704, 'samples_trained': 3604480, 'skipped_steps': 8, 'timestamp': 1592975949.7063766}
  0: {'training_steps': 713, 'average_loss': 1.41796875, 'step_loss': 1.41796875, 'learning_rate': 0.0004893939393939393, 'seq/s': 24225.168285826447, 'global_steps': 705, 'samples_trained': 3609600, 'skipped_steps': 8, 'timestamp': 1592975949.9177277}
  0: {'training_steps': 714, 'average_loss': 1.2607421875, 'step_loss': 1.2607421875, 'learning_rate': 0.00048767676767676757, 'seq/s': 24199.971016158604, 'global_steps': 706, 'samples_trained': 3614720, 'skipped_steps': 8, 'timestamp': 1592975950.1292987}
  0: {'training_steps': 715, 'average_loss': 1.0439453125, 'step_loss': 1.0439453125, 'learning_rate': 0.00048595959595959585, 'seq/s': 24096.999695909817, 'global_steps': 707, 'samples_trained': 3619840, 'skipped_steps': 8, 'timestamp': 1592975950.3417737}
  0: {'training_steps': 716, 'average_loss': 1.3076171875, 'step_loss': 1.3076171875, 'learning_rate': 0.00048424242424242414, 'seq/s': 24132.934407364788, 'global_steps': 708, 'samples_trained': 3624960, 'skipped_steps': 8, 'timestamp': 1592975950.5539324}
  0: {'training_steps': 717, 'average_loss': 1.384765625, 'step_loss': 1.384765625, 'learning_rate': 0.0004825252525252526, 'seq/s': 23732.300354301908, 'global_steps': 709, 'samples_trained': 3630080, 'skipped_steps': 8, 'timestamp': 1592975950.7696726}
  0: {'training_steps': 718, 'average_loss': 1.2490234375, 'step_loss': 1.2490234375, 'learning_rate': 0.00048080808080808087, 'seq/s': 24225.933486756014, 'global_steps': 710, 'samples_trained': 3635200, 'skipped_steps': 8, 'timestamp': 1592975950.981017}
  0: {'training_steps': 719, 'average_loss': 1.1064453125, 'step_loss': 1.1064453125, 'learning_rate': 0.00047909090909090915, 'seq/s': 24207.036247142478, 'global_steps': 711, 'samples_trained': 3640320, 'skipped_steps': 8, 'timestamp': 1592975951.1925263}
  0: {'training_steps': 720, 'average_loss': 1.4150390625, 'step_loss': 1.4150390625, 'learning_rate': 0.0004773737373737374, 'seq/s': 24132.934407364788, 'global_steps': 712, 'samples_trained': 3645440, 'skipped_steps': 8, 'timestamp': 1592975951.404685}
  0: {'training_steps': 721, 'average_loss': 1.33984375, 'step_loss': 1.33984375, 'learning_rate': 0.00047565656565656567, 'seq/s': 24120.601093325815, 'global_steps': 713, 'samples_trained': 3650560, 'skipped_steps': 8, 'timestamp': 1592975951.6169524}
  0: {'training_steps': 722, 'average_loss': 1.220703125, 'step_loss': 1.220703125, 'learning_rate': 0.00047393939393939395, 'seq/s': 24209.001059680293, 'global_steps': 714, 'samples_trained': 3655680, 'skipped_steps': 8, 'timestamp': 1592975951.8284445}
  0: {'training_steps': 723, 'average_loss': 1.328125, 'step_loss': 1.328125, 'learning_rate': 0.00047222222222222224, 'seq/s': 24214.10560474837, 'global_steps': 715, 'samples_trained': 3660800, 'skipped_steps': 8, 'timestamp': 1592975952.039892}
  0: {'training_steps': 724, 'average_loss': 1.35546875, 'step_loss': 1.35546875, 'learning_rate': 0.00047050505050505047, 'seq/s': 23309.883769901746, 'global_steps': 716, 'samples_trained': 3665920, 'skipped_steps': 8, 'timestamp': 1592975952.2595417}
  0: {'training_steps': 725, 'average_loss': 1.439453125, 'step_loss': 1.439453125, 'learning_rate': 0.00046878787878787875, 'seq/s': 24281.265100291715, 'global_steps': 717, 'samples_trained': 3671040, 'skipped_steps': 8, 'timestamp': 1592975952.4704044}
  0: {'training_steps': 726, 'average_loss': 1.2314453125, 'step_loss': 1.2314453125, 'learning_rate': 0.00046707070707070704, 'seq/s': 23283.37243379503, 'global_steps': 718, 'samples_trained': 3676160, 'skipped_steps': 8, 'timestamp': 1592975952.6903045}
  0: {'training_steps': 727, 'average_loss': 1.330078125, 'step_loss': 1.330078125, 'learning_rate': 0.0004653535353535353, 'seq/s': 24115.969194211673, 'global_steps': 719, 'samples_trained': 3681280, 'skipped_steps': 8, 'timestamp': 1592975952.9026124}
  0: {'training_steps': 728, 'average_loss': 1.6318359375, 'step_loss': 1.6318359375, 'learning_rate': 0.00046363636363636355, 'seq/s': 24212.549445841272, 'global_steps': 720, 'samples_trained': 3686400, 'skipped_steps': 8, 'timestamp': 1592975953.1140738}
  0: {'training_steps': 729, 'average_loss': 1.3330078125, 'step_loss': 1.3330078125, 'learning_rate': 0.00046191919191919184, 'seq/s': 24172.295445668482, 'global_steps': 721, 'samples_trained': 3691520, 'skipped_steps': 8, 'timestamp': 1592975953.325887}
  0: {'training_steps': 730, 'average_loss': 1.546875, 'step_loss': 1.546875, 'learning_rate': 0.0004602020202020201, 'seq/s': 24300.71842410197, 'global_steps': 722, 'samples_trained': 3696640, 'skipped_steps': 8, 'timestamp': 1592975953.5365808}
  0: {'training_steps': 731, 'average_loss': 1.3994140625, 'step_loss': 1.3994140625, 'learning_rate': 0.0004584848484848484, 'seq/s': 24208.264217602107, 'global_steps': 723, 'samples_trained': 3701760, 'skipped_steps': 8, 'timestamp': 1592975953.7480793}
  0: {'training_steps': 732, 'average_loss': 1.4013671875, 'step_loss': 1.4013671875, 'learning_rate': 0.0004567676767676767, 'seq/s': 24073.336494559215, 'global_steps': 724, 'samples_trained': 3706880, 'skipped_steps': 8, 'timestamp': 1592975953.9607632}
  0: {'training_steps': 733, 'average_loss': 1.3544921875, 'step_loss': 1.3544921875, 'learning_rate': 0.0004550505050505049, 'seq/s': 24233.42407630173, 'global_steps': 725, 'samples_trained': 3712000, 'skipped_steps': 8, 'timestamp': 1592975954.1720421}
  0: {'training_steps': 734, 'average_loss': 1.33984375, 'step_loss': 1.33984375, 'learning_rate': 0.0004533333333333334, 'seq/s': 24235.830795934442, 'global_steps': 726, 'samples_trained': 3717120, 'skipped_steps': 8, 'timestamp': 1592975954.3833}
  0: {'training_steps': 735, 'average_loss': 1.50390625, 'step_loss': 1.50390625, 'learning_rate': 0.00045161616161616165, 'seq/s': 24224.53976408108, 'global_steps': 727, 'samples_trained': 3722240, 'skipped_steps': 8, 'timestamp': 1592975954.5946565}
  0: {'training_steps': 736, 'average_loss': 1.509765625, 'step_loss': 1.509765625, 'learning_rate': 0.00044989898989898993, 'seq/s': 24119.815441292092, 'global_steps': 728, 'samples_trained': 3727360, 'skipped_steps': 8, 'timestamp': 1592975954.8069308}
  0: {'training_steps': 737, 'average_loss': 1.3046875, 'step_loss': 1.3046875, 'learning_rate': 0.0004481818181818182, 'seq/s': 24277.476977202172, 'global_steps': 729, 'samples_trained': 3732480, 'skipped_steps': 8, 'timestamp': 1592975955.0178263}
  0: {'training_steps': 738, 'average_loss': 1.4912109375, 'step_loss': 1.4912109375, 'learning_rate': 0.0004464646464646465, 'seq/s': 24075.46859795063, 'global_steps': 730, 'samples_trained': 3737600, 'skipped_steps': 8, 'timestamp': 1592975955.2304916}
  0: {'training_steps': 739, 'average_loss': 1.2412109375, 'step_loss': 1.2412109375, 'learning_rate': 0.00044474747474747473, 'seq/s': 22751.61140905325, 'global_steps': 731, 'samples_trained': 3742720, 'skipped_steps': 8, 'timestamp': 1592975955.4555314}
  0: {'training_steps': 740, 'average_loss': 1.3076171875, 'step_loss': 1.3076171875, 'learning_rate': 0.000443030303030303, 'seq/s': 24192.44658188262, 'global_steps': 732, 'samples_trained': 3747840, 'skipped_steps': 8, 'timestamp': 1592975955.6671681}
  0: {'training_steps': 741, 'average_loss': 1.12109375, 'step_loss': 1.12109375, 'learning_rate': 0.0004413131313131313, 'seq/s': 24228.694077548207, 'global_steps': 733, 'samples_trained': 3752960, 'skipped_steps': 8, 'timestamp': 1592975955.8784883}
  0: {'training_steps': 742, 'average_loss': 1.3681640625, 'step_loss': 1.3681640625, 'learning_rate': 0.0004395959595959596, 'seq/s': 24200.21645694864, 'global_steps': 734, 'samples_trained': 3758080, 'skipped_steps': 8, 'timestamp': 1592975956.0900571}
  0: {'training_steps': 743, 'average_loss': 1.33203125, 'step_loss': 1.33203125, 'learning_rate': 0.0004378787878787878, 'seq/s': 24274.348549518916, 'global_steps': 735, 'samples_trained': 3763200, 'skipped_steps': 8, 'timestamp': 1592975956.3009803}
  0: {'training_steps': 744, 'average_loss': 1.466796875, 'step_loss': 1.466796875, 'learning_rate': 0.0004361616161616161, 'seq/s': 24236.678731489414, 'global_steps': 736, 'samples_trained': 3768320, 'skipped_steps': 8, 'timestamp': 1592975956.5122309}
  0: {'training_steps': 745, 'average_loss': 1.59765625, 'step_loss': 1.59765625, 'learning_rate': 0.0004344444444444444, 'seq/s': 24105.4389243785, 'global_steps': 737, 'samples_trained': 3773440, 'skipped_steps': 8, 'timestamp': 1592975956.7246315}
  0: {'training_steps': 746, 'average_loss': 1.4462890625, 'step_loss': 1.4462890625, 'learning_rate': 0.00043272727272727267, 'seq/s': 24160.139325468524, 'global_steps': 738, 'samples_trained': 3778560, 'skipped_steps': 8, 'timestamp': 1592975956.9365513}
  0: {'training_steps': 747, 'average_loss': 1.2783203125, 'step_loss': 1.2783203125, 'learning_rate': 0.00043101010101010095, 'seq/s': 24193.291484347188, 'global_steps': 739, 'samples_trained': 3783680, 'skipped_steps': 8, 'timestamp': 1592975957.1481807}
  0: {'training_steps': 748, 'average_loss': 1.2275390625, 'step_loss': 1.2275390625, 'learning_rate': 0.0004292929292929292, 'seq/s': 24243.081192080044, 'global_steps': 740, 'samples_trained': 3788800, 'skipped_steps': 8, 'timestamp': 1592975957.3593757}
  0: {'training_steps': 749, 'average_loss': 1.353515625, 'step_loss': 1.353515625, 'learning_rate': 0.00042757575757575747, 'seq/s': 23296.355196455672, 'global_steps': 741, 'samples_trained': 3793920, 'skipped_steps': 8, 'timestamp': 1592975957.579153}
  0: {'training_steps': 750, 'average_loss': 1.041015625, 'step_loss': 1.041015625, 'learning_rate': 0.00042585858585858575, 'seq/s': 24212.877041620533, 'global_steps': 742, 'samples_trained': 3799040, 'skipped_steps': 8, 'timestamp': 1592975957.7906113}
  0: {'training_steps': 751, 'average_loss': 1.2490234375, 'step_loss': 1.2490234375, 'learning_rate': 0.0004241414141414142, 'seq/s': 24145.796159580474, 'global_steps': 743, 'samples_trained': 3804160, 'skipped_steps': 8, 'timestamp': 1592975958.002657}
  0: {'training_steps': 752, 'average_loss': 1.1201171875, 'step_loss': 1.1201171875, 'learning_rate': 0.0004224242424242425, 'seq/s': 24184.24591877185, 'global_steps': 744, 'samples_trained': 3809280, 'skipped_steps': 8, 'timestamp': 1592975958.2143655}
  0: {'training_steps': 753, 'average_loss': 1.2724609375, 'step_loss': 1.2724609375, 'learning_rate': 0.00042070707070707077, 'seq/s': 24180.433550874444, 'global_steps': 745, 'samples_trained': 3814400, 'skipped_steps': 8, 'timestamp': 1592975958.4261074}
  0: {'training_steps': 754, 'average_loss': 1.431640625, 'step_loss': 1.431640625, 'learning_rate': 0.000418989898989899, 'seq/s': 24213.39575306771, 'global_steps': 746, 'samples_trained': 3819520, 'skipped_steps': 8, 'timestamp': 1592975958.637561}
  0: {'training_steps': 755, 'average_loss': 1.0478515625, 'step_loss': 1.0478515625, 'learning_rate': 0.0004172727272727273, 'seq/s': 24238.78515073874, 'global_steps': 747, 'samples_trained': 3824640, 'skipped_steps': 8, 'timestamp': 1592975958.8487933}
  0: {'training_steps': 756, 'average_loss': 1.375, 'step_loss': 1.375, 'learning_rate': 0.00041555555555555557, 'seq/s': 24107.901479602147, 'global_steps': 748, 'samples_trained': 3829760, 'skipped_steps': 8, 'timestamp': 1592975959.0611722}
  0: {'training_steps': 757, 'average_loss': 1.5078125, 'step_loss': 1.5078125, 'learning_rate': 0.00041383838383838385, 'seq/s': 21879.765296339352, 'global_steps': 749, 'samples_trained': 3834880, 'skipped_steps': 8, 'timestamp': 1592975959.295179}
  0: {'training_steps': 758, 'average_loss': 1.515625, 'step_loss': 1.515625, 'learning_rate': 0.00041212121212121214, 'seq/s': 24069.585988760344, 'global_steps': 750, 'samples_trained': 3840000, 'skipped_steps': 8, 'timestamp': 1592975959.507896}
  0: {'training_steps': 759, 'average_loss': 1.3251953125, 'step_loss': 1.3251953125, 'learning_rate': 0.00041040404040404037, 'seq/s': 24278.547413905184, 'global_steps': 751, 'samples_trained': 3845120, 'skipped_steps': 8, 'timestamp': 1592975959.7187822}
  0: {'training_steps': 760, 'average_loss': 1.25390625, 'step_loss': 1.25390625, 'learning_rate': 0.00040868686868686865, 'seq/s': 24162.749004790956, 'global_steps': 752, 'samples_trained': 3850240, 'skipped_steps': 8, 'timestamp': 1592975959.930679}
  0: {'training_steps': 761, 'average_loss': 1.3369140625, 'step_loss': 1.3369140625, 'learning_rate': 0.00040696969696969693, 'seq/s': 24185.417101669624, 'global_steps': 753, 'samples_trained': 3855360, 'skipped_steps': 8, 'timestamp': 1592975960.1423776}
  0: {'training_steps': 762, 'average_loss': 1.224609375, 'step_loss': 1.224609375, 'learning_rate': 0.0004052525252525252, 'seq/s': 24171.39759578587, 'global_steps': 754, 'samples_trained': 3860480, 'skipped_steps': 8, 'timestamp': 1592975960.354199}
  0: {'training_steps': 763, 'average_loss': 1.515625, 'step_loss': 1.515625, 'learning_rate': 0.00040353535353535345, 'seq/s': 24136.97597074093, 'global_steps': 755, 'samples_trained': 3865600, 'skipped_steps': 8, 'timestamp': 1592975960.5663223}
  0: {'training_steps': 764, 'average_loss': 1.38671875, 'step_loss': 1.38671875, 'learning_rate': 0.00040181818181818173, 'seq/s': 24244.64127818496, 'global_steps': 756, 'samples_trained': 3870720, 'skipped_steps': 8, 'timestamp': 1592975960.7775035}
  0: {'training_steps': 765, 'average_loss': 1.3662109375, 'step_loss': 1.3662109375, 'learning_rate': 0.00040010101010101, 'seq/s': 24117.702562167433, 'global_steps': 757, 'samples_trained': 3875840, 'skipped_steps': 8, 'timestamp': 1592975960.9897964}
  0: {'training_steps': 766, 'average_loss': 1.380859375, 'step_loss': 1.380859375, 'learning_rate': 0.0003983838383838383, 'seq/s': 23424.326012380356, 'global_steps': 758, 'samples_trained': 3880960, 'skipped_steps': 8, 'timestamp': 1592975961.208373}
  0: {'training_steps': 767, 'average_loss': 1.22265625, 'step_loss': 1.22265625, 'learning_rate': 0.00039666666666666653, 'seq/s': 24142.32159278704, 'global_steps': 759, 'samples_trained': 3886080, 'skipped_steps': 8, 'timestamp': 1592975961.4204495}
  0: {'training_steps': 768, 'average_loss': 1.5537109375, 'step_loss': 1.5537109375, 'learning_rate': 0.00039494949494949503, 'seq/s': 24113.64037333477, 'global_steps': 760, 'samples_trained': 3891200, 'skipped_steps': 8, 'timestamp': 1592975961.632778}
  0: {'training_steps': 769, 'average_loss': 1.2275390625, 'step_loss': 1.2275390625, 'learning_rate': 0.00039323232323232326, 'seq/s': 24204.49883625912, 'global_steps': 761, 'samples_trained': 3896320, 'skipped_steps': 8, 'timestamp': 1592975961.8443093}
  0: {'training_steps': 770, 'average_loss': 1.3955078125, 'step_loss': 1.3955078125, 'learning_rate': 0.00039151515151515155, 'seq/s': 24172.94846929759, 'global_steps': 762, 'samples_trained': 3901440, 'skipped_steps': 8, 'timestamp': 1592975962.0561168}
  0: {'training_steps': 771, 'average_loss': 1.490234375, 'step_loss': 1.490234375, 'learning_rate': 0.00038979797979797983, 'seq/s': 24213.313849782728, 'global_steps': 763, 'samples_trained': 3906560, 'skipped_steps': 8, 'timestamp': 1592975962.2675712}
  0: {'training_steps': 772, 'average_loss': 1.37109375, 'step_loss': 1.37109375, 'learning_rate': 0.0003880808080808081, 'seq/s': 24287.965834856408, 'global_steps': 764, 'samples_trained': 3911680, 'skipped_steps': 8, 'timestamp': 1592975962.4783757}
  0: {'training_steps': 773, 'average_loss': 1.2705078125, 'step_loss': 1.2705078125, 'learning_rate': 0.0003863636363636364, 'seq/s': 24200.73462607749, 'global_steps': 765, 'samples_trained': 3916800, 'skipped_steps': 8, 'timestamp': 1592975962.6899397}
  0: {'training_steps': 774, 'average_loss': 1.4453125, 'step_loss': 1.4453125, 'learning_rate': 0.00038464646464646463, 'seq/s': 21578.412861736335, 'global_steps': 766, 'samples_trained': 3921920, 'skipped_steps': 8, 'timestamp': 1592975962.9272144}
  0: {'training_steps': 775, 'average_loss': 1.3447265625, 'step_loss': 1.3447265625, 'learning_rate': 0.0003829292929292929, 'seq/s': 24248.035843329963, 'global_steps': 767, 'samples_trained': 3927040, 'skipped_steps': 8, 'timestamp': 1592975963.138366}
  0: {'training_steps': 776, 'average_loss': 1.4443359375, 'step_loss': 1.4443359375, 'learning_rate': 0.0003812121212121212, 'seq/s': 24111.25785937556, 'global_steps': 768, 'samples_trained': 3932160, 'skipped_steps': 8, 'timestamp': 1592975963.3507154}
  0: {'training_steps': 777, 'average_loss': 1.2421875, 'step_loss': 1.2421875, 'learning_rate': 0.0003794949494949495, 'seq/s': 21610.35501630726, 'global_steps': 769, 'samples_trained': 3937280, 'skipped_steps': 8, 'timestamp': 1592975963.5876393}
  0: {'training_steps': 778, 'average_loss': 1.03515625, 'step_loss': 1.03515625, 'learning_rate': 0.0003777777777777777, 'seq/s': 21550.759806799353, 'global_steps': 770, 'samples_trained': 3942400, 'skipped_steps': 8, 'timestamp': 1592975963.825219}
  0: {'training_steps': 779, 'average_loss': 1.251953125, 'step_loss': 1.251953125, 'learning_rate': 0.000376060606060606, 'seq/s': 24283.489114468546, 'global_steps': 771, 'samples_trained': 3947520, 'skipped_steps': 8, 'timestamp': 1592975964.0360622}
  0: {'training_steps': 780, 'average_loss': 1.1845703125, 'step_loss': 1.1845703125, 'learning_rate': 0.0003743434343434343, 'seq/s': 24182.36681579709, 'global_steps': 772, 'samples_trained': 3952640, 'skipped_steps': 8, 'timestamp': 1592975964.2477872}
  0: {'training_steps': 781, 'average_loss': 1.4912109375, 'step_loss': 1.4912109375, 'learning_rate': 0.00037262626262626257, 'seq/s': 21646.60226900455, 'global_steps': 773, 'samples_trained': 3957760, 'skipped_steps': 8, 'timestamp': 1592975964.4843144}
  0: {'training_steps': 782, 'average_loss': 1.357421875, 'step_loss': 1.357421875, 'learning_rate': 0.0003709090909090908, 'seq/s': 21594.29612616997, 'global_steps': 774, 'samples_trained': 3962880, 'skipped_steps': 8, 'timestamp': 1592975964.7214146}
  0: {'training_steps': 783, 'average_loss': 1.3564453125, 'step_loss': 1.3564453125, 'learning_rate': 0.0003691919191919191, 'seq/s': 24241.93178341828, 'global_steps': 775, 'samples_trained': 3968000, 'skipped_steps': 8, 'timestamp': 1592975964.9326196}
  0: {'training_steps': 784, 'average_loss': 1.4736328125, 'step_loss': 1.4736328125, 'learning_rate': 0.00036747474747474737, 'seq/s': 24154.867318749944, 'global_steps': 776, 'samples_trained': 3973120, 'skipped_steps': 8, 'timestamp': 1592975965.1445856}
  0: {'training_steps': 785, 'average_loss': 1.29296875, 'step_loss': 1.29296875, 'learning_rate': 0.0003657575757575758, 'seq/s': 21252.91355664155, 'global_steps': 777, 'samples_trained': 3978240, 'skipped_steps': 8, 'timestamp': 1592975965.3854942}
  0: {'training_steps': 786, 'average_loss': 1.21484375, 'step_loss': 1.21484375, 'learning_rate': 0.0003640404040404041, 'seq/s': 21575.464446176968, 'global_steps': 778, 'samples_trained': 3983360, 'skipped_steps': 8, 'timestamp': 1592975965.6228013}
  0: {'training_steps': 787, 'average_loss': 1.3994140625, 'step_loss': 1.3994140625, 'learning_rate': 0.0003623232323232324, 'seq/s': 24211.51211768632, 'global_steps': 779, 'samples_trained': 3988480, 'skipped_steps': 8, 'timestamp': 1592975965.8342714}
  0: {'training_steps': 788, 'average_loss': 1.2451171875, 'step_loss': 1.2451171875, 'learning_rate': 0.00036060606060606067, 'seq/s': 24241.16557152581, 'global_steps': 780, 'samples_trained': 3993600, 'skipped_steps': 8, 'timestamp': 1592975966.045483}
  0: {'training_steps': 789, 'average_loss': 1.15625, 'step_loss': 1.15625, 'learning_rate': 0.0003588888888888889, 'seq/s': 24261.431746056853, 'global_steps': 781, 'samples_trained': 3998720, 'skipped_steps': 8, 'timestamp': 1592975966.2565181}
  0: :::MLLOG {"namespace": "", "time_ms": 1592975966602, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7095216512680054, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 843, "epoch_num": 1}}
  0: {'global_steps': 782, 'eval_loss': 1.3496590852737427, 'eval_mlm_accuracy': 0.7095216512680054}
  0: {'training_steps': 790, 'average_loss': 1.146484375, 'step_loss': 1.146484375, 'learning_rate': 0.0003571717171717172, 'seq/s': 14790.423088525575, 'global_steps': 782, 'samples_trained': 4003840, 'skipped_steps': 8, 'timestamp': 1592975966.6026886}
  0: {'training_steps': 791, 'average_loss': 1.28125, 'step_loss': 1.28125, 'learning_rate': 0.00035545454545454547, 'seq/s': 25517.284726348058, 'global_steps': 783, 'samples_trained': 4008960, 'skipped_steps': 8, 'timestamp': 1592975966.8033376}
  0: {'training_steps': 792, 'average_loss': 1.3125, 'step_loss': 1.3125, 'learning_rate': 0.00035373737373737375, 'seq/s': 24124.990849846487, 'global_steps': 784, 'samples_trained': 4014080, 'skipped_steps': 8, 'timestamp': 1592975967.015566}
  0: {'training_steps': 793, 'average_loss': 1.4345703125, 'step_loss': 1.4345703125, 'learning_rate': 0.000352020202020202, 'seq/s': 24228.28404903684, 'global_steps': 785, 'samples_trained': 4019200, 'skipped_steps': 8, 'timestamp': 1592975967.22689}
  0: {'training_steps': 794, 'average_loss': 1.36328125, 'step_loss': 1.36328125, 'learning_rate': 0.00035030303030303026, 'seq/s': 24284.56008142033, 'global_steps': 786, 'samples_trained': 4024320, 'skipped_steps': 8, 'timestamp': 1592975967.437724}
  0: {'training_steps': 795, 'average_loss': 1.353515625, 'step_loss': 1.353515625, 'learning_rate': 0.00034858585858585855, 'seq/s': 24143.271570308327, 'global_steps': 787, 'samples_trained': 4029440, 'skipped_steps': 8, 'timestamp': 1592975967.649792}
  0: {'training_steps': 796, 'average_loss': 1.4072265625, 'step_loss': 1.4072265625, 'learning_rate': 0.00034686868686868683, 'seq/s': 24154.75864178923, 'global_steps': 788, 'samples_trained': 4034560, 'skipped_steps': 8, 'timestamp': 1592975967.861759}
  0: {'training_steps': 797, 'average_loss': 1.4951171875, 'step_loss': 1.4951171875, 'learning_rate': 0.00034515151515151506, 'seq/s': 24247.87156829314, 'global_steps': 789, 'samples_trained': 4039680, 'skipped_steps': 8, 'timestamp': 1592975968.0729122}
  0: {'training_steps': 798, 'average_loss': 1.2236328125, 'step_loss': 1.2236328125, 'learning_rate': 0.00034343434343434335, 'seq/s': 24183.374414414415, 'global_steps': 790, 'samples_trained': 4044800, 'skipped_steps': 8, 'timestamp': 1592975968.2846284}
  0: {'training_steps': 799, 'average_loss': 1.181640625, 'step_loss': 1.181640625, 'learning_rate': 0.00034171717171717163, 'seq/s': 24260.910974488284, 'global_steps': 791, 'samples_trained': 4049920, 'skipped_steps': 8, 'timestamp': 1592975968.495668}
  0: {'training_steps': 800, 'average_loss': 1.3134765625, 'step_loss': 1.3134765625, 'learning_rate': 0.0003399999999999999, 'seq/s': 24135.61959051741, 'global_steps': 792, 'samples_trained': 4055040, 'skipped_steps': 8, 'timestamp': 1592975968.7078032}
  0: {'training_steps': 801, 'average_loss': 1.2666015625, 'step_loss': 1.2666015625, 'learning_rate': 0.0003382828282828282, 'seq/s': 24244.3401933014, 'global_steps': 793, 'samples_trained': 4060160, 'skipped_steps': 8, 'timestamp': 1592975968.918987}
  0: {'training_steps': 802, 'average_loss': 1.4609375, 'step_loss': 1.4609375, 'learning_rate': 0.00033656565656565665, 'seq/s': 24178.22837256485, 'global_steps': 794, 'samples_trained': 4065280, 'skipped_steps': 8, 'timestamp': 1592975969.1307485}
  0: {'training_steps': 803, 'average_loss': 1.4892578125, 'step_loss': 1.4892578125, 'learning_rate': 0.00033484848484848493, 'seq/s': 24212.05806879321, 'global_steps': 795, 'samples_trained': 4070400, 'skipped_steps': 8, 'timestamp': 1592975969.3422136}
  0: {'training_steps': 804, 'average_loss': 1.109375, 'step_loss': 1.109375, 'learning_rate': 0.00033313131313131316, 'seq/s': 24232.63105749863, 'global_steps': 796, 'samples_trained': 4075520, 'skipped_steps': 8, 'timestamp': 1592975969.5534995}
  0: {'training_steps': 805, 'average_loss': 1.2421875, 'step_loss': 1.2421875, 'learning_rate': 0.00033141414141414145, 'seq/s': 24109.01114692407, 'global_steps': 797, 'samples_trained': 4080640, 'skipped_steps': 8, 'timestamp': 1592975969.765869}
  0: {'training_steps': 806, 'average_loss': 1.0419921875, 'step_loss': 1.0419921875, 'learning_rate': 0.00032969696969696973, 'seq/s': 24224.649069867915, 'global_steps': 798, 'samples_trained': 4085760, 'skipped_steps': 8, 'timestamp': 1592975969.9772243}
  0: {'training_steps': 807, 'average_loss': 1.44921875, 'step_loss': 1.44921875, 'learning_rate': 0.000327979797979798, 'seq/s': 24192.119538707124, 'global_steps': 799, 'samples_trained': 4090880, 'skipped_steps': 8, 'timestamp': 1592975970.188864}
  0: {'training_steps': 808, 'average_loss': 1.392578125, 'step_loss': 1.392578125, 'learning_rate': 0.00032626262626262624, 'seq/s': 24208.673568774575, 'global_steps': 800, 'samples_trained': 4096000, 'skipped_steps': 8, 'timestamp': 1592975970.400359}
  0: {'training_steps': 809, 'average_loss': 1.0205078125, 'step_loss': 1.0205078125, 'learning_rate': 0.00032454545454545453, 'seq/s': 24236.78814685066, 'global_steps': 801, 'samples_trained': 4101120, 'skipped_steps': 8, 'timestamp': 1592975970.6116085}
  0: {'training_steps': 810, 'average_loss': 1.2939453125, 'step_loss': 1.2939453125, 'learning_rate': 0.0003228282828282828, 'seq/s': 24183.755689841957, 'global_steps': 802, 'samples_trained': 4106240, 'skipped_steps': 8, 'timestamp': 1592975970.8233213}
  0: {'training_steps': 811, 'average_loss': 1.294921875, 'step_loss': 1.294921875, 'learning_rate': 0.0003211111111111111, 'seq/s': 24280.11206812729, 'global_steps': 803, 'samples_trained': 4111360, 'skipped_steps': 8, 'timestamp': 1592975971.034194}
  0: {'training_steps': 812, 'average_loss': 1.3583984375, 'step_loss': 1.3583984375, 'learning_rate': 0.0003193939393939394, 'seq/s': 24195.826545868764, 'global_steps': 804, 'samples_trained': 4116480, 'skipped_steps': 8, 'timestamp': 1592975971.2458012}
  0: {'training_steps': 813, 'average_loss': 1.1533203125, 'step_loss': 1.1533203125, 'learning_rate': 0.0003176767676767676, 'seq/s': 24258.334854550547, 'global_steps': 805, 'samples_trained': 4121600, 'skipped_steps': 8, 'timestamp': 1592975971.4568632}
  0: {'training_steps': 814, 'average_loss': 1.2763671875, 'step_loss': 1.2763671875, 'learning_rate': 0.0003159595959595959, 'seq/s': 24211.40293041945, 'global_steps': 806, 'samples_trained': 4126720, 'skipped_steps': 8, 'timestamp': 1592975971.6683342}
  0: {'training_steps': 815, 'average_loss': 1.31640625, 'step_loss': 1.31640625, 'learning_rate': 0.0003142424242424242, 'seq/s': 24142.457299284433, 'global_steps': 807, 'samples_trained': 4131840, 'skipped_steps': 8, 'timestamp': 1592975971.8804092}
  0: {'training_steps': 816, 'average_loss': 1.4091796875, 'step_loss': 1.4091796875, 'learning_rate': 0.00031252525252525247, 'seq/s': 23733.821621980063, 'global_steps': 808, 'samples_trained': 4136960, 'skipped_steps': 8, 'timestamp': 1592975972.0961356}
  0: {'training_steps': 817, 'average_loss': 1.53515625, 'step_loss': 1.53515625, 'learning_rate': 0.0003108080808080807, 'seq/s': 24262.5007682713, 'global_steps': 809, 'samples_trained': 4142080, 'skipped_steps': 8, 'timestamp': 1592975972.3071613}
  0: {'training_steps': 818, 'average_loss': 1.0830078125, 'step_loss': 1.0830078125, 'learning_rate': 0.000309090909090909, 'seq/s': 24184.872351328067, 'global_steps': 810, 'samples_trained': 4147200, 'skipped_steps': 8, 'timestamp': 1592975972.5188644}
  0: {'training_steps': 819, 'average_loss': 1.1064453125, 'step_loss': 1.1064453125, 'learning_rate': 0.0003073737373737374, 'seq/s': 24156.17151856018, 'global_steps': 811, 'samples_trained': 4152320, 'skipped_steps': 8, 'timestamp': 1592975972.730819}
  0: {'training_steps': 820, 'average_loss': 1.2392578125, 'step_loss': 1.2392578125, 'learning_rate': 0.0003056565656565657, 'seq/s': 24205.18088367899, 'global_steps': 812, 'samples_trained': 4157440, 'skipped_steps': 8, 'timestamp': 1592975972.9423444}
  0: {'training_steps': 821, 'average_loss': 1.7138671875, 'step_loss': 1.7138671875, 'learning_rate': 0.000303939393939394, 'seq/s': 24177.24842241549, 'global_steps': 813, 'samples_trained': 4162560, 'skipped_steps': 8, 'timestamp': 1592975973.1541145}
  0: {'training_steps': 822, 'average_loss': 1.4150390625, 'step_loss': 1.4150390625, 'learning_rate': 0.0003022222222222223, 'seq/s': 24246.22894033858, 'global_steps': 814, 'samples_trained': 4167680, 'skipped_steps': 8, 'timestamp': 1592975973.3652818}
  0: {'training_steps': 823, 'average_loss': 1.2421875, 'step_loss': 1.2421875, 'learning_rate': 0.0003005050505050505, 'seq/s': 24052.736634248893, 'global_steps': 815, 'samples_trained': 4172800, 'skipped_steps': 8, 'timestamp': 1592975973.578148}
  0: {'training_steps': 824, 'average_loss': 1.4033203125, 'step_loss': 1.4033203125, 'learning_rate': 0.0002987878787878788, 'seq/s': 24177.54784319995, 'global_steps': 816, 'samples_trained': 4177920, 'skipped_steps': 8, 'timestamp': 1592975973.789915}
  0: {'training_steps': 825, 'average_loss': 1.4052734375, 'step_loss': 1.4052734375, 'learning_rate': 0.0002970707070707071, 'seq/s': 24180.65136808918, 'global_steps': 817, 'samples_trained': 4183040, 'skipped_steps': 8, 'timestamp': 1592975974.001655}
  0: {'training_steps': 826, 'average_loss': 1.2392578125, 'step_loss': 1.2392578125, 'learning_rate': 0.00029535353535353536, 'seq/s': 24092.78229719557, 'global_steps': 818, 'samples_trained': 4188160, 'skipped_steps': 8, 'timestamp': 1592975974.2141674}
  0: {'training_steps': 827, 'average_loss': 1.4794921875, 'step_loss': 1.4794921875, 'learning_rate': 0.00029363636363636365, 'seq/s': 24232.193552099896, 'global_steps': 819, 'samples_trained': 4193280, 'skipped_steps': 8, 'timestamp': 1592975974.4254572}
  0: {'training_steps': 828, 'average_loss': 1.248046875, 'step_loss': 1.248046875, 'learning_rate': 0.0002919191919191919, 'seq/s': 24160.601415107605, 'global_steps': 820, 'samples_trained': 4198400, 'skipped_steps': 8, 'timestamp': 1592975974.6373732}
  0: {'training_steps': 829, 'average_loss': 1.193359375, 'step_loss': 1.193359375, 'learning_rate': 0.00029020202020202016, 'seq/s': 24171.642457320828, 'global_steps': 821, 'samples_trained': 4203520, 'skipped_steps': 8, 'timestamp': 1592975974.8491921}
  0: {'training_steps': 830, 'average_loss': 1.4296875, 'step_loss': 1.4296875, 'learning_rate': 0.00028848484848484845, 'seq/s': 24203.62587164711, 'global_steps': 822, 'samples_trained': 4208640, 'skipped_steps': 8, 'timestamp': 1592975975.0607312}
  0: {'training_steps': 831, 'average_loss': 1.7197265625, 'step_loss': 1.7197265625, 'learning_rate': 0.00028676767676767673, 'seq/s': 24197.735007149513, 'global_steps': 823, 'samples_trained': 4213760, 'skipped_steps': 8, 'timestamp': 1592975975.2723217}
  0: {'training_steps': 832, 'average_loss': 1.388671875, 'step_loss': 1.388671875, 'learning_rate': 0.00028505050505050496, 'seq/s': 24173.492682608347, 'global_steps': 824, 'samples_trained': 4218880, 'skipped_steps': 8, 'timestamp': 1592975975.4841244}
  0: {'training_steps': 833, 'average_loss': 1.001953125, 'step_loss': 1.001953125, 'learning_rate': 0.00028333333333333325, 'seq/s': 24118.948574303773, 'global_steps': 825, 'samples_trained': 4224000, 'skipped_steps': 8, 'timestamp': 1592975975.6964064}
  0: {'training_steps': 834, 'average_loss': 1.2919921875, 'step_loss': 1.2919921875, 'learning_rate': 0.00028161616161616153, 'seq/s': 24146.637806670256, 'global_steps': 826, 'samples_trained': 4229120, 'skipped_steps': 8, 'timestamp': 1592975975.9084446}
  0: {'training_steps': 835, 'average_loss': 1.521484375, 'step_loss': 1.521484375, 'learning_rate': 0.0002798989898989898, 'seq/s': 24079.571935395616, 'global_steps': 827, 'samples_trained': 4234240, 'skipped_steps': 8, 'timestamp': 1592975976.1210735}
  0: {'training_steps': 836, 'average_loss': 1.326171875, 'step_loss': 1.326171875, 'learning_rate': 0.00027818181818181826, 'seq/s': 24173.138941169054, 'global_steps': 828, 'samples_trained': 4239360, 'skipped_steps': 8, 'timestamp': 1592975976.3328793}
  0: {'training_steps': 837, 'average_loss': 1.2822265625, 'step_loss': 1.2822265625, 'learning_rate': 0.00027646464646464655, 'seq/s': 24136.840325858255, 'global_steps': 829, 'samples_trained': 4244480, 'skipped_steps': 8, 'timestamp': 1592975976.545004}
  0: {'training_steps': 838, 'average_loss': 1.5263671875, 'step_loss': 1.5263671875, 'learning_rate': 0.00027474747474747483, 'seq/s': 24147.398054475147, 'global_steps': 830, 'samples_trained': 4249600, 'skipped_steps': 8, 'timestamp': 1592975976.7570355}
  0: {'training_steps': 839, 'average_loss': 1.6943359375, 'step_loss': 1.6943359375, 'learning_rate': 0.00027303030303030306, 'seq/s': 24137.328654571123, 'global_steps': 831, 'samples_trained': 4254720, 'skipped_steps': 8, 'timestamp': 1592975976.9691558}
  0: {'training_steps': 840, 'average_loss': 1.4052734375, 'step_loss': 1.4052734375, 'learning_rate': 0.00027131313131313134, 'seq/s': 24239.633293037106, 'global_steps': 832, 'samples_trained': 4259840, 'skipped_steps': 8, 'timestamp': 1592975977.1803806}
  0: {'training_steps': 841, 'average_loss': 1.1611328125, 'step_loss': 1.1611328125, 'learning_rate': 0.00026959595959595963, 'seq/s': 24245.380336423445, 'global_steps': 833, 'samples_trained': 4264960, 'skipped_steps': 8, 'timestamp': 1592975977.3915553}
  0: {'training_steps': 842, 'average_loss': 1.30859375, 'step_loss': 1.30859375, 'learning_rate': 0.0002678787878787879, 'seq/s': 22672.60767063181, 'global_steps': 834, 'samples_trained': 4270080, 'skipped_steps': 8, 'timestamp': 1592975977.6173792}
  0: {'training_steps': 843, 'average_loss': 1.5517578125, 'step_loss': 1.5517578125, 'learning_rate': 0.00026616161616161614, 'seq/s': 24130.68365359873, 'global_steps': 835, 'samples_trained': 4275200, 'skipped_steps': 8, 'timestamp': 1592975977.8295577}
  0: {'training_steps': 844, 'average_loss': 1.2822265625, 'step_loss': 1.2822265625, 'learning_rate': 0.00026444444444444443, 'seq/s': 24088.269153544676, 'global_steps': 836, 'samples_trained': 4280320, 'skipped_steps': 8, 'timestamp': 1592975978.0421097}
  0: {'training_steps': 845, 'average_loss': 2.181640625, 'step_loss': 2.181640625, 'learning_rate': 0.0002627272727272727, 'seq/s': 24243.21803370482, 'global_steps': 837, 'samples_trained': 4285440, 'skipped_steps': 8, 'timestamp': 1592975978.2533033}
  0: {'training_steps': 846, 'average_loss': 1.337890625, 'step_loss': 1.337890625, 'learning_rate': 0.000261010101010101, 'seq/s': 21567.360456357776, 'global_steps': 838, 'samples_trained': 4290560, 'skipped_steps': 8, 'timestamp': 1592975978.4906995}
  0: {'training_steps': 847, 'average_loss': 1.44140625, 'step_loss': 1.44140625, 'learning_rate': 0.0002592929292929292, 'seq/s': 24215.44351528601, 'global_steps': 839, 'samples_trained': 4295680, 'skipped_steps': 8, 'timestamp': 1592975978.7021353}
  0: {'training_steps': 848, 'average_loss': 1.376953125, 'step_loss': 1.376953125, 'learning_rate': 0.0002575757575757575, 'seq/s': 24171.80570110026, 'global_steps': 840, 'samples_trained': 4300800, 'skipped_steps': 8, 'timestamp': 1592975978.9139528}
  0: {'training_steps': 849, 'average_loss': 1.3740234375, 'step_loss': 1.3740234375, 'learning_rate': 0.0002558585858585858, 'seq/s': 24190.075719174456, 'global_steps': 841, 'samples_trained': 4305920, 'skipped_steps': 8, 'timestamp': 1592975979.1256106}
  0: {'training_steps': 850, 'average_loss': 1.357421875, 'step_loss': 1.357421875, 'learning_rate': 0.0002541414141414141, 'seq/s': 21386.148123730887, 'global_steps': 842, 'samples_trained': 4311040, 'skipped_steps': 8, 'timestamp': 1592975979.3650184}
  0: {'training_steps': 851, 'average_loss': 1.4951171875, 'step_loss': 1.4951171875, 'learning_rate': 0.00025242424242424236, 'seq/s': 24115.725459325247, 'global_steps': 843, 'samples_trained': 4316160, 'skipped_steps': 8, 'timestamp': 1592975979.5773284}
  0: {'training_steps': 852, 'average_loss': 1.333984375, 'step_loss': 1.333984375, 'learning_rate': 0.0002507070707070706, 'seq/s': 24169.33007396603, 'global_steps': 844, 'samples_trained': 4321280, 'skipped_steps': 8, 'timestamp': 1592975979.7891676}
  0: {'training_steps': 853, 'average_loss': 1.3037109375, 'step_loss': 1.3037109375, 'learning_rate': 0.0002489898989898991, 'seq/s': 24207.90945778379, 'global_steps': 845, 'samples_trained': 4326400, 'skipped_steps': 8, 'timestamp': 1592975980.0006692}
  0: {'training_steps': 854, 'average_loss': 1.4345703125, 'step_loss': 1.4345703125, 'learning_rate': 0.0002472727272727273, 'seq/s': 21605.63700643697, 'global_steps': 846, 'samples_trained': 4331520, 'skipped_steps': 8, 'timestamp': 1592975980.2376451}
  0: {'training_steps': 855, 'average_loss': 1.3828125, 'step_loss': 1.3828125, 'learning_rate': 0.0002455555555555556, 'seq/s': 24225.57820888417, 'global_steps': 847, 'samples_trained': 4336640, 'skipped_steps': 8, 'timestamp': 1592975980.4489925}
  0: {'training_steps': 856, 'average_loss': 1.2451171875, 'step_loss': 1.2451171875, 'learning_rate': 0.0002438383838383839, 'seq/s': 24177.221202711924, 'global_steps': 848, 'samples_trained': 4341760, 'skipped_steps': 8, 'timestamp': 1592975980.6607625}
  0: {'training_steps': 857, 'average_loss': 1.4931640625, 'step_loss': 1.4931640625, 'learning_rate': 0.00024212121212121215, 'seq/s': 24135.15845596747, 'global_steps': 849, 'samples_trained': 4346880, 'skipped_steps': 8, 'timestamp': 1592975980.8729017}
  0: {'training_steps': 858, 'average_loss': 1.751953125, 'step_loss': 1.751953125, 'learning_rate': 0.00024040404040404044, 'seq/s': 21447.019695454994, 'global_steps': 850, 'samples_trained': 4352000, 'skipped_steps': 8, 'timestamp': 1592975981.11163}
  0: {'training_steps': 859, 'average_loss': 1.3408203125, 'step_loss': 1.3408203125, 'learning_rate': 0.0002386868686868687, 'seq/s': 24217.65548755389, 'global_steps': 851, 'samples_trained': 4357120, 'skipped_steps': 8, 'timestamp': 1592975981.3230464}
  0: {'training_steps': 860, 'average_loss': 1.16015625, 'step_loss': 1.16015625, 'learning_rate': 0.00023696969696969698, 'seq/s': 24090.32282961085, 'global_steps': 852, 'samples_trained': 4362240, 'skipped_steps': 8, 'timestamp': 1592975981.5355804}
  0: {'training_steps': 861, 'average_loss': 1.296875, 'step_loss': 1.296875, 'learning_rate': 0.00023525252525252523, 'seq/s': 24105.628333842204, 'global_steps': 853, 'samples_trained': 4367360, 'skipped_steps': 8, 'timestamp': 1592975981.7479794}
  0: {'training_steps': 862, 'average_loss': 1.416015625, 'step_loss': 1.416015625, 'learning_rate': 0.00023353535353535352, 'seq/s': 24192.855398286716, 'global_steps': 854, 'samples_trained': 4372480, 'skipped_steps': 8, 'timestamp': 1592975981.9596126}
  0: {'training_steps': 863, 'average_loss': 1.212890625, 'step_loss': 1.212890625, 'learning_rate': 0.00023181818181818178, 'seq/s': 24210.9115999053, 'global_steps': 855, 'samples_trained': 4377600, 'skipped_steps': 8, 'timestamp': 1592975982.1710882}
  0: {'training_steps': 864, 'average_loss': 1.322265625, 'step_loss': 1.322265625, 'learning_rate': 0.00023010101010101006, 'seq/s': 24122.84996652543, 'global_steps': 856, 'samples_trained': 4382720, 'skipped_steps': 8, 'timestamp': 1592975982.3833356}
  0: {'training_steps': 865, 'average_loss': 1.0908203125, 'step_loss': 1.0908203125, 'learning_rate': 0.00022838383838383834, 'seq/s': 24231.099857715253, 'global_steps': 857, 'samples_trained': 4387840, 'skipped_steps': 8, 'timestamp': 1592975982.5946348}
  0: {'training_steps': 866, 'average_loss': 1.2822265625, 'step_loss': 1.2822265625, 'learning_rate': 0.0002266666666666666, 'seq/s': 24219.78591689082, 'global_steps': 858, 'samples_trained': 4392960, 'skipped_steps': 8, 'timestamp': 1592975982.8060327}
  0: {'training_steps': 867, 'average_loss': 1.7529296875, 'step_loss': 1.7529296875, 'learning_rate': 0.00022494949494949489, 'seq/s': 24179.371748145295, 'global_steps': 859, 'samples_trained': 4398080, 'skipped_steps': 8, 'timestamp': 1592975983.0177839}
  0: {'training_steps': 868, 'average_loss': 1.4677734375, 'step_loss': 1.4677734375, 'learning_rate': 0.00022323232323232314, 'seq/s': 24096.215580580152, 'global_steps': 860, 'samples_trained': 4403200, 'skipped_steps': 8, 'timestamp': 1592975983.2302659}
  0: {'training_steps': 869, 'average_loss': 1.2744140625, 'step_loss': 1.2744140625, 'learning_rate': 0.00022151515151515143, 'seq/s': 24288.789950980947, 'global_steps': 861, 'samples_trained': 4408320, 'skipped_steps': 8, 'timestamp': 1592975983.4410632}
  0: {'training_steps': 870, 'average_loss': 1.3955078125, 'step_loss': 1.3955078125, 'learning_rate': 0.00021979797979797987, 'seq/s': 24248.172740894304, 'global_steps': 862, 'samples_trained': 4413440, 'skipped_steps': 8, 'timestamp': 1592975983.6522136}
  0: {'training_steps': 871, 'average_loss': 1.5185546875, 'step_loss': 1.5185546875, 'learning_rate': 0.00021808080808080816, 'seq/s': 24106.386001463794, 'global_steps': 863, 'samples_trained': 4418560, 'skipped_steps': 8, 'timestamp': 1592975983.864606}
  0: {'training_steps': 872, 'average_loss': 1.2841796875, 'step_loss': 1.2841796875, 'learning_rate': 0.00021636363636363642, 'seq/s': 24212.494847406564, 'global_steps': 864, 'samples_trained': 4423680, 'skipped_steps': 8, 'timestamp': 1592975984.0760677}
  0: {'training_steps': 873, 'average_loss': 1.5322265625, 'step_loss': 1.5322265625, 'learning_rate': 0.0002146464646464647, 'seq/s': 24158.50856213312, 'global_steps': 865, 'samples_trained': 4428800, 'skipped_steps': 8, 'timestamp': 1592975984.2880018}
  0: {'training_steps': 874, 'average_loss': 1.068359375, 'step_loss': 1.068359375, 'learning_rate': 0.00021292929292929296, 'seq/s': 24271.46781618419, 'global_steps': 866, 'samples_trained': 4433920, 'skipped_steps': 8, 'timestamp': 1592975984.4989495}
  0: {'training_steps': 875, 'average_loss': 1.37890625, 'step_loss': 1.37890625, 'learning_rate': 0.00021121212121212124, 'seq/s': 24214.97932549352, 'global_steps': 867, 'samples_trained': 4439040, 'skipped_steps': 8, 'timestamp': 1592975984.7103896}
  0: {'training_steps': 876, 'average_loss': 1.384765625, 'step_loss': 1.384765625, 'learning_rate': 0.0002094949494949495, 'seq/s': 24232.30292696853, 'global_steps': 868, 'samples_trained': 4444160, 'skipped_steps': 8, 'timestamp': 1592975984.9216783}
  0: {'training_steps': 877, 'average_loss': 1.3095703125, 'step_loss': 1.3095703125, 'learning_rate': 0.00020777777777777778, 'seq/s': 24058.61100934904, 'global_steps': 869, 'samples_trained': 4449280, 'skipped_steps': 8, 'timestamp': 1592975985.1344924}
  0: {'training_steps': 878, 'average_loss': 1.4140625, 'step_loss': 1.4140625, 'learning_rate': 0.00020606060606060607, 'seq/s': 24245.708821214903, 'global_steps': 870, 'samples_trained': 4454400, 'skipped_steps': 8, 'timestamp': 1592975985.3456643}
  0: {'training_steps': 879, 'average_loss': 1.5791015625, 'step_loss': 1.5791015625, 'learning_rate': 0.00020434343434343433, 'seq/s': 24123.798412254422, 'global_steps': 871, 'samples_trained': 4459520, 'skipped_steps': 8, 'timestamp': 1592975985.5579033}
  0: {'training_steps': 880, 'average_loss': 1.29296875, 'step_loss': 1.29296875, 'learning_rate': 0.0002026262626262626, 'seq/s': 24077.46610068774, 'global_steps': 872, 'samples_trained': 4464640, 'skipped_steps': 8, 'timestamp': 1592975985.7705507}
  0: {'training_steps': 881, 'average_loss': 1.3232421875, 'step_loss': 1.3232421875, 'learning_rate': 0.00020090909090909087, 'seq/s': 24149.163100022717, 'global_steps': 873, 'samples_trained': 4469760, 'skipped_steps': 8, 'timestamp': 1592975985.9825668}
  0: {'training_steps': 882, 'average_loss': 1.2578125, 'step_loss': 1.2578125, 'learning_rate': 0.00019919191919191915, 'seq/s': 21850.71243531224, 'global_steps': 874, 'samples_trained': 4474880, 'skipped_steps': 8, 'timestamp': 1592975986.216885}
  0: {'training_steps': 883, 'average_loss': 1.3369140625, 'step_loss': 1.3369140625, 'learning_rate': 0.0001974747474747474, 'seq/s': 24162.368391443473, 'global_steps': 875, 'samples_trained': 4480000, 'skipped_steps': 8, 'timestamp': 1592975986.4287853}
  0: {'training_steps': 884, 'average_loss': 0.95849609375, 'step_loss': 0.95849609375, 'learning_rate': 0.0001957575757575757, 'seq/s': 24169.30287208911, 'global_steps': 876, 'samples_trained': 4485120, 'skipped_steps': 8, 'timestamp': 1592975986.640625}
  0: {'training_steps': 885, 'average_loss': 1.134765625, 'step_loss': 1.134765625, 'learning_rate': 0.00019404040404040395, 'seq/s': 24171.207151355116, 'global_steps': 877, 'samples_trained': 4490240, 'skipped_steps': 8, 'timestamp': 1592975986.8524477}
  0: {'training_steps': 886, 'average_loss': 1.4306640625, 'step_loss': 1.4306640625, 'learning_rate': 0.00019232323232323223, 'seq/s': 24215.798495959116, 'global_steps': 878, 'samples_trained': 4495360, 'skipped_steps': 8, 'timestamp': 1592975987.0638804}
  0: :::MLLOG {"namespace": "", "time_ms": 1592975987408, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7106431126594543, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 843, "epoch_num": 1}}
  0: {'global_steps': 879, 'eval_loss': 1.3436890840530396, 'eval_mlm_accuracy': 0.7106431126594543}
  0: {'training_steps': 887, 'average_loss': 1.4091796875, 'step_loss': 1.4091796875, 'learning_rate': 0.0001906060606060605, 'seq/s': 14834.120103753285, 'global_steps': 879, 'samples_trained': 4500480, 'skipped_steps': 8, 'timestamp': 1592975987.4090312}
  0: {'training_steps': 888, 'average_loss': 1.2646484375, 'step_loss': 1.2646484375, 'learning_rate': 0.00018888888888888897, 'seq/s': 25483.552131615983, 'global_steps': 880, 'samples_trained': 4505600, 'skipped_steps': 8, 'timestamp': 1592975987.6099455}
  0: {'training_steps': 889, 'average_loss': 1.1416015625, 'step_loss': 1.1416015625, 'learning_rate': 0.00018717171717171722, 'seq/s': 24250.80147391791, 'global_steps': 881, 'samples_trained': 4510720, 'skipped_steps': 8, 'timestamp': 1592975987.821073}
  0: {'training_steps': 890, 'average_loss': 1.4111328125, 'step_loss': 1.4111328125, 'learning_rate': 0.0001854545454545455, 'seq/s': 24084.162851676316, 'global_steps': 882, 'samples_trained': 4515840, 'skipped_steps': 8, 'timestamp': 1592975988.0336614}
  0: {'training_steps': 891, 'average_loss': 1.09765625, 'step_loss': 1.09765625, 'learning_rate': 0.00018373737373737376, 'seq/s': 24033.167119914946, 'global_steps': 883, 'samples_trained': 4520960, 'skipped_steps': 8, 'timestamp': 1592975988.2467008}
  0: {'training_steps': 892, 'average_loss': 1.224609375, 'step_loss': 1.224609375, 'learning_rate': 0.00018202020202020205, 'seq/s': 22653.402392892633, 'global_steps': 884, 'samples_trained': 4526080, 'skipped_steps': 8, 'timestamp': 1592975988.4727159}
  0: {'training_steps': 893, 'average_loss': 1.4052734375, 'step_loss': 1.4052734375, 'learning_rate': 0.00018030303030303033, 'seq/s': 24278.73955356174, 'global_steps': 885, 'samples_trained': 4531200, 'skipped_steps': 8, 'timestamp': 1592975988.6836004}
  0: {'training_steps': 894, 'average_loss': 1.3095703125, 'step_loss': 1.3095703125, 'learning_rate': 0.0001785858585858586, 'seq/s': 24160.92760667173, 'global_steps': 886, 'samples_trained': 4536320, 'skipped_steps': 8, 'timestamp': 1592975988.8955133}
  0: {'training_steps': 895, 'average_loss': 1.4658203125, 'step_loss': 1.4658203125, 'learning_rate': 0.00017686868686868687, 'seq/s': 24107.360215536595, 'global_steps': 887, 'samples_trained': 4541440, 'skipped_steps': 8, 'timestamp': 1592975989.107897}
  0: {'training_steps': 896, 'average_loss': 1.267578125, 'step_loss': 1.267578125, 'learning_rate': 0.00017515151515151513, 'seq/s': 24241.68549574201, 'global_steps': 888, 'samples_trained': 4546560, 'skipped_steps': 8, 'timestamp': 1592975989.3191037}
  0: {'training_steps': 897, 'average_loss': 1.5576171875, 'step_loss': 1.5576171875, 'learning_rate': 0.00017343434343434342, 'seq/s': 24242.588575021648, 'global_steps': 889, 'samples_trained': 4551680, 'skipped_steps': 8, 'timestamp': 1592975989.5303028}
  0: {'training_steps': 898, 'average_loss': 1.462890625, 'step_loss': 1.462890625, 'learning_rate': 0.00017171717171717167, 'seq/s': 24252.36255384122, 'global_steps': 890, 'samples_trained': 4556800, 'skipped_steps': 8, 'timestamp': 1592975989.7414167}
  0: {'training_steps': 899, 'average_loss': 1.220703125, 'step_loss': 1.220703125, 'learning_rate': 0.00016999999999999996, 'seq/s': 24278.437621181132, 'global_steps': 891, 'samples_trained': 4561920, 'skipped_steps': 8, 'timestamp': 1592975989.952304}
  0: {'training_steps': 900, 'average_loss': 1.525390625, 'step_loss': 1.525390625, 'learning_rate': 0.00016828282828282822, 'seq/s': 24229.760216630937, 'global_steps': 892, 'samples_trained': 4567040, 'skipped_steps': 8, 'timestamp': 1592975990.1636147}
  0: {'training_steps': 901, 'average_loss': 1.439453125, 'step_loss': 1.439453125, 'learning_rate': 0.0001665656565656565, 'seq/s': 24137.22013537178, 'global_steps': 893, 'samples_trained': 4572160, 'skipped_steps': 8, 'timestamp': 1592975990.3757355}
  0: {'training_steps': 902, 'average_loss': 1.1435546875, 'step_loss': 1.1435546875, 'learning_rate': 0.00016484848484848476, 'seq/s': 21544.316902008977, 'global_steps': 894, 'samples_trained': 4577280, 'skipped_steps': 8, 'timestamp': 1592975990.6133854}
  0: {'training_steps': 903, 'average_loss': 1.4755859375, 'step_loss': 1.4755859375, 'learning_rate': 0.00016313131313131304, 'seq/s': 24259.321389033234, 'global_steps': 895, 'samples_trained': 4582400, 'skipped_steps': 8, 'timestamp': 1592975990.8244388}
  0: {'training_steps': 904, 'average_loss': 1.392578125, 'step_loss': 1.392578125, 'learning_rate': 0.00016141414141414133, 'seq/s': 24230.79910906707, 'global_steps': 896, 'samples_trained': 4587520, 'skipped_steps': 8, 'timestamp': 1592975991.0357406}
  0: {'training_steps': 905, 'average_loss': 1.220703125, 'step_loss': 1.220703125, 'learning_rate': 0.00015969696969696977, 'seq/s': 21661.493570093495, 'global_steps': 897, 'samples_trained': 4592640, 'skipped_steps': 8, 'timestamp': 1592975991.2721052}
  0: {'training_steps': 906, 'average_loss': 1.44921875, 'step_loss': 1.44921875, 'learning_rate': 0.00015797979797979806, 'seq/s': 21688.993602834387, 'global_steps': 898, 'samples_trained': 4597760, 'skipped_steps': 8, 'timestamp': 1592975991.5081701}
  0: {'training_steps': 907, 'average_loss': 1.400390625, 'step_loss': 1.400390625, 'learning_rate': 0.00015626262626262631, 'seq/s': 24260.19837593822, 'global_steps': 899, 'samples_trained': 4602880, 'skipped_steps': 8, 'timestamp': 1592975991.7192159}
  0: {'training_steps': 908, 'average_loss': 1.2421875, 'step_loss': 1.2421875, 'learning_rate': 0.0001545454545454546, 'seq/s': 24278.657207622255, 'global_steps': 900, 'samples_trained': 4608000, 'skipped_steps': 8, 'timestamp': 1592975991.9301012}
  0: {'training_steps': 909, 'average_loss': 1.3037109375, 'step_loss': 1.3037109375, 'learning_rate': 0.00015282828282828286, 'seq/s': 21306.240201287215, 'global_steps': 901, 'samples_trained': 4613120, 'skipped_steps': 8, 'timestamp': 1592975992.170407}
  0: {'training_steps': 910, 'average_loss': 1.412109375, 'step_loss': 1.412109375, 'learning_rate': 0.00015111111111111114, 'seq/s': 23993.667723997536, 'global_steps': 902, 'samples_trained': 4618240, 'skipped_steps': 8, 'timestamp': 1592975992.383797}
  0: {'training_steps': 911, 'average_loss': 1.3740234375, 'step_loss': 1.3740234375, 'learning_rate': 0.0001493939393939394, 'seq/s': 24353.243774707815, 'global_steps': 903, 'samples_trained': 4623360, 'skipped_steps': 8, 'timestamp': 1592975992.5940366}
  0: {'training_steps': 912, 'average_loss': 1.58203125, 'step_loss': 1.58203125, 'learning_rate': 0.00014767676767676768, 'seq/s': 24181.413759244744, 'global_steps': 904, 'samples_trained': 4628480, 'skipped_steps': 8, 'timestamp': 1592975992.8057702}
  0: {'training_steps': 913, 'average_loss': 1.4267578125, 'step_loss': 1.4267578125, 'learning_rate': 0.00014595959595959594, 'seq/s': 24202.725692839995, 'global_steps': 905, 'samples_trained': 4633600, 'skipped_steps': 8, 'timestamp': 1592975993.017317}
  0: {'training_steps': 914, 'average_loss': 1.138671875, 'step_loss': 1.138671875, 'learning_rate': 0.00014424242424242422, 'seq/s': 24270.480293576158, 'global_steps': 906, 'samples_trained': 4638720, 'skipped_steps': 8, 'timestamp': 1592975993.2282734}
  0: {'training_steps': 915, 'average_loss': 1.166015625, 'step_loss': 1.166015625, 'learning_rate': 0.00014252525252525248, 'seq/s': 24280.057164565205, 'global_steps': 907, 'samples_trained': 4643840, 'skipped_steps': 8, 'timestamp': 1592975993.4391465}
  0: {'training_steps': 916, 'average_loss': 1.388671875, 'step_loss': 1.388671875, 'learning_rate': 0.00014080808080808076, 'seq/s': 24202.507477758318, 'global_steps': 908, 'samples_trained': 4648960, 'skipped_steps': 8, 'timestamp': 1592975993.6506956}
  0: {'training_steps': 917, 'average_loss': 1.5009765625, 'step_loss': 1.5009765625, 'learning_rate': 0.00013909090909090902, 'seq/s': 24154.351111895954, 'global_steps': 909, 'samples_trained': 4654080, 'skipped_steps': 8, 'timestamp': 1592975993.8626661}
  0: {'training_steps': 918, 'average_loss': 1.4814453125, 'step_loss': 1.4814453125, 'learning_rate': 0.0001373737373737373, 'seq/s': 22502.33824913186, 'global_steps': 910, 'samples_trained': 4659200, 'skipped_steps': 8, 'timestamp': 1592975994.0901985}
  0: {'training_steps': 919, 'average_loss': 1.5712890625, 'step_loss': 1.5712890625, 'learning_rate': 0.0001356565656565656, 'seq/s': 24271.166064639212, 'global_steps': 911, 'samples_trained': 4664320, 'skipped_steps': 8, 'timestamp': 1592975994.301149}
  0: {'training_steps': 920, 'average_loss': 1.517578125, 'step_loss': 1.517578125, 'learning_rate': 0.00013393939393939385, 'seq/s': 24109.66075568504, 'global_steps': 912, 'samples_trained': 4669440, 'skipped_steps': 8, 'timestamp': 1592975994.5135124}
  0: {'training_steps': 921, 'average_loss': 1.2373046875, 'step_loss': 1.2373046875, 'learning_rate': 0.00013222222222222213, 'seq/s': 24261.294698739646, 'global_steps': 913, 'samples_trained': 4674560, 'skipped_steps': 8, 'timestamp': 1592975994.7245486}
  0: {'training_steps': 922, 'average_loss': 1.3720703125, 'step_loss': 1.3720703125, 'learning_rate': 0.00013050505050505058, 'seq/s': 24205.42643015991, 'global_steps': 914, 'samples_trained': 4679680, 'skipped_steps': 8, 'timestamp': 1592975994.9360719}
  0: {'training_steps': 923, 'average_loss': 1.44921875, 'step_loss': 1.44921875, 'learning_rate': 0.00012878787878787886, 'seq/s': 24162.55869661834, 'global_steps': 915, 'samples_trained': 4684800, 'skipped_steps': 8, 'timestamp': 1592975995.1479707}
  0: {'training_steps': 924, 'average_loss': 1.396484375, 'step_loss': 1.396484375, 'learning_rate': 0.00012707070707070712, 'seq/s': 24231.345930344083, 'global_steps': 916, 'samples_trained': 4689920, 'skipped_steps': 8, 'timestamp': 1592975995.359268}
  0: {'training_steps': 925, 'average_loss': 1.3740234375, 'step_loss': 1.3740234375, 'learning_rate': 0.0001253535353535354, 'seq/s': 24031.04250197789, 'global_steps': 917, 'samples_trained': 4695040, 'skipped_steps': 8, 'timestamp': 1592975995.5723262}
  0: {'training_steps': 926, 'average_loss': 1.154296875, 'step_loss': 1.154296875, 'learning_rate': 0.00012363636363636366, 'seq/s': 24203.81682727529, 'global_steps': 918, 'samples_trained': 4700160, 'skipped_steps': 8, 'timestamp': 1592975995.7838635}
  0: {'training_steps': 927, 'average_loss': 1.416015625, 'step_loss': 1.416015625, 'learning_rate': 0.00012191919191919195, 'seq/s': 24123.635816261307, 'global_steps': 919, 'samples_trained': 4705280, 'skipped_steps': 8, 'timestamp': 1592975995.996104}
  0: {'training_steps': 928, 'average_loss': 1.4482421875, 'step_loss': 1.4482421875, 'learning_rate': 0.00012020202020202022, 'seq/s': 24227.60069902378, 'global_steps': 920, 'samples_trained': 4710400, 'skipped_steps': 8, 'timestamp': 1592975996.207434}
  0: {'training_steps': 929, 'average_loss': 1.62109375, 'step_loss': 1.62109375, 'learning_rate': 0.00011848484848484849, 'seq/s': 24187.37840611002, 'global_steps': 921, 'samples_trained': 4715520, 'skipped_steps': 8, 'timestamp': 1592975996.419115}
  0: {'training_steps': 930, 'average_loss': 1.2900390625, 'step_loss': 1.2900390625, 'learning_rate': 0.00011676767676767676, 'seq/s': 24107.68497105933, 'global_steps': 922, 'samples_trained': 4720640, 'skipped_steps': 8, 'timestamp': 1592975996.631496}
  0: {'training_steps': 931, 'average_loss': 1.3515625, 'step_loss': 1.3515625, 'learning_rate': 0.00011505050505050503, 'seq/s': 24206.545093839824, 'global_steps': 923, 'samples_trained': 4725760, 'skipped_steps': 8, 'timestamp': 1592975996.8430095}
  0: {'training_steps': 932, 'average_loss': 1.2958984375, 'step_loss': 1.2958984375, 'learning_rate': 0.0001133333333333333, 'seq/s': 24163.42870130849, 'global_steps': 924, 'samples_trained': 4730880, 'skipped_steps': 8, 'timestamp': 1592975997.0549004}
  0: {'training_steps': 933, 'average_loss': 1.404296875, 'step_loss': 1.404296875, 'learning_rate': 0.00011161616161616157, 'seq/s': 24221.179092592716, 'global_steps': 925, 'samples_trained': 4736000, 'skipped_steps': 8, 'timestamp': 1592975997.2662864}
  0: {'training_steps': 934, 'average_loss': 1.513671875, 'step_loss': 1.513671875, 'learning_rate': 0.00010989898989898984, 'seq/s': 24172.404280489824, 'global_steps': 926, 'samples_trained': 4741120, 'skipped_steps': 8, 'timestamp': 1592975997.4780986}
  0: {'training_steps': 935, 'average_loss': 1.3408203125, 'step_loss': 1.3408203125, 'learning_rate': 0.00010818181818181811, 'seq/s': 24117.51296291097, 'global_steps': 927, 'samples_trained': 4746240, 'skipped_steps': 8, 'timestamp': 1592975997.690393}
  0: {'training_steps': 936, 'average_loss': 1.296875, 'step_loss': 1.296875, 'learning_rate': 0.00010646464646464638, 'seq/s': 24281.622013394284, 'global_steps': 928, 'samples_trained': 4751360, 'skipped_steps': 8, 'timestamp': 1592975997.9012525}
  0: {'training_steps': 937, 'average_loss': 1.3017578125, 'step_loss': 1.3017578125, 'learning_rate': 0.00010474747474747465, 'seq/s': 24198.85296000144, 'global_steps': 929, 'samples_trained': 4756480, 'skipped_steps': 8, 'timestamp': 1592975998.1128333}
  0: {'training_steps': 938, 'average_loss': 1.36328125, 'step_loss': 1.36328125, 'learning_rate': 0.00010303030303030294, 'seq/s': 24250.062085148573, 'global_steps': 930, 'samples_trained': 4761600, 'skipped_steps': 8, 'timestamp': 1592975998.3239672}
  0: {'training_steps': 939, 'average_loss': 1.2001953125, 'step_loss': 1.2001953125, 'learning_rate': 0.0001013131313131314, 'seq/s': 24231.072516620556, 'global_steps': 931, 'samples_trained': 4766720, 'skipped_steps': 8, 'timestamp': 1592975998.5352666}
  0: {'training_steps': 940, 'average_loss': 1.46875, 'step_loss': 1.46875, 'learning_rate': 9.959595959595967e-05, 'seq/s': 24225.195613598702, 'global_steps': 932, 'samples_trained': 4771840, 'skipped_steps': 8, 'timestamp': 1592975998.7466173}
  0: {'training_steps': 941, 'average_loss': 1.224609375, 'step_loss': 1.224609375, 'learning_rate': 9.787878787878794e-05, 'seq/s': 24223.282818427208, 'global_steps': 933, 'samples_trained': 4776960, 'skipped_steps': 8, 'timestamp': 1592975998.9579847}
  0: {'training_steps': 942, 'average_loss': 1.2880859375, 'step_loss': 1.2880859375, 'learning_rate': 9.616161616161621e-05, 'seq/s': 24192.90990818453, 'global_steps': 934, 'samples_trained': 4782080, 'skipped_steps': 8, 'timestamp': 1592975999.1696174}
  0: {'training_steps': 943, 'average_loss': 1.4296875, 'step_loss': 1.4296875, 'learning_rate': 9.444444444444448e-05, 'seq/s': 24153.916428499928, 'global_steps': 935, 'samples_trained': 4787200, 'skipped_steps': 8, 'timestamp': 1592975999.3815918}
  0: {'training_steps': 944, 'average_loss': 1.2646484375, 'step_loss': 1.2646484375, 'learning_rate': 9.272727272727275e-05, 'seq/s': 23633.15829439381, 'global_steps': 936, 'samples_trained': 4792320, 'skipped_steps': 8, 'timestamp': 1592975999.598237}
  0: {'training_steps': 945, 'average_loss': 1.369140625, 'step_loss': 1.369140625, 'learning_rate': 9.101010101010102e-05, 'seq/s': 24061.9267167293, 'global_steps': 937, 'samples_trained': 4797440, 'skipped_steps': 8, 'timestamp': 1592975999.8110218}
  0: {'training_steps': 946, 'average_loss': 1.4453125, 'step_loss': 1.4453125, 'learning_rate': 8.92929292929293e-05, 'seq/s': 24126.9423656605, 'global_steps': 938, 'samples_trained': 4802560, 'skipped_steps': 8, 'timestamp': 1592976000.0232332}
  0: {'training_steps': 947, 'average_loss': 1.63671875, 'step_loss': 1.63671875, 'learning_rate': 8.757575757575757e-05, 'seq/s': 24208.018613543518, 'global_steps': 939, 'samples_trained': 4807680, 'skipped_steps': 8, 'timestamp': 1592976000.2347338}
  0: {'training_steps': 948, 'average_loss': 1.44921875, 'step_loss': 1.44921875, 'learning_rate': 8.585858585858584e-05, 'seq/s': 24065.78271262379, 'global_steps': 940, 'samples_trained': 4812800, 'skipped_steps': 8, 'timestamp': 1592976000.4474847}
  0: {'training_steps': 949, 'average_loss': 1.4873046875, 'step_loss': 1.4873046875, 'learning_rate': 8.414141414141411e-05, 'seq/s': 24208.864604059454, 'global_steps': 941, 'samples_trained': 4817920, 'skipped_steps': 8, 'timestamp': 1592976000.658978}
  0: {'training_steps': 950, 'average_loss': 1.19140625, 'step_loss': 1.19140625, 'learning_rate': 8.242424242424238e-05, 'seq/s': 24287.965834856408, 'global_steps': 942, 'samples_trained': 4823040, 'skipped_steps': 8, 'timestamp': 1592976000.8697824}
  0: {'training_steps': 951, 'average_loss': 1.248046875, 'step_loss': 1.248046875, 'learning_rate': 8.070707070707066e-05, 'seq/s': 24218.77528188726, 'global_steps': 943, 'samples_trained': 4828160, 'skipped_steps': 8, 'timestamp': 1592976001.0811892}
  0: {'training_steps': 952, 'average_loss': 1.419921875, 'step_loss': 1.419921875, 'learning_rate': 7.898989898989893e-05, 'seq/s': 24170.282178234538, 'global_steps': 944, 'samples_trained': 4833280, 'skipped_steps': 8, 'timestamp': 1592976001.2930202}
  0: {'training_steps': 953, 'average_loss': 1.2724609375, 'step_loss': 1.2724609375, 'learning_rate': 7.72727272727272e-05, 'seq/s': 24166.202259430516, 'global_steps': 945, 'samples_trained': 4838400, 'skipped_steps': 8, 'timestamp': 1592976001.5048869}
  0: {'training_steps': 954, 'average_loss': 1.09375, 'step_loss': 1.09375, 'learning_rate': 7.555555555555548e-05, 'seq/s': 21790.60412436619, 'global_steps': 946, 'samples_trained': 4843520, 'skipped_steps': 8, 'timestamp': 1592976001.739851}
  0: {'training_steps': 955, 'average_loss': 1.4072265625, 'step_loss': 1.4072265625, 'learning_rate': 7.383838383838375e-05, 'seq/s': 24144.33020475897, 'global_steps': 947, 'samples_trained': 4848640, 'skipped_steps': 8, 'timestamp': 1592976001.9519095}
  0: {'training_steps': 956, 'average_loss': 1.341796875, 'step_loss': 1.341796875, 'learning_rate': 7.21212121212122e-05, 'seq/s': 24105.330691735653, 'global_steps': 948, 'samples_trained': 4853760, 'skipped_steps': 8, 'timestamp': 1592976002.1643116}
  0: {'training_steps': 957, 'average_loss': 1.37109375, 'step_loss': 1.37109375, 'learning_rate': 7.040404040404048e-05, 'seq/s': 24218.556777300357, 'global_steps': 949, 'samples_trained': 4858880, 'skipped_steps': 8, 'timestamp': 1592976002.3757203}
  0: {'training_steps': 958, 'average_loss': 1.4287109375, 'step_loss': 1.4287109375, 'learning_rate': 6.868686868686875e-05, 'seq/s': 24220.03175978057, 'global_steps': 950, 'samples_trained': 4864000, 'skipped_steps': 8, 'timestamp': 1592976002.587116}
  0: {'training_steps': 959, 'average_loss': 1.26953125, 'step_loss': 1.26953125, 'learning_rate': 6.696969696969702e-05, 'seq/s': 24163.83653757435, 'global_steps': 951, 'samples_trained': 4869120, 'skipped_steps': 8, 'timestamp': 1592976002.7990034}
  0: {'training_steps': 960, 'average_loss': 1.486328125, 'step_loss': 1.486328125, 'learning_rate': 6.525252525252529e-05, 'seq/s': 20067.014977255654, 'global_steps': 952, 'samples_trained': 4874240, 'skipped_steps': 8, 'timestamp': 1592976003.054149}
  0: {'training_steps': 961, 'average_loss': 1.3212890625, 'step_loss': 1.3212890625, 'learning_rate': 6.353535353535356e-05, 'seq/s': 24184.872351328067, 'global_steps': 953, 'samples_trained': 4879360, 'skipped_steps': 8, 'timestamp': 1592976003.265852}
  0: {'training_steps': 962, 'average_loss': 1.67578125, 'step_loss': 1.67578125, 'learning_rate': 6.181818181818183e-05, 'seq/s': 24234.271843455004, 'global_steps': 954, 'samples_trained': 4884480, 'skipped_steps': 8, 'timestamp': 1592976003.4771235}
  0: {'training_steps': 963, 'average_loss': 1.2529296875, 'step_loss': 1.2529296875, 'learning_rate': 6.010101010101011e-05, 'seq/s': 24169.629298653355, 'global_steps': 955, 'samples_trained': 4889600, 'skipped_steps': 8, 'timestamp': 1592976003.68896}
  0: {'training_steps': 964, 'average_loss': 1.537109375, 'step_loss': 1.537109375, 'learning_rate': 5.838383838383838e-05, 'seq/s': 24190.94770660184, 'global_steps': 956, 'samples_trained': 4894720, 'skipped_steps': 8, 'timestamp': 1592976003.90061}
  0: {'training_steps': 965, 'average_loss': 1.234375, 'step_loss': 1.234375, 'learning_rate': 5.666666666666665e-05, 'seq/s': 24193.754843012597, 'global_steps': 957, 'samples_trained': 4899840, 'skipped_steps': 8, 'timestamp': 1592976004.1122353}
  0: {'training_steps': 966, 'average_loss': 1.6123046875, 'step_loss': 1.6123046875, 'learning_rate': 5.494949494949492e-05, 'seq/s': 24175.86029567387, 'global_steps': 958, 'samples_trained': 4904960, 'skipped_steps': 8, 'timestamp': 1592976004.3240175}
  0: {'training_steps': 967, 'average_loss': 1.1455078125, 'step_loss': 1.1455078125, 'learning_rate': 5.323232323232319e-05, 'seq/s': 24184.300389879794, 'global_steps': 959, 'samples_trained': 4910080, 'skipped_steps': 8, 'timestamp': 1592976004.5357256}
  0: {'training_steps': 968, 'average_loss': 1.455078125, 'step_loss': 1.455078125, 'learning_rate': 5.151515151515147e-05, 'seq/s': 24213.204646264654, 'global_steps': 960, 'samples_trained': 4915200, 'skipped_steps': 8, 'timestamp': 1592976004.747181}
  0: {'training_steps': 969, 'average_loss': 1.455078125, 'step_loss': 1.455078125, 'learning_rate': 4.979797979797974e-05, 'seq/s': 24177.820050348793, 'global_steps': 961, 'samples_trained': 4920320, 'skipped_steps': 8, 'timestamp': 1592976004.9589458}
  0: {'training_steps': 970, 'average_loss': 1.24609375, 'step_loss': 1.24609375, 'learning_rate': 4.808080808080801e-05, 'seq/s': 21611.377160902583, 'global_steps': 962, 'samples_trained': 4925440, 'skipped_steps': 8, 'timestamp': 1592976005.1958585}
  0: {'training_steps': 971, 'average_loss': 1.4892578125, 'step_loss': 1.4892578125, 'learning_rate': 4.636363636363628e-05, 'seq/s': 24149.842032403205, 'global_steps': 963, 'samples_trained': 4930560, 'skipped_steps': 8, 'timestamp': 1592976005.4078689}
  0: {'training_steps': 972, 'average_loss': 1.2451171875, 'step_loss': 1.2451171875, 'learning_rate': 4.464646464646455e-05, 'seq/s': 23902.014329074533, 'global_steps': 964, 'samples_trained': 4935680, 'skipped_steps': 8, 'timestamp': 1592976005.622077}
  0: {'training_steps': 973, 'average_loss': 1.20703125, 'step_loss': 1.20703125, 'learning_rate': 4.292929292929301e-05, 'seq/s': 24245.7361953493, 'global_steps': 965, 'samples_trained': 4940800, 'skipped_steps': 8, 'timestamp': 1592976005.8332489}
  0: {'training_steps': 974, 'average_loss': 1.2978515625, 'step_loss': 1.2978515625, 'learning_rate': 4.1212121212121284e-05, 'seq/s': 21365.57293998492, 'global_steps': 966, 'samples_trained': 4945920, 'skipped_steps': 8, 'timestamp': 1592976006.0728872}
  0: {'training_steps': 975, 'average_loss': 1.3359375, 'step_loss': 1.3359375, 'learning_rate': 3.949494949494956e-05, 'seq/s': 24090.05258906937, 'global_steps': 967, 'samples_trained': 4951040, 'skipped_steps': 8, 'timestamp': 1592976006.2854235}
  0: {'training_steps': 976, 'average_loss': 1.3359375, 'step_loss': 1.3359375, 'learning_rate': 3.777777777777783e-05, 'seq/s': 24094.458266060945, 'global_steps': 968, 'samples_trained': 4956160, 'skipped_steps': 8, 'timestamp': 1592976006.497921}
  0: {'training_steps': 977, 'average_loss': 1.1669921875, 'step_loss': 1.1669921875, 'learning_rate': 3.60606060606061e-05, 'seq/s': 24119.84253188954, 'global_steps': 969, 'samples_trained': 4961280, 'skipped_steps': 8, 'timestamp': 1592976006.7101948}
  0: {'training_steps': 978, 'average_loss': 1.568359375, 'step_loss': 1.568359375, 'learning_rate': 3.4343434343434374e-05, 'seq/s': 21627.592163450452, 'global_steps': 970, 'samples_trained': 4966400, 'skipped_steps': 8, 'timestamp': 1592976006.94693}
  0: {'training_steps': 979, 'average_loss': 1.177734375, 'step_loss': 1.177734375, 'learning_rate': 3.2626262626262645e-05, 'seq/s': 24275.501034330737, 'global_steps': 971, 'samples_trained': 4971520, 'skipped_steps': 8, 'timestamp': 1592976007.1578426}
  0: {'training_steps': 980, 'average_loss': 1.1943359375, 'step_loss': 1.1943359375, 'learning_rate': 3.0909090909090916e-05, 'seq/s': 24170.853476802557, 'global_steps': 972, 'samples_trained': 4976640, 'skipped_steps': 8, 'timestamp': 1592976007.3696687}
  0: {'training_steps': 981, 'average_loss': 1.4443359375, 'step_loss': 1.4443359375, 'learning_rate': 2.919191919191919e-05, 'seq/s': 24222.90029564007, 'global_steps': 973, 'samples_trained': 4981760, 'skipped_steps': 8, 'timestamp': 1592976007.5810394}
  0: {'training_steps': 982, 'average_loss': 1.1767578125, 'step_loss': 1.1767578125, 'learning_rate': 2.747474747474746e-05, 'seq/s': 21344.931228543086, 'global_steps': 974, 'samples_trained': 4986880, 'skipped_steps': 8, 'timestamp': 1592976007.8209095}
  0: {'training_steps': 983, 'average_loss': 1.16015625, 'step_loss': 1.16015625, 'learning_rate': 2.5757575757575735e-05, 'seq/s': 24305.421570702434, 'global_steps': 975, 'samples_trained': 4992000, 'skipped_steps': 8, 'timestamp': 1592976008.0315626}
  0: {'training_steps': 984, 'average_loss': 1.45703125, 'step_loss': 1.45703125, 'learning_rate': 2.4040404040404006e-05, 'seq/s': 24132.120833455072, 'global_steps': 976, 'samples_trained': 4997120, 'skipped_steps': 8, 'timestamp': 1592976008.2437284}
  0: :::MLLOG {"namespace": "", "time_ms": 1592976008589, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7117679715156555, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 843, "epoch_num": 1}}
  0: {'global_steps': 977, 'eval_loss': 1.3361753225326538, 'eval_mlm_accuracy': 0.7117679715156555}
  0: {'training_steps': 985, 'average_loss': 1.162109375, 'step_loss': 1.162109375, 'learning_rate': 2.2323232323232276e-05, 'seq/s': 14806.586571444133, 'global_steps': 977, 'samples_trained': 5002240, 'skipped_steps': 8, 'timestamp': 1592976008.5895207}
  0: {'training_steps': 986, 'average_loss': 1.318359375, 'step_loss': 1.318359375, 'learning_rate': 2.0606060606060547e-05, 'seq/s': 25413.07535463196, 'global_steps': 978, 'samples_trained': 5007360, 'skipped_steps': 8, 'timestamp': 1592976008.7909925}
  0: {'training_steps': 987, 'average_loss': 1.1884765625, 'step_loss': 1.1884765625, 'learning_rate': 1.888888888888882e-05, 'seq/s': 24236.760792917732, 'global_steps': 979, 'samples_trained': 5012480, 'skipped_steps': 8, 'timestamp': 1592976009.0022423}
  0: {'training_steps': 988, 'average_loss': 1.4013671875, 'step_loss': 1.4013671875, 'learning_rate': 1.7171717171717092e-05, 'seq/s': 24197.8168050751, 'global_steps': 980, 'samples_trained': 5017600, 'skipped_steps': 8, 'timestamp': 1592976009.2138324}
  0: {'training_steps': 989, 'average_loss': 1.2734375, 'step_loss': 1.2734375, 'learning_rate': 1.5454545454545363e-05, 'seq/s': 24092.620119033596, 'global_steps': 981, 'samples_trained': 5022720, 'skipped_steps': 8, 'timestamp': 1592976009.426346}
  0: {'training_steps': 990, 'average_loss': 1.0830078125, 'step_loss': 1.0830078125, 'learning_rate': 1.3737373737373825e-05, 'seq/s': 24242.232808485467, 'global_steps': 982, 'samples_trained': 5027840, 'skipped_steps': 8, 'timestamp': 1592976009.637548}
  0: {'training_steps': 991, 'average_loss': 1.341796875, 'step_loss': 1.341796875, 'learning_rate': 1.2020202020202098e-05, 'seq/s': 24160.981972788733, 'global_steps': 983, 'samples_trained': 5032960, 'skipped_steps': 8, 'timestamp': 1592976009.8494604}
  0: {'training_steps': 992, 'average_loss': 1.2578125, 'step_loss': 1.2578125, 'learning_rate': 1.0303030303030368e-05, 'seq/s': 24212.440249218093, 'global_steps': 984, 'samples_trained': 5038080, 'skipped_steps': 8, 'timestamp': 1592976010.0609224}
  0: {'training_steps': 993, 'average_loss': 1.310546875, 'step_loss': 1.310546875, 'learning_rate': 8.585858585858641e-06, 'seq/s': 24234.873520645786, 'global_steps': 985, 'samples_trained': 5043200, 'skipped_steps': 8, 'timestamp': 1592976010.272189}
  0: {'training_steps': 994, 'average_loss': 1.626953125, 'step_loss': 1.626953125, 'learning_rate': 6.868686868686913e-06, 'seq/s': 22853.593793565826, 'global_steps': 986, 'samples_trained': 5048320, 'skipped_steps': 8, 'timestamp': 1592976010.4962242}
  0: {'training_steps': 995, 'average_loss': 1.30859375, 'step_loss': 1.30859375, 'learning_rate': 5.151515151515184e-06, 'seq/s': 24274.156479355788, 'global_steps': 987, 'samples_trained': 5053440, 'skipped_steps': 8, 'timestamp': 1592976010.7071486}
  0: {'training_steps': 996, 'average_loss': 1.62109375, 'step_loss': 1.62109375, 'learning_rate': 3.4343434343434563e-06, 'seq/s': 24131.388663835678, 'global_steps': 988, 'samples_trained': 5058560, 'skipped_steps': 8, 'timestamp': 1592976010.9193208}
  0: {'training_steps': 997, 'average_loss': 1.2763671875, 'step_loss': 1.2763671875, 'learning_rate': 1.7171717171717281e-06, 'seq/s': 24131.009037819957, 'global_steps': 989, 'samples_trained': 5063680, 'skipped_steps': 8, 'timestamp': 1592976011.1314964}
  0: {'training_steps': 998, 'average_loss': 1.1650390625, 'step_loss': 1.1650390625, 'learning_rate': 0.0, 'seq/s': 23545.111000008772, 'global_steps': 990, 'samples_trained': 5068800, 'skipped_steps': 8, 'timestamp': 1592976011.3489518}
  0: (1, 998.0) {'final_loss': 0.0}
  0: :::MLLOG {"namespace": "", "time_ms": 1592976011424, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "first_epoch_num": 1}}
  0: :::MLLOG {"namespace": "", "time_ms": 1592976011425, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 956, "epoch_num": 1}}
  0: :::MLLOG {"namespace": "", "time_ms": 1592976011425, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 5068800, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 961}}
  0: :::MLLOG {"namespace": "", "time_ms": 1592976011425, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 10000, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 964}}
  0: :::MLLOG {"namespace": "", "time_ms": 1592976011425, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 966, "status": "aborted"}}
  0: {'e2e_time': 233.10850930213928, 'training_sequences_per_second': 23337.247156235466, 'final_loss': 0.0, 'raw_train_time': 218.9529881477356}
  9: ++ date +%s
  9: + END=1592976012
  9: ++ date '+%Y-%m-%d %r'
  9: + END_FMT='2020-06-23 10:20:12 PM'
  9: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:12 PM'
  9: ENDING TIMING RUN AT 2020-06-23 10:20:12 PM
  9: + RESULT=235
  9: RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM
  9: + RESULT_NAME=bert
  9: + echo 'RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM'
  9: + set +x
 93: ++ date +%s
 93: + END=1592976012
 93: ++ date '+%Y-%m-%d %r'
 93: + END_FMT='2020-06-23 10:20:12 PM'
 93: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:12 PM'
 93: ENDING TIMING RUN AT 2020-06-23 10:20:12 PM
 93: + RESULT=235
 93: + RESULT_NAME=bert
 93: RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM
 93: + echo 'RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM'
 93: + set +x
156: ++ date +%s
156: + END=1592976012
156: ++ date '+%Y-%m-%d %r'
156: + END_FMT='2020-06-23 10:20:12 PM'
156: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:12 PM'
156: ENDING TIMING RUN AT 2020-06-23 10:20:12 PM
156: + RESULT=235
156: + RESULT_NAME=bert
156: RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM
156: + echo 'RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM'
156: + set +x
205: ++ date +%s
 21: ++ date +%s
205: + END=1592976012
 21: + END=1592976012
205: ++ date '+%Y-%m-%d %r'
 21: ++ date '+%Y-%m-%d %r'
205: + END_FMT='2020-06-23 10:20:12 PM'
205: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:12 PM'
205: ENDING TIMING RUN AT 2020-06-23 10:20:12 PM
205: + RESULT=235
205: + RESULT_NAME=bert
205: RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM
205: + echo 'RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM'
205: + set +x
 21: + END_FMT='2020-06-23 10:20:12 PM'
 21: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:12 PM'
 21: ENDING TIMING RUN AT 2020-06-23 10:20:12 PM
 21: + RESULT=235
 21: + RESULT_NAME=bert
 21: RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM
 21: + echo 'RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM'
 21: + set +x
237: ++ date +%s
 38: ++ date +%s
237: + END=1592976012
 38: + END=1592976012
237: ++ date '+%Y-%m-%d %r'
 53: ++ date +%s
 38: ++ date '+%Y-%m-%d %r'
237: + END_FMT='2020-06-23 10:20:12 PM'
237: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:12 PM'
237: ENDING TIMING RUN AT 2020-06-23 10:20:12 PM
237: + RESULT=235
237: + RESULT_NAME=bert
237: RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM
237: + echo 'RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM'
237: + set +x
 38: + END_FMT='2020-06-23 10:20:12 PM'
 53: + END=1592976012
 38: ENDING TIMING RUN AT 2020-06-23 10:20:12 PM
 38: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:12 PM'
 38: + RESULT=235
 38: + RESULT_NAME=bert
 38: RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM
 38: + echo 'RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM'
 38: + set +x
 53: ++ date '+%Y-%m-%d %r'
165: ++ date +%s
 53: + END_FMT='2020-06-23 10:20:12 PM'
 53: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:12 PM'
 53: ENDING TIMING RUN AT 2020-06-23 10:20:12 PM
 53: + RESULT=235
 53: + RESULT_NAME=bert
 53: RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM
 53: + echo 'RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM'
 53: + set +x
165: + END=1592976012
107: ++ date +%s
165: ++ date '+%Y-%m-%d %r'
107: + END=1592976012
107: ++ date '+%Y-%m-%d %r'
165: + END_FMT='2020-06-23 10:20:12 PM'
165: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:12 PM'
165: ENDING TIMING RUN AT 2020-06-23 10:20:12 PM
165: + RESULT=235
165: + RESULT_NAME=bert
165: RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM
165: + echo 'RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM'
165: + set +x
107: + END_FMT='2020-06-23 10:20:12 PM'
107: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:12 PM'
107: ENDING TIMING RUN AT 2020-06-23 10:20:12 PM
107: + RESULT=235
107: + RESULT_NAME=bert
107: RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM
107: + echo 'RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM'
107: + set +x
 98: ++ date +%s
 98: + END=1592976012
 98: ++ date '+%Y-%m-%d %r'
 98: + END_FMT='2020-06-23 10:20:12 PM'
 98: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:12 PM'
 98: ENDING TIMING RUN AT 2020-06-23 10:20:12 PM
 98: + RESULT=235
 98: + RESULT_NAME=bert
 98: RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM
 98: + echo 'RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM'
 98: + set +x
  4: ++ date +%s
  4: + END=1592976012
  4: ++ date '+%Y-%m-%d %r'
  4: + END_FMT='2020-06-23 10:20:12 PM'
  4: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:12 PM'
  4: ENDING TIMING RUN AT 2020-06-23 10:20:12 PM
  4: + RESULT=235
  4: + RESULT_NAME=bert
  4: + echo 'RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM'
  4: RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM
  4: + set +x
187: ++ date +%s
187: + END=1592976012
187: ++ date '+%Y-%m-%d %r'
246: ++ date +%s
187: + END_FMT='2020-06-23 10:20:12 PM'
187: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:12 PM'
187: ENDING TIMING RUN AT 2020-06-23 10:20:12 PM
187: + RESULT=235
187: + RESULT_NAME=bert
187: RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM
187: + echo 'RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM'
187: + set +x
246: + END=1592976012
246: ++ date '+%Y-%m-%d %r'
246: + END_FMT='2020-06-23 10:20:12 PM'
246: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:12 PM'
246: ENDING TIMING RUN AT 2020-06-23 10:20:12 PM
246: + RESULT=235
246: + RESULT_NAME=bert
246: RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM
246: + echo 'RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM'
246: + set +x
125: ++ date +%s
125: + END=1592976012
125: ++ date '+%Y-%m-%d %r'
125: + END_FMT='2020-06-23 10:20:12 PM'
125: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:12 PM'
125: ENDING TIMING RUN AT 2020-06-23 10:20:12 PM
125: + RESULT=235
125: + RESULT_NAME=bert
125: RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM
125: + echo 'RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM'
125: + set +x
221: ++ date +%s
221: + END=1592976012
221: ++ date '+%Y-%m-%d %r'
221: + END_FMT='2020-06-23 10:20:12 PM'
221: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:12 PM'
221: ENDING TIMING RUN AT 2020-06-23 10:20:12 PM
221: + RESULT=235
221: + RESULT_NAME=bert
221: RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM
221: + echo 'RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM'
221: + set +x
134: ++ date +%s
134: + END=1592976012
134: ++ date '+%Y-%m-%d %r'
134: + END_FMT='2020-06-23 10:20:12 PM'
134: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:12 PM'
134: ENDING TIMING RUN AT 2020-06-23 10:20:12 PM
134: + RESULT=235
134: + RESULT_NAME=bert
134: RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM
134: + echo 'RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM'
134: + set +x
169: ++ date +%s
169: + END=1592976012
169: ++ date '+%Y-%m-%d %r'
169: + END_FMT='2020-06-23 10:20:12 PM'
169: ENDING TIMING RUN AT 2020-06-23 10:20:12 PM
169: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:12 PM'
169: + RESULT=235
169: + RESULT_NAME=bert
169: RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM
169: + echo 'RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM'
169: + set +x
 60: ++ date +%s
 60: + END=1592976012
 60: ++ date '+%Y-%m-%d %r'
 60: + END_FMT='2020-06-23 10:20:12 PM'
 60: ENDING TIMING RUN AT 2020-06-23 10:20:12 PM
 60: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:12 PM'
 60: + RESULT=235
 60: + RESULT_NAME=bert
 60: RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM
 60: + echo 'RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM'
 60: + set +x
 25: ++ date +%s
 25: + END=1592976012
 25: ++ date '+%Y-%m-%d %r'
 25: + END_FMT='2020-06-23 10:20:12 PM'
 25: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:12 PM'
 25: ENDING TIMING RUN AT 2020-06-23 10:20:12 PM
 25: + RESULT=235
 25: + RESULT_NAME=bert
 25: RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM
 25: + echo 'RESULT,bert,28019,235,root,2020-06-23 10:16:17 PM'
 25: + set +x
 81: ++ date +%s
 81: + END=1592976013
 81: ++ date '+%Y-%m-%d %r'
 81: + END_FMT='2020-06-23 10:20:13 PM'
 81: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:13 PM'
 81: ENDING TIMING RUN AT 2020-06-23 10:20:13 PM
 81: + RESULT=236
 81: + RESULT_NAME=bert
 81: RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM
 81: + echo 'RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM'
 81: + set +x
181: ++ date +%s
181: + END=1592976013
181: ++ date '+%Y-%m-%d %r'
181: + END_FMT='2020-06-23 10:20:13 PM'
181: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:13 PM'
181: ENDING TIMING RUN AT 2020-06-23 10:20:13 PM
181: + RESULT=236
181: + RESULT_NAME=bert
181: RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM
181: + echo 'RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM'
181: + set +x
227: ++ date +%s
227: + END=1592976013
227: ++ date '+%Y-%m-%d %r'
227: + END_FMT='2020-06-23 10:20:13 PM'
227: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:13 PM'
227: ENDING TIMING RUN AT 2020-06-23 10:20:13 PM
227: + RESULT=236
227: + RESULT_NAME=bert
227: RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM
227: + echo 'RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM'
227: + set +x
 67: ++ date +%s
 67: + END=1592976013
 67: ++ date '+%Y-%m-%d %r'
 67: + END_FMT='2020-06-23 10:20:13 PM'
 67: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:13 PM'
 67: ENDING TIMING RUN AT 2020-06-23 10:20:13 PM
 67: + RESULT=236
 67: RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM
 67: + RESULT_NAME=bert
 67: + echo 'RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM'
 67: + set +x
253: ++ date +%s
253: + END=1592976013
253: ++ date '+%Y-%m-%d %r'
219: ++ date +%s
253: + END_FMT='2020-06-23 10:20:13 PM'
253: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:13 PM'
253: ENDING TIMING RUN AT 2020-06-23 10:20:13 PM
253: + RESULT=236
253: + RESULT_NAME=bert
253: RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM
253: + echo 'RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM'
253: + set +x
219: + END=1592976013
219: ++ date '+%Y-%m-%d %r'
219: + END_FMT='2020-06-23 10:20:13 PM'
219: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:13 PM'
219: ENDING TIMING RUN AT 2020-06-23 10:20:13 PM
219: + RESULT=236
219: + RESULT_NAME=bert
219: RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM
219: + echo 'RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM'
219: + set +x
252: ++ date +%s
252: + END=1592976013
252: ++ date '+%Y-%m-%d %r'
252: + END_FMT='2020-06-23 10:20:13 PM'
252: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:13 PM'
252: ENDING TIMING RUN AT 2020-06-23 10:20:13 PM
252: + RESULT=236
252: + RESULT_NAME=bert
252: RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM
252: + echo 'RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM'
252: + set +x
 75: ++ date +%s
 75: + END=1592976013
 75: ++ date '+%Y-%m-%d %r'
 75: + END_FMT='2020-06-23 10:20:13 PM'
 75: ENDING TIMING RUN AT 2020-06-23 10:20:13 PM
 75: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:13 PM'
 75: + RESULT=236
 75: + RESULT_NAME=bert
 75: RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM
 75: + echo 'RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM'
 75: + set +x
188: ++ date +%s
188: + END=1592976013
188: ++ date '+%Y-%m-%d %r'
188: + END_FMT='2020-06-23 10:20:13 PM'
188: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:13 PM'
188: ENDING TIMING RUN AT 2020-06-23 10:20:13 PM
188: + RESULT=236
188: + RESULT_NAME=bert
188: + echo 'RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM'
188: RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM
188: + set +x
  2: ++ date +%s
133: ++ date +%s
  2: + END=1592976013
115: ++ date +%s
  2: ++ date '+%Y-%m-%d %r'
133: + END=1592976013
115: + END=1592976013
133: ++ date '+%Y-%m-%d %r'
  2: + END_FMT='2020-06-23 10:20:13 PM'
  2: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:13 PM'
  2: ENDING TIMING RUN AT 2020-06-23 10:20:13 PM
  2: + RESULT=236
  2: + RESULT_NAME=bert
  2: RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM
  2: + echo 'RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM'
  2: + set +x
115: ++ date '+%Y-%m-%d %r'
133: + END_FMT='2020-06-23 10:20:13 PM'
133: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:13 PM'
133: ENDING TIMING RUN AT 2020-06-23 10:20:13 PM
133: + RESULT=236
133: + RESULT_NAME=bert
133: RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM
133: + echo 'RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM'
133: + set +x
115: + END_FMT='2020-06-23 10:20:13 PM'
115: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:13 PM'
115: ENDING TIMING RUN AT 2020-06-23 10:20:13 PM
115: + RESULT=236
115: + RESULT_NAME=bert
115: RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM
115: + echo 'RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM'
115: + set +x
117: ++ date +%s
117: + END=1592976013
117: ++ date '+%Y-%m-%d %r'
117: + END_FMT='2020-06-23 10:20:13 PM'
117: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:13 PM'
117: ENDING TIMING RUN AT 2020-06-23 10:20:13 PM
117: + RESULT=236
117: + RESULT_NAME=bert
117: RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM
117: + echo 'RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM'
117: + set +x
245: ++ date +%s
245: + END=1592976013
245: ++ date '+%Y-%m-%d %r'
245: + END_FMT='2020-06-23 10:20:13 PM'
245: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:13 PM'
245: ENDING TIMING RUN AT 2020-06-23 10:20:13 PM
245: + RESULT=236
245: + RESULT_NAME=bert
245: RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM
245: + echo 'RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM'
245: + set +x
 42: ++ date +%s
 42: + END=1592976013
 42: ++ date '+%Y-%m-%d %r'
 42: + END_FMT='2020-06-23 10:20:13 PM'
 42: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:13 PM'
 42: ENDING TIMING RUN AT 2020-06-23 10:20:13 PM
 42: + RESULT=236
 42: + RESULT_NAME=bert
 42: RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM
 42: + echo 'RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM'
 42: + set +x
197: ++ date +%s
197: + END=1592976013
197: ++ date '+%Y-%m-%d %r'
197: + END_FMT='2020-06-23 10:20:13 PM'
197: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:13 PM'
197: ENDING TIMING RUN AT 2020-06-23 10:20:13 PM
197: + RESULT=236
197: + RESULT_NAME=bert
197: + echo 'RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM'
197: RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM
197: + set +x
137: ++ date +%s
137: + END=1592976013
137: ++ date '+%Y-%m-%d %r'
137: + END_FMT='2020-06-23 10:20:13 PM'
137: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:13 PM'
137: ENDING TIMING RUN AT 2020-06-23 10:20:13 PM
137: + RESULT=236
137: + RESULT_NAME=bert
137: + echo 'RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM'
137: RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM
137: + set +x
146: ++ date +%s
139: ++ date +%s
146: + END=1592976013
139: + END=1592976013
146: ++ date '+%Y-%m-%d %r'
139: ++ date '+%Y-%m-%d %r'
146: + END_FMT='2020-06-23 10:20:13 PM'
146: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:13 PM'
146: ENDING TIMING RUN AT 2020-06-23 10:20:13 PM
146: + RESULT=236
146: + RESULT_NAME=bert
146: RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM
146: + echo 'RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM'
146: + set +x
139: + END_FMT='2020-06-23 10:20:13 PM'
139: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:13 PM'
139: ENDING TIMING RUN AT 2020-06-23 10:20:13 PM
139: + RESULT=236
139: + RESULT_NAME=bert
139: RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM
139: + echo 'RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM'
139: + set +x
127: ++ date +%s
172: ++ date +%s
127: + END=1592976013
172: + END=1592976013
127: ++ date '+%Y-%m-%d %r'
172: ++ date '+%Y-%m-%d %r'
127: + END_FMT='2020-06-23 10:20:13 PM'
127: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:13 PM'
127: ENDING TIMING RUN AT 2020-06-23 10:20:13 PM
127: + RESULT=236
127: + RESULT_NAME=bert
127: RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM
127: + echo 'RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM'
127: + set +x
172: + END_FMT='2020-06-23 10:20:13 PM'
172: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:13 PM'
172: ENDING TIMING RUN AT 2020-06-23 10:20:13 PM
172: + RESULT=236
172: + RESULT_NAME=bert
172: RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM
172: + echo 'RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM'
172: + set +x
196: ++ date +%s
196: + END=1592976013
196: ++ date '+%Y-%m-%d %r'
196: + END_FMT='2020-06-23 10:20:13 PM'
196: ENDING TIMING RUN AT 2020-06-23 10:20:13 PM
196: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:13 PM'
196: + RESULT=236
196: + RESULT_NAME=bert
196: RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM
196: + echo 'RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM'
196: + set +x
211: ++ date +%s
211: + END=1592976013
211: ++ date '+%Y-%m-%d %r'
211: + END_FMT='2020-06-23 10:20:13 PM'
211: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:13 PM'
211: ENDING TIMING RUN AT 2020-06-23 10:20:13 PM
211: + RESULT=236
211: + RESULT_NAME=bert
211: RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM
211: + echo 'RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM'
211: + set +x
 61: ++ date +%s
 61: + END=1592976013
 61: ++ date '+%Y-%m-%d %r'
 61: + END_FMT='2020-06-23 10:20:13 PM'
 61: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:13 PM'
 61: ENDING TIMING RUN AT 2020-06-23 10:20:13 PM
 61: + RESULT=236
 61: + RESULT_NAME=bert
 61: RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM
 61: + echo 'RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM'
 61: + set +x
 63: ++ date +%s
 63: + END=1592976013
 63: ++ date '+%Y-%m-%d %r'
 63: + END_FMT='2020-06-23 10:20:13 PM'
 63: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:13 PM'
 63: ENDING TIMING RUN AT 2020-06-23 10:20:13 PM
 63: + RESULT=236
 63: + RESULT_NAME=bert
 63: + echo 'RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM'
 63: RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM
 63: + set +x
182: ++ date +%s
182: + END=1592976013
182: ++ date '+%Y-%m-%d %r'
182: + END_FMT='2020-06-23 10:20:13 PM'
182: ENDING TIMING RUN AT 2020-06-23 10:20:13 PM
182: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:13 PM'
182: + RESULT=236
182: + RESULT_NAME=bert
182: RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM
182: + echo 'RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM'
182: + set +x
179: ++ date +%s
179: + END=1592976013
179: ++ date '+%Y-%m-%d %r'
179: + END_FMT='2020-06-23 10:20:13 PM'
179: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:13 PM'
179: ENDING TIMING RUN AT 2020-06-23 10:20:13 PM
179: + RESULT=236
179: + RESULT_NAME=bert
179: RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM
179: + echo 'RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM'
179: + set +x
123: ++ date +%s
123: + END=1592976013
123: ++ date '+%Y-%m-%d %r'
123: + END_FMT='2020-06-23 10:20:13 PM'
123: ENDING TIMING RUN AT 2020-06-23 10:20:13 PM
123: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:13 PM'
123: + RESULT=236
123: + RESULT_NAME=bert
123: RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM
123: + echo 'RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM'
123: + set +x
  3: ++ date +%s
  3: + END=1592976013
  3: ++ date '+%Y-%m-%d %r'
  3: + END_FMT='2020-06-23 10:20:13 PM'
  3: ENDING TIMING RUN AT 2020-06-23 10:20:13 PM
  3: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:13 PM'
  3: + RESULT=236
  3: + RESULT_NAME=bert
  3: RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM
  3: + echo 'RESULT,bert,28019,236,root,2020-06-23 10:16:17 PM'
  3: + set +x
195: ++ date +%s
195: + END=1592976014
195: ++ date '+%Y-%m-%d %r'
195: + END_FMT='2020-06-23 10:20:14 PM'
195: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
195: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
195: + RESULT=237
195: + RESULT_NAME=bert
195: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
195: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
195: + set +x
  5: ++ date +%s
  6: ++ date +%s
  1: ++ date +%s
  0: ++ date +%s
  5: + END=1592976014
  5: ++ date '+%Y-%m-%d %r'
  6: + END=1592976014
  1: + END=1592976014
  6: ++ date '+%Y-%m-%d %r'
  0: + END=1592976014
  5: + END_FMT='2020-06-23 10:20:14 PM'
  1: ++ date '+%Y-%m-%d %r'
  5: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
  5: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
  5: + RESULT=237
  5: + RESULT_NAME=bert
  5: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
  5: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
  5: + set +x
  0: ++ date '+%Y-%m-%d %r'
  6: + END_FMT='2020-06-23 10:20:14 PM'
  6: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
  6: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
  6: + RESULT=237
  6: + RESULT_NAME=bert
  6: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
  6: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
  6: + set +x
  1: + END_FMT='2020-06-23 10:20:14 PM'
  1: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
  1: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
  1: + RESULT=237
  1: + RESULT_NAME=bert
  1: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
  1: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
  1: + set +x
  0: + END_FMT='2020-06-23 10:20:14 PM'
  0: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
  0: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
  0: + RESULT=237
  0: + RESULT_NAME=bert
  0: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
  0: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
  0: + set +x
 59: ++ date +%s
 58: ++ date +%s
 56: ++ date +%s
 62: ++ date +%s
 59: + END=1592976014
 58: + END=1592976014
 56: + END=1592976014
 59: ++ date '+%Y-%m-%d %r'
 62: + END=1592976014
 58: ++ date '+%Y-%m-%d %r'
 56: ++ date '+%Y-%m-%d %r'
 62: ++ date '+%Y-%m-%d %r'
 59: + END_FMT='2020-06-23 10:20:14 PM'
 59: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 59: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 59: + RESULT=237
 59: + RESULT_NAME=bert
 59: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 59: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 59: + set +x
 56: + END_FMT='2020-06-23 10:20:14 PM'
 56: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 56: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 58: + END_FMT='2020-06-23 10:20:14 PM'
 56: + RESULT=237
 56: + RESULT_NAME=bert
 58: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 56: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 58: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 56: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 56: + set +x
 58: + RESULT=237
 58: + RESULT_NAME=bert
 58: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 58: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 58: + set +x
 62: + END_FMT='2020-06-23 10:20:14 PM'
 62: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 62: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 62: + RESULT=237
 62: + RESULT_NAME=bert
 62: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 62: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 62: + set +x
185: ++ date +%s
189: ++ date +%s
186: ++ date +%s
190: ++ date +%s
191: ++ date +%s
185: + END=1592976014
185: ++ date '+%Y-%m-%d %r'
189: + END=1592976014
190: + END=1592976014
186: + END=1592976014
191: + END=1592976014
190: ++ date '+%Y-%m-%d %r'
189: ++ date '+%Y-%m-%d %r'
186: ++ date '+%Y-%m-%d %r'
191: ++ date '+%Y-%m-%d %r'
185: + END_FMT='2020-06-23 10:20:14 PM'
185: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
185: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
185: + RESULT=237
185: + RESULT_NAME=bert
185: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
185: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
185: + set +x
190: + END_FMT='2020-06-23 10:20:14 PM'
190: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
190: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
190: + RESULT=237
190: + RESULT_NAME=bert
190: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
190: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
190: + set +x
189: + END_FMT='2020-06-23 10:20:14 PM'
184: slurmstepd: error: _is_a_lwp: open() /proc/144450/status failed: No such file or directory
189: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
189: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
189: + RESULT=237
189: + RESULT_NAME=bert
186: + END_FMT='2020-06-23 10:20:14 PM'
189: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
189: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
189: + set +x
186: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
186: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
186: + RESULT=237
186: + RESULT_NAME=bert
186: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
186: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
186: + set +x
191: + END_FMT='2020-06-23 10:20:14 PM'
191: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
191: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
191: + RESULT=237
191: + RESULT_NAME=bert
191: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
191: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
191: + set +x
 12: ++ date +%s
 10: ++ date +%s
 13: ++ date +%s
 11: ++ date +%s
 14: ++ date +%s
 15: ++ date +%s
 12: + END=1592976014
 13: + END=1592976014
 14: + END=1592976014
 10: + END=1592976014
 11: + END=1592976014
 13: ++ date '+%Y-%m-%d %r'
 12: ++ date '+%Y-%m-%d %r'
 14: ++ date '+%Y-%m-%d %r'
 11: ++ date '+%Y-%m-%d %r'
 10: ++ date '+%Y-%m-%d %r'
 15: + END=1592976014
 11: + END_FMT='2020-06-23 10:20:14 PM'
 11: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 11: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 15: ++ date '+%Y-%m-%d %r'
 11: + RESULT=237
 11: + RESULT_NAME=bert
 11: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 11: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 11: + set +x
 13: + END_FMT='2020-06-23 10:20:14 PM'
 14: + END_FMT='2020-06-23 10:20:14 PM'
 13: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 13: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 14: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 14: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 12: + END_FMT='2020-06-23 10:20:14 PM'
 13: + RESULT=237
 13: + RESULT_NAME=bert
 14: + RESULT=237
 14: + RESULT_NAME=bert
 10: + END_FMT='2020-06-23 10:20:14 PM'
 13: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 13: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 13: + set +x
 14: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 14: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 14: + set +x
 12: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 12: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 10: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 10: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 12: + RESULT=237
 10: + RESULT=237
 12: + RESULT_NAME=bert
 10: + RESULT_NAME=bert
 12: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 12: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 10: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 10: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 10: + set +x
 12: + set +x
 15: + END_FMT='2020-06-23 10:20:14 PM'
 15: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 15: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 15: + RESULT=237
 15: + RESULT_NAME=bert
 15: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 15: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 15: + set +x
220: ++ date +%s
217: ++ date +%s
222: ++ date +%s
216: ++ date +%s
223: ++ date +%s
217: + END=1592976014
220: + END=1592976014
222: + END=1592976014
216: + END=1592976014
217: ++ date '+%Y-%m-%d %r'
220: ++ date '+%Y-%m-%d %r'
223: + END=1592976014
216: ++ date '+%Y-%m-%d %r'
222: ++ date '+%Y-%m-%d %r'
223: ++ date '+%Y-%m-%d %r'
217: + END_FMT='2020-06-23 10:20:14 PM'
217: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
217: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
220: + END_FMT='2020-06-23 10:20:14 PM'
217: + RESULT=237
217: + RESULT_NAME=bert
217: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
217: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
217: + set +x
220: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
220: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
220: + RESULT=237
220: + RESULT_NAME=bert
220: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
220: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
220: + set +x
216: + END_FMT='2020-06-23 10:20:14 PM'
216: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
216: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
216: + RESULT=237
216: + RESULT_NAME=bert
216: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
216: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
216: + set +x
223: + END_FMT='2020-06-23 10:20:14 PM'
223: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
223: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
223: + RESULT=237
223: + RESULT_NAME=bert
223: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
223: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
223: + set +x
222: + END_FMT='2020-06-23 10:20:14 PM'
222: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
222: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
222: + RESULT=237
222: + RESULT_NAME=bert
222: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
222: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
222: + set +x
171: ++ date +%s
171: + END=1592976014
171: ++ date '+%Y-%m-%d %r'
171: + END_FMT='2020-06-23 10:20:14 PM'
171: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
171: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
171: + RESULT=237
171: + RESULT_NAME=bert
171: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
171: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
171: + set +x
168: ++ date +%s
168: + END=1592976014
126: ++ date +%s
168: ++ date '+%Y-%m-%d %r'
170: ++ date +%s
173: ++ date +%s
174: ++ date +%s
126: + END=1592976014
168: + END_FMT='2020-06-23 10:20:14 PM'
168: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
168: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
168: + RESULT=237
168: + RESULT_NAME=bert
168: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
168: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
168: + set +x
126: ++ date '+%Y-%m-%d %r'
170: + END=1592976014
173: + END=1592976014
174: + END=1592976014
180: ++ date +%s
177: ++ date +%s
183: ++ date +%s
178: ++ date +%s
173: ++ date '+%Y-%m-%d %r'
170: ++ date '+%Y-%m-%d %r'
174: ++ date '+%Y-%m-%d %r'
126: + END_FMT='2020-06-23 10:20:14 PM'
126: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
126: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
126: + RESULT=237
126: + RESULT_NAME=bert
126: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
126: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
126: + set +x
183: + END=1592976014
180: + END=1592976014
174: + END_FMT='2020-06-23 10:20:14 PM'
174: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
174: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
174: + RESULT=237
174: + RESULT_NAME=bert
174: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
174: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
174: + set +x
178: + END=1592976014
177: + END=1592976014
183: ++ date '+%Y-%m-%d %r'
180: ++ date '+%Y-%m-%d %r'
170: + END_FMT='2020-06-23 10:20:14 PM'
173: + END_FMT='2020-06-23 10:20:14 PM'
170: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
170: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
178: ++ date '+%Y-%m-%d %r'
173: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
173: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
170: + RESULT=237
170: + RESULT_NAME=bert
173: + RESULT=237
170: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
173: + RESULT_NAME=bert
170: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
170: + set +x
173: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
173: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
173: + set +x
122: ++ date +%s
 94: ++ date +%s
177: ++ date '+%Y-%m-%d %r'
 91: ++ date +%s
 92: ++ date +%s
 88: ++ date +%s
 89: ++ date +%s
 95: ++ date +%s
122: + END=1592976014
178: + END_FMT='2020-06-23 10:20:14 PM'
180: + END_FMT='2020-06-23 10:20:14 PM'
183: + END_FMT='2020-06-23 10:20:14 PM'
178: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
180: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
183: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
178: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
180: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
183: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
178: + RESULT=237
180: + RESULT=237
180: + RESULT_NAME=bert
183: + RESULT=237
183: + RESULT_NAME=bert
178: + RESULT_NAME=bert
178: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
178: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
180: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
180: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
180: + set +x
183: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
183: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
183: + set +x
178: + set +x
124: ++ date +%s
122: ++ date '+%Y-%m-%d %r'
 94: + END=1592976014
177: + END_FMT='2020-06-23 10:20:14 PM'
177: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
177: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
177: + RESULT=237
177: + RESULT_NAME=bert
120: ++ date +%s
177: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
177: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
177: + set +x
 88: + END=1592976014
124: + END=1592976014
 94: ++ date '+%Y-%m-%d %r'
 91: + END=1592976014
122: + END_FMT='2020-06-23 10:20:14 PM'
122: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
122: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 89: + END=1592976014
122: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
122: + RESULT=237
122: + RESULT_NAME=bert
122: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
122: + set +x
 92: + END=1592976014
120: + END=1592976014
 95: + END=1592976014
 88: ++ date '+%Y-%m-%d %r'
124: ++ date '+%Y-%m-%d %r'
 91: ++ date '+%Y-%m-%d %r'
251: ++ date +%s
120: ++ date '+%Y-%m-%d %r'
 92: ++ date '+%Y-%m-%d %r'
 89: ++ date '+%Y-%m-%d %r'
 95: ++ date '+%Y-%m-%d %r'
249: ++ date +%s
248: ++ date +%s
254: ++ date +%s
 94: + END_FMT='2020-06-23 10:20:14 PM'
124: + END_FMT='2020-06-23 10:20:14 PM'
124: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
250: ++ date +%s
124: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 94: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
124: + RESULT=237
124: + RESULT_NAME=bert
 94: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 94: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 94: + RESULT=237
 94: + RESULT_NAME=bert
 94: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 94: + set +x
124: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
124: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
124: + set +x
251: + END=1592976014
120: + END_FMT='2020-06-23 10:20:14 PM'
120: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
120: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 88: + END_FMT='2020-06-23 10:20:14 PM'
120: + RESULT=237
120: + RESULT_NAME=bert
 88: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 88: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
120: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 88: + RESULT=237
 88: + RESULT_NAME=bert
120: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
120: + set +x
 88: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 88: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 88: + set +x
 91: + END_FMT='2020-06-23 10:20:14 PM'
 91: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 91: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 91: + RESULT=237
 91: + RESULT_NAME=bert
 91: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 91: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 91: + set +x
 89: + END_FMT='2020-06-23 10:20:14 PM'
 89: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 89: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
251: ++ date '+%Y-%m-%d %r'
 89: + RESULT=237
 89: + RESULT_NAME=bert
 92: + END_FMT='2020-06-23 10:20:14 PM'
 89: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 89: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 89: + set +x
 92: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 92: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 92: + RESULT=237
 92: + RESULT_NAME=bert
 92: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 92: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 92: + set +x
248: + END=1592976014
 95: + END_FMT='2020-06-23 10:20:14 PM'
 95: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 95: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
249: + END=1592976014
254: + END=1592976014
250: + END=1592976014
 95: + RESULT=237
 95: + RESULT_NAME=bert
 95: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 95: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 95: + set +x
248: ++ date '+%Y-%m-%d %r'
249: ++ date '+%Y-%m-%d %r'
250: ++ date '+%Y-%m-%d %r'
251: + END_FMT='2020-06-23 10:20:14 PM'
251: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
251: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
251: + RESULT=237
251: + RESULT_NAME=bert
251: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
251: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
251: + set +x
254: ++ date '+%Y-%m-%d %r'
248: + END_FMT='2020-06-23 10:20:14 PM'
248: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
248: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
248: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
248: + RESULT=237
248: + RESULT_NAME=bert
248: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
248: + set +x
249: + END_FMT='2020-06-23 10:20:14 PM'
250: + END_FMT='2020-06-23 10:20:14 PM'
249: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
249: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
250: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
250: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
250: + RESULT=237
249: + RESULT=237
249: + RESULT_NAME=bert
250: + RESULT_NAME=bert
249: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
250: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
249: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
250: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
254: + END_FMT='2020-06-23 10:20:14 PM'
249: + set +x
250: + set +x
254: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
254: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
254: + RESULT=237
254: + RESULT_NAME=bert
254: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
254: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
254: + set +x
203: ++ date +%s
201: ++ date +%s
206: ++ date +%s
200: ++ date +%s
202: ++ date +%s
204: ++ date +%s
131: ++ date +%s
128: ++ date +%s
135: ++ date +%s
130: ++ date +%s
132: ++ date +%s
201: + END=1592976014
203: + END=1592976014
202: + END=1592976014
201: ++ date '+%Y-%m-%d %r'
135: + END=1592976014
128: + END=1592976014
200: + END=1592976014
130: + END=1592976014
206: + END=1592976014
202: ++ date '+%Y-%m-%d %r'
203: ++ date '+%Y-%m-%d %r'
204: + END=1592976014
135: ++ date '+%Y-%m-%d %r'
131: + END=1592976014
132: + END=1592976014
128: ++ date '+%Y-%m-%d %r'
130: ++ date '+%Y-%m-%d %r'
200: ++ date '+%Y-%m-%d %r'
206: ++ date '+%Y-%m-%d %r'
204: ++ date '+%Y-%m-%d %r'
131: ++ date '+%Y-%m-%d %r'
201: + END_FMT='2020-06-23 10:20:14 PM'
132: ++ date '+%Y-%m-%d %r'
202: + END_FMT='2020-06-23 10:20:14 PM'
135: + END_FMT='2020-06-23 10:20:14 PM'
135: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
203: + END_FMT='2020-06-23 10:20:14 PM'
135: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
201: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
201: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
128: + END_FMT='2020-06-23 10:20:14 PM'
135: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
202: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
135: + RESULT=237
135: + RESULT_NAME=bert
135: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
135: + set +x
128: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
202: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
203: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
128: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
128: + RESULT=237
128: + RESULT_NAME=bert
128: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
203: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
201: + RESULT=237
201: + RESULT_NAME=bert
128: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
128: + set +x
201: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
202: + RESULT=237
202: + RESULT_NAME=bert
130: + END_FMT='2020-06-23 10:20:14 PM'
202: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
203: + RESULT=237
201: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
201: + set +x
202: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
202: + set +x
203: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
203: + RESULT_NAME=bert
203: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
203: + set +x
130: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
130: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
130: + RESULT=237
130: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
130: + RESULT_NAME=bert
130: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
130: + set +x
200: + END_FMT='2020-06-23 10:20:14 PM'
200: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
200: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
200: + RESULT=237
200: + RESULT_NAME=bert
200: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
200: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
200: + set +x
204: + END_FMT='2020-06-23 10:20:14 PM'
206: + END_FMT='2020-06-23 10:20:14 PM'
204: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
204: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
206: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
206: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
204: + RESULT=237
204: + RESULT_NAME=bert
206: + RESULT=237
206: + RESULT_NAME=bert
204: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
204: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
204: + set +x
206: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
206: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
206: + set +x
132: + END_FMT='2020-06-23 10:20:14 PM'
132: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
132: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
132: + RESULT=237
132: + RESULT_NAME=bert
131: + END_FMT='2020-06-23 10:20:14 PM'
132: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
132: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
132: + set +x
131: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
131: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
131: + RESULT=237
131: + RESULT_NAME=bert
131: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
131: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
131: + set +x
243: ++ date +%s
241: ++ date +%s
240: ++ date +%s
244: ++ date +%s
242: ++ date +%s
193: ++ date +%s
194: ++ date +%s
192: ++ date +%s
198: ++ date +%s
241: + END=1592976014
243: + END=1592976014
193: + END=1592976014
194: + END=1592976014
241: ++ date '+%Y-%m-%d %r'
240: + END=1592976014
244: + END=1592976014
243: ++ date '+%Y-%m-%d %r'
193: ++ date '+%Y-%m-%d %r'
242: + END=1592976014
194: ++ date '+%Y-%m-%d %r'
240: ++ date '+%Y-%m-%d %r'
198: + END=1592976014
192: + END=1592976014
244: ++ date '+%Y-%m-%d %r'
242: ++ date '+%Y-%m-%d %r'
241: + END_FMT='2020-06-23 10:20:14 PM'
241: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
241: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
241: + RESULT=237
241: + RESULT_NAME=bert
241: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
241: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
241: + set +x
192: ++ date '+%Y-%m-%d %r'
198: ++ date '+%Y-%m-%d %r'
193: + END_FMT='2020-06-23 10:20:14 PM'
243: + END_FMT='2020-06-23 10:20:14 PM'
193: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
243: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
240: + END_FMT='2020-06-23 10:20:14 PM'
243: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
193: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
193: + RESULT=237
193: + RESULT_NAME=bert
193: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
243: + RESULT=237
243: + RESULT_NAME=bert
240: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
193: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
193: + set +x
240: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
243: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
240: + RESULT=237
243: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
240: + RESULT_NAME=bert
194: + END_FMT='2020-06-23 10:20:14 PM'
243: + set +x
240: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
240: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
240: + set +x
194: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
244: + END_FMT='2020-06-23 10:20:14 PM'
244: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
244: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
194: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
194: + RESULT=237
194: + RESULT_NAME=bert
194: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
244: + RESULT=237
194: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
194: + set +x
244: + RESULT_NAME=bert
244: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
244: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
244: + set +x
192: + END_FMT='2020-06-23 10:20:14 PM'
242: + END_FMT='2020-06-23 10:20:14 PM'
198: + END_FMT='2020-06-23 10:20:14 PM'
192: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
242: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
198: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
192: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
198: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
242: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
192: + RESULT=237
242: + RESULT=237
198: + RESULT=237
242: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
242: + RESULT_NAME=bert
198: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
198: + RESULT_NAME=bert
192: + RESULT_NAME=bert
198: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
192: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
192: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
198: + set +x
242: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
242: + set +x
192: + set +x
 16: ++ date +%s
 17: ++ date +%s
 18: ++ date +%s
 20: ++ date +%s
 19: ++ date +%s
 22: ++ date +%s
 16: + END=1592976014
 18: + END=1592976014
 16: ++ date '+%Y-%m-%d %r'
 17: + END=1592976014
 20: + END=1592976014
 19: + END=1592976014
 22: + END=1592976014
 18: ++ date '+%Y-%m-%d %r'
 17: ++ date '+%Y-%m-%d %r'
 20: ++ date '+%Y-%m-%d %r'
113: ++ date +%s
 19: ++ date '+%Y-%m-%d %r'
 22: ++ date '+%Y-%m-%d %r'
 16: + END_FMT='2020-06-23 10:20:14 PM'
 16: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 16: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 16: + RESULT=237
 16: + RESULT_NAME=bert
 16: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 16: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 16: + set +x
 18: + END_FMT='2020-06-23 10:20:14 PM'
 18: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 18: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
114: ++ date +%s
 18: + RESULT=237
 18: + RESULT_NAME=bert
 18: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 18: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 18: + set +x
113: + END=1592976014
112: ++ date +%s
 20: + END_FMT='2020-06-23 10:20:14 PM'
116: ++ date +%s
 17: + END_FMT='2020-06-23 10:20:14 PM'
 17: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
118: ++ date +%s
 17: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 20: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 20: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 20: + RESULT=237
 17: + RESULT=237
 20: + RESULT_NAME=bert
 17: + RESULT_NAME=bert
 20: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 20: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 17: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 17: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 17: + set +x
 20: + set +x
113: ++ date '+%Y-%m-%d %r'
 22: + END_FMT='2020-06-23 10:20:14 PM'
 22: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 22: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 22: + RESULT=237
 22: + RESULT_NAME=bert
 22: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 22: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 22: + set +x
 19: + END_FMT='2020-06-23 10:20:14 PM'
 19: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
114: + END=1592976014
 19: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 19: + RESULT=237
 19: + RESULT_NAME=bert
 19: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 19: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 19: + set +x
114: ++ date '+%Y-%m-%d %r'
112: + END=1592976014
116: + END=1592976014
 32: ++ date +%s
113: + END_FMT='2020-06-23 10:20:14 PM'
113: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
113: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
113: + RESULT=237
113: + RESULT_NAME=bert
113: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 35: ++ date +%s
113: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
113: + set +x
118: + END=1592976014
 34: ++ date +%s
 33: ++ date +%s
116: ++ date '+%Y-%m-%d %r'
 37: ++ date +%s
112: ++ date '+%Y-%m-%d %r'
 39: ++ date +%s
118: ++ date '+%Y-%m-%d %r'
114: + END_FMT='2020-06-23 10:20:14 PM'
114: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
114: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
114: + RESULT=237
114: + RESULT_NAME=bert
114: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
114: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
114: + set +x
 32: + END=1592976014
 35: + END=1592976014
116: + END_FMT='2020-06-23 10:20:14 PM'
116: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
116: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
116: + RESULT=237
116: + RESULT_NAME=bert
116: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
116: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
116: + set +x
112: + END_FMT='2020-06-23 10:20:14 PM'
118: + END_FMT='2020-06-23 10:20:14 PM'
 32: ++ date '+%Y-%m-%d %r'
112: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 35: ++ date '+%Y-%m-%d %r'
 34: + END=1592976014
112: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
118: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
118: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 39: + END=1592976014
112: + RESULT=237
118: + RESULT=237
112: + RESULT_NAME=bert
118: + RESULT_NAME=bert
112: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 33: + END=1592976014
118: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
112: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 37: + END=1592976014
118: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
118: + set +x
112: + set +x
 37: ++ date '+%Y-%m-%d %r'
 33: ++ date '+%Y-%m-%d %r'
 34: ++ date '+%Y-%m-%d %r'
 39: ++ date '+%Y-%m-%d %r'
 32: + END_FMT='2020-06-23 10:20:14 PM'
 35: + END_FMT='2020-06-23 10:20:14 PM'
 32: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 35: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 32: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 35: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 32: + RESULT=237
 32: + RESULT_NAME=bert
 35: + RESULT=237
 35: + RESULT_NAME=bert
 32: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 32: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 32: + set +x
 35: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 35: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 35: + set +x
 37: + END_FMT='2020-06-23 10:20:14 PM'
 37: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 37: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 37: + RESULT=237
 37: + RESULT_NAME=bert
 37: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 37: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 37: + set +x
 32: slurmstepd: error: _is_a_lwp: open() /proc/169220/status failed: No such file or directory
 33: + END_FMT='2020-06-23 10:20:14 PM'
 34: + END_FMT='2020-06-23 10:20:14 PM'
 33: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 34: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 33: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 34: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 34: + RESULT=237
 34: + RESULT_NAME=bert
 33: + RESULT=237
 33: + RESULT_NAME=bert
 34: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 34: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 34: + set +x
 33: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 33: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 33: + set +x
 39: + END_FMT='2020-06-23 10:20:14 PM'
 39: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 39: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 39: + RESULT=237
 39: + RESULT_NAME=bert
 39: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 39: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 39: + set +x
 49: ++ date +%s
 48: ++ date +%s
 50: ++ date +%s
 54: ++ date +%s
 51: ++ date +%s
 52: ++ date +%s
 49: + END=1592976014
 48: + END=1592976014
 50: + END=1592976014
 52: + END=1592976014
 51: + END=1592976014
 54: + END=1592976014
 50: ++ date '+%Y-%m-%d %r'
 52: ++ date '+%Y-%m-%d %r'
 54: ++ date '+%Y-%m-%d %r'
 48: ++ date '+%Y-%m-%d %r'
 49: ++ date '+%Y-%m-%d %r'
 51: ++ date '+%Y-%m-%d %r'
 52: + END_FMT='2020-06-23 10:20:14 PM'
 54: + END_FMT='2020-06-23 10:20:14 PM'
 54: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 52: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 52: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 52: + RESULT=237
 52: + RESULT_NAME=bert
 54: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 54: + RESULT=237
 54: + RESULT_NAME=bert
 48: + END_FMT='2020-06-23 10:20:14 PM'
 48: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 50: + END_FMT='2020-06-23 10:20:14 PM'
 50: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 52: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 52: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 52: + set +x
 54: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 54: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 54: + set +x
 48: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 48: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 48: + RESULT=237
 48: + RESULT_NAME=bert
 48: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 48: + set +x
 50: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 50: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 50: + RESULT=237
 50: + RESULT_NAME=bert
 50: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 50: + set +x
157: ++ date +%s
154: ++ date +%s
 49: + END_FMT='2020-06-23 10:20:14 PM'
 49: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
158: ++ date +%s
 49: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 51: + END_FMT='2020-06-23 10:20:14 PM'
 49: + RESULT=237
 49: + RESULT_NAME=bert
 51: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 51: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 49: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 49: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 49: + set +x
 51: + RESULT=237
 51: + RESULT_NAME=bert
 51: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 51: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 51: + set +x
152: ++ date +%s
155: ++ date +%s
153: ++ date +%s
154: + END=1592976014
158: + END=1592976014
157: + END=1592976014
154: ++ date '+%Y-%m-%d %r'
158: ++ date '+%Y-%m-%d %r'
152: + END=1592976014
155: + END=1592976014
157: ++ date '+%Y-%m-%d %r'
153: + END=1592976014
152: ++ date '+%Y-%m-%d %r'
155: ++ date '+%Y-%m-%d %r'
153: ++ date '+%Y-%m-%d %r'
154: + END_FMT='2020-06-23 10:20:14 PM'
158: + END_FMT='2020-06-23 10:20:14 PM'
154: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
158: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
154: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
158: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
154: + RESULT=237
158: + RESULT=237
154: + RESULT_NAME=bert
158: + RESULT_NAME=bert
235: ++ date +%s
154: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
158: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
154: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
158: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
154: + set +x
158: + set +x
232: ++ date +%s
157: + END_FMT='2020-06-23 10:20:14 PM'
157: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
157: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
152: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
152: + END_FMT='2020-06-23 10:20:14 PM'
152: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
157: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
234: ++ date +%s
157: + RESULT=237
157: + RESULT_NAME=bert
157: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
157: + set +x
238: ++ date +%s
152: + RESULT=237
152: + RESULT_NAME=bert
152: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
152: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
152: + set +x
155: + END_FMT='2020-06-23 10:20:14 PM'
155: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
155: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
155: + RESULT=237
155: + RESULT_NAME=bert
155: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
155: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
155: + set +x
233: ++ date +%s
153: + END_FMT='2020-06-23 10:20:14 PM'
235: + END=1592976014
153: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
153: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
238: + END=1592976014
153: + RESULT=237
153: + RESULT_NAME=bert
153: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
153: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
153: + set +x
232: + END=1592976014
234: + END=1592976014
235: ++ date '+%Y-%m-%d %r'
238: ++ date '+%Y-%m-%d %r'
233: + END=1592976014
234: ++ date '+%Y-%m-%d %r'
160: ++ date +%s
232: ++ date '+%Y-%m-%d %r'
164: ++ date +%s
161: ++ date +%s
162: ++ date +%s
163: ++ date +%s
167: ++ date +%s
233: ++ date '+%Y-%m-%d %r'
235: + END_FMT='2020-06-23 10:20:14 PM'
238: + END_FMT='2020-06-23 10:20:14 PM'
235: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
238: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
235: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
238: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
235: + RESULT=237
238: + RESULT=237
234: + END_FMT='2020-06-23 10:20:14 PM'
235: + RESULT_NAME=bert
238: + RESULT_NAME=bert
234: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
234: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
234: + RESULT=237
235: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
238: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
234: + RESULT_NAME=bert
235: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
238: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
235: + set +x
238: + set +x
234: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
234: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
234: + set +x
232: + END_FMT='2020-06-23 10:20:14 PM'
232: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
232: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
232: + RESULT=237
232: + RESULT_NAME=bert
232: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
232: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
232: + set +x
233: + END_FMT='2020-06-23 10:20:14 PM'
233: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
233: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
233: + RESULT=237
233: + RESULT_NAME=bert
233: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
160: + END=1592976014
233: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
233: + set +x
164: + END=1592976014
161: + END=1592976014
163: + END=1592976014
162: + END=1592976014
167: + END=1592976014
160: ++ date '+%Y-%m-%d %r'
164: ++ date '+%Y-%m-%d %r'
161: ++ date '+%Y-%m-%d %r'
163: ++ date '+%Y-%m-%d %r'
167: ++ date '+%Y-%m-%d %r'
162: ++ date '+%Y-%m-%d %r'
106: ++ date +%s
105: ++ date +%s
108: ++ date +%s
109: ++ date +%s
110: ++ date +%s
104: ++ date +%s
164: + END_FMT='2020-06-23 10:20:14 PM'
160: + END_FMT='2020-06-23 10:20:14 PM'
164: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
164: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
160: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
160: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
164: + RESULT=237
160: + RESULT=237
160: + RESULT_NAME=bert
164: + RESULT_NAME=bert
164: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
164: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
160: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
160: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
160: + set +x
164: + set +x
161: + END_FMT='2020-06-23 10:20:14 PM'
162: + END_FMT='2020-06-23 10:20:14 PM'
163: + END_FMT='2020-06-23 10:20:14 PM'
167: + END_FMT='2020-06-23 10:20:14 PM'
161: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
161: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
162: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
162: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
163: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
163: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
167: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
167: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
161: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
161: + RESULT=237
161: + RESULT_NAME=bert
161: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
161: + set +x
162: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
162: + RESULT=237
162: + RESULT_NAME=bert
162: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
162: + set +x
163: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
163: + RESULT=237
163: + RESULT_NAME=bert
163: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
163: + set +x
167: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
167: + RESULT=237
167: + RESULT_NAME=bert
167: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
167: + set +x
105: + END=1592976014
106: + END=1592976014
108: + END=1592976014
105: ++ date '+%Y-%m-%d %r'
106: ++ date '+%Y-%m-%d %r'
110: + END=1592976014
108: ++ date '+%Y-%m-%d %r'
109: + END=1592976014
104: + END=1592976014
110: ++ date '+%Y-%m-%d %r'
109: ++ date '+%Y-%m-%d %r'
104: ++ date '+%Y-%m-%d %r'
108: + END_FMT='2020-06-23 10:20:14 PM'
105: + END_FMT='2020-06-23 10:20:14 PM'
106: + END_FMT='2020-06-23 10:20:14 PM'
108: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
108: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
108: + RESULT=237
106: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
108: + RESULT_NAME=bert
105: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
106: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
105: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
108: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
108: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
108: + set +x
105: + RESULT=237
105: + RESULT_NAME=bert
106: + RESULT=237
106: + RESULT_NAME=bert
106: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
106: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
105: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
106: + set +x
105: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
105: + set +x
110: + END_FMT='2020-06-23 10:20:14 PM'
110: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
110: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
109: + END_FMT='2020-06-23 10:20:14 PM'
110: + RESULT=237
110: + RESULT_NAME=bert
109: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
110: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
110: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
110: + set +x
109: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
109: + RESULT=237
109: + RESULT_NAME=bert
109: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
109: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
109: + set +x
104: + END_FMT='2020-06-23 10:20:14 PM'
104: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
104: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
104: + RESULT=237
104: + RESULT_NAME=bert
104: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
104: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
104: + set +x
239: ++ date +%s
239: + END=1592976014
239: ++ date '+%Y-%m-%d %r'
239: + END_FMT='2020-06-23 10:20:14 PM'
239: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
239: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
239: + RESULT=237
239: + RESULT_NAME=bert
239: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
239: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
239: + set +x
141: ++ date +%s
140: ++ date +%s
138: ++ date +%s
136: ++ date +%s
142: ++ date +%s
141: + END=1592976014
141: ++ date '+%Y-%m-%d %r'
140: + END=1592976014
138: + END=1592976014
136: + END=1592976014
142: + END=1592976014
140: ++ date '+%Y-%m-%d %r'
138: ++ date '+%Y-%m-%d %r'
136: ++ date '+%Y-%m-%d %r'
142: ++ date '+%Y-%m-%d %r'
141: + END_FMT='2020-06-23 10:20:14 PM'
141: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
141: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
141: + RESULT=237
141: + RESULT_NAME=bert
141: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
141: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
141: + set +x
140: + END_FMT='2020-06-23 10:20:14 PM'
140: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
140: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
140: + RESULT=237
140: + RESULT_NAME=bert
140: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
140: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
140: + set +x
142: + END_FMT='2020-06-23 10:20:14 PM'
142: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
142: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
142: + RESULT=237
142: + RESULT_NAME=bert
142: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
142: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
142: + set +x
136: + END_FMT='2020-06-23 10:20:14 PM'
138: + END_FMT='2020-06-23 10:20:14 PM'
136: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
138: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
136: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
138: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
136: + RESULT=237
138: + RESULT=237
136: + RESULT_NAME=bert
138: + RESULT_NAME=bert
136: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
138: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
136: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
138: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
136: + set +x
138: + set +x
 30: ++ date +%s
 28: ++ date +%s
 24: ++ date +%s
 29: ++ date +%s
 27: ++ date +%s
 31: ++ date +%s
 30: + END=1592976014
 30: ++ date '+%Y-%m-%d %r'
 28: + END=1592976014
 29: + END=1592976014
 24: + END=1592976014
 27: + END=1592976014
 28: ++ date '+%Y-%m-%d %r'
 31: + END=1592976014
 97: ++ date +%s
 29: ++ date '+%Y-%m-%d %r'
 24: ++ date '+%Y-%m-%d %r'
100: ++ date +%s
 96: ++ date +%s
 27: ++ date '+%Y-%m-%d %r'
103: ++ date +%s
 30: + END_FMT='2020-06-23 10:20:14 PM'
 31: ++ date '+%Y-%m-%d %r'
 30: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 30: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 30: + RESULT=237
 30: + RESULT_NAME=bert
 30: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 30: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 30: + set +x
 28: + END_FMT='2020-06-23 10:20:14 PM'
 28: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 28: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 28: + RESULT=237
 28: + RESULT_NAME=bert
 28: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 28: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 28: + set +x
 24: + END_FMT='2020-06-23 10:20:14 PM'
 24: slurmstepd: error: _is_a_lwp: open() /proc/95768/status failed: No such file or directory
 24: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 24: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 24: + RESULT=237
 24: + RESULT_NAME=bert
 24: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 24: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 24: + set +x
 29: + END_FMT='2020-06-23 10:20:14 PM'
 27: + END_FMT='2020-06-23 10:20:14 PM'
 29: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 29: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 27: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 27: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 29: + RESULT=237
 29: + RESULT_NAME=bert
 27: + RESULT=237
 29: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 96: + END=1592976014
 29: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 29: + set +x
 27: + RESULT_NAME=bert
 27: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 27: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 27: + set +x
 97: + END=1592976014
103: + END=1592976014
100: + END=1592976014
 31: + END_FMT='2020-06-23 10:20:14 PM'
 31: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 31: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 31: + RESULT=237
 31: + RESULT_NAME=bert
 96: ++ date '+%Y-%m-%d %r'
 31: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 31: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 31: + set +x
100: ++ date '+%Y-%m-%d %r'
103: ++ date '+%Y-%m-%d %r'
 97: ++ date '+%Y-%m-%d %r'
 96: + END_FMT='2020-06-23 10:20:14 PM'
 96: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 96: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 96: + RESULT=237
 96: + RESULT_NAME=bert
 96: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 96: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 96: + set +x
 97: + END_FMT='2020-06-23 10:20:14 PM'
100: + END_FMT='2020-06-23 10:20:14 PM'
103: + END_FMT='2020-06-23 10:20:14 PM'
103: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 97: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
100: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
103: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 97: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
100: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
103: + RESULT=237
103: + RESULT_NAME=bert
100: + RESULT=237
 97: + RESULT=237
103: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 97: + RESULT_NAME=bert
100: + RESULT_NAME=bert
103: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
103: + set +x
 97: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 97: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
100: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
100: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 97: + set +x
100: + set +x
101: ++ date +%s
 99: ++ date +%s
 99: + END=1592976014
101: + END=1592976014
 99: ++ date '+%Y-%m-%d %r'
101: ++ date '+%Y-%m-%d %r'
 99: + END_FMT='2020-06-23 10:20:14 PM'
 99: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 99: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 99: + RESULT=237
 99: + RESULT_NAME=bert
 99: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 99: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 99: + set +x
101: + END_FMT='2020-06-23 10:20:14 PM'
101: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
101: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
101: + RESULT=237
101: + RESULT_NAME=bert
101: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
101: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
101: + set +x
 74: ++ date +%s
 76: ++ date +%s
 73: ++ date +%s
 78: ++ date +%s
 72: ++ date +%s
 77: ++ date +%s
 74: + END=1592976014
 73: + END=1592976014
 76: + END=1592976014
 78: + END=1592976014
 77: + END=1592976014
 72: + END=1592976014
 74: ++ date '+%Y-%m-%d %r'
 73: ++ date '+%Y-%m-%d %r'
 76: ++ date '+%Y-%m-%d %r'
 78: ++ date '+%Y-%m-%d %r'
 77: ++ date '+%Y-%m-%d %r'
 72: ++ date '+%Y-%m-%d %r'
 74: + END_FMT='2020-06-23 10:20:14 PM'
 74: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 74: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 74: + RESULT=237
 74: + RESULT_NAME=bert
 74: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 74: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 74: + set +x
 76: + END_FMT='2020-06-23 10:20:14 PM'
 76: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 76: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 76: + RESULT=237
 76: + RESULT_NAME=bert
 78: + END_FMT='2020-06-23 10:20:14 PM'
 76: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 76: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 76: + set +x
 78: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 78: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 78: + RESULT=237
 78: + RESULT_NAME=bert
 78: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 78: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 78: + set +x
 77: + END_FMT='2020-06-23 10:20:14 PM'
 77: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 77: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 77: + RESULT=237
 77: + RESULT_NAME=bert
 73: + END_FMT='2020-06-23 10:20:14 PM'
 77: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 77: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 77: + set +x
 72: + END_FMT='2020-06-23 10:20:14 PM'
 73: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 73: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 73: + RESULT=237
 72: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 73: + RESULT_NAME=bert
 72: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 73: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 72: + RESULT=237
 72: + RESULT_NAME=bert
 73: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 73: + set +x
 72: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 72: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 72: + set +x
 68: ++ date +%s
 69: ++ date +%s
 70: ++ date +%s
 64: ++ date +%s
 71: ++ date +%s
 65: ++ date +%s
 69: + END=1592976014
 70: + END=1592976014
 68: + END=1592976014
 69: ++ date '+%Y-%m-%d %r'
 70: ++ date '+%Y-%m-%d %r'
 68: ++ date '+%Y-%m-%d %r'
 71: + END=1592976014
 64: + END=1592976014
 65: + END=1592976014
 69: + END_FMT='2020-06-23 10:20:14 PM'
 69: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 69: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 69: + RESULT=237
 64: ++ date '+%Y-%m-%d %r'
 69: + RESULT_NAME=bert
 71: ++ date '+%Y-%m-%d %r'
 69: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 69: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 69: + set +x
 70: + END_FMT='2020-06-23 10:20:14 PM'
 70: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 70: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 70: + RESULT=237
 70: + RESULT_NAME=bert
 70: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 70: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 70: + set +x
 65: ++ date '+%Y-%m-%d %r'
 68: + END_FMT='2020-06-23 10:20:14 PM'
 68: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 68: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 68: + RESULT=237
 68: + RESULT_NAME=bert
 68: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 68: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 68: + set +x
 64: + END_FMT='2020-06-23 10:20:14 PM'
 65: + END_FMT='2020-06-23 10:20:14 PM'
 40: ++ date +%s
 71: + END_FMT='2020-06-23 10:20:14 PM'
 64: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 65: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 71: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 71: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 64: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 65: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 71: + RESULT=237
 71: + RESULT_NAME=bert
 64: + RESULT=237
 65: + RESULT=237
 65: + RESULT_NAME=bert
 64: + RESULT_NAME=bert
 71: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 71: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 65: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 71: + set +x
 64: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 64: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 65: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 64: + set +x
 65: + set +x
 44: ++ date +%s
 45: ++ date +%s
 41: ++ date +%s
 46: ++ date +%s
 47: ++ date +%s
 40: + END=1592976014
 40: ++ date '+%Y-%m-%d %r'
 44: + END=1592976014
 46: + END=1592976014
 44: ++ date '+%Y-%m-%d %r'
 41: + END=1592976014
 45: + END=1592976014
 47: + END=1592976014
 46: ++ date '+%Y-%m-%d %r'
 40: + END_FMT='2020-06-23 10:20:14 PM'
 40: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 40: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 40: + RESULT=237
 40: + RESULT_NAME=bert
 40: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 40: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 40: + set +x
 45: ++ date '+%Y-%m-%d %r'
 47: ++ date '+%Y-%m-%d %r'
 41: ++ date '+%Y-%m-%d %r'
 44: + END_FMT='2020-06-23 10:20:14 PM'
 44: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 44: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 44: + RESULT=237
 44: + RESULT_NAME=bert
 44: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 44: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 44: + set +x
 46: + END_FMT='2020-06-23 10:20:14 PM'
 47: + END_FMT='2020-06-23 10:20:14 PM'
 46: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 46: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 47: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 47: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 46: + RESULT=237
 47: + RESULT=237
 46: + RESULT_NAME=bert
 47: + RESULT_NAME=bert
 46: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 47: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 46: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 46: + set +x
 47: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 47: + set +x
 41: + END_FMT='2020-06-23 10:20:14 PM'
 45: + END_FMT='2020-06-23 10:20:14 PM'
 41: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 41: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 45: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 41: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 41: + RESULT=237
 41: + RESULT_NAME=bert
 41: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 41: + set +x
 45: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 45: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 45: + RESULT=237
 45: + RESULT_NAME=bert
 45: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 45: + set +x
 84: ++ date +%s
 83: ++ date +%s
 85: ++ date +%s
 82: ++ date +%s
 87: ++ date +%s
 86: ++ date +%s
 84: + END=1592976014
 83: + END=1592976014
 84: ++ date '+%Y-%m-%d %r'
 83: ++ date '+%Y-%m-%d %r'
 85: + END=1592976014
 82: + END=1592976014
 86: + END=1592976014
 87: + END=1592976014
 85: ++ date '+%Y-%m-%d %r'
 82: ++ date '+%Y-%m-%d %r'
 86: ++ date '+%Y-%m-%d %r'
 87: ++ date '+%Y-%m-%d %r'
 83: + END_FMT='2020-06-23 10:20:14 PM'
 84: + END_FMT='2020-06-23 10:20:14 PM'
 83: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 83: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 83: + RESULT=237
 83: + RESULT_NAME=bert
 83: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 83: + set +x
 84: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 84: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 84: + RESULT=237
 84: + RESULT_NAME=bert
 83: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 84: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 84: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 84: + set +x
 85: + END_FMT='2020-06-23 10:20:14 PM'
 85: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 85: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 85: + RESULT=237
 85: + RESULT_NAME=bert
 85: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 85: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 85: + set +x
 86: + END_FMT='2020-06-23 10:20:14 PM'
 86: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 86: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 86: + RESULT=237
 86: + RESULT_NAME=bert
 82: + END_FMT='2020-06-23 10:20:14 PM'
 86: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 86: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 86: + set +x
 87: + END_FMT='2020-06-23 10:20:14 PM'
 82: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 82: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 87: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 87: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 82: + RESULT=237
 82: + RESULT_NAME=bert
 87: + RESULT=237
 87: + RESULT_NAME=bert
 82: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 82: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 82: + set +x
 87: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 87: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 87: + set +x
226: ++ date +%s
225: ++ date +%s
226: + END=1592976014
226: ++ date '+%Y-%m-%d %r'
225: + END=1592976014
225: ++ date '+%Y-%m-%d %r'
226: + END_FMT='2020-06-23 10:20:14 PM'
226: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
226: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
226: + RESULT=237
226: + RESULT_NAME=bert
226: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
226: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
226: + set +x
225: + END_FMT='2020-06-23 10:20:14 PM'
225: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
225: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
225: + RESULT=237
225: + RESULT_NAME=bert
225: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
225: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
225: + set +x
212: ++ date +%s
213: ++ date +%s
214: ++ date +%s
209: ++ date +%s
210: ++ date +%s
215: ++ date +%s
214: + END=1592976014
212: + END=1592976014
213: + END=1592976014
210: + END=1592976014
214: ++ date '+%Y-%m-%d %r'
215: + END=1592976014
213: ++ date '+%Y-%m-%d %r'
210: ++ date '+%Y-%m-%d %r'
212: ++ date '+%Y-%m-%d %r'
209: + END=1592976014
215: ++ date '+%Y-%m-%d %r'
214: + END_FMT='2020-06-23 10:20:14 PM'
209: ++ date '+%Y-%m-%d %r'
214: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
214: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
214: + RESULT=237
214: + RESULT_NAME=bert
214: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
214: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
214: + set +x
213: + END_FMT='2020-06-23 10:20:14 PM'
210: + END_FMT='2020-06-23 10:20:14 PM'
210: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
210: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
212: + END_FMT='2020-06-23 10:20:14 PM'
213: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
213: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
210: + RESULT=237
213: + RESULT=237
210: + RESULT_NAME=bert
212: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
213: + RESULT_NAME=bert
212: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
210: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
210: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
210: + set +x
213: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
212: + RESULT=237
212: + RESULT_NAME=bert
213: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
213: + set +x
212: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
212: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
212: + set +x
224: ++ date +%s
228: ++ date +%s
229: ++ date +%s
230: ++ date +%s
215: + END_FMT='2020-06-23 10:20:14 PM'
215: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
215: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
215: + RESULT=237
215: + RESULT_NAME=bert
215: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
215: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
215: + set +x
224: + END=1592976014
209: + END_FMT='2020-06-23 10:20:14 PM'
209: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
209: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
209: + RESULT=237
209: + RESULT_NAME=bert
209: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
209: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
209: + set +x
224: ++ date '+%Y-%m-%d %r'
228: + END=1592976014
229: + END=1592976014
230: + END=1592976014
228: ++ date '+%Y-%m-%d %r'
229: ++ date '+%Y-%m-%d %r'
230: ++ date '+%Y-%m-%d %r'
224: + END_FMT='2020-06-23 10:20:14 PM'
224: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
224: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
224: + RESULT=237
224: + RESULT_NAME=bert
224: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
224: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
224: + set +x
229: + END_FMT='2020-06-23 10:20:14 PM'
230: + END_FMT='2020-06-23 10:20:14 PM'
230: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
229: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
229: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
230: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
228: + END_FMT='2020-06-23 10:20:14 PM'
229: + RESULT=237
230: + RESULT=237
230: + RESULT_NAME=bert
229: + RESULT_NAME=bert
229: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
229: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
230: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
230: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
230: + set +x
229: + set +x
228: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
228: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
228: + RESULT=237
228: + RESULT_NAME=bert
228: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
228: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
228: + set +x
150: ++ date +%s
148: ++ date +%s
149: ++ date +%s
151: ++ date +%s
147: ++ date +%s
145: ++ date +%s
148: + END=1592976014
150: + END=1592976014
151: + END=1592976014
147: + END=1592976014
149: + END=1592976014
145: + END=1592976014
150: ++ date '+%Y-%m-%d %r'
151: ++ date '+%Y-%m-%d %r'
148: ++ date '+%Y-%m-%d %r'
149: ++ date '+%Y-%m-%d %r'
147: ++ date '+%Y-%m-%d %r'
145: ++ date '+%Y-%m-%d %r'
150: + END_FMT='2020-06-23 10:20:14 PM'
149: + END_FMT='2020-06-23 10:20:14 PM'
150: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
150: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
149: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
150: + RESULT=237
150: + RESULT_NAME=bert
149: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
149: + RESULT=237
150: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
149: + RESULT_NAME=bert
150: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
150: + set +x
149: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
149: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
149: + set +x
148: + END_FMT='2020-06-23 10:20:14 PM'
148: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
148: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
148: + RESULT=237
151: + END_FMT='2020-06-23 10:20:14 PM'
147: + END_FMT='2020-06-23 10:20:14 PM'
148: + RESULT_NAME=bert
148: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
148: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
148: + set +x
151: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
147: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
147: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
151: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
144: slurmstepd: error: _is_a_lwp: open() /proc/11850/status failed: No such file or directory
151: + RESULT=237
151: + RESULT_NAME=bert
145: + END_FMT='2020-06-23 10:20:14 PM'
147: + RESULT=237
147: + RESULT_NAME=bert
147: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
147: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
147: + set +x
151: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
151: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
151: + set +x
145: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
145: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
145: + RESULT=237
145: + RESULT_NAME=bert
145: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
145: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
145: + set +x
 57: ++ date +%s
 57: + END=1592976014
 57: ++ date '+%Y-%m-%d %r'
 57: + END_FMT='2020-06-23 10:20:14 PM'
 57: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 57: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 57: + RESULT=237
 57: + RESULT_NAME=bert
 57: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 57: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 57: + set +x
  7: ++ date +%s
  7: + END=1592976014
  7: ++ date '+%Y-%m-%d %r'
  7: + END_FMT='2020-06-23 10:20:14 PM'
  7: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
  7: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
  7: + RESULT=237
  7: + RESULT_NAME=bert
  7: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
  7: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
  7: + set +x
184: ++ date +%s
184: + END=1592976014
184: ++ date '+%Y-%m-%d %r'
184: + END_FMT='2020-06-23 10:20:14 PM'
184: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
184: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
184: + RESULT=237
184: + RESULT_NAME=bert
184: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
184: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
184: + set +x
218: ++ date +%s
218: + END=1592976014
218: ++ date '+%Y-%m-%d %r'
218: + END_FMT='2020-06-23 10:20:14 PM'
218: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
218: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
218: + RESULT=237
218: + RESULT_NAME=bert
218: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
218: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
218: + set +x
207: ++ date +%s
207: + END=1592976014
207: ++ date '+%Y-%m-%d %r'
207: + END_FMT='2020-06-23 10:20:14 PM'
207: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
207: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
207: + RESULT=237
207: + RESULT_NAME=bert
207: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
207: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
207: + set +x
121: ++ date +%s
121: + END=1592976014
121: ++ date '+%Y-%m-%d %r'
121: + END_FMT='2020-06-23 10:20:14 PM'
121: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
121: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
121: + RESULT=237
121: + RESULT_NAME=bert
121: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
121: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
121: + set +x
176: ++ date +%s
176: + END=1592976014
176: ++ date '+%Y-%m-%d %r'
176: + END_FMT='2020-06-23 10:20:14 PM'
176: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
176: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
176: + RESULT=237
176: + RESULT_NAME=bert
176: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
176: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
176: + set +x
255: ++ date +%s
255: + END=1592976014
255: ++ date '+%Y-%m-%d %r'
255: + END_FMT='2020-06-23 10:20:14 PM'
255: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
255: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
255: + RESULT=237
255: + RESULT_NAME=bert
255: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
255: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
255: + set +x
 90: ++ date +%s
 90: + END=1592976014
 90: ++ date '+%Y-%m-%d %r'
 90: + END_FMT='2020-06-23 10:20:14 PM'
 90: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 90: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 90: + RESULT=237
 90: + RESULT_NAME=bert
 90: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 90: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 90: + set +x
175: ++ date +%s
175: + END=1592976014
175: ++ date '+%Y-%m-%d %r'
  8: ++ date +%s
129: ++ date +%s
175: + END_FMT='2020-06-23 10:20:14 PM'
  8: + END=1592976014
175: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
175: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
175: + RESULT=237
175: + RESULT_NAME=bert
175: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
175: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
175: + set +x
129: + END=1592976014
  8: ++ date '+%Y-%m-%d %r'
129: ++ date '+%Y-%m-%d %r'
  8: + END_FMT='2020-06-23 10:20:14 PM'
  8: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
  8: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
  8: + RESULT=237
  8: + RESULT_NAME=bert
  8: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
  8: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
  8: + set +x
129: + END_FMT='2020-06-23 10:20:14 PM'
129: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
129: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
129: + RESULT=237
129: + RESULT_NAME=bert
129: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
129: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
129: + set +x
199: ++ date +%s
199: + END=1592976014
199: ++ date '+%Y-%m-%d %r'
199: + END_FMT='2020-06-23 10:20:14 PM'
199: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
199: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
199: + RESULT=237
199: + RESULT_NAME=bert
199: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
199: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
199: + set +x
236: ++ date +%s
166: ++ date +%s
236: + END=1592976014
247: ++ date +%s
236: ++ date '+%Y-%m-%d %r'
166: + END=1592976014
247: + END=1592976014
166: ++ date '+%Y-%m-%d %r'
236: + END_FMT='2020-06-23 10:20:14 PM'
247: ++ date '+%Y-%m-%d %r'
236: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
236: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
236: + RESULT=237
236: + RESULT_NAME=bert
236: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
236: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
236: + set +x
166: + END_FMT='2020-06-23 10:20:14 PM'
166: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
166: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
166: + RESULT=237
166: + RESULT_NAME=bert
166: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
247: + END_FMT='2020-06-23 10:20:14 PM'
166: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
166: + set +x
247: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
247: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
247: + RESULT=237
247: + RESULT_NAME=bert
247: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
247: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
247: + set +x
 55: ++ date +%s
 55: + END=1592976014
 55: ++ date '+%Y-%m-%d %r'
 55: + END_FMT='2020-06-23 10:20:14 PM'
 55: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 55: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 55: + RESULT=237
 55: + RESULT_NAME=bert
 55: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 55: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 55: + set +x
 36: ++ date +%s
119: ++ date +%s
 36: + END=1592976014
119: + END=1592976014
 36: ++ date '+%Y-%m-%d %r'
119: ++ date '+%Y-%m-%d %r'
 36: + END_FMT='2020-06-23 10:20:14 PM'
 36: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 36: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 36: + RESULT=237
 36: + RESULT_NAME=bert
 36: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 36: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 36: + set +x
119: + END_FMT='2020-06-23 10:20:14 PM'
119: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
119: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
119: + RESULT=237
119: + RESULT_NAME=bert
119: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
119: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
119: + set +x
 23: ++ date +%s
 23: + END=1592976014
 23: ++ date '+%Y-%m-%d %r'
 23: + END_FMT='2020-06-23 10:20:14 PM'
 23: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 23: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 23: + RESULT=237
 23: + RESULT_NAME=bert
 23: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 23: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 23: + set +x
159: ++ date +%s
159: + END=1592976014
159: ++ date '+%Y-%m-%d %r'
159: + END_FMT='2020-06-23 10:20:14 PM'
159: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
159: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
159: + RESULT=237
159: + RESULT_NAME=bert
159: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
159: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
159: + set +x
102: ++ date +%s
102: + END=1592976014
102: ++ date '+%Y-%m-%d %r'
102: + END_FMT='2020-06-23 10:20:14 PM'
102: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
102: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
102: + RESULT=237
102: + RESULT_NAME=bert
102: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
102: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
102: + set +x
143: ++ date +%s
143: + END=1592976014
143: ++ date '+%Y-%m-%d %r'
143: + END_FMT='2020-06-23 10:20:14 PM'
143: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
143: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
143: + RESULT=237
143: + RESULT_NAME=bert
143: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
143: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
143: + set +x
111: ++ date +%s
111: + END=1592976014
111: ++ date '+%Y-%m-%d %r'
 26: ++ date +%s
111: + END_FMT='2020-06-23 10:20:14 PM'
111: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
111: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
111: + RESULT=237
111: + RESULT_NAME=bert
111: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
111: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
111: + set +x
 26: + END=1592976014
 26: ++ date '+%Y-%m-%d %r'
 26: + END_FMT='2020-06-23 10:20:14 PM'
 26: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 26: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 26: + RESULT=237
 26: + RESULT_NAME=bert
 26: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 26: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 26: + set +x
 66: ++ date +%s
 66: + END=1592976014
 66: ++ date '+%Y-%m-%d %r'
 66: + END_FMT='2020-06-23 10:20:14 PM'
 66: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 66: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 66: + RESULT=237
 66: + RESULT_NAME=bert
 66: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 66: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 66: + set +x
 80: ++ date +%s
 80: + END=1592976014
 80: ++ date '+%Y-%m-%d %r'
 80: + END_FMT='2020-06-23 10:20:14 PM'
 80: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 80: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 80: + RESULT=237
 80: + RESULT_NAME=bert
 80: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 80: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 80: + set +x
 43: ++ date +%s
 43: + END=1592976014
 43: ++ date '+%Y-%m-%d %r'
 43: + END_FMT='2020-06-23 10:20:14 PM'
 43: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 43: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 43: + RESULT=237
 43: + RESULT_NAME=bert
 43: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 43: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 43: + set +x
208: ++ date +%s
208: + END=1592976014
208: ++ date '+%Y-%m-%d %r'
208: + END_FMT='2020-06-23 10:20:14 PM'
208: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
208: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
208: + RESULT=237
208: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
208: + RESULT_NAME=bert
208: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
208: + set +x
 79: ++ date +%s
 79: + END=1592976014
 79: ++ date '+%Y-%m-%d %r'
 79: + END_FMT='2020-06-23 10:20:14 PM'
 79: ENDING TIMING RUN AT 2020-06-23 10:20:14 PM
 79: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:14 PM'
 79: + RESULT=237
 79: + RESULT_NAME=bert
 79: RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM
 79: + echo 'RESULT,bert,28019,237,root,2020-06-23 10:16:17 PM'
 79: + set +x
231: ++ date +%s
231: + END=1592976015
231: ++ date '+%Y-%m-%d %r'
231: + END_FMT='2020-06-23 10:20:15 PM'
231: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:15 PM'
231: ENDING TIMING RUN AT 2020-06-23 10:20:15 PM
231: + RESULT=238
231: + RESULT_NAME=bert
231: RESULT,bert,28019,238,root,2020-06-23 10:16:17 PM
231: + echo 'RESULT,bert,28019,238,root,2020-06-23 10:16:17 PM'
231: + set +x
144: ++ date +%s
144: + END=1592976015
144: ++ date '+%Y-%m-%d %r'
144: + END_FMT='2020-06-23 10:20:15 PM'
144: + echo 'ENDING TIMING RUN AT 2020-06-23 10:20:15 PM'
144: ENDING TIMING RUN AT 2020-06-23 10:20:15 PM
144: + RESULT=238
144: + RESULT_NAME=bert
144: + echo 'RESULT,bert,28019,238,root,2020-06-23 10:16:17 PM'
144: RESULT,bert,28019,238,root,2020-06-23 10:16:17 PM
144: + set +x
