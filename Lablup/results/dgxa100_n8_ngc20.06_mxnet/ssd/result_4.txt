+ echo 'Beginning trial 4 of 5'
Beginning trial 4 of 5
+ srun -N1 -n1 --container-name=single_stage_detector python -c '
import mlperf_log_utils
from mlperf_logging.mllog import constants
mlperf_log_utils.mlperf_submission_log(constants.SSD)'
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
:::MLLOG {"namespace": "", "time_ms": 1592976155029, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "ssd", "metadata": {"file": "/workspace/ssd/mlperf_log_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1592976155037, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "NVIDIA", "metadata": {"file": "/workspace/ssd/mlperf_log_utils.py", "lineno": 80}}
:::MLLOG {"namespace": "", "time_ms": 1592976155037, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/ssd/mlperf_log_utils.py", "lineno": 84}}
:::MLLOG {"namespace": "", "time_ms": 1592976155037, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/ssd/mlperf_log_utils.py", "lineno": 88}}
:::MLLOG {"namespace": "", "time_ms": 1592976155037, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "8xNVIDIA DGX A100", "metadata": {"file": "/workspace/ssd/mlperf_log_utils.py", "lineno": 92}}
+ '[' 1 -eq 1 ']'
+ srun --ntasks=8 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0205
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0207
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0208
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0211
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0212
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0209
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0210
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0206
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=8 --container-name=single_stage_detector python -c '
from mlperf_logging.mllog import constants
from mlperf_log_utils import log_event
log_event(key=constants.CACHE_CLEAR, value=True)'
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
:::MLLOG {"namespace": "", "time_ms": 1592976159765, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
+ srun --mpi=pmix --ntasks=64 --ntasks-per-node=8 --container-name=single_stage_detector --container-mounts=/raid/datasets/coco/coco-2017:/data,/lustre/fsw/mlperf-ci/14140760/results:/results,/raid/datasets/coco/coco-2017/coco2017/models:/pretrained/mxnet ./run_and_time.sh
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
running benchmark
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ '[' -n 3 ']'
+ declare -a CMD
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ '[' -n 6 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ '[' -n 1 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
+ export PRETRAINED_DIR=/pretrained/mxnet
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' -n 6 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ '[' -n 0 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ NUMEPOCHS=80
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ NUMEPOCHS=80
+ '[' -n 7 ']'
running benchmark
+ echo 'running benchmark'
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ '[' 64 -gt 8 ']'
+ cluster=
+ export DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ NUMEPOCHS=80
+ DATASET_DIR=/data/coco2017
+ declare -a CMD
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
running benchmark
+ echo 'running benchmark'
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ declare -a CMD
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ '[' -n 5 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ '[' -n 2 ']'
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ '[' -n 3 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ declare -a CMD
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ '[' -n 2 ']'
+ '[' 64 -gt 8 ']'
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ '[' -n 3 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
running benchmark
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ '[' -n 5 ']'
running benchmark
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ '[' -n 6 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ NUMEPOCHS=80
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' -n 4 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ '[' -n 7 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ '[' -n 5 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ '[' -n 4 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ declare -a CMD
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ '[' -n 6 ']'
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:22:42 PM
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ '[' -n 5 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
:::MLLOG {"namespace": "", "time_ms": 1592976165395, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165391, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165393, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165397, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165402, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165402, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165402, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165403, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165403, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165403, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165403, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165404, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165405, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165399, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165400, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165401, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165399, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165401, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165401, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165408, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165408, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165408, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165408, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165409, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165412, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165594, "event_type": "POINT_IN_TIME", "key": "sgd", "value": 2005202969, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 193}}
:::MLLOG {"namespace": "", "time_ms": 1592976165410, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165410, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165413, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165405, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165405, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165410, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165414, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165414, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165413, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165408, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165408, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165413, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165416, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165410, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165410, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165410, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165410, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165413, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165415, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165415, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165419, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165420, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165417, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165420, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165416, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165419, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165420, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165421, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165419, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165422, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165419, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165419, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165421, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165418, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165420, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165421, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165420, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165421, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165421, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976165688, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2005202969, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 218}}
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=2005202993, start_epoch=1, synthetiabout to model_zoo.get_model( resnet34_v1 )
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=2005203017, start_epoch=1, synthetiabout to model_zoo.get_model( resnet34_v1 )
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=2005203001, start_epoch=1, synthetiabout to model_zoo.get_model( resnet34_v1 )
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=2005202977, start_epoch=1, synthetiabout to model_zoo.get_model( resnet34_v1 )
c=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
c=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
c=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
c=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=2005202993, start_epoch=1, synthetic=False, tabout to model_zoo.get_model( resnet34_v1 )
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=2005203009, start_epoch=1, synthetiabout to model_zoo.get_model( resnet34_v1 )
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=2005202977, start_epoch=1, synthetic=False, tabout to model_zoo.get_model( resnet34_v1 )
arget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
c=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
arget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=2005202969, start_epoch=1, synthetiabout to model_zoo.get_model( resnet34_v1 )
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=2005203017, start_epoch=1, synthetic=False, tabout to model_zoo.get_model( resnet34_v1 )
c=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
arget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=2005203009, start_epoch=1, synthetic=False, tabout to model_zoo.get_model( resnet34_v1 )
arget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=2005203001, start_epoch=1, synthetic=False, tabout to model_zoo.get_model( resnet34_v1 )
INFO:root:Seed: 2005202977
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=2005203025, start_epoch=1, synthetiabout to model_zoo.get_model( resnet34_v1 )
arget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Seed: 2005202993
Seed: 2005202993
INFO:root:precision: fp16
precision: fp16
about to model_zoo.get_model( resnet34_v1 )
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=2005202969, start_epoch=1, synthetic=False, tabout to model_zoo.get_model( resnet34_v1 )
INFO:root:Seed: 2005203017
Seed: 2005203017
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=2005202985, start_epoch=1, synthetiabout to model_zoo.get_model( resnet34_v1 )
Seed: 2005202977
about to model_zoo.get_model( resnet34_v1 )
arget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Seed: 2005203009
Seed: 2005203009
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Seed: 2005202969
Seed: 2005202969
about to model_zoo.get_model( resnet34_v1 )
INFO:root:loss scaling: 128.0
about to model_zoo.get_model( resnet34_v1 )
INFO:root:precision: fp16
precision: fp16
about to model_zoo.get_model( resnet34_v1 )
c=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Seed: 2005203001
Seed: 2005203001
about to model_zoo.get_model( resnet34_v1 )
INFO:root:precision: fp16
about to model_zoo.get_model( resnet34_v1 )
INFO:root:precision: fp16
about to model_zoo.get_model( resnet34_v1 )
INFO:root:precision: fp16
precision: fp16
about to model_zoo.get_model( resnet34_v1 )
INFO:root:precision: fp16
about to model_zoo.get_model( resnet34_v1 )
precision: fp16
about to model_zoo.get_model( resnet34_v1 )
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=2005202985, start_epoch=1, synthetic=False, tabout to model_zoo.get_model( resnet34_v1 )
INFO:root:loss scaling: 128.0
about to model_zoo.get_model( resnet34_v1 )
precision: fp16
about to model_zoo.get_model( resnet34_v1 )
precision: fp16
about to model_zoo.get_model( resnet34_v1 )
INFO:root:loss scaling: 128.0
loss scaling: 128.0
about to model_zoo.get_model( resnet34_v1 )
loss scaling: 128.0
about to model_zoo.get_model( resnet34_v1 )
INFO:root:loss scaling: 128.0
about to model_zoo.get_model( resnet34_v1 )
loss scaling: 128.0
about to model_zoo.get_model( resnet34_v1 )
INFO:root:loss scaling: 128.0
loss scaling: 128.0
about to model_zoo.get_model( resnet34_v1 )
INFO:root:loss scaling: 128.0
about to model_zoo.get_model( resnet34_v1 )
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
about to model_zoo.get_model( resnet34_v1 )
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
about to model_zoo.get_model( resnet34_v1 )
loss scaling: 128.0
about to model_zoo.get_model( resnet34_v1 )
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
about to model_zoo.get_model( resnet34_v1 )
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
about to model_zoo.get_model( resnet34_v1 )
loss scaling: 128.0
about to model_zoo.get_model( resnet34_v1 )
INFO:root:fuse bn relu: True
about to model_zoo.get_model( resnet34_v1 )
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
about to model_zoo.get_model( resnet34_v1 )
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
about to model_zoo.get_model( resnet34_v1 )
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
fuse bn relu: True
INFO:root:fuse bn relu: True
fuse bn relu: True
INFO:root:fuse bn relu: True
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
INFO:root:fuse bn add relu: True
fuse bn add relu: True
INFO:root:fuse bn add relu: True
fuse bn add relu: True
fuse bn relu: True
INFO:root:fuse bn relu: True
INFO:root:bn group: 1
bn group: 1
INFO:root:bn group: 1
bn group: 1
INFO:root:fuse bn add relu: True
fuse bn add relu: True
fuse bn relu: True
INFO:root:bn all reduce fp16: False
INFO:root:bn all reduce fp16: False
bn all reduce fp16: False
INFO:root:bn group: 1
bn group: 1
INFO:root:fuse bn relu: True
INFO:root:fuse bn add relu: True
fuse bn add relu: True
c=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
bn all reduce fp16: False
INFO:root:MPI size: 64
MPI size: 64
INFO:root:bn all reduce fp16: False
bn all reduce fp16: False
fuse bn relu: True
INFO:root:bn group: 1
bn group: 1
INFO:root:MPI size: 64
MPI size: 64
INFO:root:MPI global rank: 48
MPI global rank: 48
INFO:root:MPI size: 64
MPI size: 64
INFO:root:fuse bn add relu: True
INFO:root:bn all reduce fp16: False
INFO:root:MPI global rank: 24
MPI global rank: 24
INFO:root:MPI local rank: 0
MPI local rank: 0
fuse bn add relu: True
INFO:root:async validation: True
async validation: True
INFO:root:bn group: 1
bn group: 1
INFO:root:MPI global rank: 40
MPI global rank: 40
INFO:root:bn all reduce fp16: False
bn all reduce fp16: False
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=2005203025, start_epoch=1, synthetic=False, tINFO:root:MPI size: 64
MPI size: 64
arget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
INFO:root:MPI local rank: 0
INFO:root:MPI local rank: 0
INFO:root:MPI global rank: 32
MPI global rank: 32
bn all reduce fp16: False
INFO:root:Seed: 2005203025
Seed: 2005203025
MPI local rank: 0
MPI local rank: 0
INFO:root:MPI local rank: 0
MPI local rank: 0
INFO:root:MPI size: 64
INFO:root:async validation: True
async validation: True
MPI size: 64
INFO:root:async validation: True
async validation: True
INFO:root:MPI global rank: 8
MPI global rank: 8
INFO:root:precision: fp16
INFO:root:[SSD] network: resnet34_v1
[SSD] network: resnet34_v1
INFO:root:async validation: True
async validation: True
INFO:root:MPI local rank: 0
MPI local rank: 0
precision: fp16
INFO:root:[SSD] network: resnet34_v1
[SSD] network: resnet34_v1
INFO:root:async validation: True
async validation: True
INFO:root:loss scaling: 128.0
loss scaling: 128.0
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
INFO:root:[SSD] network: resnet34_v1
[SSD] network: resnet34_v1
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
INFO:root:[SSD] network: resnet34_v1
INFO:root:[SSD] network: resnet34_v1
[SSD] network: resnet34_v1
INFO:root:fuse bn relu: True
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
fuse bn relu: True
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
INFO:root:fuse bn add relu: True
[SSD] network: resnet34_v1
fuse bn add relu: True
INFO:root:[SSD] fuse bn add relu: True
[SSD] fuse bn add relu: True
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
about to model_zoo.get_model( resnet34_v1 )
INFO:root:bn group: 1
bn group: 1
INFO:root:[SSD] bn group: 1
[SSD] bn group: 1
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
INFO:root:bn all reduce fp16: False
bn all reduce fp16: False
INFO:root:[SSD] fuse bn add relu: True
[SSD] fuse bn add relu: True
INFO:root:[SSD] fuse bn add relu: True
[SSD] fuse bn add relu: True
INFO:root:MPI size: 64
MPI size: 64
INFO:root:[SSD] bn group: 1
[SSD] bn group: 1
INFO:root:[SSD] fuse bn relu: True
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
INFO:root:[SSD] bn group: 1
[SSD] bn group: 1
INFO:root:[SSD] fuse bn add relu: True
[SSD] fuse bn add relu: True
INFO:root:MPI global rank: 56
MPI global rank: 56
INFO:root:[SSD] fuse bn add relu: True
[SSD] fuse bn add relu: True
INFO:root:[SSD] bn group: 1
[SSD] bn group: 1
INFO:root:MPI local rank: 0
MPI local rank: 0
INFO:root:[SSD] bn group: 1
about to model_zoo.get_model( resnet34_v1 )
INFO:root:async validation: True
async validation: True
[SSD] bn group: 1
INFO:root:[SSD] network: resnet34_v1
[SSD] network: resnet34_v1
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
INFO:root:[SSD] fuse bn add relu: True
[SSD] fuse bn add relu: True
INFO:root:[SSD] bn group: 1
[SSD] bn group: 1
arget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
INFO:root:Seed: 2005202985
Seed: 2005202985
INFO:root:precision: fp16
precision: fp16
INFO:root:loss scaling: 128.0
loss scaling: 128.0
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
INFO:root:fuse bn relu: True
fuse bn relu: True
INFO:root:fuse bn add relu: True
fuse bn add relu: True
INFO:root:bn group: 1
bn group: 1
INFO:root:bn all reduce fp16: False
bn all reduce fp16: False
INFO:root:MPI size: 64
MPI size: 64
INFO:root:MPI global rank: 16
MPI global rank: 16
INFO:root:MPI local rank: 0
MPI local rank: 0
INFO:root:async validation: True
async validation: True
INFO:root:[SSD] network: resnet34_v1
[SSD] network: resnet34_v1
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
INFO:root:[SSD] fuse bn add relu: True
[SSD] fuse bn add relu: True
INFO:root:[SSD] bn group: 1
[SSD] bn group: 1
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
INFO:root:fuse bn relu: True
fuse bn relu: True
INFO:root:fuse bn add relu: True
fuse bn add relu: True
INFO:root:bn group: 1
bn group: 1
INFO:root:bn all reduce fp16: False
bn all reduce fp16: False
about to model_zoo.get_model( resnet34_v1 )
INFO:root:MPI size: 64
MPI size: 64
INFO:root:MPI global rank: 0
MPI global rank: 0
INFO:root:MPI local rank: 0
MPI local rank: 0
INFO:root:async validation: True
async validation: True
INFO:root:[SSD] network: resnet34_v1
[SSD] network: resnet34_v1
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
INFO:root:[SSD] fuse bn add relu: True
[SSD] fuse bn add relu: True
INFO:root:[SSD] bn group: 1
[SSD] bn group: 1
about to model_zoo.get_model( resnet34_v1 )
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
INFO:root:COCO reader: raw images
COCO reader: raw images
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:COCO reader: raw images
COCO reader: raw images
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
:::MLLOG {"namespace": "", "time_ms": 1592976167866, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 117266, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 363}}
:::MLLOG {"namespace": "", "time_ms": 1592976167867, "event_type": "POINT_IN_TIME", "key": "max_samples", "value": 1, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 364}}
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
:::MLLOG {"namespace": "", "time_ms": 1592976167868, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 839, "metadata": {"file": "/workspace/ssd/lr_scheduler.py", "lineno": 30}}
:::MLLOG {"namespace": "", "time_ms": 1592976167868, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_factor", "value": 0, "metadata": {"file": "/workspace/ssd/lr_scheduler.py", "lineno": 31}}
:::MLLOG {"namespace": "", "time_ms": 1592976167868, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.14, "metadata": {"file": "/workspace/ssd/lr_scheduler.py", "lineno": 36}}
:::MLLOG {"namespace": "", "time_ms": 1592976167868, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_boundary_epochs", "value": [44, 55], "metadata": {"file": "/workspace/ssd/lr_scheduler.py", "lineno": 37}}
INFO:root:COCO reader: raw images
COCO reader: raw images
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
:::MLLOG {"namespace": "", "time_ms": 1592976168665, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 5000, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 407}}
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
:::MLLOG {"namespace": "", "time_ms": 1592976172603, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.00017, "metadata": {"file": "/workspace/ssd/trainer.py", "lineno": 29}}
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[22:22:54] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:54] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:54] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:54] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:54] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:54] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:54] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:54] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:54] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:54] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:54] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:54] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:54] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:54] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:54] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:54] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:54] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:54] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:54] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:54] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:54] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:22:55] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
INFO:root:Done
Done
INFO:root:Done
Done
INFO:root:Done
Done
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
INFO:root:Done
Done
INFO:root:Done
Done
INFO:root:Done
Done
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
INFO:root:Done
Done
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
INFO:root:Done
Done
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
:::MLLOG {"namespace": "", "time_ms": 1592976193713, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 495}}
:::MLLOG {"namespace": "", "time_ms": 1592976193714, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 499}}
INFO:root:Training from epoch: 1
Training from epoch: 1
INFO:root:Training from epoch: 1
Training from epoch: 1
INFO:root:Training from epoch: 1
Training from epoch: 1
INFO:root:Training from epoch: 1
Training from epoch: 1
INFO:root:Training from epoch: 1
Training from epoch: 1
INFO:root:Training from epoch: 1
Training from epoch: 1
INFO:root:Training from epoch: 1
Training from epoch: 1
:::MLLOG {"namespace": "", "time_ms": 1592976194741, "event_type": "POINT_IN_TIME", "key": "model_bn_span", "value": 24, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 101}}
:::MLLOG {"namespace": "", "time_ms": 1592976194741, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 1536, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 102}}
INFO:root:Training from epoch: 1
Training from epoch: 1
:::MLLOG {"namespace": "", "time_ms": 1592976194741, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 1, "current_iter_num": 0}}
INFO:root:[Training][Epoch 1] training time: 2.425 [sec],avg speed: 48779.595 [imgs/sec],loss=16.232
[Training][Epoch 1] training time: 2.425 [sec],avg speed: 48779.595 [imgs/sec],loss=16.232
:::MLLOG {"namespace": "", "time_ms": 1592976197166, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1592976197166, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 2, "current_iter_num": 0}}
INFO:root:[Training][Iteration 100][Epoch 2, Batch 23/77] lr: 0.01669, training time: 29.252 [ms], speed: 52508.336 [imgs/sec], loss=9.416
[Training][Iteration 100][Epoch 2, Batch 23/77] lr: 0.01669, training time: 29.252 [ms], speed: 52508.336 [imgs/sec], loss=9.416
INFO:root:[Training][Epoch 2] training time: 2.201 [sec],avg speed: 53041.646 [imgs/sec],loss=9.240
[Training][Epoch 2] training time: 2.201 [sec],avg speed: 53041.646 [imgs/sec],loss=9.240
:::MLLOG {"namespace": "", "time_ms": 1592976199367, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1592976199368, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 3, "current_iter_num": 0}}
INFO:root:[Training][Iteration 200][Epoch 3, Batch 46/77] lr: 0.03337, training time: 29.023 [ms], speed: 52924.008 [imgs/sec], loss=8.445
[Training][Iteration 200][Epoch 3, Batch 46/77] lr: 0.03337, training time: 29.023 [ms], speed: 52924.008 [imgs/sec], loss=8.445
INFO:root:[Training][Epoch 3] training time: 2.215 [sec],avg speed: 52705.356 [imgs/sec],loss=8.170
[Training][Epoch 3] training time: 2.215 [sec],avg speed: 52705.356 [imgs/sec],loss=8.170
:::MLLOG {"namespace": "", "time_ms": 1592976201583, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592976201583, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 4, "current_iter_num": 0}}
INFO:root:[Training][Iteration 300][Epoch 4, Batch 69/77] lr: 0.05006, training time: 28.819 [ms], speed: 53297.543 [imgs/sec], loss=7.105
[Training][Iteration 300][Epoch 4, Batch 69/77] lr: 0.05006, training time: 28.819 [ms], speed: 53297.543 [imgs/sec], loss=7.105
INFO:root:[Training][Epoch 4] training time: 2.218 [sec],avg speed: 53315.000 [imgs/sec],loss=7.511
[Training][Epoch 4] training time: 2.218 [sec],avg speed: 53315.000 [imgs/sec],loss=7.511
:::MLLOG {"namespace": "", "time_ms": 1592976203801, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592976203802, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 5, "current_iter_num": 0}}
INFO:root:[Training][Epoch 5] training time: 2.173 [sec],avg speed: 53716.859 [imgs/sec],loss=7.176
[Training][Epoch 5] training time: 2.173 [sec],avg speed: 53716.859 [imgs/sec],loss=7.176
:::MLLOG {"namespace": "", "time_ms": 1592976205975, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1592976205975, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 6, "current_iter_num": 0}}
INFO:root:[Training][Iteration 400][Epoch 6, Batch 15/77] lr: 0.06675, training time: 28.287 [ms], speed: 54300.842 [imgs/sec], loss=6.608
[Training][Iteration 400][Epoch 6, Batch 15/77] lr: 0.06675, training time: 28.287 [ms], speed: 54300.842 [imgs/sec], loss=6.608
INFO:root:[Training][Epoch 6] training time: 2.156 [sec],avg speed: 54145.721 [imgs/sec],loss=6.644
[Training][Epoch 6] training time: 2.156 [sec],avg speed: 54145.721 [imgs/sec],loss=6.644
:::MLLOG {"namespace": "", "time_ms": 1592976208131, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 6}}
:::MLLOG {"namespace": "", "time_ms": 1592976208132, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 7, "current_iter_num": 0}}
INFO:root:[Training][Iteration 500][Epoch 7, Batch 38/77] lr: 0.08343, training time: 28.377 [ms], speed: 54129.266 [imgs/sec], loss=6.724
[Training][Iteration 500][Epoch 7, Batch 38/77] lr: 0.08343, training time: 28.377 [ms], speed: 54129.266 [imgs/sec], loss=6.724
INFO:root:[Training][Epoch 7] training time: 2.191 [sec],avg speed: 53983.704 [imgs/sec],loss=6.440
[Training][Epoch 7] training time: 2.191 [sec],avg speed: 53983.704 [imgs/sec],loss=6.440
:::MLLOG {"namespace": "", "time_ms": 1592976210323, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1592976210323, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 8, "current_iter_num": 0}}
INFO:root:[Training][Iteration 600][Epoch 8, Batch 61/77] lr: 0.10012, training time: 28.384 [ms], speed: 54115.938 [imgs/sec], loss=6.611
[Training][Iteration 600][Epoch 8, Batch 61/77] lr: 0.10012, training time: 28.384 [ms], speed: 54115.938 [imgs/sec], loss=6.611
INFO:root:[Training][Epoch 8] training time: 2.156 [sec],avg speed: 54156.321 [imgs/sec],loss=6.031
[Training][Epoch 8] training time: 2.156 [sec],avg speed: 54156.321 [imgs/sec],loss=6.031
:::MLLOG {"namespace": "", "time_ms": 1592976212479, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 8}}
:::MLLOG {"namespace": "", "time_ms": 1592976212479, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 9, "current_iter_num": 0}}
INFO:root:[Training][Epoch 9] training time: 2.160 [sec],avg speed: 54037.989 [imgs/sec],loss=5.749
[Training][Epoch 9] training time: 2.160 [sec],avg speed: 54037.989 [imgs/sec],loss=5.749
:::MLLOG {"namespace": "", "time_ms": 1592976214639, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 9}}
:::MLLOG {"namespace": "", "time_ms": 1592976214640, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 10, "current_iter_num": 0}}
INFO:root:[Training][Iteration 700][Epoch 10, Batch 7/77] lr: 0.11681, training time: 28.176 [ms], speed: 54514.478 [imgs/sec], loss=5.860
[Training][Iteration 700][Epoch 10, Batch 7/77] lr: 0.11681, training time: 28.176 [ms], speed: 54514.478 [imgs/sec], loss=5.860
INFO:root:[Training][Epoch 10] training time: 2.173 [sec],avg speed: 54438.651 [imgs/sec],loss=5.567
[Training][Epoch 10] training time: 2.173 [sec],avg speed: 54438.651 [imgs/sec],loss=5.567
:::MLLOG {"namespace": "", "time_ms": 1592976216812, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 10}}
:::MLLOG {"namespace": "", "time_ms": 1592976216813, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 11, "current_iter_num": 0}}
INFO:root:[Training][Iteration 800][Epoch 11, Batch 30/77] lr: 0.13349, training time: 28.233 [ms], speed: 54404.000 [imgs/sec], loss=5.586
[Training][Iteration 800][Epoch 11, Batch 30/77] lr: 0.13349, training time: 28.233 [ms], speed: 54404.000 [imgs/sec], loss=5.586
INFO:root:[Training][Epoch 11] training time: 2.146 [sec],avg speed: 54405.089 [imgs/sec],loss=5.376
[Training][Epoch 11] training time: 2.146 [sec],avg speed: 54405.089 [imgs/sec],loss=5.376
:::MLLOG {"namespace": "", "time_ms": 1592976218958, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1592976218959, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 12, "current_iter_num": 0}}
INFO:root:[Training][Iteration 900][Epoch 12, Batch 53/77] lr: 0.14000, training time: 28.153 [ms], speed: 54558.683 [imgs/sec], loss=5.184
[Training][Iteration 900][Epoch 12, Batch 53/77] lr: 0.14000, training time: 28.153 [ms], speed: 54558.683 [imgs/sec], loss=5.184
INFO:root:[Training][Epoch 12] training time: 2.141 [sec],avg speed: 54517.618 [imgs/sec],loss=5.154
[Training][Epoch 12] training time: 2.141 [sec],avg speed: 54517.618 [imgs/sec],loss=5.154
:::MLLOG {"namespace": "", "time_ms": 1592976221100, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1592976221100, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 13, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1000][Epoch 13, Batch 76/77] lr: 0.14000, training time: 28.310 [ms], speed: 54256.920 [imgs/sec], loss=4.738
[Training][Iteration 1000][Epoch 13, Batch 76/77] lr: 0.14000, training time: 28.310 [ms], speed: 54256.920 [imgs/sec], loss=4.738
INFO:root:[Training][Epoch 13] training time: 2.181 [sec],avg speed: 54222.693 [imgs/sec],loss=5.048
[Training][Epoch 13] training time: 2.181 [sec],avg speed: 54222.693 [imgs/sec],loss=5.048
:::MLLOG {"namespace": "", "time_ms": 1592976223281, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 13}}
:::MLLOG {"namespace": "", "time_ms": 1592976223282, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 14, "current_iter_num": 0}}
INFO:root:[Training][Epoch 14] training time: 2.145 [sec],avg speed: 54415.598 [imgs/sec],loss=4.902
[Training][Epoch 14] training time: 2.145 [sec],avg speed: 54415.598 [imgs/sec],loss=4.902
:::MLLOG {"namespace": "", "time_ms": 1592976225427, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 14}}
:::MLLOG {"namespace": "", "time_ms": 1592976225427, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 15, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1100][Epoch 15, Batch 22/77] lr: 0.14000, training time: 28.307 [ms], speed: 54261.856 [imgs/sec], loss=4.456
[Training][Iteration 1100][Epoch 15, Batch 22/77] lr: 0.14000, training time: 28.307 [ms], speed: 54261.856 [imgs/sec], loss=4.456
INFO:root:[Training][Epoch 15] training time: 2.161 [sec],avg speed: 54028.376 [imgs/sec],loss=4.857
[Training][Epoch 15] training time: 2.161 [sec],avg speed: 54028.376 [imgs/sec],loss=4.857
:::MLLOG {"namespace": "", "time_ms": 1592976227588, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1592976227588, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 16, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1200][Epoch 16, Batch 45/77] lr: 0.14000, training time: 28.131 [ms], speed: 54601.011 [imgs/sec], loss=5.610
[Training][Iteration 1200][Epoch 16, Batch 45/77] lr: 0.14000, training time: 28.131 [ms], speed: 54601.011 [imgs/sec], loss=5.610
INFO:root:[Training][Epoch 16] training time: 2.165 [sec],avg speed: 54637.175 [imgs/sec],loss=4.710
[Training][Epoch 16] training time: 2.165 [sec],avg speed: 54637.175 [imgs/sec],loss=4.710
:::MLLOG {"namespace": "", "time_ms": 1592976229753, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1592976229754, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 17, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1300][Epoch 17, Batch 68/77] lr: 0.14000, training time: 28.207 [ms], speed: 54453.937 [imgs/sec], loss=4.509
[Training][Iteration 1300][Epoch 17, Batch 68/77] lr: 0.14000, training time: 28.207 [ms], speed: 54453.937 [imgs/sec], loss=4.509
INFO:root:[Training][Epoch 17] training time: 2.145 [sec],avg speed: 54428.398 [imgs/sec],loss=4.665
[Training][Epoch 17] training time: 2.145 [sec],avg speed: 54428.398 [imgs/sec],loss=4.665
:::MLLOG {"namespace": "", "time_ms": 1592976231899, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 17}}
:::MLLOG {"namespace": "", "time_ms": 1592976231899, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 18, "current_iter_num": 0}}
INFO:root:[Training][Epoch 18] training time: 2.149 [sec],avg speed: 54328.971 [imgs/sec],loss=4.623
[Training][Epoch 18] training time: 2.149 [sec],avg speed: 54328.971 [imgs/sec],loss=4.623
:::MLLOG {"namespace": "", "time_ms": 1592976234048, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1592976234048, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 19, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1400][Epoch 19, Batch 14/77] lr: 0.14000, training time: 28.179 [ms], speed: 54508.581 [imgs/sec], loss=4.245
[Training][Iteration 1400][Epoch 19, Batch 14/77] lr: 0.14000, training time: 28.179 [ms], speed: 54508.581 [imgs/sec], loss=4.245
INFO:root:[Training][Epoch 19] training time: 2.171 [sec],avg speed: 54476.786 [imgs/sec],loss=4.537
[Training][Epoch 19] training time: 2.171 [sec],avg speed: 54476.786 [imgs/sec],loss=4.537
:::MLLOG {"namespace": "", "time_ms": 1592976236219, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1592976236220, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 20, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1500][Epoch 20, Batch 37/77] lr: 0.14000, training time: 28.066 [ms], speed: 54727.882 [imgs/sec], loss=4.811
[Training][Iteration 1500][Epoch 20, Batch 37/77] lr: 0.14000, training time: 28.066 [ms], speed: 54727.882 [imgs/sec], loss=4.811
INFO:root:[Training][Epoch 20] training time: 2.137 [sec],avg speed: 54615.013 [imgs/sec],loss=4.292
[Training][Epoch 20] training time: 2.137 [sec],avg speed: 54615.013 [imgs/sec],loss=4.292
:::MLLOG {"namespace": "", "time_ms": 1592976238357, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1592976238358, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 21, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1600][Epoch 21, Batch 60/77] lr: 0.14000, training time: 28.100 [ms], speed: 54661.524 [imgs/sec], loss=4.152
[Training][Iteration 1600][Epoch 21, Batch 60/77] lr: 0.14000, training time: 28.100 [ms], speed: 54661.524 [imgs/sec], loss=4.152
INFO:root:[Training][Epoch 21] training time: 2.140 [sec],avg speed: 54555.414 [imgs/sec],loss=4.447
[Training][Epoch 21] training time: 2.140 [sec],avg speed: 54555.414 [imgs/sec],loss=4.447
:::MLLOG {"namespace": "", "time_ms": 1592976240497, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 21}}
:::MLLOG {"namespace": "", "time_ms": 1592976240498, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 22, "current_iter_num": 0}}
INFO:root:[Training][Epoch 22] training time: 2.173 [sec],avg speed: 54427.344 [imgs/sec],loss=4.421
[Training][Epoch 22] training time: 2.173 [sec],avg speed: 54427.344 [imgs/sec],loss=4.421
:::MLLOG {"namespace": "", "time_ms": 1592976242671, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 22}}
:::MLLOG {"namespace": "", "time_ms": 1592976242671, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 23, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1700][Epoch 23, Batch 6/77] lr: 0.14000, training time: 28.419 [ms], speed: 54047.407 [imgs/sec], loss=3.750
[Training][Iteration 1700][Epoch 23, Batch 6/77] lr: 0.14000, training time: 28.419 [ms], speed: 54047.407 [imgs/sec], loss=3.750
INFO:root:[Training][Epoch 23] training time: 2.141 [sec],avg speed: 54517.551 [imgs/sec],loss=4.287
[Training][Epoch 23] training time: 2.141 [sec],avg speed: 54517.551 [imgs/sec],loss=4.287
:::MLLOG {"namespace": "", "time_ms": 1592976244813, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1592976244813, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 24, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1800][Epoch 24, Batch 29/77] lr: 0.14000, training time: 28.211 [ms], speed: 54447.605 [imgs/sec], loss=3.415
[Training][Iteration 1800][Epoch 24, Batch 29/77] lr: 0.14000, training time: 28.211 [ms], speed: 54447.605 [imgs/sec], loss=3.415
INFO:root:[Training][Epoch 24] training time: 2.142 [sec],avg speed: 54496.890 [imgs/sec],loss=4.259
[Training][Epoch 24] training time: 2.142 [sec],avg speed: 54496.890 [imgs/sec],loss=4.259
:::MLLOG {"namespace": "", "time_ms": 1592976246955, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1592976246956, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 25, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1900][Epoch 25, Batch 52/77] lr: 0.14000, training time: 28.131 [ms], speed: 54602.310 [imgs/sec], loss=4.231
[Training][Iteration 1900][Epoch 25, Batch 52/77] lr: 0.14000, training time: 28.131 [ms], speed: 54602.310 [imgs/sec], loss=4.231
INFO:root:[Training][Epoch 25] training time: 2.167 [sec],avg speed: 54576.301 [imgs/sec],loss=4.268
[Training][Epoch 25] training time: 2.167 [sec],avg speed: 54576.301 [imgs/sec],loss=4.268
:::MLLOG {"namespace": "", "time_ms": 1592976249123, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 25}}
:::MLLOG {"namespace": "", "time_ms": 1592976249123, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 26, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2000][Epoch 26, Batch 75/77] lr: 0.14000, training time: 28.219 [ms], speed: 54432.324 [imgs/sec], loss=4.088
[Training][Iteration 2000][Epoch 26, Batch 75/77] lr: 0.14000, training time: 28.219 [ms], speed: 54432.324 [imgs/sec], loss=4.088
INFO:root:[Training][Epoch 26] training time: 2.146 [sec],avg speed: 54391.932 [imgs/sec],loss=4.244
[Training][Epoch 26] training time: 2.146 [sec],avg speed: 54391.932 [imgs/sec],loss=4.244
:::MLLOG {"namespace": "", "time_ms": 1592976251270, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 26}}
:::MLLOG {"namespace": "", "time_ms": 1592976251270, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 27, "current_iter_num": 0}}
INFO:root:[Training][Epoch 27] training time: 2.139 [sec],avg speed: 54584.583 [imgs/sec],loss=4.249
[Training][Epoch 27] training time: 2.139 [sec],avg speed: 54584.583 [imgs/sec],loss=4.249
:::MLLOG {"namespace": "", "time_ms": 1592976253409, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1592976253409, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 28, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2100][Epoch 28, Batch 21/77] lr: 0.14000, training time: 28.191 [ms], speed: 54485.520 [imgs/sec], loss=4.329
[Training][Iteration 2100][Epoch 28, Batch 21/77] lr: 0.14000, training time: 28.191 [ms], speed: 54485.520 [imgs/sec], loss=4.329
INFO:root:[Training][Epoch 28] training time: 2.166 [sec],avg speed: 54598.093 [imgs/sec],loss=4.166
[Training][Epoch 28] training time: 2.166 [sec],avg speed: 54598.093 [imgs/sec],loss=4.166
:::MLLOG {"namespace": "", "time_ms": 1592976255576, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1592976255576, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 29, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2200][Epoch 29, Batch 44/77] lr: 0.14000, training time: 28.135 [ms], speed: 54593.330 [imgs/sec], loss=4.551
[Training][Iteration 2200][Epoch 29, Batch 44/77] lr: 0.14000, training time: 28.135 [ms], speed: 54593.330 [imgs/sec], loss=4.551
INFO:root:[Training][Epoch 29] training time: 2.137 [sec],avg speed: 54622.605 [imgs/sec],loss=4.188
[Training][Epoch 29] training time: 2.137 [sec],avg speed: 54622.605 [imgs/sec],loss=4.188
:::MLLOG {"namespace": "", "time_ms": 1592976257713, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 29}}
:::MLLOG {"namespace": "", "time_ms": 1592976257714, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 30, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2300][Epoch 30, Batch 67/77] lr: 0.14000, training time: 28.027 [ms], speed: 54803.355 [imgs/sec], loss=4.366
[Training][Iteration 2300][Epoch 30, Batch 67/77] lr: 0.14000, training time: 28.027 [ms], speed: 54803.355 [imgs/sec], loss=4.366
INFO:root:[Training][Epoch 30] training time: 2.132 [sec],avg speed: 54756.078 [imgs/sec],loss=4.062
[Training][Epoch 30] training time: 2.132 [sec],avg speed: 54756.078 [imgs/sec],loss=4.062
:::MLLOG {"namespace": "", "time_ms": 1592976259846, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 30}}
:::MLLOG {"namespace": "", "time_ms": 1592976259846, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 31, "current_iter_num": 0}}
INFO:root:[Training][Epoch 31] training time: 2.184 [sec],avg speed: 54163.620 [imgs/sec],loss=4.145
[Training][Epoch 31] training time: 2.184 [sec],avg speed: 54163.620 [imgs/sec],loss=4.145
:::MLLOG {"namespace": "", "time_ms": 1592976262030, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1592976262030, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 32, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2400][Epoch 32, Batch 13/77] lr: 0.14000, training time: 28.180 [ms], speed: 54507.109 [imgs/sec], loss=3.670
[Training][Iteration 2400][Epoch 32, Batch 13/77] lr: 0.14000, training time: 28.180 [ms], speed: 54507.109 [imgs/sec], loss=3.670
INFO:root:[Training][Epoch 32] training time: 2.139 [sec],avg speed: 54576.107 [imgs/sec],loss=4.116
[Training][Epoch 32] training time: 2.139 [sec],avg speed: 54576.107 [imgs/sec],loss=4.116
:::MLLOG {"namespace": "", "time_ms": 1592976264169, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1592976264170, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 33, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2500][Epoch 33, Batch 36/77] lr: 0.14000, training time: 28.125 [ms], speed: 54613.485 [imgs/sec], loss=4.050
[Training][Iteration 2500][Epoch 33, Batch 36/77] lr: 0.14000, training time: 28.125 [ms], speed: 54613.485 [imgs/sec], loss=4.050
INFO:root:[Training][Epoch 33] training time: 2.149 [sec],avg speed: 54328.302 [imgs/sec],loss=4.122
[Training][Epoch 33] training time: 2.149 [sec],avg speed: 54328.302 [imgs/sec],loss=4.122
:::MLLOG {"namespace": "", "time_ms": 1592976266318, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 33}}
:::MLLOG {"namespace": "", "time_ms": 1592976266319, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 34, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2600][Epoch 34, Batch 59/77] lr: 0.14000, training time: 28.111 [ms], speed: 54640.860 [imgs/sec], loss=4.365
[Training][Iteration 2600][Epoch 34, Batch 59/77] lr: 0.14000, training time: 28.111 [ms], speed: 54640.860 [imgs/sec], loss=4.365
INFO:root:[Training][Epoch 34] training time: 2.170 [sec],avg speed: 54506.943 [imgs/sec],loss=3.966
[Training][Epoch 34] training time: 2.170 [sec],avg speed: 54506.943 [imgs/sec],loss=3.966
:::MLLOG {"namespace": "", "time_ms": 1592976268489, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 34}}
:::MLLOG {"namespace": "", "time_ms": 1592976268489, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 35, "current_iter_num": 0}}
INFO:root:[Training][Epoch 35] training time: 2.138 [sec],avg speed: 54589.214 [imgs/sec],loss=3.988
[Training][Epoch 35] training time: 2.138 [sec],avg speed: 54589.214 [imgs/sec],loss=3.988
:::MLLOG {"namespace": "", "time_ms": 1592976270628, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1592976270628, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 36, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2700][Epoch 36, Batch 5/77] lr: 0.14000, training time: 28.340 [ms], speed: 54198.727 [imgs/sec], loss=3.995
[Training][Iteration 2700][Epoch 36, Batch 5/77] lr: 0.14000, training time: 28.340 [ms], speed: 54198.727 [imgs/sec], loss=3.995
INFO:root:[Training][Epoch 36] training time: 2.139 [sec],avg speed: 54584.345 [imgs/sec],loss=3.991
[Training][Epoch 36] training time: 2.139 [sec],avg speed: 54584.345 [imgs/sec],loss=3.991
:::MLLOG {"namespace": "", "time_ms": 1592976272767, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 36}}
:::MLLOG {"namespace": "", "time_ms": 1592976272767, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 37, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2800][Epoch 37, Batch 28/77] lr: 0.14000, training time: 28.090 [ms], speed: 54681.596 [imgs/sec], loss=4.473
[Training][Iteration 2800][Epoch 37, Batch 28/77] lr: 0.14000, training time: 28.090 [ms], speed: 54681.596 [imgs/sec], loss=4.473
INFO:root:[Training][Epoch 37] training time: 2.167 [sec],avg speed: 54568.160 [imgs/sec],loss=4.016
[Training][Epoch 37] training time: 2.167 [sec],avg speed: 54568.160 [imgs/sec],loss=4.016
:::MLLOG {"namespace": "", "time_ms": 1592976274935, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 37}}
:::MLLOG {"namespace": "", "time_ms": 1592976274935, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 38, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2900][Epoch 38, Batch 51/77] lr: 0.14000, training time: 27.988 [ms], speed: 54881.490 [imgs/sec], loss=4.202
[Training][Iteration 2900][Epoch 38, Batch 51/77] lr: 0.14000, training time: 27.988 [ms], speed: 54881.490 [imgs/sec], loss=4.202
INFO:root:[Training][Epoch 38] training time: 2.134 [sec],avg speed: 54691.942 [imgs/sec],loss=4.018
[Training][Epoch 38] training time: 2.134 [sec],avg speed: 54691.942 [imgs/sec],loss=4.018
:::MLLOG {"namespace": "", "time_ms": 1592976277070, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 38}}
:::MLLOG {"namespace": "", "time_ms": 1592976277070, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 39, "current_iter_num": 0}}
INFO:root:[Training][Iteration 3000][Epoch 39, Batch 74/77] lr: 0.14000, training time: 28.194 [ms], speed: 54479.747 [imgs/sec], loss=3.552
[Training][Iteration 3000][Epoch 39, Batch 74/77] lr: 0.14000, training time: 28.194 [ms], speed: 54479.747 [imgs/sec], loss=3.552
INFO:root:[Training][Epoch 39] training time: 2.144 [sec],avg speed: 54447.639 [imgs/sec],loss=3.955
[Training][Epoch 39] training time: 2.144 [sec],avg speed: 54447.639 [imgs/sec],loss=3.955
:::MLLOG {"namespace": "", "time_ms": 1592976279214, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 39}}
:::MLLOG {"namespace": "", "time_ms": 1592976279214, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 40, "current_iter_num": 0}}
INFO:root:[Training][Epoch 40] training time: 2.160 [sec],avg speed: 54745.957 [imgs/sec],loss=3.966
[Training][Epoch 40] training time: 2.160 [sec],avg speed: 54745.957 [imgs/sec],loss=3.966
:::MLLOG {"namespace": "", "time_ms": 1592976281375, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1592976281386, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 243, "epoch_num": 40}}
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 775.839 [ms], allgather: 134.676 [ms], asnumpy: 4.550 [ms], speed: 5464.087 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 775.839 [ms], allgather: 134.676 [ms], asnumpy: 4.550 [ms], speed: 5464.087 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 775.089 [ms], allgather: 147.415 [ms], asnumpy: 4.577 [ms], speed: 5393.269 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 775.089 [ms], allgather: 147.415 [ms], asnumpy: 4.577 [ms], speed: 5393.269 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 806.902 [ms], allgather: 125.456 [ms], asnumpy: 4.705 [ms], speed: 5335.808 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 806.902 [ms], allgather: 125.456 [ms], asnumpy: 4.705 [ms], speed: 5335.808 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 790.405 [ms], allgather: 179.741 [ms], asnumpy: 4.686 [ms], speed: 5129.080 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 790.405 [ms], allgather: 179.741 [ms], asnumpy: 4.686 [ms], speed: 5129.080 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 745.360 [ms], allgather: 226.760 [ms], asnumpy: 4.582 [ms], speed: 5119.263 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 745.360 [ms], allgather: 226.760 [ms], asnumpy: 4.582 [ms], speed: 5119.263 [imgs/sec]
:::MLLOG {"namespace": "", "time_ms": 1592976282366, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 41, "current_iter_num": 0}}
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 799.228 [ms], allgather: 194.609 [ms], asnumpy: 5.099 [ms], speed: 5005.318 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 799.228 [ms], allgather: 194.609 [ms], asnumpy: 5.099 [ms], speed: 5005.318 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 761.032 [ms], allgather: 246.052 [ms], asnumpy: 4.650 [ms], speed: 4942.008 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 761.032 [ms], allgather: 246.052 [ms], asnumpy: 4.650 [ms], speed: 4942.008 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 752.096 [ms], allgather: 260.308 [ms], asnumpy: 5.520 [ms], speed: 4911.953 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 752.096 [ms], allgather: 260.308 [ms], asnumpy: 5.520 [ms], speed: 4911.953 [imgs/sec]
INFO:root:[Training][Iteration 3100][Epoch 41, Batch 20/77] lr: 0.14000, training time: 32.273 [ms], speed: 47593.954 [imgs/sec], loss=3.873
[Training][Iteration 3100][Epoch 41, Batch 20/77] lr: 0.14000, training time: 32.273 [ms], speed: 47593.954 [imgs/sec], loss=3.873
INFO:root:[Training][Epoch 41] training time: 2.228 [sec],avg speed: 52402.904 [imgs/sec],loss=3.889
[Training][Epoch 41] training time: 2.228 [sec],avg speed: 52402.904 [imgs/sec],loss=3.889
:::MLLOG {"namespace": "", "time_ms": 1592976284593, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1592976284594, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 42, "current_iter_num": 0}}
:::MLLOG {"namespace": "", "time_ms": 1592976284872, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 291, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1592976284872, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.1712792991629605, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 294, "epoch_num": 40}}
INFO:root:[Training][Iteration 3200][Epoch 42, Batch 43/77] lr: 0.14000, training time: 28.182 [ms], speed: 54502.120 [imgs/sec], loss=3.747
[Training][Iteration 3200][Epoch 42, Batch 43/77] lr: 0.14000, training time: 28.182 [ms], speed: 54502.120 [imgs/sec], loss=3.747
INFO:root:[Training][Epoch 42] training time: 2.140 [sec],avg speed: 54555.347 [imgs/sec],loss=3.924
[Training][Epoch 42] training time: 2.140 [sec],avg speed: 54555.347 [imgs/sec],loss=3.924
:::MLLOG {"namespace": "", "time_ms": 1592976286734, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 42}}
:::MLLOG {"namespace": "", "time_ms": 1592976286734, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 43, "current_iter_num": 0}}
INFO:root:[Training][Iteration 3300][Epoch 43, Batch 66/77] lr: 0.14000, training time: 28.225 [ms], speed: 54418.951 [imgs/sec], loss=4.326
[Training][Iteration 3300][Epoch 43, Batch 66/77] lr: 0.14000, training time: 28.225 [ms], speed: 54418.951 [imgs/sec], loss=4.326
INFO:root:[Training][Epoch 43] training time: 2.173 [sec],avg speed: 54421.093 [imgs/sec],loss=3.947
[Training][Epoch 43] training time: 2.173 [sec],avg speed: 54421.093 [imgs/sec],loss=3.947
:::MLLOG {"namespace": "", "time_ms": 1592976288907, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 43}}
:::MLLOG {"namespace": "", "time_ms": 1592976288908, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 44, "current_iter_num": 0}}
INFO:root:[Training][Epoch 44] training time: 2.142 [sec],avg speed: 54500.596 [imgs/sec],loss=3.865
[Training][Epoch 44] training time: 2.142 [sec],avg speed: 54500.596 [imgs/sec],loss=3.865
:::MLLOG {"namespace": "", "time_ms": 1592976291050, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 44}}
:::MLLOG {"namespace": "", "time_ms": 1592976291050, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 45, "current_iter_num": 0}}
INFO:root:[Training][Iteration 3400][Epoch 45, Batch 12/77] lr: 0.01400, training time: 28.062 [ms], speed: 54736.279 [imgs/sec], loss=4.004
[Training][Iteration 3400][Epoch 45, Batch 12/77] lr: 0.01400, training time: 28.062 [ms], speed: 54736.279 [imgs/sec], loss=4.004
INFO:root:[Training][Epoch 45] training time: 2.133 [sec],avg speed: 54732.078 [imgs/sec],loss=3.612
[Training][Epoch 45] training time: 2.133 [sec],avg speed: 54732.078 [imgs/sec],loss=3.612
:::MLLOG {"namespace": "", "time_ms": 1592976293183, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 45}}
:::MLLOG {"namespace": "", "time_ms": 1592976293184, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 46, "current_iter_num": 0}}
INFO:root:[Training][Iteration 3500][Epoch 46, Batch 35/77] lr: 0.01400, training time: 28.077 [ms], speed: 54705.765 [imgs/sec], loss=3.477
[Training][Iteration 3500][Epoch 46, Batch 35/77] lr: 0.01400, training time: 28.077 [ms], speed: 54705.765 [imgs/sec], loss=3.477
INFO:root:[Training][Epoch 46] training time: 2.161 [sec],avg speed: 54742.115 [imgs/sec],loss=3.541
[Training][Epoch 46] training time: 2.161 [sec],avg speed: 54742.115 [imgs/sec],loss=3.541
:::MLLOG {"namespace": "", "time_ms": 1592976295344, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 46}}
:::MLLOG {"namespace": "", "time_ms": 1592976295345, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 47, "current_iter_num": 0}}
INFO:root:[Training][Iteration 3600][Epoch 47, Batch 58/77] lr: 0.01400, training time: 28.295 [ms], speed: 54285.550 [imgs/sec], loss=3.301
[Training][Iteration 3600][Epoch 47, Batch 58/77] lr: 0.01400, training time: 28.295 [ms], speed: 54285.550 [imgs/sec], loss=3.301
INFO:root:[Training][Epoch 47] training time: 2.150 [sec],avg speed: 54304.405 [imgs/sec],loss=3.457
[Training][Epoch 47] training time: 2.150 [sec],avg speed: 54304.405 [imgs/sec],loss=3.457
:::MLLOG {"namespace": "", "time_ms": 1592976297495, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 47}}
:::MLLOG {"namespace": "", "time_ms": 1592976297495, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 48, "current_iter_num": 0}}
INFO:root:[Training][Epoch 48] training time: 2.138 [sec],avg speed: 54592.269 [imgs/sec],loss=3.543
[Training][Epoch 48] training time: 2.138 [sec],avg speed: 54592.269 [imgs/sec],loss=3.543
:::MLLOG {"namespace": "", "time_ms": 1592976299634, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 48}}
:::MLLOG {"namespace": "", "time_ms": 1592976299634, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 49, "current_iter_num": 0}}
INFO:root:[Training][Iteration 3700][Epoch 49, Batch 4/77] lr: 0.01400, training time: 28.432 [ms], speed: 54024.066 [imgs/sec], loss=3.914
[Training][Iteration 3700][Epoch 49, Batch 4/77] lr: 0.01400, training time: 28.432 [ms], speed: 54024.066 [imgs/sec], loss=3.914
INFO:root:[Training][Epoch 49] training time: 2.168 [sec],avg speed: 54553.884 [imgs/sec],loss=3.435
[Training][Epoch 49] training time: 2.168 [sec],avg speed: 54553.884 [imgs/sec],loss=3.435
:::MLLOG {"namespace": "", "time_ms": 1592976301802, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 49}}
:::MLLOG {"namespace": "", "time_ms": 1592976301802, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 50, "current_iter_num": 0}}
INFO:root:[Training][Iteration 3800][Epoch 50, Batch 27/77] lr: 0.01400, training time: 28.120 [ms], speed: 54622.930 [imgs/sec], loss=3.454
[Training][Iteration 3800][Epoch 50, Batch 27/77] lr: 0.01400, training time: 28.120 [ms], speed: 54622.930 [imgs/sec], loss=3.454
INFO:root:[Training][Epoch 50] training time: 2.135 [sec],avg speed: 54668.187 [imgs/sec],loss=3.384
[Training][Epoch 50] training time: 2.135 [sec],avg speed: 54668.187 [imgs/sec],loss=3.384
:::MLLOG {"namespace": "", "time_ms": 1592976303938, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1592976303949, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 243, "epoch_num": 50}}
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 145.725 [ms], allgather: 133.069 [ms], asnumpy: 6.500 [ms], speed: 17525.762 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 145.725 [ms], allgather: 133.069 [ms], asnumpy: 6.500 [ms], speed: 17525.762 [imgs/sec]
:::MLLOG {"namespace": "", "time_ms": 1592976304236, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 51, "current_iter_num": 0}}
INFO:root:[Validation] save_parameters: 0.015 [ms], inference: 145.255 [ms], allgather: 149.454 [ms], asnumpy: 4.698 [ms], speed: 16698.878 [imgs/sec]
[Validation] save_parameters: 0.015 [ms], inference: 145.255 [ms], allgather: 149.454 [ms], asnumpy: 4.698 [ms], speed: 16698.878 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 139.277 [ms], allgather: 166.052 [ms], asnumpy: 4.919 [ms], speed: 16116.008 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 139.277 [ms], allgather: 166.052 [ms], asnumpy: 4.919 [ms], speed: 16116.008 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 141.763 [ms], allgather: 179.909 [ms], asnumpy: 4.684 [ms], speed: 15320.617 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 141.763 [ms], allgather: 179.909 [ms], asnumpy: 4.684 [ms], speed: 15320.617 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 146.698 [ms], allgather: 186.482 [ms], asnumpy: 4.901 [ms], speed: 14789.339 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 146.698 [ms], allgather: 186.482 [ms], asnumpy: 4.901 [ms], speed: 14789.339 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 140.519 [ms], allgather: 206.928 [ms], asnumpy: 4.666 [ms], speed: 14199.900 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 140.519 [ms], allgather: 206.928 [ms], asnumpy: 4.666 [ms], speed: 14199.900 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 138.889 [ms], allgather: 221.585 [ms], asnumpy: 4.760 [ms], speed: 13689.822 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 138.889 [ms], allgather: 221.585 [ms], asnumpy: 4.760 [ms], speed: 13689.822 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 128.702 [ms], allgather: 248.413 [ms], asnumpy: 5.708 [ms], speed: 13060.826 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 128.702 [ms], allgather: 248.413 [ms], asnumpy: 5.708 [ms], speed: 13060.826 [imgs/sec]
INFO:root:[Training][Iteration 3900][Epoch 51, Batch 50/77] lr: 0.01400, training time: 30.671 [ms], speed: 50079.116 [imgs/sec], loss=3.013
[Training][Iteration 3900][Epoch 51, Batch 50/77] lr: 0.01400, training time: 30.671 [ms], speed: 50079.116 [imgs/sec], loss=3.013
:::MLLOG {"namespace": "", "time_ms": 1592976306271, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 291, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1592976306272, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.22581439437324524, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 294, "epoch_num": 50}}
INFO:root:[Training][Epoch 51] training time: 2.267 [sec],avg speed: 51497.336 [imgs/sec],loss=3.403
[Training][Epoch 51] training time: 2.267 [sec],avg speed: 51497.336 [imgs/sec],loss=3.403
:::MLLOG {"namespace": "", "time_ms": 1592976306503, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 51}}
:::MLLOG {"namespace": "", "time_ms": 1592976306503, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 52, "current_iter_num": 0}}
INFO:root:[Training][Iteration 4000][Epoch 52, Batch 73/77] lr: 0.01400, training time: 28.070 [ms], speed: 54720.044 [imgs/sec], loss=3.260
[Training][Iteration 4000][Epoch 52, Batch 73/77] lr: 0.01400, training time: 28.070 [ms], speed: 54720.044 [imgs/sec], loss=3.260
INFO:root:[Training][Epoch 52] training time: 2.163 [sec],avg speed: 54689.984 [imgs/sec],loss=3.391
[Training][Epoch 52] training time: 2.163 [sec],avg speed: 54689.984 [imgs/sec],loss=3.391
:::MLLOG {"namespace": "", "time_ms": 1592976308666, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 52}}
:::MLLOG {"namespace": "", "time_ms": 1592976308666, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 53, "current_iter_num": 0}}
INFO:root:[Training][Epoch 53] training time: 2.134 [sec],avg speed: 54710.624 [imgs/sec],loss=3.447
[Training][Epoch 53] training time: 2.134 [sec],avg speed: 54710.624 [imgs/sec],loss=3.447
:::MLLOG {"namespace": "", "time_ms": 1592976310800, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 53}}
:::MLLOG {"namespace": "", "time_ms": 1592976310800, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 54, "current_iter_num": 0}}
INFO:root:[Training][Iteration 4100][Epoch 54, Batch 19/77] lr: 0.01400, training time: 28.106 [ms], speed: 54650.303 [imgs/sec], loss=3.863
[Training][Iteration 4100][Epoch 54, Batch 19/77] lr: 0.01400, training time: 28.106 [ms], speed: 54650.303 [imgs/sec], loss=3.863
INFO:root:[Training][Epoch 54] training time: 2.148 [sec],avg speed: 54343.678 [imgs/sec],loss=3.361
[Training][Epoch 54] training time: 2.148 [sec],avg speed: 54343.678 [imgs/sec],loss=3.361
:::MLLOG {"namespace": "", "time_ms": 1592976312949, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 54}}
:::MLLOG {"namespace": "", "time_ms": 1592976312949, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 55, "current_iter_num": 0}}
INFO:root:[Training][Iteration 4200][Epoch 55, Batch 42/77] lr: 0.01400, training time: 28.180 [ms], speed: 54506.385 [imgs/sec], loss=2.874
[Training][Iteration 4200][Epoch 55, Batch 42/77] lr: 0.01400, training time: 28.180 [ms], speed: 54506.385 [imgs/sec], loss=2.874
INFO:root:[Training][Epoch 55] training time: 2.168 [sec],avg speed: 54547.609 [imgs/sec],loss=3.348
[Training][Epoch 55] training time: 2.168 [sec],avg speed: 54547.609 [imgs/sec],loss=3.348
:::MLLOG {"namespace": "", "time_ms": 1592976315118, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 55}}
:::MLLOG {"namespace": "", "time_ms": 1592976315129, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 243, "epoch_num": 55}}
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 142.074 [ms], allgather: 76.968 [ms], asnumpy: 5.049 [ms], speed: 22312.193 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 142.074 [ms], allgather: 76.968 [ms], asnumpy: 5.049 [ms], speed: 22312.193 [imgs/sec]
:::MLLOG {"namespace": "", "time_ms": 1592976315354, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 56, "current_iter_num": 0}}
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 141.940 [ms], allgather: 89.036 [ms], asnumpy: 5.090 [ms], speed: 21180.380 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 141.940 [ms], allgather: 89.036 [ms], asnumpy: 5.090 [ms], speed: 21180.380 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 144.283 [ms], allgather: 89.501 [ms], asnumpy: 4.897 [ms], speed: 20948.288 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 144.283 [ms], allgather: 89.501 [ms], asnumpy: 4.897 [ms], speed: 20948.288 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 140.977 [ms], allgather: 102.679 [ms], asnumpy: 5.267 [ms], speed: 20086.393 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 140.977 [ms], allgather: 102.679 [ms], asnumpy: 5.267 [ms], speed: 20086.393 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 139.598 [ms], allgather: 109.016 [ms], asnumpy: 5.192 [ms], speed: 19699.929 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 139.598 [ms], allgather: 109.016 [ms], asnumpy: 5.192 [ms], speed: 19699.929 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 134.540 [ms], allgather: 122.949 [ms], asnumpy: 4.669 [ms], speed: 19072.387 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 134.540 [ms], allgather: 122.949 [ms], asnumpy: 4.669 [ms], speed: 19072.387 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 137.370 [ms], allgather: 126.525 [ms], asnumpy: 4.916 [ms], speed: 18600.265 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 137.370 [ms], allgather: 126.525 [ms], asnumpy: 4.916 [ms], speed: 18600.265 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 134.331 [ms], allgather: 139.393 [ms], asnumpy: 5.156 [ms], speed: 17928.759 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 134.331 [ms], allgather: 139.393 [ms], asnumpy: 5.156 [ms], speed: 17928.759 [imgs/sec]
INFO:root:[Training][Iteration 4300][Epoch 56, Batch 65/77] lr: 0.00140, training time: 29.033 [ms], speed: 52905.601 [imgs/sec], loss=2.956
[Training][Iteration 4300][Epoch 56, Batch 65/77] lr: 0.00140, training time: 29.033 [ms], speed: 52905.601 [imgs/sec], loss=2.956
INFO:root:[Training][Epoch 56] training time: 2.208 [sec],avg speed: 52859.093 [imgs/sec],loss=3.272
[Training][Epoch 56] training time: 2.208 [sec],avg speed: 52859.093 [imgs/sec],loss=3.272
:::MLLOG {"namespace": "", "time_ms": 1592976317562, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 56}}
:::MLLOG {"namespace": "", "time_ms": 1592976317563, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 57, "current_iter_num": 0}}
:::MLLOG {"namespace": "", "time_ms": 1592976317570, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 291, "epoch_num": 55}}
:::MLLOG {"namespace": "", "time_ms": 1592976317570, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.2285590221806937, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 294, "epoch_num": 55}}
INFO:root:[Training][Epoch 57] training time: 2.139 [sec],avg speed: 54566.169 [imgs/sec],loss=3.370
[Training][Epoch 57] training time: 2.139 [sec],avg speed: 54566.169 [imgs/sec],loss=3.370
:::MLLOG {"namespace": "", "time_ms": 1592976319702, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 57}}
:::MLLOG {"namespace": "", "time_ms": 1592976319703, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 58, "current_iter_num": 0}}
INFO:root:[Training][Iteration 4400][Epoch 58, Batch 11/77] lr: 0.00140, training time: 28.163 [ms], speed: 54539.225 [imgs/sec], loss=3.787
[Training][Iteration 4400][Epoch 58, Batch 11/77] lr: 0.00140, training time: 28.163 [ms], speed: 54539.225 [imgs/sec], loss=3.787
INFO:root:[Training][Epoch 58] training time: 2.169 [sec],avg speed: 54532.540 [imgs/sec],loss=3.390
[Training][Epoch 58] training time: 2.169 [sec],avg speed: 54532.540 [imgs/sec],loss=3.390
:::MLLOG {"namespace": "", "time_ms": 1592976321872, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 58}}
:::MLLOG {"namespace": "", "time_ms": 1592976321872, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 59, "current_iter_num": 0}}
INFO:root:[Training][Iteration 4500][Epoch 59, Batch 34/77] lr: 0.00140, training time: 28.178 [ms], speed: 54510.046 [imgs/sec], loss=3.277
[Training][Iteration 4500][Epoch 59, Batch 34/77] lr: 0.00140, training time: 28.178 [ms], speed: 54510.046 [imgs/sec], loss=3.277
INFO:root:[Training][Epoch 59] training time: 2.148 [sec],avg speed: 54351.937 [imgs/sec],loss=3.323
[Training][Epoch 59] training time: 2.148 [sec],avg speed: 54351.937 [imgs/sec],loss=3.323
:::MLLOG {"namespace": "", "time_ms": 1592976324020, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 59}}
:::MLLOG {"namespace": "", "time_ms": 1592976324021, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 60, "current_iter_num": 0}}
INFO:root:[Training][Iteration 4600][Epoch 60, Batch 57/77] lr: 0.00140, training time: 28.082 [ms], speed: 54696.318 [imgs/sec], loss=3.830
[Training][Iteration 4600][Epoch 60, Batch 57/77] lr: 0.00140, training time: 28.082 [ms], speed: 54696.318 [imgs/sec], loss=3.830
INFO:root:[Training][Epoch 60] training time: 2.136 [sec],avg speed: 54644.710 [imgs/sec],loss=3.340
[Training][Epoch 60] training time: 2.136 [sec],avg speed: 54644.710 [imgs/sec],loss=3.340
:::MLLOG {"namespace": "", "time_ms": 1592976326157, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 60}}
:::MLLOG {"namespace": "", "time_ms": 1592976326168, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 243, "epoch_num": 60}}
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 139.774 [ms], allgather: 84.480 [ms], asnumpy: 4.951 [ms], speed: 21814.452 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 139.774 [ms], allgather: 84.480 [ms], asnumpy: 4.951 [ms], speed: 21814.452 [imgs/sec]
:::MLLOG {"namespace": "", "time_ms": 1592976326398, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 61, "current_iter_num": 0}}
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 154.123 [ms], allgather: 79.134 [ms], asnumpy: 4.668 [ms], speed: 21014.916 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 154.123 [ms], allgather: 79.134 [ms], asnumpy: 4.668 [ms], speed: 21014.916 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 121.157 [ms], allgather: 117.816 [ms], asnumpy: 5.041 [ms], speed: 20490.385 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 121.157 [ms], allgather: 117.816 [ms], asnumpy: 5.041 [ms], speed: 20490.385 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 140.626 [ms], allgather: 106.181 [ms], asnumpy: 4.867 [ms], speed: 19866.806 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 140.626 [ms], allgather: 106.181 [ms], asnumpy: 4.867 [ms], speed: 19866.806 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 142.122 [ms], allgather: 110.721 [ms], asnumpy: 5.075 [ms], speed: 19385.872 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 142.122 [ms], allgather: 110.721 [ms], asnumpy: 5.075 [ms], speed: 19385.872 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 131.841 [ms], allgather: 129.702 [ms], asnumpy: 4.618 [ms], speed: 18785.574 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 131.841 [ms], allgather: 129.702 [ms], asnumpy: 4.618 [ms], speed: 18785.574 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 121.570 [ms], allgather: 146.092 [ms], asnumpy: 4.957 [ms], speed: 18340.502 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 121.570 [ms], allgather: 146.092 [ms], asnumpy: 4.957 [ms], speed: 18340.502 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 139.786 [ms], allgather: 136.127 [ms], asnumpy: 5.580 [ms], speed: 17762.344 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 139.786 [ms], allgather: 136.127 [ms], asnumpy: 5.580 [ms], speed: 17762.344 [imgs/sec]
:::MLLOG {"namespace": "", "time_ms": 1592976328632, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 291, "epoch_num": 60}}
:::MLLOG {"namespace": "", "time_ms": 1592976328632, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.23356902526944787, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 294, "epoch_num": 60}}
INFO:root:[Training][Epoch 61] training time: 2.237 [sec],avg speed: 52859.840 [imgs/sec],loss=3.314
[Training][Epoch 61] training time: 2.237 [sec],avg speed: 52859.840 [imgs/sec],loss=3.314
:::MLLOG {"namespace": "", "time_ms": 1592976328636, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 61}}
:::MLLOG {"namespace": "", "time_ms": 1592976328636, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 520, "status": "success"}}
INFO:root:Rank 0 done. map=23.356902526944786 @ epoch=60
Rank 0 done. map=23.356902526944786 @ epoch=60
INFO:root:Rank 56 done. map=23.356902526944786 @ epoch=-1
Rank 56 done. map=23.356902526944786 @ epoch=-1
INFO:root:Rank 24 done. map=23.356902526944786 @ epoch=-1
Rank 24 done. map=23.356902526944786 @ epoch=-1
INFO:root:Rank 48 done. map=23.356902526944786 @ epoch=-1
Rank 48 done. map=23.356902526944786 @ epoch=-1
INFO:root:Rank 16 done. map=23.356902526944786 @ epoch=-1
Rank 16 done. map=23.356902526944786 @ epoch=-1
INFO:root:Rank 40 done. map=23.356902526944786 @ epoch=-1
Rank 40 done. map=23.356902526944786 @ epoch=-1
INFO:root:Rank 8 done. map=23.356902526944786 @ epoch=-1
Rank 8 done. map=23.356902526944786 @ epoch=-1
INFO:root:Rank 32 done. map=23.356902526944786 @ epoch=-1
Rank 32 done. map=23.356902526944786 @ epoch=-1
loading annotations into memory...
Done (t=0.11s)
creating index...
Loading and preparing results...
DONE (t=0.24s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=1.55s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.17128
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.31347
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.17204
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.25241
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.18084
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.26186
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.27069
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.27069
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
Loading and preparing results...
DONE (t=0.37s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=1.57s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22581
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.38373
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23329
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.30848
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.21896
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.31502
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.32687
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.32687
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
Loading and preparing results...
DONE (t=0.42s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=1.71s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22856
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.38758
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23564
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.31123
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22038
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.31788
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.32918
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.32918
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
Loading and preparing results...
DONE (t=0.42s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=1.72s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.23357
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.39331
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.24292
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.31584
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22468
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32277
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33429
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.33429
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2020-06-23 10:25:35 PM
RESULT,SINGLE_STAGE_DETECTOR,,173,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:35 PM
RESULT,SINGLE_STAGE_DETECTOR,,173,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:35 PM
RESULT,SINGLE_STAGE_DETECTOR,,173,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:35 PM
RESULT,SINGLE_STAGE_DETECTOR,,173,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:35 PM
RESULT,SINGLE_STAGE_DETECTOR,,173,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:35 PM
RESULT,SINGLE_STAGE_DETECTOR,,173,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:35 PM
RESULT,SINGLE_STAGE_DETECTOR,,173,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:35 PM
RESULT,SINGLE_STAGE_DETECTOR,,173,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
ENDING TIMING RUN AT 2020-06-23 10:25:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:22:42 PM
