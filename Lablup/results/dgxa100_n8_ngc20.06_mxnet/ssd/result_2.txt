+ echo 'Beginning trial 2 of 5'
Beginning trial 2 of 5
+ srun -N1 -n1 --container-name=single_stage_detector python -c '
import mlperf_log_utils
from mlperf_logging.mllog import constants
mlperf_log_utils.mlperf_submission_log(constants.SSD)'
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
:::MLLOG {"namespace": "", "time_ms": 1592975768699, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "ssd", "metadata": {"file": "/workspace/ssd/mlperf_log_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1592975768706, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "NVIDIA", "metadata": {"file": "/workspace/ssd/mlperf_log_utils.py", "lineno": 80}}
:::MLLOG {"namespace": "", "time_ms": 1592975768706, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/ssd/mlperf_log_utils.py", "lineno": 84}}
:::MLLOG {"namespace": "", "time_ms": 1592975768706, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/ssd/mlperf_log_utils.py", "lineno": 88}}
:::MLLOG {"namespace": "", "time_ms": 1592975768706, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "8xNVIDIA DGX A100", "metadata": {"file": "/workspace/ssd/mlperf_log_utils.py", "lineno": 92}}
+ '[' 1 -eq 1 ']'
+ srun --ntasks=8 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0205
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0212
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0211
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0208
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0210
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0207
Clearing cache on luna-0209
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0206
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=8 --container-name=single_stage_detector python -c '
from mlperf_logging.mllog import constants
from mlperf_log_utils import log_event
log_event(key=constants.CACHE_CLEAR, value=True)'
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
:::MLLOG {"namespace": "", "time_ms": 1592975773453, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
+ srun --mpi=pmix --ntasks=64 --ntasks-per-node=8 --container-name=single_stage_detector --container-mounts=/raid/datasets/coco/coco-2017:/data,/lustre/fsw/mlperf-ci/14140760/results:/results,/raid/datasets/coco/coco-2017/coco2017/models:/pretrained/mxnet ./run_and_time.sh
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ declare -a CMD
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ '[' -n 7 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 64 -gt 8 ']'
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ '[' -n 7 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ '[' -n 1 ']'
+ '[' -n 5 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 3 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 6 ']'
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ NUMEPOCHS=80
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 1 ']'
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ '[' 64 -gt 8 ']'
+ cluster=
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ '[' -n 4 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ '[' -n 5 ']'
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ '[' 64 -gt 8 ']'
+ cluster=
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ export PRETRAINED_DIR=/pretrained/mxnet
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ PRETRAINED_DIR=/pretrained/mxnet
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ declare -a CMD
+ '[' -n 2 ']'
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ '[' -n 0 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
running benchmark
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ '[' -n 1 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ NUMEPOCHS=80
+ echo 'running benchmark'
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
running benchmark
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' -n 2 ']'
+ '[' -n 6 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ NUMEPOCHS=80
+ echo 'running benchmark'
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ '[' -n 1 ']'
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ '[' -n 4 ']'
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ '[' 64 -gt 8 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
running benchmark
+ NUMEPOCHS=80
+ declare -a CMD
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 1 ']'
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ '[' -n 4 ']'
+ '[' 64 -gt 8 ']'
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' 64 -gt 8 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ '[' -n 7 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ declare -a CMD
+ '[' -n 0 ']'
+ NUMEPOCHS=80
+ '[' 64 -gt 8 ']'
+ echo 'running benchmark'
+ cluster=
running benchmark
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ '[' -n 7 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ NUMEPOCHS=80
+ '[' -n 3 ']'
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ '[' 64 -gt 8 ']'
+ cluster=
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ '[' -n 3 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 64 -gt 8 ']'
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ NUMEPOCHS=80
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ '[' -n 1 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 0 ']'
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ NUMEPOCHS=80
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ '[' -n 5 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ '[' -n 6 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ NUMEPOCHS=80
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ echo 'running benchmark'
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 2 ']'
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ '[' -n 7 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
running benchmark
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' -n 3 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:16:15 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
:::MLLOG {"namespace": "", "time_ms": 1592975779274, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779283, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779304, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779284, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779291, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779299, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779298, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779291, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779301, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779300, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779303, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779315, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779294, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779305, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779299, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779491, "event_type": "POINT_IN_TIME", "key": "sgd", "value": 937362128, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 193}}
:::MLLOG {"namespace": "", "time_ms": 1592975779309, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779313, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779296, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779306, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779322, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779315, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779318, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779319, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779308, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779325, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779321, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779319, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779316, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779327, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779325, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779324, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779330, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779332, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779329, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779324, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779323, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779332, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779323, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779334, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779334, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779329, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779329, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779326, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779330, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779336, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779337, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779341, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779340, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779338, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779321, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779353, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779357, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779326, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779325, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779357, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779330, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779357, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779331, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779358, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779357, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779331, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779331, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779364, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779364, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975779623, "event_type": "POINT_IN_TIME", "key": "seed", "value": 937362128, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 218}}
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=937362168, start_epoch=1, syntheticabout to model_zoo.get_model( resnet34_v1 )
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=937362184, start_epoch=1, syntheticabout to model_zoo.get_model( resnet34_v1 )
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=937362160, start_epoch=1, syntheticabout to model_zoo.get_model( resnet34_v1 )
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=937362176, start_epoch=1, syntheticabout to model_zoo.get_model( resnet34_v1 )
=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=937362152, start_epoch=1, syntheticabout to model_zoo.get_model( resnet34_v1 )
=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=937362168, start_epoch=1, synthetic=False, taabout to model_zoo.get_model( resnet34_v1 )
=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=937362184, start_epoch=1, synthetic=False, taabout to model_zoo.get_model( resnet34_v1 )
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=937362160, start_epoch=1, synthetic=False, taabout to model_zoo.get_model( resnet34_v1 )
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=937362176, start_epoch=1, synthetic=False, taabout to model_zoo.get_model( resnet34_v1 )
rget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
rget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
rget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
rget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Seed: 937362184
Seed: 937362184
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=937362136, start_epoch=1, syntheticabout to model_zoo.get_model( resnet34_v1 )
INFO:root:Seed: 937362176
Seed: 937362176
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Seed: 937362168
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=937362128, start_epoch=1, syntheticabout to model_zoo.get_model( resnet34_v1 )
=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Seed: 937362160
Seed: 937362160
about to model_zoo.get_model( resnet34_v1 )
=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
INFO:root:precision: fp16
precision: fp16
about to model_zoo.get_model( resnet34_v1 )
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=937362136, start_epoch=1, synthetic=False, taabout to model_zoo.get_model( resnet34_v1 )
INFO:root:loss scaling: 128.0
loss scaling: 128.0
about to model_zoo.get_model( resnet34_v1 )
rget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
Seed: 937362168
about to model_zoo.get_model( resnet34_v1 )
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=937362128, start_epoch=1, synthetic=False, taabout to model_zoo.get_model( resnet34_v1 )
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=937362144, start_epoch=1, syntheticabout to model_zoo.get_model( resnet34_v1 )
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=937362152, start_epoch=1, synthetic=False, taabout to model_zoo.get_model( resnet34_v1 )
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
about to model_zoo.get_model( resnet34_v1 )
rget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
rget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
INFO:root:fuse bn relu: True
fuse bn relu: True
about to model_zoo.get_model( resnet34_v1 )
INFO:root:precision: fp16
precision: fp16
about to model_zoo.get_model( resnet34_v1 )
INFO:root:precision: fp16
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Seed: 937362128
Seed: 937362128
about to model_zoo.get_model( resnet34_v1 )
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=937362144, start_epoch=1, synthetic=False, taabout to model_zoo.get_model( resnet34_v1 )
INFO:root:fuse bn add relu: True
fuse bn add relu: True
about to model_zoo.get_model( resnet34_v1 )
precision: fp16
about to model_zoo.get_model( resnet34_v1 )
INFO:root:precision: fp16
precision: fp16
about to model_zoo.get_model( resnet34_v1 )
rget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Seed: 937362152
about to model_zoo.get_model( resnet34_v1 )
INFO:root:precision: fp16
precision: fp16
about to model_zoo.get_model( resnet34_v1 )
INFO:root:loss scaling: 128.0
loss scaling: 128.0
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Seed: 937362144
about to model_zoo.get_model( resnet34_v1 )
INFO:root:bn group: 1
bn group: 1
about to model_zoo.get_model( resnet34_v1 )
INFO:root:loss scaling: 128.0
loss scaling: 128.0
about to model_zoo.get_model( resnet34_v1 )
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
about to model_zoo.get_model( resnet34_v1 )
Seed: 937362152
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Seed: 937362136
Seed: 937362136
about to model_zoo.get_model( resnet34_v1 )
INFO:root:loss scaling: 128.0
about to model_zoo.get_model( resnet34_v1 )
INFO:root:loss scaling: 128.0
about to model_zoo.get_model( resnet34_v1 )
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
about to model_zoo.get_model( resnet34_v1 )
Seed: 937362144
about to model_zoo.get_model( resnet34_v1 )
INFO:root:precision: fp16
about to model_zoo.get_model( resnet34_v1 )
INFO:root:precision: fp16
about to model_zoo.get_model( resnet34_v1 )
loss scaling: 128.0
about to model_zoo.get_model( resnet34_v1 )
loss scaling: 128.0
about to model_zoo.get_model( resnet34_v1 )
INFO:root:precision: fp16
precision: fp16
precision: fp16
precision: fp16
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
INFO:root:fuse bn relu: True
fuse bn relu: True
INFO:root:fuse bn relu: True
INFO:root:loss scaling: 128.0
loss scaling: 128.0
INFO:root:loss scaling: 128.0
INFO:root:bn all reduce fp16: False
bn all reduce fp16: False
INFO:root:loss scaling: 128.0
loss scaling: 128.0
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
fuse bn relu: True
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
loss scaling: 128.0
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
INFO:root:fuse bn relu: True
fuse bn relu: True
INFO:root:fuse bn relu: True
fuse bn relu: True
INFO:root:fuse bn add relu: True
fuse bn add relu: True
INFO:root:fuse bn relu: True
fuse bn relu: True
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
INFO:root:fuse bn relu: True
fuse bn relu: True
INFO:root:fuse bn add relu: True
fuse bn add relu: True
INFO:root:fuse bn add relu: True
fuse bn add relu: True
INFO:root:fuse bn add relu: True
INFO:root:bn group: 1
bn group: 1
INFO:root:fuse bn add relu: True
fuse bn add relu: True
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
INFO:root:MPI size: 64
INFO:root:fuse bn add relu: True
fuse bn add relu: True
INFO:root:bn group: 1
bn group: 1
INFO:root:bn group: 1
bn group: 1
fuse bn add relu: True
INFO:root:bn all reduce fp16: False
bn all reduce fp16: False
INFO:root:bn group: 1
bn group: 1
INFO:root:fuse bn relu: True
fuse bn relu: True
MPI size: 64
INFO:root:bn group: 1
bn group: 1
INFO:root:bn all reduce fp16: False
bn all reduce fp16: False
INFO:root:bn all reduce fp16: False
bn all reduce fp16: False
INFO:root:bn group: 1
bn group: 1
INFO:root:MPI size: 64
MPI size: 64
INFO:root:bn all reduce fp16: False
bn all reduce fp16: False
INFO:root:fuse bn add relu: True
fuse bn add relu: True
INFO:root:MPI global rank: 56
INFO:root:bn all reduce fp16: False
bn all reduce fp16: False
INFO:root:MPI size: 64
MPI size: 64
INFO:root:MPI size: 64
MPI size: 64
INFO:root:bn all reduce fp16: False
bn all reduce fp16: False
INFO:root:MPI global rank: 0
MPI global rank: 0
INFO:root:MPI size: 64
MPI size: 64
INFO:root:bn group: 1
MPI global rank: 56
INFO:root:MPI size: 64
MPI size: 64
INFO:root:MPI global rank: 32
MPI global rank: 32
INFO:root:MPI global rank: 48
MPI global rank: 48
INFO:root:MPI size: 64
MPI size: 64
INFO:root:MPI local rank: 0
MPI local rank: 0
INFO:root:MPI global rank: 16
MPI global rank: 16
bn group: 1
INFO:root:MPI local rank: 0
INFO:root:MPI global rank: 8
MPI global rank: 8
INFO:root:MPI global rank: 40
MPI global rank: 40
INFO:root:async validation: True
async validation: True
INFO:root:MPI local rank: 0
MPI local rank: 0
INFO:root:bn all reduce fp16: False
bn all reduce fp16: False
MPI local rank: 0
INFO:root:MPI local rank: 0
MPI local rank: 0
INFO:root:MPI local rank: 0
MPI local rank: 0
INFO:root:MPI local rank: 0
MPI local rank: 0
INFO:root:[SSD] network: resnet34_v1
[SSD] network: resnet34_v1
INFO:root:MPI size: 64
INFO:root:async validation: True
INFO:root:MPI local rank: 0
MPI local rank: 0
INFO:root:async validation: True
async validation: True
INFO:root:async validation: True
async validation: True
INFO:root:async validation: True
async validation: True
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
INFO:root:async validation: True
async validation: True
MPI size: 64
async validation: True
INFO:root:async validation: True
async validation: True
INFO:root:[SSD] network: resnet34_v1
[SSD] network: resnet34_v1
INFO:root:[SSD] network: resnet34_v1
[SSD] network: resnet34_v1
INFO:root:[SSD] network: resnet34_v1
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
INFO:root:[SSD] network: resnet34_v1
[SSD] network: resnet34_v1
INFO:root:MPI global rank: 24
MPI global rank: 24
INFO:root:[SSD] network: resnet34_v1
[SSD] network: resnet34_v1
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
[SSD] network: resnet34_v1
INFO:root:[SSD] fuse bn add relu: True
[SSD] fuse bn add relu: True
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
INFO:root:MPI local rank: 0
INFO:root:[SSD] network: resnet34_v1
[SSD] network: resnet34_v1
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
INFO:root:[SSD] bn group: 1
[SSD] bn group: 1
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
INFO:root:[SSD] fuse bn add relu: True
[SSD] fuse bn add relu: True
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
INFO:root:[SSD] fuse bn add relu: True
[SSD] fuse bn add relu: True
MPI local rank: 0
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
INFO:root:[SSD] fuse bn add relu: True
[SSD] fuse bn add relu: True
INFO:root:[SSD] bn group: 1
[SSD] bn group: 1
INFO:root:[SSD] fuse bn add relu: True
[SSD] fuse bn add relu: True
INFO:root:[SSD] bn group: 1
[SSD] bn group: 1
INFO:root:[SSD] fuse bn add relu: True
[SSD] fuse bn add relu: True
INFO:root:[SSD] fuse bn add relu: True
[SSD] fuse bn add relu: True
INFO:root:[SSD] bn group: 1
[SSD] bn group: 1
INFO:root:[SSD] bn group: 1
[SSD] bn group: 1
INFO:root:async validation: True
async validation: True
INFO:root:[SSD] bn group: 1
[SSD] bn group: 1
INFO:root:[SSD] bn group: 1
[SSD] bn group: 1
INFO:root:[SSD] network: resnet34_v1
[SSD] network: resnet34_v1
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
INFO:root:[SSD] fuse bn add relu: True
[SSD] fuse bn add relu: True
INFO:root:[SSD] bn group: 1
[SSD] bn group: 1
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:COCO reader: raw images
COCO reader: raw images
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:COCO reader: raw images
COCO reader: raw images
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
:::MLLOG {"namespace": "", "time_ms": 1592975781851, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 117266, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 363}}
:::MLLOG {"namespace": "", "time_ms": 1592975781852, "event_type": "POINT_IN_TIME", "key": "max_samples", "value": 1, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 364}}
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
:::MLLOG {"namespace": "", "time_ms": 1592975781853, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 839, "metadata": {"file": "/workspace/ssd/lr_scheduler.py", "lineno": 30}}
:::MLLOG {"namespace": "", "time_ms": 1592975781853, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_factor", "value": 0, "metadata": {"file": "/workspace/ssd/lr_scheduler.py", "lineno": 31}}
:::MLLOG {"namespace": "", "time_ms": 1592975781853, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.14, "metadata": {"file": "/workspace/ssd/lr_scheduler.py", "lineno": 36}}
:::MLLOG {"namespace": "", "time_ms": 1592975781853, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_boundary_epochs", "value": [44, 55], "metadata": {"file": "/workspace/ssd/lr_scheduler.py", "lineno": 37}}
INFO:root:COCO reader: raw images
COCO reader: raw images
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
:::MLLOG {"namespace": "", "time_ms": 1592975782531, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 5000, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 407}}
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
:::MLLOG {"namespace": "", "time_ms": 1592975786397, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.00017, "metadata": {"file": "/workspace/ssd/trainer.py", "lineno": 29}}
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[22:16:28] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:28] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:28] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:28] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:28] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:28] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:28] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:28] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:28] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[22:16:28] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:28] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:28] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:28] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:28] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:28] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:28] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:28] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:28] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:28] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:28] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:28] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:28] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:28] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:16:29] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
INFO:root:Done
Done
INFO:root:Done
Done
INFO:root:Done
Done
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
INFO:root:Done
Done
INFO:root:Done
Done
INFO:root:Done
Done
INFO:root:Done
Done
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
INFO:root:Done
Done
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
:::MLLOG {"namespace": "", "time_ms": 1592975808209, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 495}}
:::MLLOG {"namespace": "", "time_ms": 1592975808210, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 499}}
INFO:root:Training from epoch: 1
Training from epoch: 1
INFO:root:Training from epoch: 1
Training from epoch: 1
INFO:root:Training from epoch: 1
Training from epoch: 1
INFO:root:Training from epoch: 1
Training from epoch: 1
INFO:root:Training from epoch: 1
Training from epoch: 1
INFO:root:Training from epoch: 1
Training from epoch: 1
INFO:root:Training from epoch: 1
Training from epoch: 1
:::MLLOG {"namespace": "", "time_ms": 1592975809224, "event_type": "POINT_IN_TIME", "key": "model_bn_span", "value": 24, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 101}}
:::MLLOG {"namespace": "", "time_ms": 1592975809224, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 1536, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 102}}
INFO:root:Training from epoch: 1
Training from epoch: 1
:::MLLOG {"namespace": "", "time_ms": 1592975809225, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 1, "current_iter_num": 0}}
INFO:root:[Training][Epoch 1] training time: 2.441 [sec],avg speed: 48458.725 [imgs/sec],loss=16.643
[Training][Epoch 1] training time: 2.441 [sec],avg speed: 48458.725 [imgs/sec],loss=16.643
:::MLLOG {"namespace": "", "time_ms": 1592975811665, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1592975811666, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 2, "current_iter_num": 0}}
INFO:root:[Training][Iteration 100][Epoch 2, Batch 23/77] lr: 0.01669, training time: 28.972 [ms], speed: 53017.154 [imgs/sec], loss=9.325
[Training][Iteration 100][Epoch 2, Batch 23/77] lr: 0.01669, training time: 28.972 [ms], speed: 53017.154 [imgs/sec], loss=9.325
INFO:root:[Training][Epoch 2] training time: 2.197 [sec],avg speed: 53125.545 [imgs/sec],loss=9.144
[Training][Epoch 2] training time: 2.197 [sec],avg speed: 53125.545 [imgs/sec],loss=9.144
:::MLLOG {"namespace": "", "time_ms": 1592975813863, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1592975813864, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 3, "current_iter_num": 0}}
INFO:root:[Training][Iteration 200][Epoch 3, Batch 46/77] lr: 0.03337, training time: 28.913 [ms], speed: 53125.215 [imgs/sec], loss=8.437
[Training][Iteration 200][Epoch 3, Batch 46/77] lr: 0.03337, training time: 28.913 [ms], speed: 53125.215 [imgs/sec], loss=8.437
INFO:root:[Training][Epoch 3] training time: 2.183 [sec],avg speed: 53466.057 [imgs/sec],loss=8.226
[Training][Epoch 3] training time: 2.183 [sec],avg speed: 53466.057 [imgs/sec],loss=8.226
:::MLLOG {"namespace": "", "time_ms": 1592975816047, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975816047, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 4, "current_iter_num": 0}}
INFO:root:[Training][Iteration 300][Epoch 4, Batch 69/77] lr: 0.05006, training time: 28.903 [ms], speed: 53142.890 [imgs/sec], loss=7.419
[Training][Iteration 300][Epoch 4, Batch 69/77] lr: 0.05006, training time: 28.903 [ms], speed: 53142.890 [imgs/sec], loss=7.419
INFO:root:[Training][Epoch 4] training time: 2.222 [sec],avg speed: 53237.311 [imgs/sec],loss=7.664
[Training][Epoch 4] training time: 2.222 [sec],avg speed: 53237.311 [imgs/sec],loss=7.664
:::MLLOG {"namespace": "", "time_ms": 1592975818269, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592975818269, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 5, "current_iter_num": 0}}
INFO:root:[Training][Epoch 5] training time: 2.185 [sec],avg speed: 53418.120 [imgs/sec],loss=7.053
[Training][Epoch 5] training time: 2.185 [sec],avg speed: 53418.120 [imgs/sec],loss=7.053
:::MLLOG {"namespace": "", "time_ms": 1592975820455, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1592975820455, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 6, "current_iter_num": 0}}
INFO:root:[Training][Iteration 400][Epoch 6, Batch 15/77] lr: 0.06675, training time: 29.071 [ms], speed: 52835.414 [imgs/sec], loss=6.773
[Training][Iteration 400][Epoch 6, Batch 15/77] lr: 0.06675, training time: 29.071 [ms], speed: 52835.414 [imgs/sec], loss=6.773
INFO:root:[Training][Epoch 6] training time: 2.159 [sec],avg speed: 54072.572 [imgs/sec],loss=6.691
[Training][Epoch 6] training time: 2.159 [sec],avg speed: 54072.572 [imgs/sec],loss=6.691
:::MLLOG {"namespace": "", "time_ms": 1592975822614, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 6}}
:::MLLOG {"namespace": "", "time_ms": 1592975822614, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 7, "current_iter_num": 0}}
INFO:root:[Training][Iteration 500][Epoch 7, Batch 38/77] lr: 0.08343, training time: 29.036 [ms], speed: 52898.966 [imgs/sec], loss=6.770
[Training][Iteration 500][Epoch 7, Batch 38/77] lr: 0.08343, training time: 29.036 [ms], speed: 52898.966 [imgs/sec], loss=6.770
INFO:root:[Training][Epoch 7] training time: 2.211 [sec],avg speed: 53495.365 [imgs/sec],loss=6.284
[Training][Epoch 7] training time: 2.211 [sec],avg speed: 53495.365 [imgs/sec],loss=6.284
:::MLLOG {"namespace": "", "time_ms": 1592975824825, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1592975824826, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 8, "current_iter_num": 0}}
INFO:root:[Training][Iteration 600][Epoch 8, Batch 61/77] lr: 0.10012, training time: 28.732 [ms], speed: 53460.301 [imgs/sec], loss=6.773
[Training][Iteration 600][Epoch 8, Batch 61/77] lr: 0.10012, training time: 28.732 [ms], speed: 53460.301 [imgs/sec], loss=6.773
INFO:root:[Training][Epoch 8] training time: 2.177 [sec],avg speed: 53630.567 [imgs/sec],loss=6.021
[Training][Epoch 8] training time: 2.177 [sec],avg speed: 53630.567 [imgs/sec],loss=6.021
:::MLLOG {"namespace": "", "time_ms": 1592975827002, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 8}}
:::MLLOG {"namespace": "", "time_ms": 1592975827003, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 9, "current_iter_num": 0}}
INFO:root:[Training][Epoch 9] training time: 2.173 [sec],avg speed: 53732.033 [imgs/sec],loss=5.706
[Training][Epoch 9] training time: 2.173 [sec],avg speed: 53732.033 [imgs/sec],loss=5.706
:::MLLOG {"namespace": "", "time_ms": 1592975829176, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 9}}
:::MLLOG {"namespace": "", "time_ms": 1592975829176, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 10, "current_iter_num": 0}}
INFO:root:[Training][Iteration 700][Epoch 10, Batch 7/77] lr: 0.11681, training time: 28.592 [ms], speed: 53721.947 [imgs/sec], loss=5.781
[Training][Iteration 700][Epoch 10, Batch 7/77] lr: 0.11681, training time: 28.592 [ms], speed: 53721.947 [imgs/sec], loss=5.781
INFO:root:[Training][Epoch 10] training time: 2.176 [sec],avg speed: 54349.562 [imgs/sec],loss=5.553
[Training][Epoch 10] training time: 2.176 [sec],avg speed: 54349.562 [imgs/sec],loss=5.553
:::MLLOG {"namespace": "", "time_ms": 1592975831352, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 10}}
:::MLLOG {"namespace": "", "time_ms": 1592975831352, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 11, "current_iter_num": 0}}
INFO:root:[Training][Iteration 800][Epoch 11, Batch 30/77] lr: 0.13349, training time: 28.227 [ms], speed: 54415.227 [imgs/sec], loss=6.041
[Training][Iteration 800][Epoch 11, Batch 30/77] lr: 0.13349, training time: 28.227 [ms], speed: 54415.227 [imgs/sec], loss=6.041
INFO:root:[Training][Epoch 11] training time: 2.161 [sec],avg speed: 54025.652 [imgs/sec],loss=5.335
[Training][Epoch 11] training time: 2.161 [sec],avg speed: 54025.652 [imgs/sec],loss=5.335
:::MLLOG {"namespace": "", "time_ms": 1592975833513, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1592975833514, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 12, "current_iter_num": 0}}
INFO:root:[Training][Iteration 900][Epoch 12, Batch 53/77] lr: 0.14000, training time: 28.448 [ms], speed: 53992.608 [imgs/sec], loss=5.052
[Training][Iteration 900][Epoch 12, Batch 53/77] lr: 0.14000, training time: 28.448 [ms], speed: 53992.608 [imgs/sec], loss=5.052
INFO:root:[Training][Epoch 12] training time: 2.158 [sec],avg speed: 54088.515 [imgs/sec],loss=5.263
[Training][Epoch 12] training time: 2.158 [sec],avg speed: 54088.515 [imgs/sec],loss=5.263
:::MLLOG {"namespace": "", "time_ms": 1592975835672, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1592975835672, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 13, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1000][Epoch 13, Batch 76/77] lr: 0.14000, training time: 28.337 [ms], speed: 54204.116 [imgs/sec], loss=4.725
[Training][Iteration 1000][Epoch 13, Batch 76/77] lr: 0.14000, training time: 28.337 [ms], speed: 54204.116 [imgs/sec], loss=4.725
INFO:root:[Training][Epoch 13] training time: 2.184 [sec],avg speed: 54165.122 [imgs/sec],loss=5.009
[Training][Epoch 13] training time: 2.184 [sec],avg speed: 54165.122 [imgs/sec],loss=5.009
:::MLLOG {"namespace": "", "time_ms": 1592975837856, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 13}}
:::MLLOG {"namespace": "", "time_ms": 1592975837856, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 14, "current_iter_num": 0}}
INFO:root:[Training][Epoch 14] training time: 2.145 [sec],avg speed: 54411.970 [imgs/sec],loss=4.936
[Training][Epoch 14] training time: 2.145 [sec],avg speed: 54411.970 [imgs/sec],loss=4.936
:::MLLOG {"namespace": "", "time_ms": 1592975840002, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 14}}
:::MLLOG {"namespace": "", "time_ms": 1592975840002, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 15, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1100][Epoch 15, Batch 22/77] lr: 0.14000, training time: 28.765 [ms], speed: 53397.994 [imgs/sec], loss=4.334
[Training][Iteration 1100][Epoch 15, Batch 22/77] lr: 0.14000, training time: 28.765 [ms], speed: 53397.994 [imgs/sec], loss=4.334
INFO:root:[Training][Epoch 15] training time: 2.175 [sec],avg speed: 53661.608 [imgs/sec],loss=4.790
[Training][Epoch 15] training time: 2.175 [sec],avg speed: 53661.608 [imgs/sec],loss=4.790
:::MLLOG {"namespace": "", "time_ms": 1592975842178, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1592975842178, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 16, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1200][Epoch 16, Batch 45/77] lr: 0.14000, training time: 28.168 [ms], speed: 54530.322 [imgs/sec], loss=5.302
[Training][Iteration 1200][Epoch 16, Batch 45/77] lr: 0.14000, training time: 28.168 [ms], speed: 54530.322 [imgs/sec], loss=5.302
INFO:root:[Training][Epoch 16] training time: 2.170 [sec],avg speed: 54515.125 [imgs/sec],loss=4.735
[Training][Epoch 16] training time: 2.170 [sec],avg speed: 54515.125 [imgs/sec],loss=4.735
:::MLLOG {"namespace": "", "time_ms": 1592975844348, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1592975844348, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 17, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1300][Epoch 17, Batch 68/77] lr: 0.14000, training time: 28.161 [ms], speed: 54542.934 [imgs/sec], loss=4.394
[Training][Iteration 1300][Epoch 17, Batch 68/77] lr: 0.14000, training time: 28.161 [ms], speed: 54542.934 [imgs/sec], loss=4.394
INFO:root:[Training][Epoch 17] training time: 2.156 [sec],avg speed: 54133.598 [imgs/sec],loss=4.683
[Training][Epoch 17] training time: 2.156 [sec],avg speed: 54133.598 [imgs/sec],loss=4.683
:::MLLOG {"namespace": "", "time_ms": 1592975846505, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 17}}
:::MLLOG {"namespace": "", "time_ms": 1592975846505, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 18, "current_iter_num": 0}}
INFO:root:[Training][Epoch 18] training time: 2.157 [sec],avg speed: 54114.351 [imgs/sec],loss=4.623
[Training][Epoch 18] training time: 2.157 [sec],avg speed: 54114.351 [imgs/sec],loss=4.623
:::MLLOG {"namespace": "", "time_ms": 1592975848662, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1592975848663, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 19, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1400][Epoch 19, Batch 14/77] lr: 0.14000, training time: 28.178 [ms], speed: 54509.899 [imgs/sec], loss=4.271
[Training][Iteration 1400][Epoch 19, Batch 14/77] lr: 0.14000, training time: 28.178 [ms], speed: 54509.899 [imgs/sec], loss=4.271
INFO:root:[Training][Epoch 19] training time: 2.176 [sec],avg speed: 54356.029 [imgs/sec],loss=4.516
[Training][Epoch 19] training time: 2.176 [sec],avg speed: 54356.029 [imgs/sec],loss=4.516
:::MLLOG {"namespace": "", "time_ms": 1592975850839, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1592975850839, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 20, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1500][Epoch 20, Batch 37/77] lr: 0.14000, training time: 28.703 [ms], speed: 53514.255 [imgs/sec], loss=5.148
[Training][Iteration 1500][Epoch 20, Batch 37/77] lr: 0.14000, training time: 28.703 [ms], speed: 53514.255 [imgs/sec], loss=5.148
INFO:root:[Training][Epoch 20] training time: 2.160 [sec],avg speed: 54049.436 [imgs/sec],loss=4.422
[Training][Epoch 20] training time: 2.160 [sec],avg speed: 54049.436 [imgs/sec],loss=4.422
:::MLLOG {"namespace": "", "time_ms": 1592975852999, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1592975852999, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 21, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1600][Epoch 21, Batch 60/77] lr: 0.14000, training time: 28.030 [ms], speed: 54797.556 [imgs/sec], loss=4.775
[Training][Iteration 1600][Epoch 21, Batch 60/77] lr: 0.14000, training time: 28.030 [ms], speed: 54797.556 [imgs/sec], loss=4.775
INFO:root:[Training][Epoch 21] training time: 2.132 [sec],avg speed: 54761.669 [imgs/sec],loss=4.496
[Training][Epoch 21] training time: 2.132 [sec],avg speed: 54761.669 [imgs/sec],loss=4.496
:::MLLOG {"namespace": "", "time_ms": 1592975855131, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 21}}
:::MLLOG {"namespace": "", "time_ms": 1592975855131, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 22, "current_iter_num": 0}}
INFO:root:[Training][Epoch 22] training time: 2.165 [sec],avg speed: 54632.042 [imgs/sec],loss=4.326
[Training][Epoch 22] training time: 2.165 [sec],avg speed: 54632.042 [imgs/sec],loss=4.326
:::MLLOG {"namespace": "", "time_ms": 1592975857296, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 22}}
:::MLLOG {"namespace": "", "time_ms": 1592975857297, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 23, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1700][Epoch 23, Batch 6/77] lr: 0.14000, training time: 28.291 [ms], speed: 54293.291 [imgs/sec], loss=4.129
[Training][Iteration 1700][Epoch 23, Batch 6/77] lr: 0.14000, training time: 28.291 [ms], speed: 54293.291 [imgs/sec], loss=4.129
INFO:root:[Training][Epoch 23] training time: 2.140 [sec],avg speed: 54540.221 [imgs/sec],loss=4.296
[Training][Epoch 23] training time: 2.140 [sec],avg speed: 54540.221 [imgs/sec],loss=4.296
:::MLLOG {"namespace": "", "time_ms": 1592975859437, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1592975859438, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 24, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1800][Epoch 24, Batch 29/77] lr: 0.14000, training time: 28.464 [ms], speed: 53963.203 [imgs/sec], loss=3.657
[Training][Iteration 1800][Epoch 24, Batch 29/77] lr: 0.14000, training time: 28.464 [ms], speed: 53963.203 [imgs/sec], loss=3.657
INFO:root:[Training][Epoch 24] training time: 2.150 [sec],avg speed: 54303.248 [imgs/sec],loss=4.299
[Training][Epoch 24] training time: 2.150 [sec],avg speed: 54303.248 [imgs/sec],loss=4.299
:::MLLOG {"namespace": "", "time_ms": 1592975861587, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1592975861588, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 25, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1900][Epoch 25, Batch 52/77] lr: 0.14000, training time: 28.167 [ms], speed: 54531.135 [imgs/sec], loss=4.671
[Training][Iteration 1900][Epoch 25, Batch 52/77] lr: 0.14000, training time: 28.167 [ms], speed: 54531.135 [imgs/sec], loss=4.671
INFO:root:[Training][Epoch 25] training time: 2.171 [sec],avg speed: 54465.590 [imgs/sec],loss=4.306
[Training][Epoch 25] training time: 2.171 [sec],avg speed: 54465.590 [imgs/sec],loss=4.306
:::MLLOG {"namespace": "", "time_ms": 1592975863759, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 25}}
:::MLLOG {"namespace": "", "time_ms": 1592975863760, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 26, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2000][Epoch 26, Batch 75/77] lr: 0.14000, training time: 28.169 [ms], speed: 54527.819 [imgs/sec], loss=4.345
[Training][Iteration 2000][Epoch 26, Batch 75/77] lr: 0.14000, training time: 28.169 [ms], speed: 54527.819 [imgs/sec], loss=4.345
INFO:root:[Training][Epoch 26] training time: 2.142 [sec],avg speed: 54499.195 [imgs/sec],loss=4.273
[Training][Epoch 26] training time: 2.142 [sec],avg speed: 54499.195 [imgs/sec],loss=4.273
:::MLLOG {"namespace": "", "time_ms": 1592975865902, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 26}}
:::MLLOG {"namespace": "", "time_ms": 1592975865902, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 27, "current_iter_num": 0}}
INFO:root:[Training][Epoch 27] training time: 2.139 [sec],avg speed: 54563.779 [imgs/sec],loss=4.235
[Training][Epoch 27] training time: 2.139 [sec],avg speed: 54563.779 [imgs/sec],loss=4.235
:::MLLOG {"namespace": "", "time_ms": 1592975868042, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1592975868042, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 28, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2100][Epoch 28, Batch 21/77] lr: 0.14000, training time: 28.130 [ms], speed: 54604.336 [imgs/sec], loss=4.241
[Training][Iteration 2100][Epoch 28, Batch 21/77] lr: 0.14000, training time: 28.130 [ms], speed: 54604.336 [imgs/sec], loss=4.241
INFO:root:[Training][Epoch 28] training time: 2.166 [sec],avg speed: 54615.423 [imgs/sec],loss=4.174
[Training][Epoch 28] training time: 2.166 [sec],avg speed: 54615.423 [imgs/sec],loss=4.174
:::MLLOG {"namespace": "", "time_ms": 1592975870208, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1592975870208, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 29, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2200][Epoch 29, Batch 44/77] lr: 0.14000, training time: 28.237 [ms], speed: 54397.055 [imgs/sec], loss=4.395
[Training][Iteration 2200][Epoch 29, Batch 44/77] lr: 0.14000, training time: 28.237 [ms], speed: 54397.055 [imgs/sec], loss=4.395
INFO:root:[Training][Epoch 29] training time: 2.141 [sec],avg speed: 54519.779 [imgs/sec],loss=4.181
[Training][Epoch 29] training time: 2.141 [sec],avg speed: 54519.779 [imgs/sec],loss=4.181
:::MLLOG {"namespace": "", "time_ms": 1592975872349, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 29}}
:::MLLOG {"namespace": "", "time_ms": 1592975872350, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 30, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2300][Epoch 30, Batch 67/77] lr: 0.14000, training time: 28.139 [ms], speed: 54586.478 [imgs/sec], loss=4.512
[Training][Iteration 2300][Epoch 30, Batch 67/77] lr: 0.14000, training time: 28.139 [ms], speed: 54586.478 [imgs/sec], loss=4.512
INFO:root:[Training][Epoch 30] training time: 2.139 [sec],avg speed: 54578.565 [imgs/sec],loss=4.043
[Training][Epoch 30] training time: 2.139 [sec],avg speed: 54578.565 [imgs/sec],loss=4.043
:::MLLOG {"namespace": "", "time_ms": 1592975874489, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 30}}
:::MLLOG {"namespace": "", "time_ms": 1592975874489, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 31, "current_iter_num": 0}}
INFO:root:[Training][Epoch 31] training time: 2.168 [sec],avg speed: 54543.009 [imgs/sec],loss=4.105
[Training][Epoch 31] training time: 2.168 [sec],avg speed: 54543.009 [imgs/sec],loss=4.105
:::MLLOG {"namespace": "", "time_ms": 1592975876658, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1592975876658, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 32, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2400][Epoch 32, Batch 13/77] lr: 0.14000, training time: 28.260 [ms], speed: 54351.891 [imgs/sec], loss=3.962
[Training][Iteration 2400][Epoch 32, Batch 13/77] lr: 0.14000, training time: 28.260 [ms], speed: 54351.891 [imgs/sec], loss=3.962
INFO:root:[Training][Epoch 32] training time: 2.144 [sec],avg speed: 54458.794 [imgs/sec],loss=4.097
[Training][Epoch 32] training time: 2.144 [sec],avg speed: 54458.794 [imgs/sec],loss=4.097
:::MLLOG {"namespace": "", "time_ms": 1592975878802, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1592975878802, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 33, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2500][Epoch 33, Batch 36/77] lr: 0.14000, training time: 28.301 [ms], speed: 54272.785 [imgs/sec], loss=3.787
[Training][Iteration 2500][Epoch 33, Batch 36/77] lr: 0.14000, training time: 28.301 [ms], speed: 54272.785 [imgs/sec], loss=3.787
INFO:root:[Training][Epoch 33] training time: 2.143 [sec],avg speed: 54483.603 [imgs/sec],loss=4.056
[Training][Epoch 33] training time: 2.143 [sec],avg speed: 54483.603 [imgs/sec],loss=4.056
:::MLLOG {"namespace": "", "time_ms": 1592975880945, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 33}}
:::MLLOG {"namespace": "", "time_ms": 1592975880945, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 34, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2600][Epoch 34, Batch 59/77] lr: 0.14000, training time: 28.081 [ms], speed: 54699.102 [imgs/sec], loss=3.838
[Training][Iteration 2600][Epoch 34, Batch 59/77] lr: 0.14000, training time: 28.081 [ms], speed: 54699.102 [imgs/sec], loss=3.838
INFO:root:[Training][Epoch 34] training time: 2.162 [sec],avg speed: 54701.556 [imgs/sec],loss=4.010
[Training][Epoch 34] training time: 2.162 [sec],avg speed: 54701.556 [imgs/sec],loss=4.010
:::MLLOG {"namespace": "", "time_ms": 1592975883107, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 34}}
:::MLLOG {"namespace": "", "time_ms": 1592975883107, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 35, "current_iter_num": 0}}
INFO:root:[Training][Epoch 35] training time: 2.141 [sec],avg speed: 54527.344 [imgs/sec],loss=4.028
[Training][Epoch 35] training time: 2.141 [sec],avg speed: 54527.344 [imgs/sec],loss=4.028
:::MLLOG {"namespace": "", "time_ms": 1592975885249, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1592975885249, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 36, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2700][Epoch 36, Batch 5/77] lr: 0.14000, training time: 28.379 [ms], speed: 54123.871 [imgs/sec], loss=3.854
[Training][Iteration 2700][Epoch 36, Batch 5/77] lr: 0.14000, training time: 28.379 [ms], speed: 54123.871 [imgs/sec], loss=3.854
INFO:root:[Training][Epoch 36] training time: 2.137 [sec],avg speed: 54632.186 [imgs/sec],loss=4.022
[Training][Epoch 36] training time: 2.137 [sec],avg speed: 54632.186 [imgs/sec],loss=4.022
:::MLLOG {"namespace": "", "time_ms": 1592975887386, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 36}}
:::MLLOG {"namespace": "", "time_ms": 1592975887386, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 37, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2800][Epoch 37, Batch 28/77] lr: 0.14000, training time: 28.177 [ms], speed: 54513.259 [imgs/sec], loss=4.915
[Training][Iteration 2800][Epoch 37, Batch 28/77] lr: 0.14000, training time: 28.177 [ms], speed: 54513.259 [imgs/sec], loss=4.915
INFO:root:[Training][Epoch 37] training time: 2.162 [sec],avg speed: 54706.992 [imgs/sec],loss=3.972
[Training][Epoch 37] training time: 2.162 [sec],avg speed: 54706.992 [imgs/sec],loss=3.972
:::MLLOG {"namespace": "", "time_ms": 1592975889548, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 37}}
:::MLLOG {"namespace": "", "time_ms": 1592975889548, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 38, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2900][Epoch 38, Batch 51/77] lr: 0.14000, training time: 28.236 [ms], speed: 54397.872 [imgs/sec], loss=4.149
[Training][Iteration 2900][Epoch 38, Batch 51/77] lr: 0.14000, training time: 28.236 [ms], speed: 54397.872 [imgs/sec], loss=4.149
INFO:root:[Training][Epoch 38] training time: 2.140 [sec],avg speed: 54554.933 [imgs/sec],loss=3.968
[Training][Epoch 38] training time: 2.140 [sec],avg speed: 54554.933 [imgs/sec],loss=3.968
:::MLLOG {"namespace": "", "time_ms": 1592975891688, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 38}}
:::MLLOG {"namespace": "", "time_ms": 1592975891689, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 39, "current_iter_num": 0}}
INFO:root:[Training][Iteration 3000][Epoch 39, Batch 74/77] lr: 0.14000, training time: 28.071 [ms], speed: 54717.970 [imgs/sec], loss=3.777
[Training][Iteration 3000][Epoch 39, Batch 74/77] lr: 0.14000, training time: 28.071 [ms], speed: 54717.970 [imgs/sec], loss=3.777
INFO:root:[Training][Epoch 39] training time: 2.134 [sec],avg speed: 54696.554 [imgs/sec],loss=3.936
[Training][Epoch 39] training time: 2.134 [sec],avg speed: 54696.554 [imgs/sec],loss=3.936
:::MLLOG {"namespace": "", "time_ms": 1592975893823, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 39}}
:::MLLOG {"namespace": "", "time_ms": 1592975893823, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 40, "current_iter_num": 0}}
INFO:root:[Training][Epoch 40] training time: 2.158 [sec],avg speed: 54818.003 [imgs/sec],loss=3.980
[Training][Epoch 40] training time: 2.158 [sec],avg speed: 54818.003 [imgs/sec],loss=3.980
:::MLLOG {"namespace": "", "time_ms": 1592975895981, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1592975895994, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 243, "epoch_num": 40}}
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 763.501 [ms], allgather: 179.578 [ms], asnumpy: 5.085 [ms], speed: 5273.340 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 763.501 [ms], allgather: 179.578 [ms], asnumpy: 5.085 [ms], speed: 5273.340 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 814.946 [ms], allgather: 169.858 [ms], asnumpy: 4.945 [ms], speed: 5051.776 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 814.946 [ms], allgather: 169.858 [ms], asnumpy: 4.945 [ms], speed: 5051.776 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 802.755 [ms], allgather: 243.778 [ms], asnumpy: 4.891 [ms], speed: 4755.448 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 802.755 [ms], allgather: 243.778 [ms], asnumpy: 4.891 [ms], speed: 4755.448 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 801.394 [ms], allgather: 285.999 [ms], asnumpy: 4.808 [ms], speed: 4577.904 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 801.394 [ms], allgather: 285.999 [ms], asnumpy: 4.808 [ms], speed: 4577.904 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 797.221 [ms], allgather: 316.639 [ms], asnumpy: 4.878 [ms], speed: 4469.313 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 797.221 [ms], allgather: 316.639 [ms], asnumpy: 4.878 [ms], speed: 4469.313 [imgs/sec]
:::MLLOG {"namespace": "", "time_ms": 1592975897129, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 41, "current_iter_num": 0}}
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 782.636 [ms], allgather: 362.873 [ms], asnumpy: 5.107 [ms], speed: 4345.489 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 782.636 [ms], allgather: 362.873 [ms], asnumpy: 5.107 [ms], speed: 4345.489 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 795.382 [ms], allgather: 389.376 [ms], asnumpy: 4.835 [ms], speed: 4203.113 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 795.382 [ms], allgather: 389.376 [ms], asnumpy: 4.835 [ms], speed: 4203.113 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 800.183 [ms], allgather: 426.846 [ms], asnumpy: 4.882 [ms], speed: 4058.730 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 800.183 [ms], allgather: 426.846 [ms], asnumpy: 4.882 [ms], speed: 4058.730 [imgs/sec]
INFO:root:[Training][Iteration 3100][Epoch 41, Batch 20/77] lr: 0.14000, training time: 34.062 [ms], speed: 45094.534 [imgs/sec], loss=3.584
[Training][Iteration 3100][Epoch 41, Batch 20/77] lr: 0.14000, training time: 34.062 [ms], speed: 45094.534 [imgs/sec], loss=3.584
INFO:root:[Training][Epoch 41] training time: 2.255 [sec],avg speed: 51775.365 [imgs/sec],loss=3.927
[Training][Epoch 41] training time: 2.255 [sec],avg speed: 51775.365 [imgs/sec],loss=3.927
:::MLLOG {"namespace": "", "time_ms": 1592975899383, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1592975899384, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 42, "current_iter_num": 0}}
:::MLLOG {"namespace": "", "time_ms": 1592975899785, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 291, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1592975899785, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.1679553565701122, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 294, "epoch_num": 40}}
INFO:root:[Training][Iteration 3200][Epoch 42, Batch 43/77] lr: 0.14000, training time: 28.086 [ms], speed: 54688.344 [imgs/sec], loss=4.029
[Training][Iteration 3200][Epoch 42, Batch 43/77] lr: 0.14000, training time: 28.086 [ms], speed: 54688.344 [imgs/sec], loss=4.029
INFO:root:[Training][Epoch 42] training time: 2.137 [sec],avg speed: 54634.332 [imgs/sec],loss=3.969
[Training][Epoch 42] training time: 2.137 [sec],avg speed: 54634.332 [imgs/sec],loss=3.969
:::MLLOG {"namespace": "", "time_ms": 1592975901521, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 42}}
:::MLLOG {"namespace": "", "time_ms": 1592975901521, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 43, "current_iter_num": 0}}
INFO:root:[Training][Iteration 3300][Epoch 43, Batch 66/77] lr: 0.14000, training time: 28.356 [ms], speed: 54169.045 [imgs/sec], loss=4.149
[Training][Iteration 3300][Epoch 43, Batch 66/77] lr: 0.14000, training time: 28.356 [ms], speed: 54169.045 [imgs/sec], loss=4.149
INFO:root:[Training][Epoch 43] training time: 2.182 [sec],avg speed: 54192.246 [imgs/sec],loss=3.932
[Training][Epoch 43] training time: 2.182 [sec],avg speed: 54192.246 [imgs/sec],loss=3.932
:::MLLOG {"namespace": "", "time_ms": 1592975903704, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 43}}
:::MLLOG {"namespace": "", "time_ms": 1592975903704, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 44, "current_iter_num": 0}}
INFO:root:[Training][Epoch 44] training time: 2.131 [sec],avg speed: 54781.533 [imgs/sec],loss=3.819
[Training][Epoch 44] training time: 2.131 [sec],avg speed: 54781.533 [imgs/sec],loss=3.819
:::MLLOG {"namespace": "", "time_ms": 1592975905835, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 44}}
:::MLLOG {"namespace": "", "time_ms": 1592975905836, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 45, "current_iter_num": 0}}
INFO:root:[Training][Iteration 3400][Epoch 45, Batch 12/77] lr: 0.01400, training time: 28.243 [ms], speed: 54385.262 [imgs/sec], loss=4.113
[Training][Iteration 3400][Epoch 45, Batch 12/77] lr: 0.01400, training time: 28.243 [ms], speed: 54385.262 [imgs/sec], loss=4.113
INFO:root:[Training][Epoch 45] training time: 2.131 [sec],avg speed: 54770.717 [imgs/sec],loss=3.602
[Training][Epoch 45] training time: 2.131 [sec],avg speed: 54770.717 [imgs/sec],loss=3.602
:::MLLOG {"namespace": "", "time_ms": 1592975907967, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 45}}
:::MLLOG {"namespace": "", "time_ms": 1592975907968, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 46, "current_iter_num": 0}}
INFO:root:[Training][Iteration 3500][Epoch 46, Batch 35/77] lr: 0.01400, training time: 27.989 [ms], speed: 54878.824 [imgs/sec], loss=3.101
[Training][Iteration 3500][Epoch 46, Batch 35/77] lr: 0.01400, training time: 27.989 [ms], speed: 54878.824 [imgs/sec], loss=3.101
INFO:root:[Training][Epoch 46] training time: 2.158 [sec],avg speed: 54817.113 [imgs/sec],loss=3.522
[Training][Epoch 46] training time: 2.158 [sec],avg speed: 54817.113 [imgs/sec],loss=3.522
:::MLLOG {"namespace": "", "time_ms": 1592975910125, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 46}}
:::MLLOG {"namespace": "", "time_ms": 1592975910126, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 47, "current_iter_num": 0}}
INFO:root:[Training][Iteration 3600][Epoch 47, Batch 58/77] lr: 0.01400, training time: 28.012 [ms], speed: 54834.503 [imgs/sec], loss=3.081
[Training][Iteration 3600][Epoch 47, Batch 58/77] lr: 0.01400, training time: 28.012 [ms], speed: 54834.503 [imgs/sec], loss=3.081
INFO:root:[Training][Epoch 47] training time: 2.130 [sec],avg speed: 54810.471 [imgs/sec],loss=3.467
[Training][Epoch 47] training time: 2.130 [sec],avg speed: 54810.471 [imgs/sec],loss=3.467
:::MLLOG {"namespace": "", "time_ms": 1592975912256, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 47}}
:::MLLOG {"namespace": "", "time_ms": 1592975912256, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 48, "current_iter_num": 0}}
INFO:root:[Training][Epoch 48] training time: 2.130 [sec],avg speed: 54794.290 [imgs/sec],loss=3.530
[Training][Epoch 48] training time: 2.130 [sec],avg speed: 54794.290 [imgs/sec],loss=3.530
:::MLLOG {"namespace": "", "time_ms": 1592975914387, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 48}}
:::MLLOG {"namespace": "", "time_ms": 1592975914387, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 49, "current_iter_num": 0}}
INFO:root:[Training][Iteration 3700][Epoch 49, Batch 4/77] lr: 0.01400, training time: 28.145 [ms], speed: 54574.842 [imgs/sec], loss=3.743
[Training][Iteration 3700][Epoch 49, Batch 4/77] lr: 0.01400, training time: 28.145 [ms], speed: 54574.842 [imgs/sec], loss=3.743
INFO:root:[Training][Epoch 49] training time: 2.155 [sec],avg speed: 54879.454 [imgs/sec],loss=3.372
[Training][Epoch 49] training time: 2.155 [sec],avg speed: 54879.454 [imgs/sec],loss=3.372
:::MLLOG {"namespace": "", "time_ms": 1592975916543, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 49}}
:::MLLOG {"namespace": "", "time_ms": 1592975916543, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 50, "current_iter_num": 0}}
INFO:root:[Training][Iteration 3800][Epoch 50, Batch 27/77] lr: 0.01400, training time: 28.089 [ms], speed: 54682.498 [imgs/sec], loss=3.603
[Training][Iteration 3800][Epoch 50, Batch 27/77] lr: 0.01400, training time: 28.089 [ms], speed: 54682.498 [imgs/sec], loss=3.603
INFO:root:[Training][Epoch 50] training time: 2.130 [sec],avg speed: 54795.940 [imgs/sec],loss=3.369
[Training][Epoch 50] training time: 2.130 [sec],avg speed: 54795.940 [imgs/sec],loss=3.369
:::MLLOG {"namespace": "", "time_ms": 1592975918674, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1592975918685, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 243, "epoch_num": 50}}
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 144.296 [ms], allgather: 134.369 [ms], asnumpy: 6.087 [ms], speed: 17559.043 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 144.296 [ms], allgather: 134.369 [ms], asnumpy: 6.087 [ms], speed: 17559.043 [imgs/sec]
:::MLLOG {"namespace": "", "time_ms": 1592975918971, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 51, "current_iter_num": 0}}
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 145.178 [ms], allgather: 156.529 [ms], asnumpy: 4.931 [ms], speed: 16305.771 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 145.178 [ms], allgather: 156.529 [ms], asnumpy: 4.931 [ms], speed: 16305.771 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 131.496 [ms], allgather: 174.802 [ms], asnumpy: 4.805 [ms], speed: 16071.768 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 131.496 [ms], allgather: 174.802 [ms], asnumpy: 4.805 [ms], speed: 16071.768 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 117.759 [ms], allgather: 208.534 [ms], asnumpy: 5.206 [ms], speed: 15082.900 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 117.759 [ms], allgather: 208.534 [ms], asnumpy: 5.206 [ms], speed: 15082.900 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 134.772 [ms], allgather: 197.737 [ms], asnumpy: 5.068 [ms], speed: 14811.400 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 134.772 [ms], allgather: 197.737 [ms], asnumpy: 5.068 [ms], speed: 14811.400 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 150.662 [ms], allgather: 204.614 [ms], asnumpy: 4.912 [ms], speed: 13881.557 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 150.662 [ms], allgather: 204.614 [ms], asnumpy: 4.912 [ms], speed: 13881.557 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 132.836 [ms], allgather: 227.898 [ms], asnumpy: 5.038 [ms], speed: 13669.655 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 132.836 [ms], allgather: 227.898 [ms], asnumpy: 5.038 [ms], speed: 13669.655 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 133.664 [ms], allgather: 247.793 [ms], asnumpy: 4.985 [ms], speed: 12938.514 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 133.664 [ms], allgather: 247.793 [ms], asnumpy: 4.985 [ms], speed: 12938.514 [imgs/sec]
INFO:root:[Training][Iteration 3900][Epoch 51, Batch 50/77] lr: 0.01400, training time: 30.687 [ms], speed: 50053.071 [imgs/sec], loss=3.376
[Training][Iteration 3900][Epoch 51, Batch 50/77] lr: 0.01400, training time: 30.687 [ms], speed: 50053.071 [imgs/sec], loss=3.376
:::MLLOG {"namespace": "", "time_ms": 1592975921160, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 291, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1592975921160, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.22416912672193112, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 294, "epoch_num": 50}}
INFO:root:[Training][Epoch 51] training time: 2.267 [sec],avg speed: 51492.208 [imgs/sec],loss=3.394
[Training][Epoch 51] training time: 2.267 [sec],avg speed: 51492.208 [imgs/sec],loss=3.394
:::MLLOG {"namespace": "", "time_ms": 1592975921238, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 51}}
:::MLLOG {"namespace": "", "time_ms": 1592975921238, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 52, "current_iter_num": 0}}
INFO:root:[Training][Iteration 4000][Epoch 52, Batch 73/77] lr: 0.01400, training time: 28.256 [ms], speed: 54360.479 [imgs/sec], loss=2.825
[Training][Iteration 4000][Epoch 52, Batch 73/77] lr: 0.01400, training time: 28.256 [ms], speed: 54360.479 [imgs/sec], loss=2.825
INFO:root:[Training][Epoch 52] training time: 2.176 [sec],avg speed: 54344.090 [imgs/sec],loss=3.417
[Training][Epoch 52] training time: 2.176 [sec],avg speed: 54344.090 [imgs/sec],loss=3.417
:::MLLOG {"namespace": "", "time_ms": 1592975923415, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 52}}
:::MLLOG {"namespace": "", "time_ms": 1592975923415, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 53, "current_iter_num": 0}}
INFO:root:[Training][Epoch 53] training time: 2.155 [sec],avg speed: 54167.213 [imgs/sec],loss=3.386
[Training][Epoch 53] training time: 2.155 [sec],avg speed: 54167.213 [imgs/sec],loss=3.386
:::MLLOG {"namespace": "", "time_ms": 1592975925570, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 53}}
:::MLLOG {"namespace": "", "time_ms": 1592975925571, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 54, "current_iter_num": 0}}
INFO:root:[Training][Iteration 4100][Epoch 54, Batch 19/77] lr: 0.01400, training time: 28.118 [ms], speed: 54627.279 [imgs/sec], loss=3.780
[Training][Iteration 4100][Epoch 54, Batch 19/77] lr: 0.01400, training time: 28.118 [ms], speed: 54627.279 [imgs/sec], loss=3.780
INFO:root:[Training][Epoch 54] training time: 2.146 [sec],avg speed: 54404.134 [imgs/sec],loss=3.381
[Training][Epoch 54] training time: 2.146 [sec],avg speed: 54404.134 [imgs/sec],loss=3.381
:::MLLOG {"namespace": "", "time_ms": 1592975927717, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 54}}
:::MLLOG {"namespace": "", "time_ms": 1592975927717, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 55, "current_iter_num": 0}}
INFO:root:[Training][Iteration 4200][Epoch 55, Batch 42/77] lr: 0.01400, training time: 28.133 [ms], speed: 54597.879 [imgs/sec], loss=2.926
[Training][Iteration 4200][Epoch 55, Batch 42/77] lr: 0.01400, training time: 28.133 [ms], speed: 54597.879 [imgs/sec], loss=2.926
INFO:root:[Training][Epoch 55] training time: 2.170 [sec],avg speed: 54493.507 [imgs/sec],loss=3.345
[Training][Epoch 55] training time: 2.170 [sec],avg speed: 54493.507 [imgs/sec],loss=3.345
:::MLLOG {"namespace": "", "time_ms": 1592975929888, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 55}}
:::MLLOG {"namespace": "", "time_ms": 1592975929900, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 243, "epoch_num": 55}}
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 124.161 [ms], allgather: 100.955 [ms], asnumpy: 4.902 [ms], speed: 21737.303 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 124.161 [ms], allgather: 100.955 [ms], asnumpy: 4.902 [ms], speed: 21737.303 [imgs/sec]
:::MLLOG {"namespace": "", "time_ms": 1592975930130, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 56, "current_iter_num": 0}}
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 157.154 [ms], allgather: 79.917 [ms], asnumpy: 5.061 [ms], speed: 20649.837 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 157.154 [ms], allgather: 79.917 [ms], asnumpy: 5.061 [ms], speed: 20649.837 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 147.287 [ms], allgather: 92.113 [ms], asnumpy: 4.971 [ms], speed: 20460.519 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 147.287 [ms], allgather: 92.113 [ms], asnumpy: 4.971 [ms], speed: 20460.519 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 138.579 [ms], allgather: 110.967 [ms], asnumpy: 5.188 [ms], speed: 19628.150 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 138.579 [ms], allgather: 110.967 [ms], asnumpy: 5.188 [ms], speed: 19628.150 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 130.941 [ms], allgather: 122.682 [ms], asnumpy: 4.973 [ms], speed: 19335.005 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 130.941 [ms], allgather: 122.682 [ms], asnumpy: 4.973 [ms], speed: 19335.005 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 150.042 [ms], allgather: 113.594 [ms], asnumpy: 5.066 [ms], speed: 18607.824 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 150.042 [ms], allgather: 113.594 [ms], asnumpy: 5.066 [ms], speed: 18607.824 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 132.872 [ms], allgather: 135.619 [ms], asnumpy: 4.995 [ms], speed: 18282.351 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 132.872 [ms], allgather: 135.619 [ms], asnumpy: 4.995 [ms], speed: 18282.351 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 133.326 [ms], allgather: 143.679 [ms], asnumpy: 5.784 [ms], speed: 17681.013 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 133.326 [ms], allgather: 143.679 [ms], asnumpy: 5.784 [ms], speed: 17681.013 [imgs/sec]
INFO:root:[Training][Iteration 4300][Epoch 56, Batch 65/77] lr: 0.00140, training time: 29.076 [ms], speed: 52826.453 [imgs/sec], loss=3.417
[Training][Iteration 4300][Epoch 56, Batch 65/77] lr: 0.00140, training time: 29.076 [ms], speed: 52826.453 [imgs/sec], loss=3.417
:::MLLOG {"namespace": "", "time_ms": 1592975932223, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 291, "epoch_num": 55}}
:::MLLOG {"namespace": "", "time_ms": 1592975932224, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.22472979337413, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 294, "epoch_num": 55}}
INFO:root:[Training][Epoch 56] training time: 2.201 [sec],avg speed: 53047.301 [imgs/sec],loss=3.312
[Training][Epoch 56] training time: 2.201 [sec],avg speed: 53047.301 [imgs/sec],loss=3.312
:::MLLOG {"namespace": "", "time_ms": 1592975932331, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 56}}
:::MLLOG {"namespace": "", "time_ms": 1592975932331, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 57, "current_iter_num": 0}}
INFO:root:[Training][Epoch 57] training time: 2.161 [sec],avg speed: 54030.886 [imgs/sec],loss=3.380
[Training][Epoch 57] training time: 2.161 [sec],avg speed: 54030.886 [imgs/sec],loss=3.380
:::MLLOG {"namespace": "", "time_ms": 1592975934492, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 57}}
:::MLLOG {"namespace": "", "time_ms": 1592975934492, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 58, "current_iter_num": 0}}
INFO:root:[Training][Iteration 4400][Epoch 58, Batch 11/77] lr: 0.00140, training time: 28.303 [ms], speed: 54268.961 [imgs/sec], loss=3.703
[Training][Iteration 4400][Epoch 58, Batch 11/77] lr: 0.00140, training time: 28.303 [ms], speed: 54268.961 [imgs/sec], loss=3.703
INFO:root:[Training][Epoch 58] training time: 2.174 [sec],avg speed: 54401.559 [imgs/sec],loss=3.393
[Training][Epoch 58] training time: 2.174 [sec],avg speed: 54401.559 [imgs/sec],loss=3.393
:::MLLOG {"namespace": "", "time_ms": 1592975936667, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 58}}
:::MLLOG {"namespace": "", "time_ms": 1592975936667, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 59, "current_iter_num": 0}}
INFO:root:[Training][Iteration 4500][Epoch 59, Batch 34/77] lr: 0.00140, training time: 28.144 [ms], speed: 54576.528 [imgs/sec], loss=3.478
[Training][Iteration 4500][Epoch 59, Batch 34/77] lr: 0.00140, training time: 28.144 [ms], speed: 54576.528 [imgs/sec], loss=3.478
INFO:root:[Training][Epoch 59] training time: 2.146 [sec],avg speed: 54388.524 [imgs/sec],loss=3.338
[Training][Epoch 59] training time: 2.146 [sec],avg speed: 54388.524 [imgs/sec],loss=3.338
:::MLLOG {"namespace": "", "time_ms": 1592975938814, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 59}}
:::MLLOG {"namespace": "", "time_ms": 1592975938814, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 60, "current_iter_num": 0}}
INFO:root:[Training][Iteration 4600][Epoch 60, Batch 57/77] lr: 0.00140, training time: 28.178 [ms], speed: 54510.470 [imgs/sec], loss=3.176
[Training][Iteration 4600][Epoch 60, Batch 57/77] lr: 0.00140, training time: 28.178 [ms], speed: 54510.470 [imgs/sec], loss=3.176
INFO:root:[Training][Epoch 60] training time: 2.141 [sec],avg speed: 54522.499 [imgs/sec],loss=3.399
[Training][Epoch 60] training time: 2.141 [sec],avg speed: 54522.499 [imgs/sec],loss=3.399
:::MLLOG {"namespace": "", "time_ms": 1592975940955, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 60}}
:::MLLOG {"namespace": "", "time_ms": 1592975940967, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 243, "epoch_num": 60}}
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 135.365 [ms], allgather: 88.384 [ms], asnumpy: 4.984 [ms], speed: 21859.451 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 135.365 [ms], allgather: 88.384 [ms], asnumpy: 4.984 [ms], speed: 21859.451 [imgs/sec]
:::MLLOG {"namespace": "", "time_ms": 1592975941196, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 61, "current_iter_num": 0}}
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 153.804 [ms], allgather: 80.577 [ms], asnumpy: 5.062 [ms], speed: 20881.791 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 153.804 [ms], allgather: 80.577 [ms], asnumpy: 5.062 [ms], speed: 20881.791 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 133.174 [ms], allgather: 103.695 [ms], asnumpy: 4.845 [ms], speed: 20685.440 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 133.174 [ms], allgather: 103.695 [ms], asnumpy: 4.845 [ms], speed: 20685.440 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 137.412 [ms], allgather: 110.483 [ms], asnumpy: 5.288 [ms], speed: 19748.458 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 137.412 [ms], allgather: 110.483 [ms], asnumpy: 5.288 [ms], speed: 19748.458 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 128.742 [ms], allgather: 123.089 [ms], asnumpy: 5.157 [ms], speed: 19456.067 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 128.742 [ms], allgather: 123.089 [ms], asnumpy: 5.157 [ms], speed: 19456.067 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 146.458 [ms], allgather: 115.040 [ms], asnumpy: 4.959 [ms], speed: 18764.631 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 146.458 [ms], allgather: 115.040 [ms], asnumpy: 4.959 [ms], speed: 18764.631 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 138.504 [ms], allgather: 127.526 [ms], asnumpy: 5.176 [ms], speed: 18436.112 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 138.504 [ms], allgather: 127.526 [ms], asnumpy: 5.176 [ms], speed: 18436.112 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 127.820 [ms], allgather: 148.060 [ms], asnumpy: 5.148 [ms], speed: 17791.623 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 127.820 [ms], allgather: 148.060 [ms], asnumpy: 5.148 [ms], speed: 17791.623 [imgs/sec]
:::MLLOG {"namespace": "", "time_ms": 1592975943320, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 291, "epoch_num": 60}}
:::MLLOG {"namespace": "", "time_ms": 1592975943320, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.23065135349440558, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 294, "epoch_num": 60}}
INFO:root:[Training][Epoch 61] training time: 2.241 [sec],avg speed: 52771.152 [imgs/sec],loss=3.364
[Training][Epoch 61] training time: 2.241 [sec],avg speed: 52771.152 [imgs/sec],loss=3.364
:::MLLOG {"namespace": "", "time_ms": 1592975943438, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 61}}
:::MLLOG {"namespace": "", "time_ms": 1592975943438, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 520, "status": "success"}}
INFO:root:Rank 0 done. map=23.065135349440556 @ epoch=60
Rank 0 done. map=23.065135349440556 @ epoch=60
INFO:root:Rank 24 done. map=23.065135349440556 @ epoch=-1
INFO:root:Rank 8 done. map=23.065135349440556 @ epoch=-1
Rank 8 done. map=23.065135349440556 @ epoch=-1
INFO:root:Rank 48 done. map=23.065135349440556 @ epoch=-1
Rank 48 done. map=23.065135349440556 @ epoch=-1
INFO:root:Rank 40 done. map=23.065135349440556 @ epoch=-1
Rank 40 done. map=23.065135349440556 @ epoch=-1
Rank 24 done. map=23.065135349440556 @ epoch=-1
INFO:root:Rank 56 done. map=23.065135349440556 @ epoch=-1
Rank 56 done. map=23.065135349440556 @ epoch=-1
INFO:root:Rank 32 done. map=23.065135349440556 @ epoch=-1
Rank 32 done. map=23.065135349440556 @ epoch=-1
INFO:root:Rank 16 done. map=23.065135349440556 @ epoch=-1
Rank 16 done. map=23.065135349440556 @ epoch=-1
loading annotations into memory...
Done (t=0.12s)
creating index...
Loading and preparing results...
DONE (t=0.26s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=1.66s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.16796
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.31518
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.16620
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.25330
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.18026
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.25935
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.26957
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.26957
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
Loading and preparing results...
DONE (t=0.41s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=1.69s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22417
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.38188
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23198
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.30733
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.21834
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.31377
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.32557
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.32557
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
Loading and preparing results...
DONE (t=0.42s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=1.59s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22473
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.38167
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23398
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.30761
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.21919
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.31490
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.32565
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.32565
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
Loading and preparing results...
DONE (t=0.40s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=1.64s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.23065
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.38934
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23926
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.31343
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22231
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32001
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33160
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.33160
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
ENDING TIMING RUN AT 2020-06-23 10:19:09 PM
RESULT,SINGLE_STAGE_DETECTOR,,174,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:09 PM
RESULT,SINGLE_STAGE_DETECTOR,,174,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,175,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
ENDING TIMING RUN AT 2020-06-23 10:19:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:16:15 PM
