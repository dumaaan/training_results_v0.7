+ echo 'Beginning trial 5 of 5'
Beginning trial 5 of 5
+ srun -N1 -n1 --container-name=single_stage_detector python -c '
import mlperf_log_utils
from mlperf_logging.mllog import constants
mlperf_log_utils.mlperf_submission_log(constants.SSD)'
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
:::MLLOG {"namespace": "", "time_ms": 1592976342213, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "ssd", "metadata": {"file": "/workspace/ssd/mlperf_log_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1592976342220, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "NVIDIA", "metadata": {"file": "/workspace/ssd/mlperf_log_utils.py", "lineno": 80}}
:::MLLOG {"namespace": "", "time_ms": 1592976342221, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/ssd/mlperf_log_utils.py", "lineno": 84}}
:::MLLOG {"namespace": "", "time_ms": 1592976342221, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/ssd/mlperf_log_utils.py", "lineno": 88}}
:::MLLOG {"namespace": "", "time_ms": 1592976342221, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "8xNVIDIA DGX A100", "metadata": {"file": "/workspace/ssd/mlperf_log_utils.py", "lineno": 92}}
+ '[' 1 -eq 1 ']'
+ srun --ntasks=8 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0267
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0265
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0266
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0264
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0268
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0261
Clearing cache on luna-0269
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0263
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=8 --container-name=single_stage_detector python -c '
from mlperf_logging.mllog import constants
from mlperf_log_utils import log_event
log_event(key=constants.CACHE_CLEAR, value=True)'
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
:::MLLOG {"namespace": "", "time_ms": 1592976347297, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
+ srun --mpi=pmix --ntasks=64 --ntasks-per-node=8 --container-name=single_stage_detector --container-mounts=/raid/datasets/coco/coco-2017:/data,/lustre/fsw/mlperf-ci/14140759/results:/results,/raid/datasets/coco/coco-2017/coco2017/models:/pretrained/mxnet ./run_and_time.sh
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ '[' -n 4 ']'
+ NUMEPOCHS=80
+ '[' 64 -gt 8 ']'
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ cluster=
+ DATASET_DIR=/data/coco2017
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ '[' -n 5 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ '[' -n 6 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ NUMEPOCHS=80
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
running benchmark
+ echo 'running benchmark'
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 2 ']'
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ NUMEPOCHS=80
+ declare -a CMD
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ '[' -n 1 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 2 ']'
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ NUMEPOCHS=80
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ '[' -n 3 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 3 ']'
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ NUMEPOCHS=80
+ '[' -n 3 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
running benchmark
+ echo 'running benchmark'
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ declare -a CMD
+ '[' -n 7 ']'
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ '[' -n 5 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ '[' -n 0 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ NUMEPOCHS=80
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ '[' -n 1 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ '[' -n 3 ']'
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ '[' 64 -gt 8 ']'
+ cluster=
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ '[' -n 6 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' -n 5 ']'
+ '[' 64 -gt 8 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' -n 5 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ '[' -n 4 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 3 ']'
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ '[' -n 5 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ '[' -n 0 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:25:49 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
:::MLLOG {"namespace": "", "time_ms": 1592976353204, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353196, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353226, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353209, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353204, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353206, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353218, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353218, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353207, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353207, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353207, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353220, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353218, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353218, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353207, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353207, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353219, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353220, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353223, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353216, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353224, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353237, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353224, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353224, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353218, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353219, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353219, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353218, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353219, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353220, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353226, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353226, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353226, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353226, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353242, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353243, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353244, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353245, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353234, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353246, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353234, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353245, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353241, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353241, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353238, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353240, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353241, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353241, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353241, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353241, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353247, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353247, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353250, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353249, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353250, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353250, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353444, "event_type": "POINT_IN_TIME", "key": "sgd", "value": 1075448076, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 193}}
:::MLLOG {"namespace": "", "time_ms": 1592976353252, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353253, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353258, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353261, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353261, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353261, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353261, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353261, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592976353535, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1075448076, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 218}}
about to model_zoo.get_model( resnet34_v1 )
about to model_zoo.get_model( resnet34_v1 )
about to model_zoo.get_model( resnet34_v1 )
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1075448108, start_epoch=1, synthetiabout to model_zoo.get_model( resnet34_v1 )
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1075448092, start_epoch=1, synthetiabout to model_zoo.get_model( resnet34_v1 )
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1075448084, start_epoch=1, synthetiabout to model_zoo.get_model( resnet34_v1 )
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1075448132, start_epoch=1, synthetiabout to model_zoo.get_model( resnet34_v1 )
c=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
c=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1075448076, start_epoch=1, synthetiabout to model_zoo.get_model( resnet34_v1 )
c=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1075448100, start_epoch=1, synthetiabout to model_zoo.get_model( resnet34_v1 )
c=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1075448092, start_epoch=1, synthetic=False, tabout to model_zoo.get_model( resnet34_v1 )
c=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
arget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1075448076, start_epoch=1, synthetic=False, tabout to model_zoo.get_model( resnet34_v1 )
arget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1075448084, start_epoch=1, synthetic=False, tabout to model_zoo.get_model( resnet34_v1 )
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1075448116, start_epoch=1, synthetiabout to model_zoo.get_model( resnet34_v1 )
c=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1075448100, start_epoch=1, synthetic=False, tabout to model_zoo.get_model( resnet34_v1 )
arget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
c=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
arget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1075448132, start_epoch=1, synthetic=False, tabout to model_zoo.get_model( resnet34_v1 )
INFO:root:Seed: 1075448076
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Seed: 1075448084
about to model_zoo.get_model( resnet34_v1 )
arget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Seed: 1075448092
Seed: 1075448092
about to model_zoo.get_model( resnet34_v1 )
Seed: 1075448076
about to model_zoo.get_model( resnet34_v1 )
Seed: 1075448084
about to model_zoo.get_model( resnet34_v1 )
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1075448108, start_epoch=1, synthetic=False, tabout to model_zoo.get_model( resnet34_v1 )
INFO:root:Seed: 1075448132
Seed: 1075448132
about to model_zoo.get_model( resnet34_v1 )
INFO:root:precision: fp16
about to model_zoo.get_model( resnet34_v1 )
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1075448116, start_epoch=1, synthetic=False, tabout to model_zoo.get_model( resnet34_v1 )
arget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Seed: 1075448100
about to model_zoo.get_model( resnet34_v1 )
precision: fp16
about to model_zoo.get_model( resnet34_v1 )
INFO:root:precision: fp16
precision: fp16
about to model_zoo.get_model( resnet34_v1 )
arget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
INFO:root:precision: fp16
about to model_zoo.get_model( resnet34_v1 )
INFO:root:loss scaling: 128.0
loss scaling: 128.0
about to model_zoo.get_model( resnet34_v1 )
INFO:root:loss scaling: 128.0
loss scaling: 128.0
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Seed: 1075448116
Seed: 1075448116
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Seed: 1075448108
about to model_zoo.get_model( resnet34_v1 )
INFO:root:precision: fp16
about to model_zoo.get_model( resnet34_v1 )
precision: fp16
about to model_zoo.get_model( resnet34_v1 )
Seed: 1075448100
about to model_zoo.get_model( resnet34_v1 )
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
about to model_zoo.get_model( resnet34_v1 )
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
about to model_zoo.get_model( resnet34_v1 )
precision: fp16
about to model_zoo.get_model( resnet34_v1 )
INFO:root:loss scaling: 128.0
loss scaling: 128.0
about to model_zoo.get_model( resnet34_v1 )
INFO:root:precision: fp16
about to model_zoo.get_model( resnet34_v1 )
INFO:root:fuse bn relu: True
about to model_zoo.get_model( resnet34_v1 )
INFO:root:fuse bn relu: True
fuse bn relu: True
about to model_zoo.get_model( resnet34_v1 )
Seed: 1075448108
about to model_zoo.get_model( resnet34_v1 )
INFO:root:loss scaling: 128.0
about to model_zoo.get_model( resnet34_v1 )
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
about to model_zoo.get_model( resnet34_v1 )
precision: fp16
about to model_zoo.get_model( resnet34_v1 )
INFO:root:precision: fp16
about to model_zoo.get_model( resnet34_v1 )
loss scaling: 128.0
INFO:root:fuse bn relu: True
fuse bn relu: True
INFO:root:loss scaling: 128.0
fuse bn relu: True
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
loss scaling: 128.0
INFO:root:fuse bn add relu: True
INFO:root:fuse bn add relu: True
fuse bn add relu: True
INFO:root:precision: fp16
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
INFO:root:fuse bn add relu: True
fuse bn add relu: True
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
INFO:root:bn group: 1
bn group: 1
precision: fp16
precision: fp16
INFO:root:fuse bn relu: True
INFO:root:fuse bn relu: True
fuse bn relu: True
fuse bn add relu: True
INFO:root:bn all reduce fp16: False
bn all reduce fp16: False
INFO:root:loss scaling: 128.0
INFO:root:loss scaling: 128.0
about to model_zoo.get_model( resnet34_v1 )
fuse bn relu: True
INFO:root:bn group: 1
bn group: 1
INFO:root:bn group: 1
bn group: 1
loss scaling: 128.0
loss scaling: 128.0
INFO:root:fuse bn add relu: True
fuse bn add relu: True
INFO:root:bn all reduce fp16: False
bn all reduce fp16: False
INFO:root:MPI size: 64
MPI size: 64
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1075448124, start_epoch=1, synthetiINFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
INFO:root:fuse bn add relu: True
INFO:root:bn all reduce fp16: False
bn all reduce fp16: False
INFO:root:bn group: 1
bn group: 1
INFO:root:MPI size: 64
MPI size: 64
INFO:root:MPI global rank: 8
MPI global rank: 8
c=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
INFO:root:fuse bn relu: True
fuse bn relu: True
INFO:root:fuse bn relu: True
fuse bn relu: True
fuse bn add relu: True
INFO:root:MPI size: 64
MPI size: 64
INFO:root:bn all reduce fp16: False
bn all reduce fp16: False
INFO:root:MPI global rank: 0
MPI global rank: 0
INFO:root:MPI local rank: 0
MPI local rank: 0
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1075448124, start_epoch=1, synthetic=False, tINFO:root:fuse bn add relu: True
fuse bn add relu: True
INFO:root:fuse bn add relu: True
fuse bn add relu: True
INFO:root:bn group: 1
bn group: 1
INFO:root:MPI size: 64
MPI size: 64
INFO:root:MPI local rank: 0
MPI local rank: 0
arget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
INFO:root:bn group: 1
bn group: 1
INFO:root:bn group: 1
bn group: 1
INFO:root:bn all reduce fp16: False
bn all reduce fp16: False
INFO:root:MPI global rank: 16
MPI global rank: 16
INFO:root:MPI global rank: 24
MPI global rank: 24
INFO:root:async validation: True
async validation: True
INFO:root:Seed: 1075448124
INFO:root:bn all reduce fp16: False
bn all reduce fp16: False
INFO:root:bn all reduce fp16: False
bn all reduce fp16: False
INFO:root:MPI size: 64
MPI size: 64
INFO:root:MPI local rank: 0
MPI local rank: 0
INFO:root:MPI local rank: 0
MPI local rank: 0
INFO:root:async validation: True
async validation: True
INFO:root:MPI size: 64
MPI size: 64
INFO:root:MPI size: 64
MPI size: 64
INFO:root:MPI global rank: 56
MPI global rank: 56
INFO:root:async validation: True
async validation: True
INFO:root:MPI global rank: 40
MPI global rank: 40
INFO:root:MPI global rank: 32
MPI global rank: 32
INFO:root:MPI local rank: 0
MPI local rank: 0
INFO:root:[SSD] network: resnet34_v1
Seed: 1075448124
INFO:root:MPI local rank: 0
MPI local rank: 0
INFO:root:async validation: True
async validation: True
INFO:root:async validation: True
async validation: True
INFO:root:[SSD] network: resnet34_v1
[SSD] network: resnet34_v1
INFO:root:[SSD] network: resnet34_v1
[SSD] network: resnet34_v1
INFO:root:precision: fp16
precision: fp16
INFO:root:MPI local rank: 0
MPI local rank: 0
INFO:root:async validation: True
INFO:root:[SSD] network: resnet34_v1
[SSD] network: resnet34_v1
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
INFO:root:loss scaling: 128.0
loss scaling: 128.0
INFO:root:async validation: True
async validation: True
async validation: True
[SSD] network: resnet34_v1
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
INFO:root:[SSD] network: resnet34_v1
[SSD] network: resnet34_v1
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
INFO:root:[SSD] fuse bn add relu: True
[SSD] fuse bn add relu: True
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
about to model_zoo.get_model( resnet34_v1 )
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
INFO:root:[SSD] bn group: 1
[SSD] bn group: 1
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
INFO:root:fuse bn relu: True
fuse bn relu: True
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
INFO:root:[SSD] network: resnet34_v1
[SSD] network: resnet34_v1
INFO:root:[SSD] fuse bn add relu: True
[SSD] fuse bn add relu: True
INFO:root:fuse bn add relu: True
fuse bn add relu: True
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
INFO:root:[SSD] fuse bn add relu: True
INFO:root:[SSD] fuse bn add relu: True
[SSD] fuse bn add relu: True
INFO:root:bn group: 1
bn group: 1
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn add relu: True
INFO:root:[SSD] bn group: 1
[SSD] fuse bn relu: True
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
[SSD] bn group: 1
INFO:root:[SSD] bn group: 1
[SSD] bn group: 1
INFO:root:[SSD] network: resnet34_v1
[SSD] network: resnet34_v1
INFO:root:[SSD] fuse bn add relu: True
INFO:root:[SSD] bn group: 1
INFO:root:bn all reduce fp16: False
bn all reduce fp16: False
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
[SSD] fuse bn add relu: True
[SSD] bn group: 1
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
INFO:root:MPI size: 64
MPI size: 64
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
INFO:root:[SSD] bn group: 1
INFO:root:MPI global rank: 48
MPI global rank: 48
[SSD] bn group: 1
INFO:root:[SSD] fuse bn add relu: True
[SSD] fuse bn add relu: True
INFO:root:[SSD] fuse bn add relu: True
[SSD] fuse bn add relu: True
INFO:root:[SSD] bn group: 1
[SSD] bn group: 1
INFO:root:MPI local rank: 0
MPI local rank: 0
INFO:root:async validation: True
async validation: True
INFO:root:[SSD] bn group: 1
[SSD] bn group: 1
INFO:root:[SSD] network: resnet34_v1
[SSD] network: resnet34_v1
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
INFO:root:[SSD] fuse bn add relu: True
[SSD] fuse bn add relu: True
INFO:root:[SSD] bn group: 1
[SSD] bn group: 1
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:COCO reader: raw images
COCO reader: raw images
:::MLLOG {"namespace": "", "time_ms": 1592976355629, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 117266, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 363}}
:::MLLOG {"namespace": "", "time_ms": 1592976355629, "event_type": "POINT_IN_TIME", "key": "max_samples", "value": 1, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 364}}
:::MLLOG {"namespace": "", "time_ms": 1592976355630, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 839, "metadata": {"file": "/workspace/ssd/lr_scheduler.py", "lineno": 30}}
:::MLLOG {"namespace": "", "time_ms": 1592976355630, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_factor", "value": 0, "metadata": {"file": "/workspace/ssd/lr_scheduler.py", "lineno": 31}}
:::MLLOG {"namespace": "", "time_ms": 1592976355630, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.14, "metadata": {"file": "/workspace/ssd/lr_scheduler.py", "lineno": 36}}
:::MLLOG {"namespace": "", "time_ms": 1592976355630, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_boundary_epochs", "value": [44, 55], "metadata": {"file": "/workspace/ssd/lr_scheduler.py", "lineno": 37}}
INFO:root:COCO reader: raw images
COCO reader: raw images
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:COCO reader: raw images
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
COCO reader: raw images
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
:::MLLOG {"namespace": "", "time_ms": 1592976355658, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 5000, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 407}}
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
:::MLLOG {"namespace": "", "time_ms": 1592976359220, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.00017, "metadata": {"file": "/workspace/ssd/trainer.py", "lineno": 29}}
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[22:26:02] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:02] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:02] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[22:26:02] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:02] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:02] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:02] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:02] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:02] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:02] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:02] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[22:26:02] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:02] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:02] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[22:26:02] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:02] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[22:26:02] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:02] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:02] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:02] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:02] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:02] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:02] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[22:26:02] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:02] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:26:03] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
INFO:root:Done
Done
INFO:root:Done
Done
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
INFO:root:Done
Done
INFO:root:Done
Done
INFO:root:Done
Done
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
INFO:root:Done
Done
INFO:root:Done
Done
INFO:root:Done
Done
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
:::MLLOG {"namespace": "", "time_ms": 1592976381803, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 495}}
:::MLLOG {"namespace": "", "time_ms": 1592976381804, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 499}}
:::MLLOG {"namespace": "", "time_ms": 1592976382793, "event_type": "POINT_IN_TIME", "key": "model_bn_span", "value": 24, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 101}}
INFO:root:Training from epoch: 1
Training from epoch: 1
INFO:root:Training from epoch: 1
Training from epoch: 1
:::MLLOG {"namespace": "", "time_ms": 1592976382793, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 1536, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 102}}
INFO:root:Training from epoch: 1
Training from epoch: 1
:::MLLOG {"namespace": "", "time_ms": 1592976382811, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 1, "current_iter_num": 0}}
INFO:root:Training from epoch: 1
Training from epoch: 1
INFO:root:Training from epoch: 1
Training from epoch: 1
INFO:root:Training from epoch: 1
Training from epoch: 1
INFO:root:Training from epoch: 1
Training from epoch: 1
INFO:root:Training from epoch: 1
Training from epoch: 1
INFO:root:[Training][Epoch 1] training time: 2.475 [sec],avg speed: 47789.145 [imgs/sec],loss=16.349
[Training][Epoch 1] training time: 2.475 [sec],avg speed: 47789.145 [imgs/sec],loss=16.349
:::MLLOG {"namespace": "", "time_ms": 1592976385286, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1592976385287, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 2, "current_iter_num": 0}}
INFO:root:[Training][Iteration 100][Epoch 2, Batch 23/77] lr: 0.01669, training time: 29.044 [ms], speed: 52884.398 [imgs/sec], loss=9.045
[Training][Iteration 100][Epoch 2, Batch 23/77] lr: 0.01669, training time: 29.044 [ms], speed: 52884.398 [imgs/sec], loss=9.045
INFO:root:[Training][Epoch 2] training time: 2.205 [sec],avg speed: 52944.756 [imgs/sec],loss=9.135
[Training][Epoch 2] training time: 2.205 [sec],avg speed: 52944.756 [imgs/sec],loss=9.135
:::MLLOG {"namespace": "", "time_ms": 1592976387492, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1592976387492, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 3, "current_iter_num": 0}}
INFO:root:[Training][Iteration 200][Epoch 3, Batch 46/77] lr: 0.03337, training time: 28.495 [ms], speed: 53904.202 [imgs/sec], loss=8.590
[Training][Iteration 200][Epoch 3, Batch 46/77] lr: 0.03337, training time: 28.495 [ms], speed: 53904.202 [imgs/sec], loss=8.590
INFO:root:[Training][Epoch 3] training time: 2.169 [sec],avg speed: 53808.219 [imgs/sec],loss=8.153
[Training][Epoch 3] training time: 2.169 [sec],avg speed: 53808.219 [imgs/sec],loss=8.153
:::MLLOG {"namespace": "", "time_ms": 1592976389662, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592976389662, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 4, "current_iter_num": 0}}
INFO:root:[Training][Iteration 300][Epoch 4, Batch 69/77] lr: 0.05006, training time: 28.484 [ms], speed: 53925.438 [imgs/sec], loss=7.244
[Training][Iteration 300][Epoch 4, Batch 69/77] lr: 0.05006, training time: 28.484 [ms], speed: 53925.438 [imgs/sec], loss=7.244
INFO:root:[Training][Epoch 4] training time: 2.197 [sec],avg speed: 53836.458 [imgs/sec],loss=7.493
[Training][Epoch 4] training time: 2.197 [sec],avg speed: 53836.458 [imgs/sec],loss=7.493
:::MLLOG {"namespace": "", "time_ms": 1592976391859, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592976391859, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 5, "current_iter_num": 0}}
INFO:root:[Training][Epoch 5] training time: 2.176 [sec],avg speed: 53659.120 [imgs/sec],loss=7.171
[Training][Epoch 5] training time: 2.176 [sec],avg speed: 53659.120 [imgs/sec],loss=7.171
:::MLLOG {"namespace": "", "time_ms": 1592976394035, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1592976394035, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 6, "current_iter_num": 0}}
INFO:root:[Training][Iteration 400][Epoch 6, Batch 15/77] lr: 0.06675, training time: 28.370 [ms], speed: 54141.064 [imgs/sec], loss=6.331
[Training][Iteration 400][Epoch 6, Batch 15/77] lr: 0.06675, training time: 28.370 [ms], speed: 54141.064 [imgs/sec], loss=6.331
INFO:root:[Training][Epoch 6] training time: 2.161 [sec],avg speed: 54009.955 [imgs/sec],loss=6.634
[Training][Epoch 6] training time: 2.161 [sec],avg speed: 54009.955 [imgs/sec],loss=6.634
:::MLLOG {"namespace": "", "time_ms": 1592976396197, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 6}}
:::MLLOG {"namespace": "", "time_ms": 1592976396197, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 7, "current_iter_num": 0}}
INFO:root:[Training][Iteration 500][Epoch 7, Batch 38/77] lr: 0.08343, training time: 28.304 [ms], speed: 54268.670 [imgs/sec], loss=6.388
[Training][Iteration 500][Epoch 7, Batch 38/77] lr: 0.08343, training time: 28.304 [ms], speed: 54268.670 [imgs/sec], loss=6.388
INFO:root:[Training][Epoch 7] training time: 2.178 [sec],avg speed: 54300.451 [imgs/sec],loss=6.279
[Training][Epoch 7] training time: 2.178 [sec],avg speed: 54300.451 [imgs/sec],loss=6.279
:::MLLOG {"namespace": "", "time_ms": 1592976398375, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1592976398376, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 8, "current_iter_num": 0}}
INFO:root:[Training][Iteration 600][Epoch 8, Batch 61/77] lr: 0.10012, training time: 28.262 [ms], speed: 54348.630 [imgs/sec], loss=6.388
[Training][Iteration 600][Epoch 8, Batch 61/77] lr: 0.10012, training time: 28.262 [ms], speed: 54348.630 [imgs/sec], loss=6.388
INFO:root:[Training][Epoch 8] training time: 2.149 [sec],avg speed: 54316.194 [imgs/sec],loss=5.969
[Training][Epoch 8] training time: 2.149 [sec],avg speed: 54316.194 [imgs/sec],loss=5.969
:::MLLOG {"namespace": "", "time_ms": 1592976400525, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 8}}
:::MLLOG {"namespace": "", "time_ms": 1592976400525, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 9, "current_iter_num": 0}}
INFO:root:[Training][Epoch 9] training time: 2.153 [sec],avg speed: 54214.794 [imgs/sec],loss=5.885
[Training][Epoch 9] training time: 2.153 [sec],avg speed: 54214.794 [imgs/sec],loss=5.885
:::MLLOG {"namespace": "", "time_ms": 1592976402679, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 9}}
:::MLLOG {"namespace": "", "time_ms": 1592976402679, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 10, "current_iter_num": 0}}
INFO:root:[Training][Iteration 700][Epoch 10, Batch 7/77] lr: 0.11681, training time: 28.162 [ms], speed: 54540.784 [imgs/sec], loss=5.465
[Training][Iteration 700][Epoch 10, Batch 7/77] lr: 0.11681, training time: 28.162 [ms], speed: 54540.784 [imgs/sec], loss=5.465
INFO:root:[Training][Epoch 10] training time: 2.200 [sec],avg speed: 53759.999 [imgs/sec],loss=5.572
[Training][Epoch 10] training time: 2.200 [sec],avg speed: 53759.999 [imgs/sec],loss=5.572
:::MLLOG {"namespace": "", "time_ms": 1592976404879, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 10}}
:::MLLOG {"namespace": "", "time_ms": 1592976404879, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 11, "current_iter_num": 0}}
INFO:root:[Training][Iteration 800][Epoch 11, Batch 30/77] lr: 0.13349, training time: 28.340 [ms], speed: 54198.530 [imgs/sec], loss=5.245
[Training][Iteration 800][Epoch 11, Batch 30/77] lr: 0.13349, training time: 28.340 [ms], speed: 54198.530 [imgs/sec], loss=5.245
INFO:root:[Training][Epoch 11] training time: 2.149 [sec],avg speed: 54324.884 [imgs/sec],loss=5.405
[Training][Epoch 11] training time: 2.149 [sec],avg speed: 54324.884 [imgs/sec],loss=5.405
:::MLLOG {"namespace": "", "time_ms": 1592976407028, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1592976407029, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 12, "current_iter_num": 0}}
INFO:root:[Training][Iteration 900][Epoch 12, Batch 53/77] lr: 0.14000, training time: 28.134 [ms], speed: 54596.527 [imgs/sec], loss=5.261
[Training][Iteration 900][Epoch 12, Batch 53/77] lr: 0.14000, training time: 28.134 [ms], speed: 54596.527 [imgs/sec], loss=5.261
INFO:root:[Training][Epoch 12] training time: 2.139 [sec],avg speed: 54578.443 [imgs/sec],loss=5.134
[Training][Epoch 12] training time: 2.139 [sec],avg speed: 54578.443 [imgs/sec],loss=5.134
:::MLLOG {"namespace": "", "time_ms": 1592976409168, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1592976409168, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 13, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1000][Epoch 13, Batch 76/77] lr: 0.14000, training time: 28.214 [ms], speed: 54441.506 [imgs/sec], loss=4.730
[Training][Iteration 1000][Epoch 13, Batch 76/77] lr: 0.14000, training time: 28.214 [ms], speed: 54441.506 [imgs/sec], loss=4.730
INFO:root:[Training][Epoch 13] training time: 2.174 [sec],avg speed: 54413.720 [imgs/sec],loss=4.991
[Training][Epoch 13] training time: 2.174 [sec],avg speed: 54413.720 [imgs/sec],loss=4.991
:::MLLOG {"namespace": "", "time_ms": 1592976411342, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 13}}
:::MLLOG {"namespace": "", "time_ms": 1592976411342, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 14, "current_iter_num": 0}}
INFO:root:[Training][Epoch 14] training time: 2.146 [sec],avg speed: 54389.684 [imgs/sec],loss=4.926
[Training][Epoch 14] training time: 2.146 [sec],avg speed: 54389.684 [imgs/sec],loss=4.926
:::MLLOG {"namespace": "", "time_ms": 1592976413488, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 14}}
:::MLLOG {"namespace": "", "time_ms": 1592976413489, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 15, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1100][Epoch 15, Batch 22/77] lr: 0.14000, training time: 28.234 [ms], speed: 54403.340 [imgs/sec], loss=4.330
[Training][Iteration 1100][Epoch 15, Batch 22/77] lr: 0.14000, training time: 28.234 [ms], speed: 54403.340 [imgs/sec], loss=4.330
INFO:root:[Training][Epoch 15] training time: 2.145 [sec],avg speed: 54428.706 [imgs/sec],loss=4.743
[Training][Epoch 15] training time: 2.145 [sec],avg speed: 54428.706 [imgs/sec],loss=4.743
:::MLLOG {"namespace": "", "time_ms": 1592976415634, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1592976415634, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 16, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1200][Epoch 16, Batch 45/77] lr: 0.14000, training time: 28.112 [ms], speed: 54639.375 [imgs/sec], loss=5.302
[Training][Iteration 1200][Epoch 16, Batch 45/77] lr: 0.14000, training time: 28.112 [ms], speed: 54639.375 [imgs/sec], loss=5.302
INFO:root:[Training][Epoch 16] training time: 2.169 [sec],avg speed: 54540.568 [imgs/sec],loss=4.746
[Training][Epoch 16] training time: 2.169 [sec],avg speed: 54540.568 [imgs/sec],loss=4.746
:::MLLOG {"namespace": "", "time_ms": 1592976417803, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1592976417803, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 17, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1300][Epoch 17, Batch 68/77] lr: 0.14000, training time: 28.104 [ms], speed: 54654.503 [imgs/sec], loss=4.479
[Training][Iteration 1300][Epoch 17, Batch 68/77] lr: 0.14000, training time: 28.104 [ms], speed: 54654.503 [imgs/sec], loss=4.479
INFO:root:[Training][Epoch 17] training time: 2.137 [sec],avg speed: 54623.964 [imgs/sec],loss=4.635
[Training][Epoch 17] training time: 2.137 [sec],avg speed: 54623.964 [imgs/sec],loss=4.635
:::MLLOG {"namespace": "", "time_ms": 1592976419940, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 17}}
:::MLLOG {"namespace": "", "time_ms": 1592976419940, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 18, "current_iter_num": 0}}
INFO:root:[Training][Epoch 18] training time: 2.139 [sec],avg speed: 54574.684 [imgs/sec],loss=4.628
[Training][Epoch 18] training time: 2.139 [sec],avg speed: 54574.684 [imgs/sec],loss=4.628
:::MLLOG {"namespace": "", "time_ms": 1592976422080, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1592976422080, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 19, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1400][Epoch 19, Batch 14/77] lr: 0.14000, training time: 28.339 [ms], speed: 54201.554 [imgs/sec], loss=4.014
[Training][Iteration 1400][Epoch 19, Batch 14/77] lr: 0.14000, training time: 28.339 [ms], speed: 54201.554 [imgs/sec], loss=4.014
INFO:root:[Training][Epoch 19] training time: 2.174 [sec],avg speed: 54396.882 [imgs/sec],loss=4.507
[Training][Epoch 19] training time: 2.174 [sec],avg speed: 54396.882 [imgs/sec],loss=4.507
:::MLLOG {"namespace": "", "time_ms": 1592976424254, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1592976424254, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 20, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1500][Epoch 20, Batch 37/77] lr: 0.14000, training time: 28.114 [ms], speed: 54633.982 [imgs/sec], loss=5.083
[Training][Iteration 1500][Epoch 20, Batch 37/77] lr: 0.14000, training time: 28.114 [ms], speed: 54633.982 [imgs/sec], loss=5.083
INFO:root:[Training][Epoch 20] training time: 2.141 [sec],avg speed: 54523.118 [imgs/sec],loss=4.382
[Training][Epoch 20] training time: 2.141 [sec],avg speed: 54523.118 [imgs/sec],loss=4.382
:::MLLOG {"namespace": "", "time_ms": 1592976426396, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1592976426396, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 21, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1600][Epoch 21, Batch 60/77] lr: 0.14000, training time: 28.222 [ms], speed: 54425.287 [imgs/sec], loss=4.503
[Training][Iteration 1600][Epoch 21, Batch 60/77] lr: 0.14000, training time: 28.222 [ms], speed: 54425.287 [imgs/sec], loss=4.503
INFO:root:[Training][Epoch 21] training time: 2.146 [sec],avg speed: 54408.287 [imgs/sec],loss=4.444
[Training][Epoch 21] training time: 2.146 [sec],avg speed: 54408.287 [imgs/sec],loss=4.444
:::MLLOG {"namespace": "", "time_ms": 1592976428542, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 21}}
:::MLLOG {"namespace": "", "time_ms": 1592976428542, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 22, "current_iter_num": 0}}
INFO:root:[Training][Epoch 22] training time: 2.163 [sec],avg speed: 54685.179 [imgs/sec],loss=4.396
[Training][Epoch 22] training time: 2.163 [sec],avg speed: 54685.179 [imgs/sec],loss=4.396
:::MLLOG {"namespace": "", "time_ms": 1592976430705, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 22}}
:::MLLOG {"namespace": "", "time_ms": 1592976430705, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 23, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1700][Epoch 23, Batch 6/77] lr: 0.14000, training time: 28.177 [ms], speed: 54512.117 [imgs/sec], loss=3.701
[Training][Iteration 1700][Epoch 23, Batch 6/77] lr: 0.14000, training time: 28.177 [ms], speed: 54512.117 [imgs/sec], loss=3.701
INFO:root:[Training][Epoch 23] training time: 2.138 [sec],avg speed: 54609.884 [imgs/sec],loss=4.330
[Training][Epoch 23] training time: 2.138 [sec],avg speed: 54609.884 [imgs/sec],loss=4.330
:::MLLOG {"namespace": "", "time_ms": 1592976432843, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1592976432843, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 24, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1800][Epoch 24, Batch 29/77] lr: 0.14000, training time: 28.100 [ms], speed: 54661.975 [imgs/sec], loss=3.624
[Training][Iteration 1800][Epoch 24, Batch 29/77] lr: 0.14000, training time: 28.100 [ms], speed: 54661.975 [imgs/sec], loss=3.624
INFO:root:[Training][Epoch 24] training time: 2.132 [sec],avg speed: 54752.232 [imgs/sec],loss=4.295
[Training][Epoch 24] training time: 2.132 [sec],avg speed: 54752.232 [imgs/sec],loss=4.295
:::MLLOG {"namespace": "", "time_ms": 1592976434976, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1592976434976, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 25, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1900][Epoch 25, Batch 52/77] lr: 0.14000, training time: 28.099 [ms], speed: 54664.312 [imgs/sec], loss=3.901
[Training][Iteration 1900][Epoch 25, Batch 52/77] lr: 0.14000, training time: 28.099 [ms], speed: 54664.312 [imgs/sec], loss=3.901
INFO:root:[Training][Epoch 25] training time: 2.168 [sec],avg speed: 54555.852 [imgs/sec],loss=4.193
[Training][Epoch 25] training time: 2.168 [sec],avg speed: 54555.852 [imgs/sec],loss=4.193
:::MLLOG {"namespace": "", "time_ms": 1592976437144, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 25}}
:::MLLOG {"namespace": "", "time_ms": 1592976437144, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 26, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2000][Epoch 26, Batch 75/77] lr: 0.14000, training time: 28.168 [ms], speed: 54529.875 [imgs/sec], loss=4.281
[Training][Iteration 2000][Epoch 26, Batch 75/77] lr: 0.14000, training time: 28.168 [ms], speed: 54529.875 [imgs/sec], loss=4.281
INFO:root:[Training][Epoch 26] training time: 2.142 [sec],avg speed: 54501.767 [imgs/sec],loss=4.274
[Training][Epoch 26] training time: 2.142 [sec],avg speed: 54501.767 [imgs/sec],loss=4.274
:::MLLOG {"namespace": "", "time_ms": 1592976439286, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 26}}
:::MLLOG {"namespace": "", "time_ms": 1592976439286, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 27, "current_iter_num": 0}}
INFO:root:[Training][Epoch 27] training time: 2.134 [sec],avg speed: 54705.917 [imgs/sec],loss=4.214
[Training][Epoch 27] training time: 2.134 [sec],avg speed: 54705.917 [imgs/sec],loss=4.214
:::MLLOG {"namespace": "", "time_ms": 1592976441420, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1592976441421, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 28, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2100][Epoch 28, Batch 21/77] lr: 0.14000, training time: 28.162 [ms], speed: 54540.630 [imgs/sec], loss=4.722
[Training][Iteration 2100][Epoch 28, Batch 21/77] lr: 0.14000, training time: 28.162 [ms], speed: 54540.630 [imgs/sec], loss=4.722
INFO:root:[Training][Epoch 28] training time: 2.167 [sec],avg speed: 54578.282 [imgs/sec],loss=4.189
[Training][Epoch 28] training time: 2.167 [sec],avg speed: 54578.282 [imgs/sec],loss=4.189
:::MLLOG {"namespace": "", "time_ms": 1592976443588, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1592976443588, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 29, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2200][Epoch 29, Batch 44/77] lr: 0.14000, training time: 28.049 [ms], speed: 54762.024 [imgs/sec], loss=4.017
[Training][Iteration 2200][Epoch 29, Batch 44/77] lr: 0.14000, training time: 28.049 [ms], speed: 54762.024 [imgs/sec], loss=4.017
INFO:root:[Training][Epoch 29] training time: 2.134 [sec],avg speed: 54703.203 [imgs/sec],loss=4.171
[Training][Epoch 29] training time: 2.134 [sec],avg speed: 54703.203 [imgs/sec],loss=4.171
:::MLLOG {"namespace": "", "time_ms": 1592976445722, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 29}}
:::MLLOG {"namespace": "", "time_ms": 1592976445723, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 30, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2300][Epoch 30, Batch 67/77] lr: 0.14000, training time: 28.028 [ms], speed: 54801.755 [imgs/sec], loss=4.610
[Training][Iteration 2300][Epoch 30, Batch 67/77] lr: 0.14000, training time: 28.028 [ms], speed: 54801.755 [imgs/sec], loss=4.610
INFO:root:[Training][Epoch 30] training time: 2.130 [sec],avg speed: 54798.454 [imgs/sec],loss=4.084
[Training][Epoch 30] training time: 2.130 [sec],avg speed: 54798.454 [imgs/sec],loss=4.084
:::MLLOG {"namespace": "", "time_ms": 1592976447853, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 30}}
:::MLLOG {"namespace": "", "time_ms": 1592976447853, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 31, "current_iter_num": 0}}
INFO:root:[Training][Epoch 31] training time: 2.164 [sec],avg speed: 54658.468 [imgs/sec],loss=4.094
[Training][Epoch 31] training time: 2.164 [sec],avg speed: 54658.468 [imgs/sec],loss=4.094
:::MLLOG {"namespace": "", "time_ms": 1592976450017, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1592976450018, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 32, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2400][Epoch 32, Batch 13/77] lr: 0.14000, training time: 28.048 [ms], speed: 54762.400 [imgs/sec], loss=3.432
[Training][Iteration 2400][Epoch 32, Batch 13/77] lr: 0.14000, training time: 28.048 [ms], speed: 54762.400 [imgs/sec], loss=3.432
INFO:root:[Training][Epoch 32] training time: 2.134 [sec],avg speed: 54703.099 [imgs/sec],loss=4.046
[Training][Epoch 32] training time: 2.134 [sec],avg speed: 54703.099 [imgs/sec],loss=4.046
:::MLLOG {"namespace": "", "time_ms": 1592976452152, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1592976452152, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 33, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2500][Epoch 33, Batch 36/77] lr: 0.14000, training time: 28.007 [ms], speed: 54844.176 [imgs/sec], loss=4.216
[Training][Iteration 2500][Epoch 33, Batch 36/77] lr: 0.14000, training time: 28.007 [ms], speed: 54844.176 [imgs/sec], loss=4.216
INFO:root:[Training][Epoch 33] training time: 2.129 [sec],avg speed: 54833.846 [imgs/sec],loss=4.030
[Training][Epoch 33] training time: 2.129 [sec],avg speed: 54833.846 [imgs/sec],loss=4.030
:::MLLOG {"namespace": "", "time_ms": 1592976454281, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 33}}
:::MLLOG {"namespace": "", "time_ms": 1592976454282, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 34, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2600][Epoch 34, Batch 59/77] lr: 0.14000, training time: 27.975 [ms], speed: 54906.940 [imgs/sec], loss=3.498
[Training][Iteration 2600][Epoch 34, Batch 59/77] lr: 0.14000, training time: 27.975 [ms], speed: 54906.940 [imgs/sec], loss=3.498
INFO:root:[Training][Epoch 34] training time: 2.156 [sec],avg speed: 54863.303 [imgs/sec],loss=4.006
[Training][Epoch 34] training time: 2.156 [sec],avg speed: 54863.303 [imgs/sec],loss=4.006
:::MLLOG {"namespace": "", "time_ms": 1592976456437, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 34}}
:::MLLOG {"namespace": "", "time_ms": 1592976456438, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 35, "current_iter_num": 0}}
INFO:root:[Training][Epoch 35] training time: 2.128 [sec],avg speed: 54869.978 [imgs/sec],loss=4.058
[Training][Epoch 35] training time: 2.128 [sec],avg speed: 54869.978 [imgs/sec],loss=4.058
:::MLLOG {"namespace": "", "time_ms": 1592976458565, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1592976458566, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 36, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2700][Epoch 36, Batch 5/77] lr: 0.14000, training time: 28.232 [ms], speed: 54406.711 [imgs/sec], loss=4.204
[Training][Iteration 2700][Epoch 36, Batch 5/77] lr: 0.14000, training time: 28.232 [ms], speed: 54406.711 [imgs/sec], loss=4.204
INFO:root:[Training][Epoch 36] training time: 2.129 [sec],avg speed: 54834.411 [imgs/sec],loss=3.955
[Training][Epoch 36] training time: 2.129 [sec],avg speed: 54834.411 [imgs/sec],loss=3.955
:::MLLOG {"namespace": "", "time_ms": 1592976460695, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 36}}
:::MLLOG {"namespace": "", "time_ms": 1592976460695, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 37, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2800][Epoch 37, Batch 28/77] lr: 0.14000, training time: 28.063 [ms], speed: 54734.939 [imgs/sec], loss=4.079
[Training][Iteration 2800][Epoch 37, Batch 28/77] lr: 0.14000, training time: 28.063 [ms], speed: 54734.939 [imgs/sec], loss=4.079
INFO:root:[Training][Epoch 37] training time: 2.163 [sec],avg speed: 54674.685 [imgs/sec],loss=3.920
[Training][Epoch 37] training time: 2.163 [sec],avg speed: 54674.685 [imgs/sec],loss=3.920
:::MLLOG {"namespace": "", "time_ms": 1592976462858, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 37}}
:::MLLOG {"namespace": "", "time_ms": 1592976462859, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 38, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2900][Epoch 38, Batch 51/77] lr: 0.14000, training time: 28.039 [ms], speed: 54780.645 [imgs/sec], loss=4.122
[Training][Iteration 2900][Epoch 38, Batch 51/77] lr: 0.14000, training time: 28.039 [ms], speed: 54780.645 [imgs/sec], loss=4.122
INFO:root:[Training][Epoch 38] training time: 2.130 [sec],avg speed: 54799.123 [imgs/sec],loss=3.983
[Training][Epoch 38] training time: 2.130 [sec],avg speed: 54799.123 [imgs/sec],loss=3.983
:::MLLOG {"namespace": "", "time_ms": 1592976464989, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 38}}
:::MLLOG {"namespace": "", "time_ms": 1592976464989, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 39, "current_iter_num": 0}}
INFO:root:[Training][Iteration 3000][Epoch 39, Batch 74/77] lr: 0.14000, training time: 28.040 [ms], speed: 54778.340 [imgs/sec], loss=3.865
[Training][Iteration 3000][Epoch 39, Batch 74/77] lr: 0.14000, training time: 28.040 [ms], speed: 54778.340 [imgs/sec], loss=3.865
INFO:root:[Training][Epoch 39] training time: 2.133 [sec],avg speed: 54719.453 [imgs/sec],loss=3.938
[Training][Epoch 39] training time: 2.133 [sec],avg speed: 54719.453 [imgs/sec],loss=3.938
:::MLLOG {"namespace": "", "time_ms": 1592976467123, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 39}}
:::MLLOG {"namespace": "", "time_ms": 1592976467123, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 40, "current_iter_num": 0}}
INFO:root:[Training][Epoch 40] training time: 2.159 [sec],avg speed: 54785.027 [imgs/sec],loss=4.052
[Training][Epoch 40] training time: 2.159 [sec],avg speed: 54785.027 [imgs/sec],loss=4.052
:::MLLOG {"namespace": "", "time_ms": 1592976469282, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1592976469294, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 243, "epoch_num": 40}}
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 810.096 [ms], allgather: 131.711 [ms], asnumpy: 4.893 [ms], speed: 5281.500 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 810.096 [ms], allgather: 131.711 [ms], asnumpy: 4.893 [ms], speed: 5281.500 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 786.521 [ms], allgather: 157.454 [ms], asnumpy: 4.902 [ms], speed: 5269.376 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 786.521 [ms], allgather: 157.454 [ms], asnumpy: 4.902 [ms], speed: 5269.376 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 806.025 [ms], allgather: 141.733 [ms], asnumpy: 5.197 [ms], speed: 5246.824 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 806.025 [ms], allgather: 141.733 [ms], asnumpy: 5.197 [ms], speed: 5246.824 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 778.351 [ms], allgather: 173.517 [ms], asnumpy: 4.977 [ms], speed: 5225.501 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 778.351 [ms], allgather: 173.517 [ms], asnumpy: 4.977 [ms], speed: 5225.501 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 808.969 [ms], allgather: 146.752 [ms], asnumpy: 4.878 [ms], speed: 5205.078 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 808.969 [ms], allgather: 146.752 [ms], asnumpy: 4.878 [ms], speed: 5205.078 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 792.605 [ms], allgather: 168.882 [ms], asnumpy: 4.811 [ms], speed: 5174.379 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 792.605 [ms], allgather: 168.882 [ms], asnumpy: 4.811 [ms], speed: 5174.379 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 806.028 [ms], allgather: 166.164 [ms], asnumpy: 5.081 [ms], speed: 5116.266 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 806.028 [ms], allgather: 166.164 [ms], asnumpy: 5.081 [ms], speed: 5116.266 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 794.508 [ms], allgather: 192.796 [ms], asnumpy: 5.348 [ms], speed: 5037.000 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 794.508 [ms], allgather: 192.796 [ms], asnumpy: 5.348 [ms], speed: 5037.000 [imgs/sec]
:::MLLOG {"namespace": "", "time_ms": 1592976470289, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 41, "current_iter_num": 0}}
INFO:root:[Training][Iteration 3100][Epoch 41, Batch 20/77] lr: 0.14000, training time: 31.787 [ms], speed: 48321.112 [imgs/sec], loss=3.699
[Training][Iteration 3100][Epoch 41, Batch 20/77] lr: 0.14000, training time: 31.787 [ms], speed: 48321.112 [imgs/sec], loss=3.699
INFO:root:[Training][Epoch 41] training time: 2.213 [sec],avg speed: 52742.543 [imgs/sec],loss=3.927
[Training][Epoch 41] training time: 2.213 [sec],avg speed: 52742.543 [imgs/sec],loss=3.927
:::MLLOG {"namespace": "", "time_ms": 1592976472503, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1592976472503, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 42, "current_iter_num": 0}}
:::MLLOG {"namespace": "", "time_ms": 1592976472781, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 291, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1592976472783, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.166603832831325, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 294, "epoch_num": 40}}
INFO:root:[Training][Iteration 3200][Epoch 42, Batch 43/77] lr: 0.14000, training time: 28.120 [ms], speed: 54623.525 [imgs/sec], loss=3.849
[Training][Iteration 3200][Epoch 42, Batch 43/77] lr: 0.14000, training time: 28.120 [ms], speed: 54623.525 [imgs/sec], loss=3.849
INFO:root:[Training][Epoch 42] training time: 2.138 [sec],avg speed: 54606.906 [imgs/sec],loss=4.005
[Training][Epoch 42] training time: 2.138 [sec],avg speed: 54606.906 [imgs/sec],loss=4.005
:::MLLOG {"namespace": "", "time_ms": 1592976474641, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 42}}
:::MLLOG {"namespace": "", "time_ms": 1592976474641, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 43, "current_iter_num": 0}}
INFO:root:[Training][Iteration 3300][Epoch 43, Batch 66/77] lr: 0.14000, training time: 28.042 [ms], speed: 54774.193 [imgs/sec], loss=4.259
[Training][Iteration 3300][Epoch 43, Batch 66/77] lr: 0.14000, training time: 28.042 [ms], speed: 54774.193 [imgs/sec], loss=4.259
INFO:root:[Training][Epoch 43] training time: 2.162 [sec],avg speed: 54695.326 [imgs/sec],loss=3.878
[Training][Epoch 43] training time: 2.162 [sec],avg speed: 54695.326 [imgs/sec],loss=3.878
:::MLLOG {"namespace": "", "time_ms": 1592976476804, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 43}}
:::MLLOG {"namespace": "", "time_ms": 1592976476804, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 44, "current_iter_num": 0}}
INFO:root:[Training][Epoch 44] training time: 2.135 [sec],avg speed: 54675.928 [imgs/sec],loss=3.898
[Training][Epoch 44] training time: 2.135 [sec],avg speed: 54675.928 [imgs/sec],loss=3.898
:::MLLOG {"namespace": "", "time_ms": 1592976478940, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 44}}
:::MLLOG {"namespace": "", "time_ms": 1592976478940, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 45, "current_iter_num": 0}}
INFO:root:[Training][Iteration 3400][Epoch 45, Batch 12/77] lr: 0.01400, training time: 28.288 [ms], speed: 54297.791 [imgs/sec], loss=4.099
[Training][Iteration 3400][Epoch 45, Batch 12/77] lr: 0.01400, training time: 28.288 [ms], speed: 54297.791 [imgs/sec], loss=4.099
INFO:root:[Training][Epoch 45] training time: 2.158 [sec],avg speed: 54105.920 [imgs/sec],loss=3.611
[Training][Epoch 45] training time: 2.158 [sec],avg speed: 54105.920 [imgs/sec],loss=3.611
:::MLLOG {"namespace": "", "time_ms": 1592976481098, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 45}}
:::MLLOG {"namespace": "", "time_ms": 1592976481098, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 46, "current_iter_num": 0}}
INFO:root:[Training][Iteration 3500][Epoch 46, Batch 35/77] lr: 0.01400, training time: 28.217 [ms], speed: 54435.607 [imgs/sec], loss=3.056
[Training][Iteration 3500][Epoch 46, Batch 35/77] lr: 0.01400, training time: 28.217 [ms], speed: 54435.607 [imgs/sec], loss=3.056
INFO:root:[Training][Epoch 46] training time: 2.169 [sec],avg speed: 54536.179 [imgs/sec],loss=3.507
[Training][Epoch 46] training time: 2.169 [sec],avg speed: 54536.179 [imgs/sec],loss=3.507
:::MLLOG {"namespace": "", "time_ms": 1592976483267, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 46}}
:::MLLOG {"namespace": "", "time_ms": 1592976483267, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 47, "current_iter_num": 0}}
INFO:root:[Training][Iteration 3600][Epoch 47, Batch 58/77] lr: 0.01400, training time: 28.066 [ms], speed: 54727.487 [imgs/sec], loss=3.243
[Training][Iteration 3600][Epoch 47, Batch 58/77] lr: 0.01400, training time: 28.066 [ms], speed: 54727.487 [imgs/sec], loss=3.243
INFO:root:[Training][Epoch 47] training time: 2.133 [sec],avg speed: 54736.165 [imgs/sec],loss=3.471
[Training][Epoch 47] training time: 2.133 [sec],avg speed: 54736.165 [imgs/sec],loss=3.471
:::MLLOG {"namespace": "", "time_ms": 1592976485400, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 47}}
:::MLLOG {"namespace": "", "time_ms": 1592976485400, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 48, "current_iter_num": 0}}
INFO:root:[Training][Epoch 48] training time: 2.133 [sec],avg speed: 54726.566 [imgs/sec],loss=3.509
[Training][Epoch 48] training time: 2.133 [sec],avg speed: 54726.566 [imgs/sec],loss=3.509
:::MLLOG {"namespace": "", "time_ms": 1592976487534, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 48}}
:::MLLOG {"namespace": "", "time_ms": 1592976487534, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 49, "current_iter_num": 0}}
INFO:root:[Training][Iteration 3700][Epoch 49, Batch 4/77] lr: 0.01400, training time: 28.991 [ms], speed: 52981.989 [imgs/sec], loss=3.354
[Training][Iteration 3700][Epoch 49, Batch 4/77] lr: 0.01400, training time: 28.991 [ms], speed: 52981.989 [imgs/sec], loss=3.354
INFO:root:[Training][Epoch 49] training time: 2.161 [sec],avg speed: 54732.675 [imgs/sec],loss=3.419
[Training][Epoch 49] training time: 2.161 [sec],avg speed: 54732.675 [imgs/sec],loss=3.419
:::MLLOG {"namespace": "", "time_ms": 1592976489695, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 49}}
:::MLLOG {"namespace": "", "time_ms": 1592976489695, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 50, "current_iter_num": 0}}
INFO:root:[Training][Iteration 3800][Epoch 50, Batch 27/77] lr: 0.01400, training time: 28.101 [ms], speed: 54659.817 [imgs/sec], loss=3.606
[Training][Iteration 3800][Epoch 50, Batch 27/77] lr: 0.01400, training time: 28.101 [ms], speed: 54659.817 [imgs/sec], loss=3.606
INFO:root:[Training][Epoch 50] training time: 2.148 [sec],avg speed: 54342.243 [imgs/sec],loss=3.409
[Training][Epoch 50] training time: 2.148 [sec],avg speed: 54342.243 [imgs/sec],loss=3.409
:::MLLOG {"namespace": "", "time_ms": 1592976491844, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1592976491856, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 243, "epoch_num": 50}}
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 135.588 [ms], allgather: 144.562 [ms], asnumpy: 6.269 [ms], speed: 17456.817 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 135.588 [ms], allgather: 144.562 [ms], asnumpy: 6.269 [ms], speed: 17456.817 [imgs/sec]
:::MLLOG {"namespace": "", "time_ms": 1592976492148, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 51, "current_iter_num": 0}}
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 146.843 [ms], allgather: 150.959 [ms], asnumpy: 4.993 [ms], speed: 16512.709 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 146.843 [ms], allgather: 150.959 [ms], asnumpy: 4.993 [ms], speed: 16512.709 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 138.992 [ms], allgather: 167.514 [ms], asnumpy: 5.223 [ms], speed: 16039.563 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 138.992 [ms], allgather: 167.514 [ms], asnumpy: 5.223 [ms], speed: 16039.563 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 140.375 [ms], allgather: 184.368 [ms], asnumpy: 4.971 [ms], speed: 15164.600 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 140.375 [ms], allgather: 184.368 [ms], asnumpy: 4.971 [ms], speed: 15164.600 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 124.083 [ms], allgather: 211.679 [ms], asnumpy: 4.957 [ms], speed: 14674.758 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 124.083 [ms], allgather: 211.679 [ms], asnumpy: 4.957 [ms], speed: 14674.758 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 142.034 [ms], allgather: 210.465 [ms], asnumpy: 4.935 [ms], speed: 13988.548 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 142.034 [ms], allgather: 210.465 [ms], asnumpy: 4.935 [ms], speed: 13988.548 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 145.763 [ms], allgather: 217.248 [ms], asnumpy: 4.995 [ms], speed: 13586.639 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 145.763 [ms], allgather: 217.248 [ms], asnumpy: 4.995 [ms], speed: 13586.639 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 143.509 [ms], allgather: 235.540 [ms], asnumpy: 6.190 [ms], speed: 12978.887 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 143.509 [ms], allgather: 235.540 [ms], asnumpy: 6.190 [ms], speed: 12978.887 [imgs/sec]
INFO:root:[Training][Iteration 3900][Epoch 51, Batch 50/77] lr: 0.01400, training time: 30.334 [ms], speed: 50636.448 [imgs/sec], loss=2.982
[Training][Iteration 3900][Epoch 51, Batch 50/77] lr: 0.01400, training time: 30.334 [ms], speed: 50636.448 [imgs/sec], loss=2.982
:::MLLOG {"namespace": "", "time_ms": 1592976494195, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 291, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1592976494195, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.2249870435494651, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 294, "epoch_num": 50}}
INFO:root:[Training][Epoch 51] training time: 2.249 [sec],avg speed: 51911.623 [imgs/sec],loss=3.389
[Training][Epoch 51] training time: 2.249 [sec],avg speed: 51911.623 [imgs/sec],loss=3.389
:::MLLOG {"namespace": "", "time_ms": 1592976494396, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 51}}
:::MLLOG {"namespace": "", "time_ms": 1592976494397, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 52, "current_iter_num": 0}}
INFO:root:[Training][Iteration 4000][Epoch 52, Batch 73/77] lr: 0.01400, training time: 28.336 [ms], speed: 54205.946 [imgs/sec], loss=2.908
[Training][Iteration 4000][Epoch 52, Batch 73/77] lr: 0.01400, training time: 28.336 [ms], speed: 54205.946 [imgs/sec], loss=2.908
INFO:root:[Training][Epoch 52] training time: 2.183 [sec],avg speed: 54184.906 [imgs/sec],loss=3.410
[Training][Epoch 52] training time: 2.183 [sec],avg speed: 54184.906 [imgs/sec],loss=3.410
:::MLLOG {"namespace": "", "time_ms": 1592976496580, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 52}}
:::MLLOG {"namespace": "", "time_ms": 1592976496580, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 53, "current_iter_num": 0}}
INFO:root:[Training][Epoch 53] training time: 2.163 [sec],avg speed: 53977.201 [imgs/sec],loss=3.391
[Training][Epoch 53] training time: 2.163 [sec],avg speed: 53977.201 [imgs/sec],loss=3.391
:::MLLOG {"namespace": "", "time_ms": 1592976498743, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 53}}
:::MLLOG {"namespace": "", "time_ms": 1592976498743, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 54, "current_iter_num": 0}}
INFO:root:[Training][Iteration 4100][Epoch 54, Batch 19/77] lr: 0.01400, training time: 28.167 [ms], speed: 54531.079 [imgs/sec], loss=3.702
[Training][Iteration 4100][Epoch 54, Batch 19/77] lr: 0.01400, training time: 28.167 [ms], speed: 54531.079 [imgs/sec], loss=3.702
INFO:root:[Training][Epoch 54] training time: 2.141 [sec],avg speed: 54530.648 [imgs/sec],loss=3.376
[Training][Epoch 54] training time: 2.141 [sec],avg speed: 54530.648 [imgs/sec],loss=3.376
:::MLLOG {"namespace": "", "time_ms": 1592976500884, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 54}}
:::MLLOG {"namespace": "", "time_ms": 1592976500885, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 55, "current_iter_num": 0}}
INFO:root:[Training][Iteration 4200][Epoch 55, Batch 42/77] lr: 0.01400, training time: 28.035 [ms], speed: 54788.603 [imgs/sec], loss=3.022
[Training][Iteration 4200][Epoch 55, Batch 42/77] lr: 0.01400, training time: 28.035 [ms], speed: 54788.603 [imgs/sec], loss=3.022
INFO:root:[Training][Epoch 55] training time: 2.183 [sec],avg speed: 54189.606 [imgs/sec],loss=3.378
[Training][Epoch 55] training time: 2.183 [sec],avg speed: 54189.606 [imgs/sec],loss=3.378
:::MLLOG {"namespace": "", "time_ms": 1592976503067, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 55}}
:::MLLOG {"namespace": "", "time_ms": 1592976503079, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 243, "epoch_num": 55}}
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 137.737 [ms], allgather: 92.223 [ms], asnumpy: 5.697 [ms], speed: 21217.108 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 137.737 [ms], allgather: 92.223 [ms], asnumpy: 5.697 [ms], speed: 21217.108 [imgs/sec]
:::MLLOG {"namespace": "", "time_ms": 1592976503315, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 56, "current_iter_num": 0}}
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 153.320 [ms], allgather: 85.482 [ms], asnumpy: 5.027 [ms], speed: 20506.053 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 153.320 [ms], allgather: 85.482 [ms], asnumpy: 5.027 [ms], speed: 20506.053 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 139.080 [ms], allgather: 105.000 [ms], asnumpy: 5.098 [ms], speed: 20065.867 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 139.080 [ms], allgather: 105.000 [ms], asnumpy: 5.098 [ms], speed: 20065.867 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 137.004 [ms], allgather: 116.204 [ms], asnumpy: 4.950 [ms], speed: 19367.879 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 137.004 [ms], allgather: 116.204 [ms], asnumpy: 4.950 [ms], speed: 19367.879 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 140.424 [ms], allgather: 119.404 [ms], asnumpy: 5.097 [ms], speed: 18873.181 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 140.424 [ms], allgather: 119.404 [ms], asnumpy: 5.097 [ms], speed: 18873.181 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 145.914 [ms], allgather: 122.138 [ms], asnumpy: 4.942 [ms], speed: 18315.338 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 145.914 [ms], allgather: 122.138 [ms], asnumpy: 4.942 [ms], speed: 18315.338 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 122.821 [ms], allgather: 151.824 [ms], asnumpy: 4.933 [ms], speed: 17884.007 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 122.821 [ms], allgather: 151.824 [ms], asnumpy: 4.933 [ms], speed: 17884.007 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 148.062 [ms], allgather: 133.925 [ms], asnumpy: 5.321 [ms], speed: 17402.885 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 148.062 [ms], allgather: 133.925 [ms], asnumpy: 5.321 [ms], speed: 17402.885 [imgs/sec]
INFO:root:[Training][Iteration 4300][Epoch 56, Batch 65/77] lr: 0.00140, training time: 29.241 [ms], speed: 52528.659 [imgs/sec], loss=3.283
[Training][Iteration 4300][Epoch 56, Batch 65/77] lr: 0.00140, training time: 29.241 [ms], speed: 52528.659 [imgs/sec], loss=3.283
:::MLLOG {"namespace": "", "time_ms": 1592976505412, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 291, "epoch_num": 55}}
:::MLLOG {"namespace": "", "time_ms": 1592976505412, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.22777621735546785, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 294, "epoch_num": 55}}
INFO:root:[Training][Epoch 56] training time: 2.211 [sec],avg speed: 52790.003 [imgs/sec],loss=3.332
[Training][Epoch 56] training time: 2.211 [sec],avg speed: 52790.003 [imgs/sec],loss=3.332
:::MLLOG {"namespace": "", "time_ms": 1592976505527, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 56}}
:::MLLOG {"namespace": "", "time_ms": 1592976505527, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 57, "current_iter_num": 0}}
INFO:root:[Training][Epoch 57] training time: 2.137 [sec],avg speed: 54635.124 [imgs/sec],loss=3.358
[Training][Epoch 57] training time: 2.137 [sec],avg speed: 54635.124 [imgs/sec],loss=3.358
:::MLLOG {"namespace": "", "time_ms": 1592976507664, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 57}}
:::MLLOG {"namespace": "", "time_ms": 1592976507664, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 58, "current_iter_num": 0}}
INFO:root:[Training][Iteration 4400][Epoch 58, Batch 11/77] lr: 0.00140, training time: 28.071 [ms], speed: 54718.493 [imgs/sec], loss=3.577
[Training][Iteration 4400][Epoch 58, Batch 11/77] lr: 0.00140, training time: 28.071 [ms], speed: 54718.493 [imgs/sec], loss=3.577
INFO:root:[Training][Epoch 58] training time: 2.180 [sec],avg speed: 54247.021 [imgs/sec],loss=3.353
[Training][Epoch 58] training time: 2.180 [sec],avg speed: 54247.021 [imgs/sec],loss=3.353
:::MLLOG {"namespace": "", "time_ms": 1592976509845, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 58}}
:::MLLOG {"namespace": "", "time_ms": 1592976509845, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 59, "current_iter_num": 0}}
INFO:root:[Training][Iteration 4500][Epoch 59, Batch 34/77] lr: 0.00140, training time: 28.143 [ms], speed: 54577.997 [imgs/sec], loss=3.550
[Training][Iteration 4500][Epoch 59, Batch 34/77] lr: 0.00140, training time: 28.143 [ms], speed: 54577.997 [imgs/sec], loss=3.550
INFO:root:[Training][Epoch 59] training time: 2.138 [sec],avg speed: 54609.214 [imgs/sec],loss=3.281
[Training][Epoch 59] training time: 2.138 [sec],avg speed: 54609.214 [imgs/sec],loss=3.281
:::MLLOG {"namespace": "", "time_ms": 1592976511983, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 59}}
:::MLLOG {"namespace": "", "time_ms": 1592976511983, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 60, "current_iter_num": 0}}
INFO:root:[Training][Iteration 4600][Epoch 60, Batch 57/77] lr: 0.00140, training time: 28.118 [ms], speed: 54626.117 [imgs/sec], loss=3.377
[Training][Iteration 4600][Epoch 60, Batch 57/77] lr: 0.00140, training time: 28.118 [ms], speed: 54626.117 [imgs/sec], loss=3.377
INFO:root:[Training][Epoch 60] training time: 2.157 [sec],avg speed: 54122.893 [imgs/sec],loss=3.356
[Training][Epoch 60] training time: 2.157 [sec],avg speed: 54122.893 [imgs/sec],loss=3.356
:::MLLOG {"namespace": "", "time_ms": 1592976514140, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 60}}
:::MLLOG {"namespace": "", "time_ms": 1592976514151, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 243, "epoch_num": 60}}
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 139.769 [ms], allgather: 85.144 [ms], asnumpy: 5.165 [ms], speed: 21731.627 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 139.769 [ms], allgather: 85.144 [ms], asnumpy: 5.165 [ms], speed: 21731.627 [imgs/sec]
:::MLLOG {"namespace": "", "time_ms": 1592976514385, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 61, "current_iter_num": 0}}
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 153.723 [ms], allgather: 80.065 [ms], asnumpy: 5.174 [ms], speed: 20923.626 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 153.723 [ms], allgather: 80.065 [ms], asnumpy: 5.174 [ms], speed: 20923.626 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 131.597 [ms], allgather: 106.740 [ms], asnumpy: 5.038 [ms], speed: 20544.261 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 131.597 [ms], allgather: 106.740 [ms], asnumpy: 5.038 [ms], speed: 20544.261 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 131.736 [ms], allgather: 116.420 [ms], asnumpy: 4.874 [ms], speed: 19760.330 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 131.736 [ms], allgather: 116.420 [ms], asnumpy: 4.874 [ms], speed: 19760.330 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 124.876 [ms], allgather: 128.250 [ms], asnumpy: 4.954 [ms], speed: 19373.694 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 124.876 [ms], allgather: 128.250 [ms], asnumpy: 4.954 [ms], speed: 19373.694 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 135.770 [ms], allgather: 126.557 [ms], asnumpy: 4.916 [ms], speed: 18709.470 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 135.770 [ms], allgather: 126.557 [ms], asnumpy: 4.916 [ms], speed: 18709.470 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 136.080 [ms], allgather: 130.735 [ms], asnumpy: 4.625 [ms], speed: 18420.178 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 136.080 [ms], allgather: 130.735 [ms], asnumpy: 4.625 [ms], speed: 18420.178 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 146.637 [ms], allgather: 128.330 [ms], asnumpy: 5.651 [ms], speed: 17817.683 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 146.637 [ms], allgather: 128.330 [ms], asnumpy: 5.651 [ms], speed: 17817.683 [imgs/sec]
:::MLLOG {"namespace": "", "time_ms": 1592976516611, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 291, "epoch_num": 60}}
:::MLLOG {"namespace": "", "time_ms": 1592976516611, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.23265835140397634, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 294, "epoch_num": 60}}
INFO:root:[Training][Epoch 61] training time: 2.230 [sec],avg speed: 53038.387 [imgs/sec],loss=3.359
[Training][Epoch 61] training time: 2.230 [sec],avg speed: 53038.387 [imgs/sec],loss=3.359
:::MLLOG {"namespace": "", "time_ms": 1592976516616, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 61}}
:::MLLOG {"namespace": "", "time_ms": 1592976516616, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 520, "status": "success"}}
INFO:root:Rank 16 done. map=23.265835140397634 @ epoch=-1
INFO:root:Rank 0 done. map=23.265835140397634 @ epoch=60
INFO:root:Rank 48 done. map=23.265835140397634 @ epoch=-1
INFO:root:Rank 32 done. map=23.265835140397634 @ epoch=-1
Rank 32 done. map=23.265835140397634 @ epoch=-1
Rank 0 done. map=23.265835140397634 @ epoch=60
INFO:root:Rank 40 done. map=23.265835140397634 @ epoch=-1
Rank 40 done. map=23.265835140397634 @ epoch=-1
INFO:root:Rank 24 done. map=23.265835140397634 @ epoch=-1
Rank 24 done. map=23.265835140397634 @ epoch=-1
INFO:root:Rank 56 done. map=23.265835140397634 @ epoch=-1
Rank 56 done. map=23.265835140397634 @ epoch=-1
Rank 16 done. map=23.265835140397634 @ epoch=-1
INFO:root:Rank 8 done. map=23.265835140397634 @ epoch=-1
Rank 8 done. map=23.265835140397634 @ epoch=-1
Rank 48 done. map=23.265835140397634 @ epoch=-1
loading annotations into memory...
Done (t=0.11s)
creating index...
Loading and preparing results...
DONE (t=0.25s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=1.53s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.16660
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.30860
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.16481
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.25282
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.17675
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.25959
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.27010
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.27010
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
Loading and preparing results...
DONE (t=0.37s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=1.58s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22499
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.38400
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23202
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.30899
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.21936
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.31512
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.32724
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.32724
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
Loading and preparing results...
DONE (t=0.39s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=1.62s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22778
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.38684
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23644
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.31040
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22033
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.31765
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.32946
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.32946
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
Loading and preparing results...
DONE (t=0.41s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=1.73s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.23266
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.39320
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23968
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.31564
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22391
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32245
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33402
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.33402
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2020-06-23 10:28:43 PM
RESULT,SINGLE_STAGE_DETECTOR,,174,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:43 PM
RESULT,SINGLE_STAGE_DETECTOR,,174,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:43 PM
RESULT,SINGLE_STAGE_DETECTOR,,174,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:43 PM
RESULT,SINGLE_STAGE_DETECTOR,,174,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:43 PM
RESULT,SINGLE_STAGE_DETECTOR,,174,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:43 PM
RESULT,SINGLE_STAGE_DETECTOR,,174,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:43 PM
RESULT,SINGLE_STAGE_DETECTOR,,174,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:43 PM
RESULT,SINGLE_STAGE_DETECTOR,,174,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
ENDING TIMING RUN AT 2020-06-23 10:28:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:25:49 PM
