+ echo 'Beginning trial 3 of 5'
Beginning trial 3 of 5
+ srun -N1 -n1 --container-name=single_stage_detector python -c '
import mlperf_log_utils
from mlperf_logging.mllog import constants
mlperf_log_utils.mlperf_submission_log(constants.SSD)'
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
:::MLLOG {"namespace": "", "time_ms": 1592975961723, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "ssd", "metadata": {"file": "/workspace/ssd/mlperf_log_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1592975961730, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "NVIDIA", "metadata": {"file": "/workspace/ssd/mlperf_log_utils.py", "lineno": 80}}
:::MLLOG {"namespace": "", "time_ms": 1592975961730, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/ssd/mlperf_log_utils.py", "lineno": 84}}
:::MLLOG {"namespace": "", "time_ms": 1592975961730, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/ssd/mlperf_log_utils.py", "lineno": 88}}
:::MLLOG {"namespace": "", "time_ms": 1592975961730, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "8xNVIDIA DGX A100", "metadata": {"file": "/workspace/ssd/mlperf_log_utils.py", "lineno": 92}}
+ '[' 1 -eq 1 ']'
+ srun --ntasks=8 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0211
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0205
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0208
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0207
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0210
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0209
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0212
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0206
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=8 --container-name=single_stage_detector python -c '
from mlperf_logging.mllog import constants
from mlperf_log_utils import log_event
log_event(key=constants.CACHE_CLEAR, value=True)'
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
:::MLLOG {"namespace": "", "time_ms": 1592975966453, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
+ srun --mpi=pmix --ntasks=64 --ntasks-per-node=8 --container-name=single_stage_detector --container-mounts=/raid/datasets/coco/coco-2017:/data,/lustre/fsw/mlperf-ci/14140760/results:/results,/raid/datasets/coco/coco-2017/coco2017/models:/pretrained/mxnet ./run_and_time.sh
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ NUMEPOCHS=80
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ '[' -n 2 ']'
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ '[' -n 3 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
running benchmark
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' -n 3 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ '[' 64 -gt 8 ']'
+ NUMEPOCHS=80
running benchmark
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ echo 'running benchmark'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ '[' -n 5 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' -n 5 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ '[' 64 -gt 8 ']'
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
running benchmark
+ NUMEPOCHS=80
+ declare -a CMD
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ '[' -n 0 ']'
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ '[' 64 -gt 8 ']'
+ cluster=
+ declare -a CMD
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ '[' -n 7 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ declare -a CMD
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ '[' -n 4 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ NUMEPOCHS=80
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ NUMEPOCHS=80
+ declare -a CMD
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 3 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ '[' -n 1 ']'
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ '[' 64 -gt 8 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ '[' -n 7 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ NUMEPOCHS=80
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ '[' -n 6 ']'
+ NUMEPOCHS=80
+ '[' 64 -gt 8 ']'
+ cluster=
running benchmark
+ echo 'running benchmark'
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 64 -gt 8 ']'
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 2 ']'
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ '[' -n 7 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ '[' -n 3 ']'
+ declare -a CMD
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ '[' -n 1 ']'
+ '[' 64 -gt 8 ']'
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 4 ']'
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
running benchmark
+ echo 'running benchmark'
+ declare -a CMD
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ '[' -n 5 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ '[' -n 6 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ NUMEPOCHS=80
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ echo 'running benchmark'
running benchmark
+ '[' -n 7 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
running benchmark
+ '[' -n 0 ']'
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ '[' -n 2 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' -n 3 ']'
+ '[' 64 -gt 8 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ NUMEPOCHS=80
+ declare -a CMD
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ '[' -n 3 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
STARTING TIMING RUN AT 2020-06-23 10:19:28 PM
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export PRETRAINED_DIR=/pretrained/mxnet
+ PRETRAINED_DIR=/pretrained/mxnet
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 64 -gt 8 ']'
+ cluster=
+ [[ DGXA100_multi_8x8x24 == DGX2* ]]
+ [[ DGXA100_multi_8x8x24 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--' 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=3 --membind=3 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=4 --membind=4 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
+ exec numactl --cpunodebind=6 --membind=6 -- python -u ssd_main_async.py --log-interval=100 --coco-root=/data/coco2017 --pretrained-backbone=/pretrained/mxnet/resnet34-333f7ec4.pickle --data-layout=NHWC --epochs 80 --async-val --dataset-size 117266 --eval-dataset-size 5000 --batch-size=24 --lr-warmup-epoch=11 --lr=2.9e-3 --weight-decay=1.7e-4 --gradient-predivide-factor=8
:::MLLOG {"namespace": "", "time_ms": 1592975972318, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972319, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972329, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972321, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972322, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972324, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972326, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972327, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972325, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972325, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972335, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972327, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972327, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972327, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972336, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972328, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972337, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972330, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972330, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972337, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972330, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972330, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972331, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972330, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972338, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972338, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972339, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972339, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972331, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972343, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972335, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972335, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972335, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972335, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972344, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972344, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972351, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972348, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972355, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972352, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972355, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972355, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972356, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972356, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972355, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972355, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972353, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972354, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972337, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972355, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972355, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972357, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972338, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972366, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972367, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972367, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972366, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972367, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972345, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972560, "event_type": "POINT_IN_TIME", "key": "sgd", "value": 1708629421, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 193}}
:::MLLOG {"namespace": "", "time_ms": 1592975972348, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972348, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972348, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972348, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972349, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 231}}
:::MLLOG {"namespace": "", "time_ms": 1592975972633, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1708629421, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 218}}
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1708629461, start_epoch=1, synthetiabout to model_zoo.get_model( resnet34_v1 )
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1708629469, start_epoch=1, synthetiabout to model_zoo.get_model( resnet34_v1 )
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1708629437, start_epoch=1, synthetiabout to model_zoo.get_model( resnet34_v1 )
c=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
c=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1708629477, start_epoch=1, synthetiabout to model_zoo.get_model( resnet34_v1 )
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1708629421, start_epoch=1, synthetiabout to model_zoo.get_model( resnet34_v1 )
c=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
c=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1708629469, start_epoch=1, synthetic=False, tabout to model_zoo.get_model( resnet34_v1 )
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1708629477, start_epoch=1, synthetic=False, tabout to model_zoo.get_model( resnet34_v1 )
arget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1708629461, start_epoch=1, synthetic=False, tabout to model_zoo.get_model( resnet34_v1 )
arget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
arget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1708629453, start_epoch=1, synthetiabout to model_zoo.get_model( resnet34_v1 )
c=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Seed: 1708629461
about to model_zoo.get_model( resnet34_v1 )
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1708629421, start_epoch=1, synthetic=False, tabout to model_zoo.get_model( resnet34_v1 )
INFO:root:Seed: 1708629469
about to model_zoo.get_model( resnet34_v1 )
Seed: 1708629461
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1708629445, start_epoch=1, synthetiabout to model_zoo.get_model( resnet34_v1 )
c=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
arget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
Seed: 1708629469
about to model_zoo.get_model( resnet34_v1 )
INFO:root:precision: fp16
precision: fp16
about to model_zoo.get_model( resnet34_v1 )
c=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1708629453, start_epoch=1, synthetic=False, tabout to model_zoo.get_model( resnet34_v1 )
INFO:root:Seed: 1708629421
about to model_zoo.get_model( resnet34_v1 )
INFO:root:loss scaling: 128.0
loss scaling: 128.0
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1708629429, start_epoch=1, synthetiabout to model_zoo.get_model( resnet34_v1 )
arget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
Seed: 1708629421
about to model_zoo.get_model( resnet34_v1 )
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1708629437, start_epoch=1, synthetic=False, tabout to model_zoo.get_model( resnet34_v1 )
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
about to model_zoo.get_model( resnet34_v1 )
c=False, target_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Seed: 1708629453
Seed: 1708629453
about to model_zoo.get_model( resnet34_v1 )
INFO:root:precision: fp16
about to model_zoo.get_model( resnet34_v1 )
INFO:root:precision: fp16
precision: fp16
about to model_zoo.get_model( resnet34_v1 )
arget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Seed: 1708629477
Seed: 1708629477
about to model_zoo.get_model( resnet34_v1 )
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1708629429, start_epoch=1, synthetic=False, tabout to model_zoo.get_model( resnet34_v1 )
precision: fp16
about to model_zoo.get_model( resnet34_v1 )
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
about to model_zoo.get_model( resnet34_v1 )
INFO:root:precision: fp16
about to model_zoo.get_model( resnet34_v1 )
INFO:root:loss scaling: 128.0
about to model_zoo.get_model( resnet34_v1 )
INFO:root:Seed: 1708629437
Seed: 1708629437
about to model_zoo.get_model( resnet34_v1 )
precision: fp16
about to model_zoo.get_model( resnet34_v1 )
loss scaling: 128.0
about to model_zoo.get_model( resnet34_v1 )
INFO:root:precision: fp16
about to model_zoo.get_model( resnet34_v1 )
INFO:root:loss scaling: 128.0
about to model_zoo.get_model( resnet34_v1 )
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
about to model_zoo.get_model( resnet34_v1 )
precision: fp16
about to model_zoo.get_model( resnet34_v1 )
loss scaling: 128.0
about to model_zoo.get_model( resnet34_v1 )
INFO:root:fuse bn relu: True
fuse bn relu: True
about to model_zoo.get_model( resnet34_v1 )
INFO:root:loss scaling: 128.0
about to model_zoo.get_model( resnet34_v1 )
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
about to model_zoo.get_model( resnet34_v1 )
arget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
INFO:root:precision: fp16
precision: fp16
loss scaling: 128.0
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
INFO:root:Seed: 1708629429
INFO:root:loss scaling: 128.0
loss scaling: 128.0
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
INFO:root:fuse bn relu: True
INFO:root:fuse bn relu: True
fuse bn relu: True
Seed: 1708629429
INFO:root:fuse bn add relu: True
fuse bn add relu: True
INFO:root:fuse bn relu: True
fuse bn relu: True
fuse bn relu: True
Namespace(async_val=True, backbone='resnet34_mlperf', batch_size=24, bn_fp16=False, bn_group=1, bulk_last_wgrad=False, coco_root='/data/coco2017', cocoapi_threads=1, dali_workers=6, data_layout='NHWC', data_shape=300, dataset='coco2017', dataset_size=117266, epochs=80, eval_batch_size=24, eval_dataset_size=5000, fp16_loss_scale=128.0, gradient_predivide_factor=8.0, horovod_num_groups=1, hw_decoder_load=0.0, input_batch_multiplier=1, input_jpg_decode='gpu', log_interval=100, log_level='INFO', log_local_ranks=[0], lr=0.0029, lr_decay_epochs=[44, 55], lr_decay_factor=0.1, lr_warmup_epochs=11.0, lr_warmup_factor=0, mode='train_val', momentum=0.9, nms_overlap_thresh=0.5, nms_topk=200, nms_valid_thresh=0.0, no_fuse_bn_add_relu=False, no_fuse_bn_relu=False, post_nms=200, precision='fp16', pretrained_backbone='/pretrained/mxnet/resnet34-333f7ec4.pickle', profile_no_horovod=False, profile_start=None, profile_stop=None, results=None, resume_from='', save_interval=None, seed=1708629445, start_epoch=1, synthetic=False, tINFO:root:fuse bn add relu: True
fuse bn add relu: True
about to model_zoo.get_model( resnet34_v1 )
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
INFO:root:bn group: 1
bn group: 1
INFO:root:fuse bn add relu: True
INFO:root:fuse bn add relu: True
arget_map=23, test_anchors=False, test_initialization=False, tfrecord_root='/datasets/coco2017/tfrecord/', use_tfrecord=False, val_epochs=[40, 50, 55, 60, 65, 70, 75, 80], val_interval=None, weight_decay=0.00017)
INFO:root:bn group: 1
bn group: 1
INFO:root:bn all reduce fp16: False
bn all reduce fp16: False
fuse bn add relu: True
fuse bn add relu: True
INFO:root:bn all reduce fp16: False
bn all reduce fp16: False
INFO:root:precision: fp16
INFO:root:fuse bn relu: True
fuse bn relu: True
INFO:root:MPI size: 64
MPI size: 64
INFO:root:bn group: 1
bn group: 1
INFO:root:bn group: 1
INFO:root:MPI size: 64
MPI size: 64
precision: fp16
INFO:root:fuse bn add relu: True
about to model_zoo.get_model( resnet34_v1 )
INFO:root:MPI global rank: 48
MPI global rank: 48
INFO:root:bn all reduce fp16: False
bn all reduce fp16: False
bn group: 1
INFO:root:Seed: 1708629445
INFO:root:MPI global rank: 56
MPI global rank: 56
fuse bn add relu: True
INFO:root:MPI size: 64
MPI size: 64
INFO:root:bn all reduce fp16: False
bn all reduce fp16: False
Seed: 1708629445
INFO:root:MPI local rank: 0
MPI local rank: 0
INFO:root:MPI local rank: 0
MPI local rank: 0
INFO:root:MPI size: 64
MPI size: 64
INFO:root:precision: fp16
precision: fp16
INFO:root:async validation: True
async validation: True
INFO:root:MPI global rank: 16
MPI global rank: 16
INFO:root:MPI global rank: 40
MPI global rank: 40
INFO:root:loss scaling: 128.0
loss scaling: 128.0
INFO:root:loss scaling: 128.0
INFO:root:bn group: 1
bn group: 1
INFO:root:MPI local rank: 0
MPI local rank: 0
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
loss scaling: 128.0
INFO:root:bn all reduce fp16: False
bn all reduce fp16: False
INFO:root:fuse bn relu: True
fuse bn relu: True
INFO:root:async validation: True
async validation: True
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
INFO:root:MPI local rank: 0
MPI local rank: 0
about to model_zoo.get_model( resnet34_v1 )
INFO:root:async validation: True
async validation: True
INFO:root:fuse bn add relu: True
fuse bn add relu: True
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
INFO:root:async validation: True
async validation: True
INFO:root:[SSD] network: resnet34_v1
INFO:root:bn group: 1
bn group: 1
INFO:root:fuse bn relu: True
INFO:root:[SSD] network: resnet34_v1
[SSD] network: resnet34_v1
[SSD] network: resnet34_v1
INFO:root:bn all reduce fp16: False
bn all reduce fp16: False
INFO:root:MPI size: 64
MPI size: 64
INFO:root:MPI global rank: 24
MPI global rank: 24
INFO:root:MPI local rank: 0
MPI local rank: 0
INFO:root:[SSD] network: resnet34_v1
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
INFO:root:[SSD] network: resnet34_v1
[SSD] network: resnet34_v1
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
INFO:root:[SSD] fuse bn add relu: True
[SSD] fuse bn add relu: True
fuse bn relu: True
INFO:root:[SSD] bn group: 1
[SSD] bn group: 1
INFO:root:async validation: True
async validation: True
INFO:root:fuse bn add relu: True
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
fuse bn add relu: True
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
INFO:root:bn group: 1
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
INFO:root:[SSD] fuse bn add relu: True
bn group: 1
[SSD] fuse bn add relu: True
INFO:root:[SSD] bn group: 1
[SSD] network: resnet34_v1
[SSD] bn group: 1
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
INFO:root:bn all reduce fp16: False
INFO:root:[SSD] fuse bn add relu: True
[SSD] fuse bn add relu: True
INFO:root:[SSD] network: resnet34_v1
[SSD] network: resnet34_v1
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
bn all reduce fp16: False
INFO:root:MPI size: 64
MPI size: 64
INFO:root:[SSD] fuse bn add relu: True
INFO:root:[SSD] bn group: 1
[SSD] fuse bn add relu: True
[SSD] bn group: 1
INFO:root:[SSD] bn group: 1
[SSD] bn group: 1
INFO:root:MPI global rank: 32
MPI global rank: 32
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
INFO:root:[SSD] fuse bn add relu: True
[SSD] fuse bn add relu: True
INFO:root:MPI size: 64
INFO:root:MPI local rank: 0
MPI size: 64
MPI local rank: 0
INFO:root:MPI global rank: 8
INFO:root:async validation: True
async validation: True
MPI global rank: 8
INFO:root:MPI local rank: 0
MPI local rank: 0
INFO:root:async validation: True
async validation: True
INFO:root:[SSD] network: resnet34_v1
[SSD] network: resnet34_v1
INFO:root:[SSD] bn group: 1
[SSD] bn group: 1
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
about to model_zoo.get_model( resnet34_v1 )
INFO:root:[SSD] network: resnet34_v1
[SSD] network: resnet34_v1
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
INFO:root:[SSD] fuse bn add relu: True
[SSD] fuse bn add relu: True
INFO:root:[SSD] bn group: 1
[SSD] bn group: 1
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
INFO:root:[SSD] fuse bn add relu: True
[SSD] fuse bn add relu: True
INFO:root:[SSD] bn group: 1
[SSD] bn group: 1
about to model_zoo.get_model( resnet34_v1 )
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:loss scaling: 128.0
loss scaling: 128.0
INFO:root:network name: ssd_resnet34_mlperf_NHWC_coco2017_300
network name: ssd_resnet34_mlperf_NHWC_coco2017_300
INFO:root:fuse bn relu: True
fuse bn relu: True
INFO:root:fuse bn add relu: True
fuse bn add relu: True
INFO:root:bn group: 1
bn group: 1
INFO:root:bn all reduce fp16: False
bn all reduce fp16: False
INFO:root:MPI size: 64
MPI size: 64
INFO:root:MPI global rank: 0
MPI global rank: 0
INFO:root:MPI local rank: 0
MPI local rank: 0
INFO:root:async validation: True
async validation: True
INFO:root:[SSD] network: resnet34_v1
[SSD] network: resnet34_v1
INFO:root:[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
[SSD] norm layer: <class 'ssd.group_batch_norm.GroupBatchNorm'>
INFO:root:[SSD] fuse bn relu: True
[SSD] fuse bn relu: True
INFO:root:[SSD] fuse bn add relu: True
[SSD] fuse bn add relu: True
INFO:root:[SSD] bn group: 1
[SSD] bn group: 1
about to model_zoo.get_model( resnet34_v1 )
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
/opt/mxnet/python/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
	data: None
  input_sym_arg_type = in_param.infer_type()[0]
INFO:root:COCO reader: raw images
COCO reader: raw images
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:COCO reader: raw images
COCO reader: raw images
:::MLLOG {"namespace": "", "time_ms": 1592975974870, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 117266, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 363}}
:::MLLOG {"namespace": "", "time_ms": 1592975974870, "event_type": "POINT_IN_TIME", "key": "max_samples", "value": 1, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 364}}
:::MLLOG {"namespace": "", "time_ms": 1592975974871, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 839, "metadata": {"file": "/workspace/ssd/lr_scheduler.py", "lineno": 30}}
:::MLLOG {"namespace": "", "time_ms": 1592975974871, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_factor", "value": 0, "metadata": {"file": "/workspace/ssd/lr_scheduler.py", "lineno": 31}}
:::MLLOG {"namespace": "", "time_ms": 1592975974871, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.14, "metadata": {"file": "/workspace/ssd/lr_scheduler.py", "lineno": 36}}
:::MLLOG {"namespace": "", "time_ms": 1592975974871, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_boundary_epochs", "value": [44, 55], "metadata": {"file": "/workspace/ssd/lr_scheduler.py", "lineno": 37}}
INFO:root:COCO reader: raw images
COCO reader: raw images
INFO:root:COCO reader: raw images
COCO reader: raw images
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
:::MLLOG {"namespace": "", "time_ms": 1592975975380, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 5000, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 407}}
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
:::MLLOG {"namespace": "", "time_ms": 1592975979134, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.00017, "metadata": {"file": "/workspace/ssd/trainer.py", "lineno": 29}}
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
INFO:root:Running training dry runs
Running training dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[/opt/dali/dali/util/nvml.h:119] CPU affinity requested by user or recommended by nvml setting does not meet allowed affinity for given DALI thread. Use taskset tool to check allowed affinity
[22:19:41] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:41] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:41] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:41] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:41] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:41] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:41] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:41] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:41] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:41] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:41] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:41] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:41] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[22:19:41] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:41] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:41] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:41] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:41] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:41] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:41] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:41] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:41] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:41] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
[22:19:42] src/imperative/./../executor/cuda_graphs.h:289: Created CUDA graphs.
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
INFO:root:Done
Done
INFO:root:Running inference dry runs
Running inference dry runs
INFO:root:COCO reader: TFRecord
COCO reader: TFRecord
INFO:root:Done
Done
INFO:root:Done
Done
INFO:root:Done
Done
INFO:root:Done
Done
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
INFO:root:Done
Done
INFO:root:Done
Done
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
INFO:root:Done
Done
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
INFO:root:Done
Done
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
INFO:root:Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
Loading backbones weights from /pretrained/mxnet/resnet34-333f7ec4.pickle
:::MLLOG {"namespace": "", "time_ms": 1592976000797, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 495}}
:::MLLOG {"namespace": "", "time_ms": 1592976000797, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 499}}
INFO:root:Training from epoch: 1
Training from epoch: 1
INFO:root:Training from epoch: 1
Training from epoch: 1
INFO:root:Training from epoch: 1
Training from epoch: 1
INFO:root:Training from epoch: 1
Training from epoch: 1
INFO:root:Training from epoch: 1
Training from epoch: 1
:::MLLOG {"namespace": "", "time_ms": 1592976001807, "event_type": "POINT_IN_TIME", "key": "model_bn_span", "value": 24, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 101}}
:::MLLOG {"namespace": "", "time_ms": 1592976001807, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 1536, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 102}}
INFO:root:Training from epoch: 1
Training from epoch: 1
:::MLLOG {"namespace": "", "time_ms": 1592976001807, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 1, "current_iter_num": 0}}
INFO:root:Training from epoch: 1
Training from epoch: 1
INFO:root:Training from epoch: 1
Training from epoch: 1
INFO:root:[Training][Epoch 1] training time: 2.436 [sec],avg speed: 48554.721 [imgs/sec],loss=16.767
[Training][Epoch 1] training time: 2.436 [sec],avg speed: 48554.721 [imgs/sec],loss=16.767
:::MLLOG {"namespace": "", "time_ms": 1592976004243, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1592976004244, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 2, "current_iter_num": 0}}
INFO:root:[Training][Iteration 100][Epoch 2, Batch 23/77] lr: 0.01669, training time: 29.201 [ms], speed: 52601.331 [imgs/sec], loss=9.657
[Training][Iteration 100][Epoch 2, Batch 23/77] lr: 0.01669, training time: 29.201 [ms], speed: 52601.331 [imgs/sec], loss=9.657
INFO:root:[Training][Epoch 2] training time: 2.193 [sec],avg speed: 53232.016 [imgs/sec],loss=9.253
[Training][Epoch 2] training time: 2.193 [sec],avg speed: 53232.016 [imgs/sec],loss=9.253
:::MLLOG {"namespace": "", "time_ms": 1592976006437, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1592976006437, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 3, "current_iter_num": 0}}
INFO:root:[Training][Iteration 200][Epoch 3, Batch 46/77] lr: 0.03337, training time: 29.275 [ms], speed: 52467.720 [imgs/sec], loss=8.086
[Training][Iteration 200][Epoch 3, Batch 46/77] lr: 0.03337, training time: 29.275 [ms], speed: 52467.720 [imgs/sec], loss=8.086
INFO:root:[Training][Epoch 3] training time: 2.200 [sec],avg speed: 53073.366 [imgs/sec],loss=8.269
[Training][Epoch 3] training time: 2.200 [sec],avg speed: 53073.366 [imgs/sec],loss=8.269
:::MLLOG {"namespace": "", "time_ms": 1592976008637, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592976008637, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 4, "current_iter_num": 0}}
INFO:root:[Training][Iteration 300][Epoch 4, Batch 69/77] lr: 0.05006, training time: 28.766 [ms], speed: 53396.025 [imgs/sec], loss=7.915
[Training][Iteration 300][Epoch 4, Batch 69/77] lr: 0.05006, training time: 28.766 [ms], speed: 53396.025 [imgs/sec], loss=7.915
INFO:root:[Training][Epoch 4] training time: 2.212 [sec],avg speed: 53469.636 [imgs/sec],loss=7.681
[Training][Epoch 4] training time: 2.212 [sec],avg speed: 53469.636 [imgs/sec],loss=7.681
:::MLLOG {"namespace": "", "time_ms": 1592976010849, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592976010849, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 5, "current_iter_num": 0}}
INFO:root:[Training][Epoch 5] training time: 2.222 [sec],avg speed: 52544.479 [imgs/sec],loss=7.187
[Training][Epoch 5] training time: 2.222 [sec],avg speed: 52544.479 [imgs/sec],loss=7.187
:::MLLOG {"namespace": "", "time_ms": 1592976013071, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1592976013072, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 6, "current_iter_num": 0}}
INFO:root:[Training][Iteration 400][Epoch 6, Batch 15/77] lr: 0.06675, training time: 28.412 [ms], speed: 54061.709 [imgs/sec], loss=6.437
[Training][Iteration 400][Epoch 6, Batch 15/77] lr: 0.06675, training time: 28.412 [ms], speed: 54061.709 [imgs/sec], loss=6.437
INFO:root:[Training][Epoch 6] training time: 2.166 [sec],avg speed: 53883.387 [imgs/sec],loss=6.697
[Training][Epoch 6] training time: 2.166 [sec],avg speed: 53883.387 [imgs/sec],loss=6.697
:::MLLOG {"namespace": "", "time_ms": 1592976015238, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 6}}
:::MLLOG {"namespace": "", "time_ms": 1592976015238, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 7, "current_iter_num": 0}}
INFO:root:[Training][Iteration 500][Epoch 7, Batch 38/77] lr: 0.08343, training time: 28.380 [ms], speed: 54122.145 [imgs/sec], loss=6.556
[Training][Iteration 500][Epoch 7, Batch 38/77] lr: 0.08343, training time: 28.380 [ms], speed: 54122.145 [imgs/sec], loss=6.556
INFO:root:[Training][Epoch 7] training time: 2.181 [sec],avg speed: 54221.555 [imgs/sec],loss=6.367
[Training][Epoch 7] training time: 2.181 [sec],avg speed: 54221.555 [imgs/sec],loss=6.367
:::MLLOG {"namespace": "", "time_ms": 1592976017420, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1592976017420, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 8, "current_iter_num": 0}}
INFO:root:[Training][Iteration 600][Epoch 8, Batch 61/77] lr: 0.10012, training time: 28.641 [ms], speed: 53629.374 [imgs/sec], loss=6.452
[Training][Iteration 600][Epoch 8, Batch 61/77] lr: 0.10012, training time: 28.641 [ms], speed: 53629.374 [imgs/sec], loss=6.452
INFO:root:[Training][Epoch 8] training time: 2.173 [sec],avg speed: 53711.303 [imgs/sec],loss=6.039
[Training][Epoch 8] training time: 2.173 [sec],avg speed: 53711.303 [imgs/sec],loss=6.039
:::MLLOG {"namespace": "", "time_ms": 1592976019594, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 8}}
:::MLLOG {"namespace": "", "time_ms": 1592976019594, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 9, "current_iter_num": 0}}
INFO:root:[Training][Epoch 9] training time: 2.149 [sec],avg speed: 54333.396 [imgs/sec],loss=5.787
[Training][Epoch 9] training time: 2.149 [sec],avg speed: 54333.396 [imgs/sec],loss=5.787
:::MLLOG {"namespace": "", "time_ms": 1592976021743, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 9}}
:::MLLOG {"namespace": "", "time_ms": 1592976021743, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 10, "current_iter_num": 0}}
INFO:root:[Training][Iteration 700][Epoch 10, Batch 7/77] lr: 0.11681, training time: 28.175 [ms], speed: 54516.258 [imgs/sec], loss=5.421
[Training][Iteration 700][Epoch 10, Batch 7/77] lr: 0.11681, training time: 28.175 [ms], speed: 54516.258 [imgs/sec], loss=5.421
INFO:root:[Training][Epoch 10] training time: 2.187 [sec],avg speed: 54075.475 [imgs/sec],loss=5.592
[Training][Epoch 10] training time: 2.187 [sec],avg speed: 54075.475 [imgs/sec],loss=5.592
:::MLLOG {"namespace": "", "time_ms": 1592976023930, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 10}}
:::MLLOG {"namespace": "", "time_ms": 1592976023931, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 11, "current_iter_num": 0}}
INFO:root:[Training][Iteration 800][Epoch 11, Batch 30/77] lr: 0.13349, training time: 28.567 [ms], speed: 53768.356 [imgs/sec], loss=5.713
[Training][Iteration 800][Epoch 11, Batch 30/77] lr: 0.13349, training time: 28.567 [ms], speed: 53768.356 [imgs/sec], loss=5.713
INFO:root:[Training][Epoch 11] training time: 2.159 [sec],avg speed: 54069.592 [imgs/sec],loss=5.427
[Training][Epoch 11] training time: 2.159 [sec],avg speed: 54069.592 [imgs/sec],loss=5.427
:::MLLOG {"namespace": "", "time_ms": 1592976026090, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1592976026090, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 12, "current_iter_num": 0}}
INFO:root:[Training][Iteration 900][Epoch 12, Batch 53/77] lr: 0.14000, training time: 28.109 [ms], speed: 54643.533 [imgs/sec], loss=5.086
[Training][Iteration 900][Epoch 12, Batch 53/77] lr: 0.14000, training time: 28.109 [ms], speed: 54643.533 [imgs/sec], loss=5.086
INFO:root:[Training][Epoch 12] training time: 2.138 [sec],avg speed: 54589.116 [imgs/sec],loss=5.202
[Training][Epoch 12] training time: 2.138 [sec],avg speed: 54589.116 [imgs/sec],loss=5.202
:::MLLOG {"namespace": "", "time_ms": 1592976028229, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1592976028229, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 13, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1000][Epoch 13, Batch 76/77] lr: 0.14000, training time: 28.261 [ms], speed: 54349.614 [imgs/sec], loss=5.431
[Training][Iteration 1000][Epoch 13, Batch 76/77] lr: 0.14000, training time: 28.261 [ms], speed: 54349.614 [imgs/sec], loss=5.431
INFO:root:[Training][Epoch 13] training time: 2.178 [sec],avg speed: 54314.780 [imgs/sec],loss=5.052
[Training][Epoch 13] training time: 2.178 [sec],avg speed: 54314.780 [imgs/sec],loss=5.052
:::MLLOG {"namespace": "", "time_ms": 1592976030406, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 13}}
:::MLLOG {"namespace": "", "time_ms": 1592976030407, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 14, "current_iter_num": 0}}
INFO:root:[Training][Epoch 14] training time: 2.146 [sec],avg speed: 54405.488 [imgs/sec],loss=4.904
[Training][Epoch 14] training time: 2.146 [sec],avg speed: 54405.488 [imgs/sec],loss=4.904
:::MLLOG {"namespace": "", "time_ms": 1592976032553, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 14}}
:::MLLOG {"namespace": "", "time_ms": 1592976032553, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 15, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1100][Epoch 15, Batch 22/77] lr: 0.14000, training time: 28.343 [ms], speed: 54193.845 [imgs/sec], loss=4.101
[Training][Iteration 1100][Epoch 15, Batch 22/77] lr: 0.14000, training time: 28.343 [ms], speed: 54193.845 [imgs/sec], loss=4.101
INFO:root:[Training][Epoch 15] training time: 2.145 [sec],avg speed: 54418.537 [imgs/sec],loss=4.824
[Training][Epoch 15] training time: 2.145 [sec],avg speed: 54418.537 [imgs/sec],loss=4.824
:::MLLOG {"namespace": "", "time_ms": 1592976034698, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1592976034698, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 16, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1200][Epoch 16, Batch 45/77] lr: 0.14000, training time: 28.332 [ms], speed: 54215.147 [imgs/sec], loss=5.757
[Training][Iteration 1200][Epoch 16, Batch 45/77] lr: 0.14000, training time: 28.332 [ms], speed: 54215.147 [imgs/sec], loss=5.757
INFO:root:[Training][Epoch 16] training time: 2.188 [sec],avg speed: 54051.253 [imgs/sec],loss=4.709
[Training][Epoch 16] training time: 2.188 [sec],avg speed: 54051.253 [imgs/sec],loss=4.709
:::MLLOG {"namespace": "", "time_ms": 1592976036887, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1592976036887, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 17, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1300][Epoch 17, Batch 68/77] lr: 0.14000, training time: 28.208 [ms], speed: 54452.557 [imgs/sec], loss=4.277
[Training][Iteration 1300][Epoch 17, Batch 68/77] lr: 0.14000, training time: 28.208 [ms], speed: 54452.557 [imgs/sec], loss=4.277
INFO:root:[Training][Epoch 17] training time: 2.143 [sec],avg speed: 54464.797 [imgs/sec],loss=4.648
[Training][Epoch 17] training time: 2.143 [sec],avg speed: 54464.797 [imgs/sec],loss=4.648
:::MLLOG {"namespace": "", "time_ms": 1592976039030, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 17}}
:::MLLOG {"namespace": "", "time_ms": 1592976039031, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 18, "current_iter_num": 0}}
INFO:root:[Training][Epoch 18] training time: 2.158 [sec],avg speed: 54089.471 [imgs/sec],loss=4.634
[Training][Epoch 18] training time: 2.158 [sec],avg speed: 54089.471 [imgs/sec],loss=4.634
:::MLLOG {"namespace": "", "time_ms": 1592976041189, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1592976041189, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 19, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1400][Epoch 19, Batch 14/77] lr: 0.14000, training time: 28.409 [ms], speed: 54066.814 [imgs/sec], loss=3.996
[Training][Iteration 1400][Epoch 19, Batch 14/77] lr: 0.14000, training time: 28.409 [ms], speed: 54066.814 [imgs/sec], loss=3.996
INFO:root:[Training][Epoch 19] training time: 2.174 [sec],avg speed: 54403.170 [imgs/sec],loss=4.544
[Training][Epoch 19] training time: 2.174 [sec],avg speed: 54403.170 [imgs/sec],loss=4.544
:::MLLOG {"namespace": "", "time_ms": 1592976043364, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1592976043364, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 20, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1500][Epoch 20, Batch 37/77] lr: 0.14000, training time: 28.161 [ms], speed: 54542.587 [imgs/sec], loss=4.750
[Training][Iteration 1500][Epoch 20, Batch 37/77] lr: 0.14000, training time: 28.161 [ms], speed: 54542.587 [imgs/sec], loss=4.750
INFO:root:[Training][Epoch 20] training time: 2.136 [sec],avg speed: 54649.461 [imgs/sec],loss=4.404
[Training][Epoch 20] training time: 2.136 [sec],avg speed: 54649.461 [imgs/sec],loss=4.404
:::MLLOG {"namespace": "", "time_ms": 1592976045500, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1592976045500, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 21, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1600][Epoch 21, Batch 60/77] lr: 0.14000, training time: 28.162 [ms], speed: 54540.691 [imgs/sec], loss=4.156
[Training][Iteration 1600][Epoch 21, Batch 60/77] lr: 0.14000, training time: 28.162 [ms], speed: 54540.691 [imgs/sec], loss=4.156
INFO:root:[Training][Epoch 21] training time: 2.153 [sec],avg speed: 54222.959 [imgs/sec],loss=4.463
[Training][Epoch 21] training time: 2.153 [sec],avg speed: 54222.959 [imgs/sec],loss=4.463
:::MLLOG {"namespace": "", "time_ms": 1592976047653, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 21}}
:::MLLOG {"namespace": "", "time_ms": 1592976047654, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 22, "current_iter_num": 0}}
INFO:root:[Training][Epoch 22] training time: 2.167 [sec],avg speed: 54582.360 [imgs/sec],loss=4.436
[Training][Epoch 22] training time: 2.167 [sec],avg speed: 54582.360 [imgs/sec],loss=4.436
:::MLLOG {"namespace": "", "time_ms": 1592976049821, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 22}}
:::MLLOG {"namespace": "", "time_ms": 1592976049821, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 23, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1700][Epoch 23, Batch 6/77] lr: 0.14000, training time: 28.356 [ms], speed: 54168.438 [imgs/sec], loss=3.557
[Training][Iteration 1700][Epoch 23, Batch 6/77] lr: 0.14000, training time: 28.356 [ms], speed: 54168.438 [imgs/sec], loss=3.557
INFO:root:[Training][Epoch 23] training time: 2.150 [sec],avg speed: 54294.210 [imgs/sec],loss=4.323
[Training][Epoch 23] training time: 2.150 [sec],avg speed: 54294.210 [imgs/sec],loss=4.323
:::MLLOG {"namespace": "", "time_ms": 1592976051971, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1592976051972, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 24, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1800][Epoch 24, Batch 29/77] lr: 0.14000, training time: 28.154 [ms], speed: 54557.949 [imgs/sec], loss=3.522
[Training][Iteration 1800][Epoch 24, Batch 29/77] lr: 0.14000, training time: 28.154 [ms], speed: 54557.949 [imgs/sec], loss=3.522
INFO:root:[Training][Epoch 24] training time: 2.135 [sec],avg speed: 54666.649 [imgs/sec],loss=4.229
[Training][Epoch 24] training time: 2.135 [sec],avg speed: 54666.649 [imgs/sec],loss=4.229
:::MLLOG {"namespace": "", "time_ms": 1592976054107, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1592976054108, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 25, "current_iter_num": 0}}
INFO:root:[Training][Iteration 1900][Epoch 25, Batch 52/77] lr: 0.14000, training time: 28.271 [ms], speed: 54331.917 [imgs/sec], loss=4.419
[Training][Iteration 1900][Epoch 25, Batch 52/77] lr: 0.14000, training time: 28.271 [ms], speed: 54331.917 [imgs/sec], loss=4.419
INFO:root:[Training][Epoch 25] training time: 2.172 [sec],avg speed: 54444.034 [imgs/sec],loss=4.262
[Training][Epoch 25] training time: 2.172 [sec],avg speed: 54444.034 [imgs/sec],loss=4.262
:::MLLOG {"namespace": "", "time_ms": 1592976056280, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 25}}
:::MLLOG {"namespace": "", "time_ms": 1592976056280, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 26, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2000][Epoch 26, Batch 75/77] lr: 0.14000, training time: 28.362 [ms], speed: 54157.874 [imgs/sec], loss=4.098
[Training][Iteration 2000][Epoch 26, Batch 75/77] lr: 0.14000, training time: 28.362 [ms], speed: 54157.874 [imgs/sec], loss=4.098
INFO:root:[Training][Epoch 26] training time: 2.157 [sec],avg speed: 54128.302 [imgs/sec],loss=4.255
[Training][Epoch 26] training time: 2.157 [sec],avg speed: 54128.302 [imgs/sec],loss=4.255
:::MLLOG {"namespace": "", "time_ms": 1592976058437, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 26}}
:::MLLOG {"namespace": "", "time_ms": 1592976058437, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 27, "current_iter_num": 0}}
INFO:root:[Training][Epoch 27] training time: 2.145 [sec],avg speed: 54417.697 [imgs/sec],loss=4.226
[Training][Epoch 27] training time: 2.145 [sec],avg speed: 54417.697 [imgs/sec],loss=4.226
:::MLLOG {"namespace": "", "time_ms": 1592976060583, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1592976060583, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 28, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2100][Epoch 28, Batch 21/77] lr: 0.14000, training time: 28.235 [ms], speed: 54400.953 [imgs/sec], loss=3.976
[Training][Iteration 2100][Epoch 28, Batch 21/77] lr: 0.14000, training time: 28.235 [ms], speed: 54400.953 [imgs/sec], loss=3.976
INFO:root:[Training][Epoch 28] training time: 2.177 [sec],avg speed: 54335.144 [imgs/sec],loss=4.163
[Training][Epoch 28] training time: 2.177 [sec],avg speed: 54335.144 [imgs/sec],loss=4.163
:::MLLOG {"namespace": "", "time_ms": 1592976062760, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1592976062760, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 29, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2200][Epoch 29, Batch 44/77] lr: 0.14000, training time: 28.147 [ms], speed: 54571.186 [imgs/sec], loss=4.280
[Training][Iteration 2200][Epoch 29, Batch 44/77] lr: 0.14000, training time: 28.147 [ms], speed: 54571.186 [imgs/sec], loss=4.280
INFO:root:[Training][Epoch 29] training time: 2.144 [sec],avg speed: 54459.763 [imgs/sec],loss=4.254
[Training][Epoch 29] training time: 2.144 [sec],avg speed: 54459.763 [imgs/sec],loss=4.254
:::MLLOG {"namespace": "", "time_ms": 1592976064904, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 29}}
:::MLLOG {"namespace": "", "time_ms": 1592976064904, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 30, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2300][Epoch 30, Batch 67/77] lr: 0.14000, training time: 28.168 [ms], speed: 54529.056 [imgs/sec], loss=4.572
[Training][Iteration 2300][Epoch 30, Batch 67/77] lr: 0.14000, training time: 28.168 [ms], speed: 54529.056 [imgs/sec], loss=4.572
INFO:root:[Training][Epoch 30] training time: 2.143 [sec],avg speed: 54483.482 [imgs/sec],loss=4.097
[Training][Epoch 30] training time: 2.143 [sec],avg speed: 54483.482 [imgs/sec],loss=4.097
:::MLLOG {"namespace": "", "time_ms": 1592976067047, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 30}}
:::MLLOG {"namespace": "", "time_ms": 1592976067047, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 31, "current_iter_num": 0}}
INFO:root:[Training][Epoch 31] training time: 2.183 [sec],avg speed: 54174.409 [imgs/sec],loss=4.123
[Training][Epoch 31] training time: 2.183 [sec],avg speed: 54174.409 [imgs/sec],loss=4.123
:::MLLOG {"namespace": "", "time_ms": 1592976069230, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1592976069231, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 32, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2400][Epoch 32, Batch 13/77] lr: 0.14000, training time: 28.306 [ms], speed: 54264.064 [imgs/sec], loss=4.097
[Training][Iteration 2400][Epoch 32, Batch 13/77] lr: 0.14000, training time: 28.306 [ms], speed: 54264.064 [imgs/sec], loss=4.097
INFO:root:[Training][Epoch 32] training time: 2.156 [sec],avg speed: 54148.140 [imgs/sec],loss=4.094
[Training][Epoch 32] training time: 2.156 [sec],avg speed: 54148.140 [imgs/sec],loss=4.094
:::MLLOG {"namespace": "", "time_ms": 1592976071387, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1592976071387, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 33, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2500][Epoch 33, Batch 36/77] lr: 0.14000, training time: 28.141 [ms], speed: 54583.126 [imgs/sec], loss=4.302
[Training][Iteration 2500][Epoch 33, Batch 36/77] lr: 0.14000, training time: 28.141 [ms], speed: 54583.126 [imgs/sec], loss=4.302
INFO:root:[Training][Epoch 33] training time: 2.143 [sec],avg speed: 54482.615 [imgs/sec],loss=4.072
[Training][Epoch 33] training time: 2.143 [sec],avg speed: 54482.615 [imgs/sec],loss=4.072
:::MLLOG {"namespace": "", "time_ms": 1592976073530, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 33}}
:::MLLOG {"namespace": "", "time_ms": 1592976073530, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 34, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2600][Epoch 34, Batch 59/77] lr: 0.14000, training time: 28.076 [ms], speed: 54709.360 [imgs/sec], loss=3.684
[Training][Iteration 2600][Epoch 34, Batch 59/77] lr: 0.14000, training time: 28.076 [ms], speed: 54709.360 [imgs/sec], loss=3.684
INFO:root:[Training][Epoch 34] training time: 2.163 [sec],avg speed: 54681.477 [imgs/sec],loss=3.993
[Training][Epoch 34] training time: 2.163 [sec],avg speed: 54681.477 [imgs/sec],loss=3.993
:::MLLOG {"namespace": "", "time_ms": 1592976075693, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 34}}
:::MLLOG {"namespace": "", "time_ms": 1592976075694, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 35, "current_iter_num": 0}}
INFO:root:[Training][Epoch 35] training time: 2.148 [sec],avg speed: 54333.800 [imgs/sec],loss=4.029
[Training][Epoch 35] training time: 2.148 [sec],avg speed: 54333.800 [imgs/sec],loss=4.029
:::MLLOG {"namespace": "", "time_ms": 1592976077842, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1592976077842, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 36, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2700][Epoch 36, Batch 5/77] lr: 0.14000, training time: 28.595 [ms], speed: 53715.740 [imgs/sec], loss=3.875
[Training][Iteration 2700][Epoch 36, Batch 5/77] lr: 0.14000, training time: 28.595 [ms], speed: 53715.740 [imgs/sec], loss=3.875
INFO:root:[Training][Epoch 36] training time: 2.145 [sec],avg speed: 54426.129 [imgs/sec],loss=4.002
[Training][Epoch 36] training time: 2.145 [sec],avg speed: 54426.129 [imgs/sec],loss=4.002
:::MLLOG {"namespace": "", "time_ms": 1592976079987, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 36}}
:::MLLOG {"namespace": "", "time_ms": 1592976079988, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 37, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2800][Epoch 37, Batch 28/77] lr: 0.14000, training time: 28.054 [ms], speed: 54751.785 [imgs/sec], loss=4.662
[Training][Iteration 2800][Epoch 37, Batch 28/77] lr: 0.14000, training time: 28.054 [ms], speed: 54751.785 [imgs/sec], loss=4.662
INFO:root:[Training][Epoch 37] training time: 2.167 [sec],avg speed: 54582.648 [imgs/sec],loss=3.963
[Training][Epoch 37] training time: 2.167 [sec],avg speed: 54582.648 [imgs/sec],loss=3.963
:::MLLOG {"namespace": "", "time_ms": 1592976082155, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 37}}
:::MLLOG {"namespace": "", "time_ms": 1592976082155, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 38, "current_iter_num": 0}}
INFO:root:[Training][Iteration 2900][Epoch 38, Batch 51/77] lr: 0.14000, training time: 28.207 [ms], speed: 54454.265 [imgs/sec], loss=4.153
[Training][Iteration 2900][Epoch 38, Batch 51/77] lr: 0.14000, training time: 28.207 [ms], speed: 54454.265 [imgs/sec], loss=4.153
INFO:root:[Training][Epoch 38] training time: 2.154 [sec],avg speed: 54200.582 [imgs/sec],loss=4.017
[Training][Epoch 38] training time: 2.154 [sec],avg speed: 54200.582 [imgs/sec],loss=4.017
:::MLLOG {"namespace": "", "time_ms": 1592976084309, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 38}}
:::MLLOG {"namespace": "", "time_ms": 1592976084309, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 39, "current_iter_num": 0}}
INFO:root:[Training][Iteration 3000][Epoch 39, Batch 74/77] lr: 0.14000, training time: 28.184 [ms], speed: 54499.415 [imgs/sec], loss=3.746
[Training][Iteration 3000][Epoch 39, Batch 74/77] lr: 0.14000, training time: 28.184 [ms], speed: 54499.415 [imgs/sec], loss=3.746
INFO:root:[Training][Epoch 39] training time: 2.147 [sec],avg speed: 54372.006 [imgs/sec],loss=3.961
[Training][Epoch 39] training time: 2.147 [sec],avg speed: 54372.006 [imgs/sec],loss=3.961
:::MLLOG {"namespace": "", "time_ms": 1592976086456, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 39}}
:::MLLOG {"namespace": "", "time_ms": 1592976086457, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 40, "current_iter_num": 0}}
INFO:root:[Training][Epoch 40] training time: 2.165 [sec],avg speed: 54619.807 [imgs/sec],loss=3.909
[Training][Epoch 40] training time: 2.165 [sec],avg speed: 54619.807 [imgs/sec],loss=3.909
:::MLLOG {"namespace": "", "time_ms": 1592976088622, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1592976088635, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 243, "epoch_num": 40}}
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 810.717 [ms], allgather: 80.139 [ms], asnumpy: 5.465 [ms], speed: 5578.355 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 810.717 [ms], allgather: 80.139 [ms], asnumpy: 5.465 [ms], speed: 5578.355 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 707.893 [ms], allgather: 187.533 [ms], asnumpy: 5.381 [ms], speed: 5550.573 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 707.893 [ms], allgather: 187.533 [ms], asnumpy: 5.381 [ms], speed: 5550.573 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 744.354 [ms], allgather: 150.890 [ms], asnumpy: 5.475 [ms], speed: 5551.112 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 744.354 [ms], allgather: 150.890 [ms], asnumpy: 5.475 [ms], speed: 5551.112 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 814.550 [ms], allgather: 83.822 [ms], asnumpy: 5.565 [ms], speed: 5531.347 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 814.550 [ms], allgather: 83.822 [ms], asnumpy: 5.565 [ms], speed: 5531.347 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 804.325 [ms], allgather: 95.561 [ms], asnumpy: 5.407 [ms], speed: 5523.072 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 804.325 [ms], allgather: 95.561 [ms], asnumpy: 5.407 [ms], speed: 5523.072 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 819.502 [ms], allgather: 145.870 [ms], asnumpy: 5.574 [ms], speed: 5149.609 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 819.502 [ms], allgather: 145.870 [ms], asnumpy: 5.574 [ms], speed: 5149.609 [imgs/sec]
:::MLLOG {"namespace": "", "time_ms": 1592976089604, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 41, "current_iter_num": 0}}
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 795.736 [ms], allgather: 183.289 [ms], asnumpy: 5.876 [ms], speed: 5076.646 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 795.736 [ms], allgather: 183.289 [ms], asnumpy: 5.876 [ms], speed: 5076.646 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 805.308 [ms], allgather: 213.811 [ms], asnumpy: 5.464 [ms], speed: 4880.035 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 805.308 [ms], allgather: 213.811 [ms], asnumpy: 5.464 [ms], speed: 4880.035 [imgs/sec]
INFO:root:[Training][Iteration 3100][Epoch 41, Batch 20/77] lr: 0.14000, training time: 33.244 [ms], speed: 46204.254 [imgs/sec], loss=3.896
[Training][Iteration 3100][Epoch 41, Batch 20/77] lr: 0.14000, training time: 33.244 [ms], speed: 46204.254 [imgs/sec], loss=3.896
INFO:root:[Training][Epoch 41] training time: 2.262 [sec],avg speed: 51597.815 [imgs/sec],loss=3.951
[Training][Epoch 41] training time: 2.262 [sec],avg speed: 51597.815 [imgs/sec],loss=3.951
:::MLLOG {"namespace": "", "time_ms": 1592976091866, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1592976091866, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 42, "current_iter_num": 0}}
:::MLLOG {"namespace": "", "time_ms": 1592976092187, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 291, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1592976092187, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.17404646608671775, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 294, "epoch_num": 40}}
INFO:root:[Training][Iteration 3200][Epoch 42, Batch 43/77] lr: 0.14000, training time: 28.354 [ms], speed: 54172.523 [imgs/sec], loss=4.052
[Training][Iteration 3200][Epoch 42, Batch 43/77] lr: 0.14000, training time: 28.354 [ms], speed: 54172.523 [imgs/sec], loss=4.052
INFO:root:[Training][Epoch 42] training time: 2.150 [sec],avg speed: 54306.236 [imgs/sec],loss=3.949
[Training][Epoch 42] training time: 2.150 [sec],avg speed: 54306.236 [imgs/sec],loss=3.949
:::MLLOG {"namespace": "", "time_ms": 1592976094016, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 42}}
:::MLLOG {"namespace": "", "time_ms": 1592976094017, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 43, "current_iter_num": 0}}
INFO:root:[Training][Iteration 3300][Epoch 43, Batch 66/77] lr: 0.14000, training time: 28.235 [ms], speed: 54401.405 [imgs/sec], loss=4.046
[Training][Iteration 3300][Epoch 43, Batch 66/77] lr: 0.14000, training time: 28.235 [ms], speed: 54401.405 [imgs/sec], loss=4.046
INFO:root:[Training][Epoch 43] training time: 2.174 [sec],avg speed: 54400.276 [imgs/sec],loss=3.915
[Training][Epoch 43] training time: 2.174 [sec],avg speed: 54400.276 [imgs/sec],loss=3.915
:::MLLOG {"namespace": "", "time_ms": 1592976096191, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 43}}
:::MLLOG {"namespace": "", "time_ms": 1592976096191, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 44, "current_iter_num": 0}}
INFO:root:[Training][Epoch 44] training time: 2.137 [sec],avg speed: 54630.552 [imgs/sec],loss=3.834
[Training][Epoch 44] training time: 2.137 [sec],avg speed: 54630.552 [imgs/sec],loss=3.834
:::MLLOG {"namespace": "", "time_ms": 1592976098328, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 44}}
:::MLLOG {"namespace": "", "time_ms": 1592976098329, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 45, "current_iter_num": 0}}
INFO:root:[Training][Iteration 3400][Epoch 45, Batch 12/77] lr: 0.01400, training time: 28.191 [ms], speed: 54485.608 [imgs/sec], loss=3.720
[Training][Iteration 3400][Epoch 45, Batch 12/77] lr: 0.01400, training time: 28.191 [ms], speed: 54485.608 [imgs/sec], loss=3.720
INFO:root:[Training][Epoch 45] training time: 2.137 [sec],avg speed: 54627.005 [imgs/sec],loss=3.633
[Training][Epoch 45] training time: 2.137 [sec],avg speed: 54627.005 [imgs/sec],loss=3.633
:::MLLOG {"namespace": "", "time_ms": 1592976100466, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 45}}
:::MLLOG {"namespace": "", "time_ms": 1592976100466, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 46, "current_iter_num": 0}}
INFO:root:[Training][Iteration 3500][Epoch 46, Batch 35/77] lr: 0.01400, training time: 28.145 [ms], speed: 54573.904 [imgs/sec], loss=2.841
[Training][Iteration 3500][Epoch 46, Batch 35/77] lr: 0.01400, training time: 28.145 [ms], speed: 54573.904 [imgs/sec], loss=2.841
INFO:root:[Training][Epoch 46] training time: 2.171 [sec],avg speed: 54474.112 [imgs/sec],loss=3.551
[Training][Epoch 46] training time: 2.171 [sec],avg speed: 54474.112 [imgs/sec],loss=3.551
:::MLLOG {"namespace": "", "time_ms": 1592976102637, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 46}}
:::MLLOG {"namespace": "", "time_ms": 1592976102638, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 47, "current_iter_num": 0}}
INFO:root:[Training][Iteration 3600][Epoch 47, Batch 58/77] lr: 0.01400, training time: 28.128 [ms], speed: 54608.284 [imgs/sec], loss=3.475
[Training][Iteration 3600][Epoch 47, Batch 58/77] lr: 0.01400, training time: 28.128 [ms], speed: 54608.284 [imgs/sec], loss=3.475
INFO:root:[Training][Epoch 47] training time: 2.138 [sec],avg speed: 54609.263 [imgs/sec],loss=3.476
[Training][Epoch 47] training time: 2.138 [sec],avg speed: 54609.263 [imgs/sec],loss=3.476
:::MLLOG {"namespace": "", "time_ms": 1592976104776, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 47}}
:::MLLOG {"namespace": "", "time_ms": 1592976104776, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 48, "current_iter_num": 0}}
INFO:root:[Training][Epoch 48] training time: 2.143 [sec],avg speed: 54481.784 [imgs/sec],loss=3.520
[Training][Epoch 48] training time: 2.143 [sec],avg speed: 54481.784 [imgs/sec],loss=3.520
:::MLLOG {"namespace": "", "time_ms": 1592976106919, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 48}}
:::MLLOG {"namespace": "", "time_ms": 1592976106919, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 49, "current_iter_num": 0}}
INFO:root:[Training][Iteration 3700][Epoch 49, Batch 4/77] lr: 0.01400, training time: 28.274 [ms], speed: 54325.644 [imgs/sec], loss=3.615
[Training][Iteration 3700][Epoch 49, Batch 4/77] lr: 0.01400, training time: 28.274 [ms], speed: 54325.644 [imgs/sec], loss=3.615
INFO:root:[Training][Epoch 49] training time: 2.162 [sec],avg speed: 54713.134 [imgs/sec],loss=3.405
[Training][Epoch 49] training time: 2.162 [sec],avg speed: 54713.134 [imgs/sec],loss=3.405
:::MLLOG {"namespace": "", "time_ms": 1592976109081, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 49}}
:::MLLOG {"namespace": "", "time_ms": 1592976109081, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 50, "current_iter_num": 0}}
INFO:root:[Training][Iteration 3800][Epoch 50, Batch 27/77] lr: 0.01400, training time: 28.122 [ms], speed: 54619.123 [imgs/sec], loss=3.669
[Training][Iteration 3800][Epoch 50, Batch 27/77] lr: 0.01400, training time: 28.122 [ms], speed: 54619.123 [imgs/sec], loss=3.669
INFO:root:[Training][Epoch 50] training time: 2.139 [sec],avg speed: 54579.520 [imgs/sec],loss=3.388
[Training][Epoch 50] training time: 2.139 [sec],avg speed: 54579.520 [imgs/sec],loss=3.388
:::MLLOG {"namespace": "", "time_ms": 1592976111220, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1592976111233, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 243, "epoch_num": 50}}
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 144.392 [ms], allgather: 133.559 [ms], asnumpy: 6.736 [ms], speed: 17563.087 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 144.392 [ms], allgather: 133.559 [ms], asnumpy: 6.736 [ms], speed: 17563.087 [imgs/sec]
:::MLLOG {"namespace": "", "time_ms": 1592976111518, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 51, "current_iter_num": 0}}
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 141.704 [ms], allgather: 152.936 [ms], asnumpy: 5.287 [ms], speed: 16670.670 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 141.704 [ms], allgather: 152.936 [ms], asnumpy: 5.287 [ms], speed: 16670.670 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 136.693 [ms], allgather: 169.875 [ms], asnumpy: 5.019 [ms], speed: 16046.755 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 136.693 [ms], allgather: 169.875 [ms], asnumpy: 5.019 [ms], speed: 16046.755 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 122.482 [ms], allgather: 197.046 [ms], asnumpy: 4.817 [ms], speed: 15415.656 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 122.482 [ms], allgather: 197.046 [ms], asnumpy: 4.817 [ms], speed: 15415.656 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 138.646 [ms], allgather: 196.829 [ms], asnumpy: 5.453 [ms], speed: 14665.799 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 138.646 [ms], allgather: 196.829 [ms], asnumpy: 5.453 [ms], speed: 14665.799 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 145.000 [ms], allgather: 201.296 [ms], asnumpy: 4.796 [ms], speed: 14241.277 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 145.000 [ms], allgather: 201.296 [ms], asnumpy: 4.796 [ms], speed: 14241.277 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 133.055 [ms], allgather: 229.962 [ms], asnumpy: 5.024 [ms], speed: 13585.389 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 133.055 [ms], allgather: 229.962 [ms], asnumpy: 5.024 [ms], speed: 13585.389 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 125.225 [ms], allgather: 247.422 [ms], asnumpy: 4.902 [ms], speed: 13243.258 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 125.225 [ms], allgather: 247.422 [ms], asnumpy: 4.902 [ms], speed: 13243.258 [imgs/sec]
INFO:root:[Training][Iteration 3900][Epoch 51, Batch 50/77] lr: 0.01400, training time: 30.452 [ms], speed: 50440.347 [imgs/sec], loss=2.779
[Training][Iteration 3900][Epoch 51, Batch 50/77] lr: 0.01400, training time: 30.452 [ms], speed: 50440.347 [imgs/sec], loss=2.779
:::MLLOG {"namespace": "", "time_ms": 1592976113587, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 291, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1592976113588, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.22522551579420655, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 294, "epoch_num": 50}}
INFO:root:[Training][Epoch 51] training time: 2.272 [sec],avg speed: 51383.413 [imgs/sec],loss=3.417
[Training][Epoch 51] training time: 2.272 [sec],avg speed: 51383.413 [imgs/sec],loss=3.417
:::MLLOG {"namespace": "", "time_ms": 1592976113790, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 51}}
:::MLLOG {"namespace": "", "time_ms": 1592976113791, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 52, "current_iter_num": 0}}
INFO:root:[Training][Iteration 4000][Epoch 52, Batch 73/77] lr: 0.01400, training time: 28.049 [ms], speed: 54760.624 [imgs/sec], loss=2.925
[Training][Iteration 4000][Epoch 52, Batch 73/77] lr: 0.01400, training time: 28.049 [ms], speed: 54760.624 [imgs/sec], loss=2.925
INFO:root:[Training][Epoch 52] training time: 2.161 [sec],avg speed: 54733.478 [imgs/sec],loss=3.418
[Training][Epoch 52] training time: 2.161 [sec],avg speed: 54733.478 [imgs/sec],loss=3.418
:::MLLOG {"namespace": "", "time_ms": 1592976115952, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 52}}
:::MLLOG {"namespace": "", "time_ms": 1592976115952, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 53, "current_iter_num": 0}}
INFO:root:[Training][Epoch 53] training time: 2.136 [sec],avg speed: 54661.346 [imgs/sec],loss=3.432
[Training][Epoch 53] training time: 2.136 [sec],avg speed: 54661.346 [imgs/sec],loss=3.432
:::MLLOG {"namespace": "", "time_ms": 1592976118088, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 53}}
:::MLLOG {"namespace": "", "time_ms": 1592976118088, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 54, "current_iter_num": 0}}
INFO:root:[Training][Iteration 4100][Epoch 54, Batch 19/77] lr: 0.01400, training time: 28.040 [ms], speed: 54779.657 [imgs/sec], loss=4.080
[Training][Iteration 4100][Epoch 54, Batch 19/77] lr: 0.01400, training time: 28.040 [ms], speed: 54779.657 [imgs/sec], loss=4.080
INFO:root:[Training][Epoch 54] training time: 2.147 [sec],avg speed: 54374.517 [imgs/sec],loss=3.373
[Training][Epoch 54] training time: 2.147 [sec],avg speed: 54374.517 [imgs/sec],loss=3.373
:::MLLOG {"namespace": "", "time_ms": 1592976120235, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 54}}
:::MLLOG {"namespace": "", "time_ms": 1592976120236, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 55, "current_iter_num": 0}}
INFO:root:[Training][Iteration 4200][Epoch 55, Batch 42/77] lr: 0.01400, training time: 28.111 [ms], speed: 54641.176 [imgs/sec], loss=3.000
[Training][Iteration 4200][Epoch 55, Batch 42/77] lr: 0.01400, training time: 28.111 [ms], speed: 54641.176 [imgs/sec], loss=3.000
INFO:root:[Training][Epoch 55] training time: 2.173 [sec],avg speed: 54433.753 [imgs/sec],loss=3.403
[Training][Epoch 55] training time: 2.173 [sec],avg speed: 54433.753 [imgs/sec],loss=3.403
:::MLLOG {"namespace": "", "time_ms": 1592976122409, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 55}}
:::MLLOG {"namespace": "", "time_ms": 1592976122420, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 243, "epoch_num": 55}}
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 142.426 [ms], allgather: 75.107 [ms], asnumpy: 4.940 [ms], speed: 22474.551 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 142.426 [ms], allgather: 75.107 [ms], asnumpy: 4.940 [ms], speed: 22474.551 [imgs/sec]
:::MLLOG {"namespace": "", "time_ms": 1592976122643, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 56, "current_iter_num": 0}}
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 141.925 [ms], allgather: 83.428 [ms], asnumpy: 4.854 [ms], speed: 21719.541 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 141.925 [ms], allgather: 83.428 [ms], asnumpy: 4.854 [ms], speed: 21719.541 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 135.124 [ms], allgather: 97.259 [ms], asnumpy: 5.121 [ms], speed: 21052.171 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 135.124 [ms], allgather: 97.259 [ms], asnumpy: 5.121 [ms], speed: 21052.171 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 129.730 [ms], allgather: 108.381 [ms], asnumpy: 4.717 [ms], speed: 20590.614 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 129.730 [ms], allgather: 108.381 [ms], asnumpy: 4.717 [ms], speed: 20590.614 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 136.307 [ms], allgather: 110.210 [ms], asnumpy: 5.452 [ms], speed: 19843.609 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 136.307 [ms], allgather: 110.210 [ms], asnumpy: 5.452 [ms], speed: 19843.609 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 142.341 [ms], allgather: 108.612 [ms], asnumpy: 4.782 [ms], speed: 19551.349 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 142.341 [ms], allgather: 108.612 [ms], asnumpy: 4.782 [ms], speed: 19551.349 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 136.312 [ms], allgather: 123.749 [ms], asnumpy: 5.393 [ms], speed: 18835.516 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 136.312 [ms], allgather: 123.749 [ms], asnumpy: 5.393 [ms], speed: 18835.516 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 132.808 [ms], allgather: 132.735 [ms], asnumpy: 5.081 [ms], speed: 18475.726 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 132.808 [ms], allgather: 132.735 [ms], asnumpy: 5.081 [ms], speed: 18475.726 [imgs/sec]
INFO:root:[Training][Iteration 4300][Epoch 56, Batch 65/77] lr: 0.00140, training time: 29.015 [ms], speed: 52938.534 [imgs/sec], loss=3.381
[Training][Iteration 4300][Epoch 56, Batch 65/77] lr: 0.00140, training time: 29.015 [ms], speed: 52938.534 [imgs/sec], loss=3.381
:::MLLOG {"namespace": "", "time_ms": 1592976124751, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 291, "epoch_num": 55}}
:::MLLOG {"namespace": "", "time_ms": 1592976124752, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.2273266426500304, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 294, "epoch_num": 55}}
INFO:root:[Training][Epoch 56] training time: 2.198 [sec],avg speed: 53098.127 [imgs/sec],loss=3.322
[Training][Epoch 56] training time: 2.198 [sec],avg speed: 53098.127 [imgs/sec],loss=3.322
:::MLLOG {"namespace": "", "time_ms": 1592976124842, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 56}}
:::MLLOG {"namespace": "", "time_ms": 1592976124842, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 57, "current_iter_num": 0}}
INFO:root:[Training][Epoch 57] training time: 2.138 [sec],avg speed: 54600.920 [imgs/sec],loss=3.338
[Training][Epoch 57] training time: 2.138 [sec],avg speed: 54600.920 [imgs/sec],loss=3.338
:::MLLOG {"namespace": "", "time_ms": 1592976126981, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 57}}
:::MLLOG {"namespace": "", "time_ms": 1592976126981, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 58, "current_iter_num": 0}}
INFO:root:[Training][Iteration 4400][Epoch 58, Batch 11/77] lr: 0.00140, training time: 28.467 [ms], speed: 53957.985 [imgs/sec], loss=3.933
[Training][Iteration 4400][Epoch 58, Batch 11/77] lr: 0.00140, training time: 28.467 [ms], speed: 53957.985 [imgs/sec], loss=3.933
INFO:root:[Training][Epoch 58] training time: 2.165 [sec],avg speed: 54616.608 [imgs/sec],loss=3.356
[Training][Epoch 58] training time: 2.165 [sec],avg speed: 54616.608 [imgs/sec],loss=3.356
:::MLLOG {"namespace": "", "time_ms": 1592976129147, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 58}}
:::MLLOG {"namespace": "", "time_ms": 1592976129147, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 59, "current_iter_num": 0}}
INFO:root:[Training][Iteration 4500][Epoch 59, Batch 34/77] lr: 0.00140, training time: 28.190 [ms], speed: 54487.483 [imgs/sec], loss=3.401
[Training][Iteration 4500][Epoch 59, Batch 34/77] lr: 0.00140, training time: 28.190 [ms], speed: 54487.483 [imgs/sec], loss=3.401
INFO:root:[Training][Epoch 59] training time: 2.138 [sec],avg speed: 54609.093 [imgs/sec],loss=3.326
[Training][Epoch 59] training time: 2.138 [sec],avg speed: 54609.093 [imgs/sec],loss=3.326
:::MLLOG {"namespace": "", "time_ms": 1592976131285, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 59}}
:::MLLOG {"namespace": "", "time_ms": 1592976131285, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 60, "current_iter_num": 0}}
INFO:root:[Training][Iteration 4600][Epoch 60, Batch 57/77] lr: 0.00140, training time: 28.120 [ms], speed: 54623.282 [imgs/sec], loss=3.197
[Training][Iteration 4600][Epoch 60, Batch 57/77] lr: 0.00140, training time: 28.120 [ms], speed: 54623.282 [imgs/sec], loss=3.197
INFO:root:[Training][Epoch 60] training time: 2.142 [sec],avg speed: 54509.297 [imgs/sec],loss=3.357
[Training][Epoch 60] training time: 2.142 [sec],avg speed: 54509.297 [imgs/sec],loss=3.357
:::MLLOG {"namespace": "", "time_ms": 1592976133427, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 60}}
:::MLLOG {"namespace": "", "time_ms": 1592976133438, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 243, "epoch_num": 60}}
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 139.535 [ms], allgather: 75.912 [ms], asnumpy: 5.087 [ms], speed: 22672.061 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 139.535 [ms], allgather: 75.912 [ms], asnumpy: 5.087 [ms], speed: 22672.061 [imgs/sec]
:::MLLOG {"namespace": "", "time_ms": 1592976133659, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 159, "epoch_num": 61, "current_iter_num": 0}}
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 136.585 [ms], allgather: 86.155 [ms], asnumpy: 5.229 [ms], speed: 21932.767 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 136.585 [ms], allgather: 86.155 [ms], asnumpy: 5.229 [ms], speed: 21932.767 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 142.680 [ms], allgather: 87.261 [ms], asnumpy: 5.102 [ms], speed: 21272.548 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 142.680 [ms], allgather: 87.261 [ms], asnumpy: 5.102 [ms], speed: 21272.548 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 137.534 [ms], allgather: 98.826 [ms], asnumpy: 5.009 [ms], speed: 20715.067 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 137.534 [ms], allgather: 98.826 [ms], asnumpy: 5.009 [ms], speed: 20715.067 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 132.337 [ms], allgather: 111.230 [ms], asnumpy: 5.292 [ms], speed: 20091.550 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 132.337 [ms], allgather: 111.230 [ms], asnumpy: 5.292 [ms], speed: 20091.550 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 139.240 [ms], allgather: 109.370 [ms], asnumpy: 4.990 [ms], speed: 19715.931 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 139.240 [ms], allgather: 109.370 [ms], asnumpy: 4.990 [ms], speed: 19715.931 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.001 [ms], inference: 138.934 [ms], allgather: 119.150 [ms], asnumpy: 5.140 [ms], speed: 18995.185 [imgs/sec]
[Validation] save_parameters: 0.001 [ms], inference: 138.934 [ms], allgather: 119.150 [ms], asnumpy: 5.140 [ms], speed: 18995.185 [imgs/sec]
INFO:root:[Validation] save_parameters: 0.002 [ms], inference: 137.053 [ms], allgather: 126.051 [ms], asnumpy: 5.156 [ms], speed: 18638.518 [imgs/sec]
[Validation] save_parameters: 0.002 [ms], inference: 137.053 [ms], allgather: 126.051 [ms], asnumpy: 5.156 [ms], speed: 18638.518 [imgs/sec]
:::MLLOG {"namespace": "", "time_ms": 1592976135751, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 291, "epoch_num": 60}}
:::MLLOG {"namespace": "", "time_ms": 1592976135752, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.23176257635612305, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 294, "epoch_num": 60}}
INFO:root:[Training][Epoch 61] training time: 2.237 [sec],avg speed: 52863.141 [imgs/sec],loss=3.345
[Training][Epoch 61] training time: 2.237 [sec],avg speed: 52863.141 [imgs/sec],loss=3.345
:::MLLOG {"namespace": "", "time_ms": 1592976135897, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/ssd/model.py", "lineno": 211, "epoch_num": 61}}
:::MLLOG {"namespace": "", "time_ms": 1592976135897, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/ssd/ssd_main.py", "lineno": 520, "status": "success"}}
INFO:root:Rank 0 done. map=23.176257635612306 @ epoch=60
Rank 0 done. map=23.176257635612306 @ epoch=60
INFO:root:Rank 8 done. map=23.176257635612306 @ epoch=-1
Rank 8 done. map=23.176257635612306 @ epoch=-1
INFO:root:Rank 32 done. map=23.176257635612306 @ epoch=-1
Rank 32 done. map=23.176257635612306 @ epoch=-1
INFO:root:Rank 48 done. map=23.176257635612306 @ epoch=-1
Rank 48 done. map=23.176257635612306 @ epoch=-1
INFO:root:Rank 16 done. map=23.176257635612306 @ epoch=-1
INFO:root:Rank 56 done. map=23.176257635612306 @ epoch=-1
Rank 56 done. map=23.176257635612306 @ epoch=-1
Rank 16 done. map=23.176257635612306 @ epoch=-1
INFO:root:Rank 40 done. map=23.176257635612306 @ epoch=-1
Rank 40 done. map=23.176257635612306 @ epoch=-1
INFO:root:Rank 24 done. map=23.176257635612306 @ epoch=-1
Rank 24 done. map=23.176257635612306 @ epoch=-1
loading annotations into memory...
Done (t=0.11s)
creating index...
Loading and preparing results...
DONE (t=0.28s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=1.62s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.17405
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.31984
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.17284
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.25533
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.18392
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.26882
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.27990
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.27990
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
Loading and preparing results...
DONE (t=0.38s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=1.60s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22523
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.38298
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23182
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.30802
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.21835
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.31541
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.32641
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.32641
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
Loading and preparing results...
DONE (t=0.39s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=1.63s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22733
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.38670
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23261
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.31038
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.21955
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.31686
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.32795
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.32795
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
Loading and preparing results...
DONE (t=0.40s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=1.60s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.23176
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.39163
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23702
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.31419
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22234
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32127
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33238
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.33238
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2020-06-23 10:22:22 PM
RESULT,SINGLE_STAGE_DETECTOR,,174,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:22 PM
RESULT,SINGLE_STAGE_DETECTOR,,174,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:22 PM
RESULT,SINGLE_STAGE_DETECTOR,,174,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:22 PM
RESULT,SINGLE_STAGE_DETECTOR,,174,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:22 PM
RESULT,SINGLE_STAGE_DETECTOR,,174,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:22 PM
RESULT,SINGLE_STAGE_DETECTOR,,174,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:22 PM
RESULT,SINGLE_STAGE_DETECTOR,,174,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:22 PM
RESULT,SINGLE_STAGE_DETECTOR,,174,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:24 PM
ENDING TIMING RUN AT 2020-06-23 10:22:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:19:28 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,176,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
slurmstepd: error: _is_a_lwp: open() /proc/184247/status failed: No such file or directory
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
ENDING TIMING RUN AT 2020-06-23 10:22:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,177,nvidia,2020-06-23 10:19:28 PM
