+ echo 'Beginning trial 1 of 5'
Beginning trial 1 of 5
+ srun --nodes=1 --ntasks=1 --container-name=single_stage_detector python -c '
import mlperf_log_utils
from mlperf_logging.mllog import constants
mlperf_log_utils.mlperf_submission_log(constants.SSD)'
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
:::MLLOG {"namespace": "", "time_ms": 1592975461212, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "ssd", "metadata": {"file": "/workspace/single_stage_detector/mlperf_log_utils.py", "lineno": 17}}
:::MLLOG {"namespace": "", "time_ms": 1592975461251, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "NVIDIA", "metadata": {"file": "/workspace/single_stage_detector/mlperf_log_utils.py", "lineno": 22}}
:::MLLOG {"namespace": "", "time_ms": 1592975461251, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/single_stage_detector/mlperf_log_utils.py", "lineno": 26}}
:::MLLOG {"namespace": "", "time_ms": 1592975461251, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/single_stage_detector/mlperf_log_utils.py", "lineno": 30}}
:::MLLOG {"namespace": "", "time_ms": 1592975461251, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "2xNVIDIA DGX A100", "metadata": {"file": "/workspace/single_stage_detector/mlperf_log_utils.py", "lineno": 34}}
+ '[' 1 -eq 1 ']'
+ srun --ntasks=2 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0233
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0234
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=2 --container-name=single_stage_detector python -c '
from mlperf_logging.mllog import constants
from mlperf_logger import log_event
log_event(key=constants.CACHE_CLEAR, value=True)'
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
:::MLLOG {"namespace": "", "time_ms": 1592975466753, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592975466796, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
+ srun --mpi=none --ntasks=16 --ntasks-per-node=8 --container-name=single_stage_detector --container-mounts=/raid/datasets/coco/coco-2017:/data,/lustre/fsw/mlperf-ci/14140797/results:/results ./run_and_time.sh
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-23 10:11:09 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
++ pwd
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 16 -gt 2 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
STARTING TIMING RUN AT 2020-06-23 10:11:09 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
++ pwd
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 16 -gt 2 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
STARTING TIMING RUN AT 2020-06-23 10:11:09 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
STARTING TIMING RUN AT 2020-06-23 10:11:09 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
STARTING TIMING RUN AT 2020-06-23 10:11:09 PM
++ pwd
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 16 -gt 2 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
++ pwd
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
STARTING TIMING RUN AT 2020-06-23 10:11:09 PM
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ declare -a CMD
running benchmark
+ '[' -n 1 ']'
+ '[' 16 -gt 2 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
++ pwd
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
STARTING TIMING RUN AT 2020-06-23 10:11:09 PM
+ NUMEPOCHS=80
+ '[' -n 4 ']'
running benchmark
+ echo 'running benchmark'
+ '[' 16 -gt 2 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
++ pwd
STARTING TIMING RUN AT 2020-06-23 10:11:09 PM
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ '[' -n 2 ']'
+ '[' 16 -gt 2 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
++ pwd
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 16 -gt 2 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
++ pwd
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 16 -gt 2 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-23 10:11:09 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
++ pwd
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 16 -gt 2 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
STARTING TIMING RUN AT 2020-06-23 10:11:09 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
++ pwd
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 16 -gt 2 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
STARTING TIMING RUN AT 2020-06-23 10:11:09 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
++ pwd
STARTING TIMING RUN AT 2020-06-23 10:11:09 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
STARTING TIMING RUN AT 2020-06-23 10:11:09 PM
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ '[' -n 4 ']'
+ '[' 16 -gt 2 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
++ pwd
++ pwd
STARTING TIMING RUN AT 2020-06-23 10:11:09 PM
+ NUMEPOCHS=80
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
running benchmark
+ echo 'running benchmark'
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' -n 3 ']'
+ '[' 16 -gt 2 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ '[' 16 -gt 2 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
STARTING TIMING RUN AT 2020-06-23 10:11:09 PM
++ pwd
STARTING TIMING RUN AT 2020-06-23 10:11:09 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 16 -gt 2 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
++ pwd
++ pwd
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 16 -gt 2 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 16 -gt 2 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=4 --membind=4 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=4 --membind=4 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=6 --membind=6 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=3 --membind=3 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
+ exec numactl --cpunodebind=2 --membind=2 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
+ exec numactl --cpunodebind=1 --membind=1 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
+ exec numactl --cpunodebind=2 --membind=2 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=6 --membind=6 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
+ exec numactl --cpunodebind=3 --membind=3 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
+ exec numactl --cpunodebind=0 --membind=0 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=56 --eval-batch-size=160 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
:::MLLOG {"namespace": "", "time_ms": 1592975470663, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592975470697, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592975470858, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592975470866, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592975470866, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592975470941, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592975470972, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592975470977, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592975470982, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592975470994, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592975471074, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592975471100, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592975471113, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592975471113, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592975471116, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592975471119, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592975473298, "event_type": "POINT_IN_TIME", "key": "seed", "value": 4171542248, "metadata": {"file": "/workspace/single_stage_detector/mlperf_logger.py", "lineno": 92}}
0 Using seed = 4171542248
9 Using seed = 4171542257
10 Using seed = 4171542258
11 Using seed = 4171542259
12 Using seed = 4171542260
13 Using seed = 4171542261
14 Using seed = 4171542262
8 Using seed = 4171542256
15 Using seed = 4171542263
4 Using seed = 4171542252
5 Using seed = 4171542253
6 Using seed = 4171542254
7 Using seed = 4171542255
1 Using seed = 4171542249
2 Using seed = 4171542250
3 Using seed = 4171542251
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 20%|        | 16.7M/83.3M [00:00<00:00, 175MB/s]
 42%|     | 35.3M/83.3M [00:00<00:00, 179MB/s]
 59%|    | 49.0M/83.3M [00:00<00:00, 161MB/s]
 75%|  | 62.5M/83.3M [00:00<00:00, 154MB/s]
100%|| 83.3M/83.3M [00:00<00:00, 174MB/s]

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 18%|        | 15.2M/83.3M [00:00<00:00, 160MB/s]
 30%|       | 25.3M/83.3M [00:00<00:00, 137MB/s]
 44%|     | 37.0M/83.3M [00:00<00:00, 130MB/s]
 63%|   | 52.2M/83.3M [00:00<00:00, 138MB/s]
 92%|| 76.6M/83.3M [00:00<00:00, 160MB/s]
100%|| 83.3M/83.3M [00:00<00:00, 155MB/s]
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 16%|        | 13.6M/83.3M [00:00<00:00, 142MB/s]
 30%|       | 24.6M/83.3M [00:00<00:00, 133MB/s]
 44%|     | 36.7M/83.3M [00:00<00:00, 131MB/s]
 54%|    | 45.4M/83.3M [00:00<00:00, 115MB/s]
 64%|   | 53.4M/83.3M [00:00<00:00, 101MB/s]
 76%|  | 63.4M/83.3M [00:00<00:00, 102MB/s]
 86%| | 72.0M/83.3M [00:00<00:00, 53.5MB/s]
 95%|| 78.7M/83.3M [00:01<00:00, 40.5MB/s]
100%|| 83.3M/83.3M [00:01<00:00, 65.0MB/s]

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 17%|        | 14.1M/83.3M [00:00<00:00, 140MB/s]
 31%|       | 25.4M/83.3M [00:00<00:00, 132MB/s]
 47%|     | 38.9M/83.3M [00:00<00:00, 135MB/s]
 65%|   | 53.9M/83.3M [00:00<00:00, 141MB/s]
 77%|  | 64.3M/83.3M [00:00<00:00, 101MB/s]
 88%| | 73.2M/83.3M [00:01<00:00, 48.9MB/s]
 96%|| 80.1M/83.3M [00:01<00:00, 38.3MB/s]
100%|| 83.3M/83.3M [00:01<00:00, 63.7MB/s]

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 17%|        | 14.4M/83.3M [00:00<00:00, 149MB/s]
 29%|       | 23.8M/83.3M [00:00<00:00, 129MB/s]
 40%|      | 33.6M/83.3M [00:00<00:00, 119MB/s]
 55%|    | 45.6M/83.3M [00:00<00:00, 121MB/s]
 65%|   | 54.1M/83.3M [00:00<00:00, 104MB/s]
 75%|  | 62.3M/83.3M [00:00<00:00, 92.5MB/s]
 84%| | 70.1M/83.3M [00:00<00:00, 59.9MB/s]
 92%|| 76.6M/83.3M [00:01<00:00, 35.8MB/s]
 98%|| 81.6M/83.3M [00:01<00:00, 38.9MB/s]
100%|| 83.3M/83.3M [00:01<00:00, 62.9MB/s]

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 15%|        | 12.1M/83.3M [00:00<00:00, 127MB/s]
 26%|       | 21.9M/83.3M [00:00<00:00, 117MB/s]
 42%|     | 34.6M/83.3M [00:00<00:00, 121MB/s]
 52%|    | 42.9M/83.3M [00:00<00:00, 107MB/s]
 61%|    | 50.6M/83.3M [00:00<00:00, 94.1MB/s]
 72%|  | 59.6M/83.3M [00:00<00:00, 93.2MB/s]
 81%| | 67.7M/83.3M [00:00<00:00, 83.7MB/s]
 90%| | 75.1M/83.3M [00:01<00:00, 39.4MB/s]
 97%|| 80.8M/83.3M [00:01<00:00, 39.7MB/s]
100%|| 83.3M/83.3M [00:01<00:00, 63.2MB/s]

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 17%|        | 13.8M/83.3M [00:00<00:00, 145MB/s]
 28%|       | 23.7M/83.3M [00:00<00:00, 129MB/s]
 43%|     | 35.9M/83.3M [00:00<00:00, 129MB/s]
 55%|    | 45.7M/83.3M [00:00<00:00, 120MB/s]
 65%|   | 54.1M/83.3M [00:00<00:00, 94.2MB/s]
 74%|  | 61.8M/83.3M [00:00<00:00, 88.1MB/s]
 83%| | 69.3M/83.3M [00:00<00:00, 64.2MB/s]
 91%| | 75.8M/83.3M [00:01<00:00, 36.7MB/s]
 97%|| 80.8M/83.3M [00:01<00:00, 38.7MB/s]
100%|| 83.3M/83.3M [00:01<00:00, 63.3MB/s]

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 18%|        | 15.4M/83.3M [00:00<00:00, 151MB/s]
 31%|       | 25.5M/83.3M [00:00<00:00, 134MB/s]
 43%|     | 35.5M/83.3M [00:00<00:00, 124MB/s]
 54%|    | 44.8M/83.3M [00:00<00:00, 114MB/s]
 63%|   | 52.6M/83.3M [00:00<00:00, 101MB/s]
 75%|  | 62.4M/83.3M [00:00<00:00, 102MB/s]
 85%| | 70.8M/83.3M [00:00<00:00, 55.6MB/s]
 93%|| 77.4M/83.3M [00:01<00:00, 38.9MB/s]
 99%|| 82.7M/83.3M [00:01<00:00, 40.9MB/s]
100%|| 83.3M/83.3M [00:01<00:00, 63.7MB/s]

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 12%|        | 9.95M/83.3M [00:00<00:00, 93.1MB/s]
 30%|       | 25.0M/83.3M [00:00<00:00, 106MB/s]
 47%|     | 38.8M/83.3M [00:00<00:00, 77.2MB/s]
 61%|   | 51.0M/83.3M [00:00<00:00, 87.7MB/s]
 81%| | 67.7M/83.3M [00:00<00:00, 99.6MB/s]
 93%|| 77.2M/83.3M [00:01<00:00, 45.0MB/s]
100%|| 83.3M/83.3M [00:01<00:00, 63.3MB/s]

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 20%|        | 16.8M/83.3M [00:00<00:00, 177MB/s]
 38%|      | 31.4M/83.3M [00:00<00:00, 169MB/s]
 56%|    | 46.4M/83.3M [00:00<00:00, 165MB/s]
 68%|   | 56.4M/83.3M [00:00<00:00, 133MB/s]
 79%|  | 66.1M/83.3M [00:00<00:00, 87.3MB/s]
 89%| | 74.2M/83.3M [00:01<00:00, 39.0MB/s]
 97%|| 80.4M/83.3M [00:01<00:00, 37.9MB/s]
100%|| 83.3M/83.3M [00:01<00:00, 63.1MB/s]

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
  5%|         | 4.42M/83.3M [00:00<00:01, 46.0MB/s]
 11%|         | 8.84M/83.3M [00:00<00:01, 46.0MB/s]
 24%|       | 20.0M/83.3M [00:00<00:01, 56.2MB/s]
 38%|      | 31.6M/83.3M [00:00<00:00, 66.9MB/s]
 46%|     | 38.5M/83.3M [00:00<00:00, 66.2MB/s]
 54%|    | 45.1M/83.3M [00:00<00:00, 67.0MB/s]
 64%|   | 53.6M/83.3M [00:00<00:00, 72.1MB/s]
 75%|  | 62.6M/83.3M [00:00<00:00, 77.7MB/s]
 84%| | 70.3M/83.3M [00:00<00:00, 70.4MB/s]
 93%|| 77.4M/83.3M [00:01<00:00, 45.9MB/s]
100%|| 83.0M/83.3M [00:01<00:00, 46.9MB/s]
100%|| 83.3M/83.3M [00:01<00:00, 63.5MB/s]

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 17%|        | 13.8M/83.3M [00:00<00:00, 144MB/s]
 29%|       | 24.2M/83.3M [00:00<00:00, 130MB/s]
 46%|     | 38.5M/83.3M [00:00<00:00, 135MB/s]
 58%|    | 48.5M/83.3M [00:00<00:00, 124MB/s]
 69%|   | 57.4M/83.3M [00:00<00:00, 108MB/s]
 80%|  | 66.3M/83.3M [00:00<00:00, 101MB/s]
 90%| | 74.8M/83.3M [00:01<00:00, 40.7MB/s]
 98%|| 81.2M/83.3M [00:01<00:00, 40.5MB/s]
100%|| 83.3M/83.3M [00:01<00:00, 64.2MB/s]

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 16%|        | 13.3M/83.3M [00:00<00:00, 126MB/s]
 24%|       | 19.6M/83.3M [00:00<00:00, 99.5MB/s]
 37%|      | 30.5M/83.3M [00:00<00:00, 103MB/s]
 49%|     | 40.9M/83.3M [00:00<00:00, 103MB/s]
 58%|    | 48.3M/83.3M [00:00<00:00, 92.6MB/s]
 68%|   | 56.7M/83.3M [00:00<00:00, 91.0MB/s]
 81%| | 67.7M/83.3M [00:00<00:00, 94.4MB/s]
 91%| | 76.0M/83.3M [00:01<00:00, 41.9MB/s]
 99%|| 82.3M/83.3M [00:01<00:00, 42.1MB/s]
100%|| 83.3M/83.3M [00:01<00:00, 63.5MB/s]

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
  2%|         | 1.59M/83.3M [00:00<00:05, 15.2MB/s]
  3%|         | 2.72M/83.3M [00:00<00:06, 13.7MB/s]
  5%|         | 4.30M/83.3M [00:00<00:05, 14.5MB/s]
 21%|        | 17.4M/83.3M [00:00<00:03, 19.8MB/s]
 36%|      | 29.6M/83.3M [00:00<00:02, 26.5MB/s]
 44%|     | 36.4M/83.3M [00:00<00:01, 25.2MB/s]
 50%|     | 41.9M/83.3M [00:01<00:01, 26.1MB/s]
 75%|  | 62.8M/83.3M [00:01<00:00, 35.4MB/s]
100%|| 83.3M/83.3M [00:01<00:00, 71.0MB/s]
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 16%|        | 13.2M/83.3M [00:00<00:00, 139MB/s]
 35%|      | 29.4M/83.3M [00:00<00:00, 147MB/s]
 56%|    | 46.7M/83.3M [00:00<00:00, 156MB/s]
 69%|   | 57.2M/83.3M [00:00<00:00, 108MB/s]
 80%|  | 66.4M/83.3M [00:00<00:00, 48.9MB/s]
 88%| | 73.4M/83.3M [00:01<00:00, 48.1MB/s]
 96%|| 79.7M/83.3M [00:01<00:00, 24.8MB/s]
100%|| 83.3M/83.3M [00:01<00:00, 50.4MB/s]

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 14%|        | 11.2M/83.3M [00:00<00:00, 118MB/s]
 21%|       | 17.8M/83.3M [00:00<00:00, 96.9MB/s]
 38%|      | 31.2M/83.3M [00:00<00:00, 107MB/s]
 48%|     | 40.2M/83.3M [00:00<00:00, 102MB/s]
 57%|    | 47.8M/83.3M [00:00<00:00, 39.7MB/s]
 64%|   | 53.6M/83.3M [00:01<00:00, 39.0MB/s]
 79%|  | 65.9M/83.3M [00:01<00:00, 49.3MB/s]
 88%| | 73.2M/83.3M [00:01<00:00, 53.4MB/s]
 96%|| 80.1M/83.3M [00:01<00:00, 31.7MB/s]
100%|| 83.3M/83.3M [00:01<00:00, 49.8MB/s]
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
:::MLLOG {"namespace": "", "time_ms": 1592975480837, "event_type": "POINT_IN_TIME", "key": "model_bn_span", "value": 56, "metadata": {"file": "train.py", "lineno": 170}}
:::MLLOG {"namespace": "", "time_ms": 1592975480837, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 896, "metadata": {"file": "train.py", "lineno": 171}}
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : 128.0
Delaying allreduces to the end of backward()
:::MLLOG {"namespace": "", "time_ms": 1592975480846, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.09, "metadata": {"file": "train.py", "lineno": 199}}
:::MLLOG {"namespace": "", "time_ms": 1592975480847, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_boundary_epochs", "value": [44, 55], "metadata": {"file": "train.py", "lineno": 200}}
:::MLLOG {"namespace": "", "time_ms": 1592975480847, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_steps", "value": [44, 55], "metadata": {"file": "train.py", "lineno": 201}}
:::MLLOG {"namespace": "", "time_ms": 1592975480847, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.00013, "metadata": {"file": "train.py", "lineno": 202}}
:::MLLOG {"namespace": "", "time_ms": 1592975480847, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 650, "metadata": {"file": "train.py", "lineno": 204}}
:::MLLOG {"namespace": "", "time_ms": 1592975480847, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_factor", "value": 0, "metadata": {"file": "train.py", "lineno": 205}}
epoch nbatch loss
epoch nbatch loss
:::MLLOG {"namespace": "", "time_ms": 1592975492456, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "train.py", "lineno": 267}}
:::MLLOG {"namespace": "", "time_ms": 1592975492457, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "train.py", "lineno": 274}}
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
:::MLLOG {"namespace": "", "time_ms": 1592975494392, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 117266, "metadata": {"file": "/workspace/single_stage_detector/data/build_pipeline.py", "lineno": 48}}
epoch size is:  117266  images
:::MLLOG {"namespace": "", "time_ms": 1592975494392, "event_type": "POINT_IN_TIME", "key": "max_samples", "value": 1, "metadata": {"file": "/workspace/single_stage_detector/utils.py", "lineno": 156}}
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
Done (t=0.11s)
creating index...
Done (t=0.11s)
creating index...
Done (t=0.11s)
creating index...
Done (t=0.11s)
creating index...
Done (t=0.11s)
creating index...
Done (t=0.11s)
creating index...
Done (t=0.11s)
creating index...
Done (t=0.11s)
creating index...
Done (t=0.12s)
creating index...
Done (t=0.12s)
creating index...
Done (t=0.12s)
creating index...
Done (t=0.13s)
creating index...
Done (t=0.12s)
creating index...
Done (t=0.12s)
creating index...
Done (t=0.12s)
creating index...
Done (t=0.12s)
creating index...
:::MLLOG {"namespace": "", "time_ms": 1592975494614, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 4952, "metadata": {"file": "/workspace/single_stage_detector/data/native_pipeline.py", "lineno": 97}}
:::MLLOG {"namespace": "", "time_ms": 1592975494615, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 293, "first_epoch_num": 1, "epoch_count": 40}}
:::MLLOG {"namespace": "", "time_ms": 1592975494616, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 1, "current_iter_num": 0}}
Iteration:      0, Loss function: 22.931, Average Loss: 0.023, avg. samples / sec: 65.57
Iteration:     20, Loss function: 21.046, Average Loss: 0.447, avg. samples / sec: 14468.16
Iteration:     40, Loss function: 19.210, Average Loss: 0.838, avg. samples / sec: 16306.44
Iteration:     60, Loss function: 15.791, Average Loss: 1.119, avg. samples / sec: 16852.47
Iteration:     80, Loss function: 10.629, Average Loss: 1.332, avg. samples / sec: 16775.71
Iteration:    100, Loss function: 9.285, Average Loss: 1.501, avg. samples / sec: 16884.64
Iteration:    120, Loss function: 8.826, Average Loss: 1.653, avg. samples / sec: 16966.49
:::MLLOG {"namespace": "", "time_ms": 1592975501975, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1592975501976, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 2, "current_iter_num": 131}}
Iteration:    140, Loss function: 9.075, Average Loss: 1.795, avg. samples / sec: 16852.87
Iteration:    160, Loss function: 8.856, Average Loss: 1.936, avg. samples / sec: 17080.14
Iteration:    180, Loss function: 8.570, Average Loss: 2.070, avg. samples / sec: 17176.17
Iteration:    200, Loss function: 8.400, Average Loss: 2.197, avg. samples / sec: 17091.45
Iteration:    220, Loss function: 8.132, Average Loss: 2.316, avg. samples / sec: 17313.62
Iteration:    240, Loss function: 8.383, Average Loss: 2.429, avg. samples / sec: 17416.70
Iteration:    260, Loss function: 7.862, Average Loss: 2.538, avg. samples / sec: 17108.52
:::MLLOG {"namespace": "", "time_ms": 1592975508804, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1592975508805, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 3, "current_iter_num": 262}}
Iteration:    280, Loss function: 7.544, Average Loss: 2.641, avg. samples / sec: 17363.22
Iteration:    300, Loss function: 7.434, Average Loss: 2.736, avg. samples / sec: 17420.03
Iteration:    320, Loss function: 7.240, Average Loss: 2.828, avg. samples / sec: 17330.24
Iteration:    340, Loss function: 7.020, Average Loss: 2.918, avg. samples / sec: 17488.51
Iteration:    360, Loss function: 7.551, Average Loss: 3.002, avg. samples / sec: 17507.06
Iteration:    380, Loss function: 6.879, Average Loss: 3.082, avg. samples / sec: 17403.60
:::MLLOG {"namespace": "", "time_ms": 1592975515541, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592975515542, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 4, "current_iter_num": 393}}
Iteration:    400, Loss function: 7.344, Average Loss: 3.160, avg. samples / sec: 17530.52
Iteration:    420, Loss function: 6.707, Average Loss: 3.235, avg. samples / sec: 17623.52
Iteration:    440, Loss function: 6.760, Average Loss: 3.304, avg. samples / sec: 17427.28
Iteration:    460, Loss function: 6.225, Average Loss: 3.370, avg. samples / sec: 17622.01
Iteration:    480, Loss function: 6.052, Average Loss: 3.434, avg. samples / sec: 17501.63
Iteration:    500, Loss function: 6.818, Average Loss: 3.496, avg. samples / sec: 17628.35
Iteration:    520, Loss function: 6.341, Average Loss: 3.557, avg. samples / sec: 17717.61
:::MLLOG {"namespace": "", "time_ms": 1592975522216, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592975522217, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 5, "current_iter_num": 524}}
Iteration:    540, Loss function: 6.288, Average Loss: 3.611, avg. samples / sec: 17666.81
Iteration:    560, Loss function: 6.247, Average Loss: 3.667, avg. samples / sec: 17723.08
Iteration:    580, Loss function: 5.944, Average Loss: 3.717, avg. samples / sec: 17575.15
Iteration:    600, Loss function: 5.997, Average Loss: 3.762, avg. samples / sec: 17767.77
Iteration:    620, Loss function: 5.755, Average Loss: 3.806, avg. samples / sec: 17701.19
Iteration:    640, Loss function: 6.213, Average Loss: 3.850, avg. samples / sec: 17641.14
:::MLLOG {"namespace": "", "time_ms": 1592975528855, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1592975528856, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 6, "current_iter_num": 655}}
Iteration:    660, Loss function: 5.891, Average Loss: 3.891, avg. samples / sec: 17750.65
Iteration:    680, Loss function: 5.532, Average Loss: 3.927, avg. samples / sec: 17831.47
Iteration:    700, Loss function: 5.963, Average Loss: 3.966, avg. samples / sec: 17688.59
Iteration:    720, Loss function: 5.754, Average Loss: 4.002, avg. samples / sec: 17799.85
Iteration:    740, Loss function: 5.515, Average Loss: 4.032, avg. samples / sec: 17739.86
Iteration:    760, Loss function: 5.998, Average Loss: 4.064, avg. samples / sec: 17675.33
Iteration:    780, Loss function: 5.888, Average Loss: 4.094, avg. samples / sec: 17775.26
:::MLLOG {"namespace": "", "time_ms": 1592975535470, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 6}}
:::MLLOG {"namespace": "", "time_ms": 1592975535471, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 7, "current_iter_num": 786}}
Iteration:    800, Loss function: 5.405, Average Loss: 4.119, avg. samples / sec: 17688.66
Iteration:    820, Loss function: 5.025, Average Loss: 4.146, avg. samples / sec: 17809.40
Iteration:    840, Loss function: 5.261, Average Loss: 4.169, avg. samples / sec: 17822.04
Iteration:    860, Loss function: 5.654, Average Loss: 4.193, avg. samples / sec: 17875.02
Iteration:    880, Loss function: 4.981, Average Loss: 4.214, avg. samples / sec: 17964.98
Iteration:    900, Loss function: 5.032, Average Loss: 4.234, avg. samples / sec: 17984.21
:::MLLOG {"namespace": "", "time_ms": 1592975542039, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1592975542040, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 8, "current_iter_num": 917}}
Iteration:    920, Loss function: 5.105, Average Loss: 4.255, avg. samples / sec: 17824.95
Iteration:    940, Loss function: 4.742, Average Loss: 4.274, avg. samples / sec: 17928.55
Iteration:    960, Loss function: 5.000, Average Loss: 4.290, avg. samples / sec: 18010.33
Iteration:    980, Loss function: 5.364, Average Loss: 4.306, avg. samples / sec: 17965.85
Iteration:   1000, Loss function: 5.250, Average Loss: 4.322, avg. samples / sec: 18043.97
Iteration:   1020, Loss function: 5.537, Average Loss: 4.336, avg. samples / sec: 18006.25
Iteration:   1040, Loss function: 5.262, Average Loss: 4.352, avg. samples / sec: 18003.13
:::MLLOG {"namespace": "", "time_ms": 1592975548515, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 8}}
:::MLLOG {"namespace": "", "time_ms": 1592975548516, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 9, "current_iter_num": 1047}}
Iteration:   1060, Loss function: 4.895, Average Loss: 4.365, avg. samples / sec: 17929.73
Iteration:   1080, Loss function: 5.238, Average Loss: 4.378, avg. samples / sec: 18042.65
Iteration:   1100, Loss function: 5.018, Average Loss: 4.389, avg. samples / sec: 18080.33
Iteration:   1120, Loss function: 5.190, Average Loss: 4.401, avg. samples / sec: 18155.47
Iteration:   1140, Loss function: 4.983, Average Loss: 4.412, avg. samples / sec: 18172.91
Iteration:   1160, Loss function: 4.830, Average Loss: 4.420, avg. samples / sec: 18139.11
:::MLLOG {"namespace": "", "time_ms": 1592975554999, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 9}}
:::MLLOG {"namespace": "", "time_ms": 1592975555000, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 10, "current_iter_num": 1178}}
Iteration:   1180, Loss function: 5.029, Average Loss: 4.430, avg. samples / sec: 18204.77
Iteration:   1200, Loss function: 4.410, Average Loss: 4.439, avg. samples / sec: 18092.32
Iteration:   1220, Loss function: 5.022, Average Loss: 4.447, avg. samples / sec: 18141.23
Iteration:   1240, Loss function: 4.576, Average Loss: 4.453, avg. samples / sec: 18149.28
Iteration:   1260, Loss function: 4.956, Average Loss: 4.458, avg. samples / sec: 17985.87
Iteration:   1280, Loss function: 5.152, Average Loss: 4.465, avg. samples / sec: 18070.30
Iteration:   1300, Loss function: 4.465, Average Loss: 4.470, avg. samples / sec: 18110.01
:::MLLOG {"namespace": "", "time_ms": 1592975561487, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 10}}
:::MLLOG {"namespace": "", "time_ms": 1592975561488, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 11, "current_iter_num": 1309}}
Iteration:   1320, Loss function: 4.776, Average Loss: 4.475, avg. samples / sec: 18018.23
Iteration:   1340, Loss function: 4.552, Average Loss: 4.479, avg. samples / sec: 17963.01
Iteration:   1360, Loss function: 4.639, Average Loss: 4.485, avg. samples / sec: 18044.79
Iteration:   1380, Loss function: 4.779, Average Loss: 4.491, avg. samples / sec: 17974.58
Iteration:   1400, Loss function: 4.820, Average Loss: 4.494, avg. samples / sec: 17693.92
Iteration:   1420, Loss function: 4.758, Average Loss: 4.497, avg. samples / sec: 17824.59
:::MLLOG {"namespace": "", "time_ms": 1592975568048, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1592975568049, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 12, "current_iter_num": 1440}}
Iteration:   1440, Loss function: 4.865, Average Loss: 4.500, avg. samples / sec: 17801.70
Iteration:   1460, Loss function: 4.902, Average Loss: 4.502, avg. samples / sec: 17848.36
Iteration:   1480, Loss function: 4.227, Average Loss: 4.504, avg. samples / sec: 17817.38
Iteration:   1500, Loss function: 4.604, Average Loss: 4.507, avg. samples / sec: 17725.29
Iteration:   1520, Loss function: 4.581, Average Loss: 4.509, avg. samples / sec: 17958.50
Iteration:   1540, Loss function: 4.797, Average Loss: 4.511, avg. samples / sec: 17867.09
Iteration:   1560, Loss function: 4.974, Average Loss: 4.512, avg. samples / sec: 17926.42
:::MLLOG {"namespace": "", "time_ms": 1592975574617, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1592975574618, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 13, "current_iter_num": 1571}}
Iteration:   1580, Loss function: 4.668, Average Loss: 4.514, avg. samples / sec: 17971.08
Iteration:   1600, Loss function: 4.663, Average Loss: 4.514, avg. samples / sec: 17815.76
Iteration:   1620, Loss function: 4.487, Average Loss: 4.514, avg. samples / sec: 18004.52
Iteration:   1640, Loss function: 4.620, Average Loss: 4.515, avg. samples / sec: 18036.16
Iteration:   1660, Loss function: 4.374, Average Loss: 4.516, avg. samples / sec: 17985.75
Iteration:   1680, Loss function: 4.566, Average Loss: 4.515, avg. samples / sec: 17993.40
Iteration:   1700, Loss function: 4.432, Average Loss: 4.514, avg. samples / sec: 18040.72
:::MLLOG {"namespace": "", "time_ms": 1592975581148, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 13}}
:::MLLOG {"namespace": "", "time_ms": 1592975581149, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 14, "current_iter_num": 1702}}
Iteration:   1720, Loss function: 4.171, Average Loss: 4.512, avg. samples / sec: 17829.44
Iteration:   1740, Loss function: 4.128, Average Loss: 4.511, avg. samples / sec: 18040.88
Iteration:   1760, Loss function: 4.267, Average Loss: 4.509, avg. samples / sec: 17926.80
Iteration:   1780, Loss function: 4.706, Average Loss: 4.508, avg. samples / sec: 18098.38
Iteration:   1800, Loss function: 4.209, Average Loss: 4.506, avg. samples / sec: 18105.82
Iteration:   1820, Loss function: 4.932, Average Loss: 4.505, avg. samples / sec: 17976.28
:::MLLOG {"namespace": "", "time_ms": 1592975587684, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 14}}
:::MLLOG {"namespace": "", "time_ms": 1592975587685, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 15, "current_iter_num": 1833}}
Iteration:   1840, Loss function: 4.413, Average Loss: 4.504, avg. samples / sec: 17747.21
Iteration:   1860, Loss function: 4.474, Average Loss: 4.501, avg. samples / sec: 17890.02
Iteration:   1880, Loss function: 4.061, Average Loss: 4.498, avg. samples / sec: 17923.91
Iteration:   1900, Loss function: 4.633, Average Loss: 4.495, avg. samples / sec: 17999.21
Iteration:   1920, Loss function: 4.473, Average Loss: 4.493, avg. samples / sec: 17957.30
Iteration:   1940, Loss function: 4.364, Average Loss: 4.490, avg. samples / sec: 17937.56
Iteration:   1960, Loss function: 4.238, Average Loss: 4.489, avg. samples / sec: 17969.13
:::MLLOG {"namespace": "", "time_ms": 1592975594225, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1592975594226, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 16, "current_iter_num": 1964}}
Iteration:   1980, Loss function: 3.726, Average Loss: 4.486, avg. samples / sec: 17909.72
Iteration:   2000, Loss function: 4.457, Average Loss: 4.486, avg. samples / sec: 17946.52
Iteration:   2020, Loss function: 4.068, Average Loss: 4.483, avg. samples / sec: 17978.13
Iteration:   2040, Loss function: 4.378, Average Loss: 4.480, avg. samples / sec: 18033.73
Iteration:   2060, Loss function: 4.262, Average Loss: 4.478, avg. samples / sec: 17970.10
Iteration:   2080, Loss function: 4.177, Average Loss: 4.476, avg. samples / sec: 17836.92
:::MLLOG {"namespace": "", "time_ms": 1592975600718, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1592975600719, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 17, "current_iter_num": 2094}}
Iteration:   2100, Loss function: 4.145, Average Loss: 4.473, avg. samples / sec: 17875.74
Iteration:   2120, Loss function: 3.986, Average Loss: 4.470, avg. samples / sec: 17881.97
Iteration:   2140, Loss function: 3.956, Average Loss: 4.468, avg. samples / sec: 17871.02
Iteration:   2160, Loss function: 3.939, Average Loss: 4.464, avg. samples / sec: 17774.62
Iteration:   2180, Loss function: 4.601, Average Loss: 4.461, avg. samples / sec: 17583.29
Iteration:   2200, Loss function: 4.342, Average Loss: 4.459, avg. samples / sec: 17873.55
Iteration:   2220, Loss function: 4.241, Average Loss: 4.455, avg. samples / sec: 17896.65
:::MLLOG {"namespace": "", "time_ms": 1592975607306, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 17}}
:::MLLOG {"namespace": "", "time_ms": 1592975607307, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 18, "current_iter_num": 2225}}
Iteration:   2240, Loss function: 4.509, Average Loss: 4.452, avg. samples / sec: 17911.43
Iteration:   2260, Loss function: 4.220, Average Loss: 4.448, avg. samples / sec: 17886.47
Iteration:   2280, Loss function: 3.979, Average Loss: 4.444, avg. samples / sec: 18006.60
Iteration:   2300, Loss function: 4.419, Average Loss: 4.441, avg. samples / sec: 18069.91
Iteration:   2320, Loss function: 4.022, Average Loss: 4.437, avg. samples / sec: 18079.08
Iteration:   2340, Loss function: 4.071, Average Loss: 4.433, avg. samples / sec: 17940.09
:::MLLOG {"namespace": "", "time_ms": 1592975613830, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1592975613831, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 19, "current_iter_num": 2356}}
Iteration:   2360, Loss function: 4.196, Average Loss: 4.430, avg. samples / sec: 18039.64
Iteration:   2380, Loss function: 4.413, Average Loss: 4.426, avg. samples / sec: 17993.78
Iteration:   2400, Loss function: 3.824, Average Loss: 4.422, avg. samples / sec: 17800.50
Iteration:   2420, Loss function: 4.403, Average Loss: 4.418, avg. samples / sec: 17820.35
Iteration:   2440, Loss function: 4.120, Average Loss: 4.415, avg. samples / sec: 17838.36
Iteration:   2460, Loss function: 4.164, Average Loss: 4.410, avg. samples / sec: 17828.95
Iteration:   2480, Loss function: 4.587, Average Loss: 4.406, avg. samples / sec: 18051.61
:::MLLOG {"namespace": "", "time_ms": 1592975620408, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1592975620409, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 20, "current_iter_num": 2487}}
Iteration:   2500, Loss function: 4.358, Average Loss: 4.402, avg. samples / sec: 17899.17
Iteration:   2520, Loss function: 4.014, Average Loss: 4.395, avg. samples / sec: 18037.42
Iteration:   2540, Loss function: 3.914, Average Loss: 4.390, avg. samples / sec: 17962.29
Iteration:   2560, Loss function: 4.469, Average Loss: 4.385, avg. samples / sec: 17951.89
Iteration:   2580, Loss function: 3.948, Average Loss: 4.382, avg. samples / sec: 17948.49
Iteration:   2600, Loss function: 4.437, Average Loss: 4.378, avg. samples / sec: 17991.48
:::MLLOG {"namespace": "", "time_ms": 1592975626926, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1592975626927, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 21, "current_iter_num": 2618}}
Iteration:   2620, Loss function: 4.176, Average Loss: 4.374, avg. samples / sec: 17906.39
Iteration:   2640, Loss function: 4.053, Average Loss: 4.370, avg. samples / sec: 18023.92
Iteration:   2660, Loss function: 4.104, Average Loss: 4.366, avg. samples / sec: 18061.55
Iteration:   2680, Loss function: 4.312, Average Loss: 4.362, avg. samples / sec: 17957.73
Iteration:   2700, Loss function: 4.380, Average Loss: 4.359, avg. samples / sec: 17984.84
Iteration:   2720, Loss function: 4.055, Average Loss: 4.354, avg. samples / sec: 17973.37
Iteration:   2740, Loss function: 4.284, Average Loss: 4.350, avg. samples / sec: 17883.68
:::MLLOG {"namespace": "", "time_ms": 1592975633456, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 21}}
:::MLLOG {"namespace": "", "time_ms": 1592975633457, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 22, "current_iter_num": 2749}}
Iteration:   2760, Loss function: 4.084, Average Loss: 4.347, avg. samples / sec: 17921.96
Iteration:   2780, Loss function: 4.446, Average Loss: 4.343, avg. samples / sec: 17965.88
Iteration:   2800, Loss function: 3.867, Average Loss: 4.340, avg. samples / sec: 17967.90
Iteration:   2820, Loss function: 3.909, Average Loss: 4.335, avg. samples / sec: 17999.78
Iteration:   2840, Loss function: 4.383, Average Loss: 4.330, avg. samples / sec: 17981.69
Iteration:   2860, Loss function: 3.906, Average Loss: 4.325, avg. samples / sec: 17914.39
:::MLLOG {"namespace": "", "time_ms": 1592975639998, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 22}}
:::MLLOG {"namespace": "", "time_ms": 1592975639999, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 23, "current_iter_num": 2880}}
Iteration:   2880, Loss function: 3.730, Average Loss: 4.321, avg. samples / sec: 17863.82
Iteration:   2900, Loss function: 3.960, Average Loss: 4.315, avg. samples / sec: 17846.68
Iteration:   2920, Loss function: 4.343, Average Loss: 4.311, avg. samples / sec: 17911.67
Iteration:   2940, Loss function: 4.050, Average Loss: 4.307, avg. samples / sec: 17909.15
Iteration:   2960, Loss function: 3.622, Average Loss: 4.302, avg. samples / sec: 17909.06
Iteration:   2980, Loss function: 3.807, Average Loss: 4.298, avg. samples / sec: 17880.71
Iteration:   3000, Loss function: 4.029, Average Loss: 4.294, avg. samples / sec: 17923.37
:::MLLOG {"namespace": "", "time_ms": 1592975646557, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1592975646558, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 24, "current_iter_num": 3011}}
Iteration:   3020, Loss function: 3.979, Average Loss: 4.288, avg. samples / sec: 17907.25
Iteration:   3040, Loss function: 3.964, Average Loss: 4.284, avg. samples / sec: 17908.10
Iteration:   3060, Loss function: 4.413, Average Loss: 4.280, avg. samples / sec: 17909.85
Iteration:   3080, Loss function: 3.964, Average Loss: 4.278, avg. samples / sec: 17947.45
Iteration:   3100, Loss function: 4.096, Average Loss: 4.273, avg. samples / sec: 17949.12
Iteration:   3120, Loss function: 4.028, Average Loss: 4.269, avg. samples / sec: 17939.62
Iteration:   3140, Loss function: 3.688, Average Loss: 4.266, avg. samples / sec: 17932.08
:::MLLOG {"namespace": "", "time_ms": 1592975653069, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1592975653070, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 25, "current_iter_num": 3141}}
Iteration:   3160, Loss function: 3.899, Average Loss: 4.261, avg. samples / sec: 17876.07
Iteration:   3180, Loss function: 4.214, Average Loss: 4.256, avg. samples / sec: 17897.38
Iteration:   3200, Loss function: 3.831, Average Loss: 4.252, avg. samples / sec: 17900.25
Iteration:   3220, Loss function: 4.559, Average Loss: 4.248, avg. samples / sec: 17898.71
Iteration:   3240, Loss function: 4.257, Average Loss: 4.246, avg. samples / sec: 17892.70
Iteration:   3260, Loss function: 3.801, Average Loss: 4.241, avg. samples / sec: 17932.75
:::MLLOG {"namespace": "", "time_ms": 1592975659611, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 25}}
:::MLLOG {"namespace": "", "time_ms": 1592975659612, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 26, "current_iter_num": 3272}}
Iteration:   3280, Loss function: 3.938, Average Loss: 4.235, avg. samples / sec: 17933.55
Iteration:   3300, Loss function: 4.300, Average Loss: 4.231, avg. samples / sec: 18003.31
Iteration:   3320, Loss function: 4.206, Average Loss: 4.227, avg. samples / sec: 18091.59
Iteration:   3340, Loss function: 3.670, Average Loss: 4.223, avg. samples / sec: 18086.70
Iteration:   3360, Loss function: 4.039, Average Loss: 4.219, avg. samples / sec: 18026.82
Iteration:   3380, Loss function: 3.972, Average Loss: 4.213, avg. samples / sec: 17929.16
Iteration:   3400, Loss function: 4.212, Average Loss: 4.210, avg. samples / sec: 18051.22
:::MLLOG {"namespace": "", "time_ms": 1592975666125, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 26}}
:::MLLOG {"namespace": "", "time_ms": 1592975666126, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 27, "current_iter_num": 3403}}
Iteration:   3420, Loss function: 4.186, Average Loss: 4.206, avg. samples / sec: 18008.96
Iteration:   3440, Loss function: 3.682, Average Loss: 4.201, avg. samples / sec: 18065.07
Iteration:   3460, Loss function: 4.178, Average Loss: 4.198, avg. samples / sec: 18100.18
Iteration:   3480, Loss function: 4.202, Average Loss: 4.194, avg. samples / sec: 18091.96
Iteration:   3500, Loss function: 3.532, Average Loss: 4.188, avg. samples / sec: 17727.43
Iteration:   3520, Loss function: 3.752, Average Loss: 4.182, avg. samples / sec: 18080.31
:::MLLOG {"namespace": "", "time_ms": 1592975672635, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1592975672636, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 28, "current_iter_num": 3534}}
Iteration:   3540, Loss function: 4.063, Average Loss: 4.176, avg. samples / sec: 18133.24
Iteration:   3560, Loss function: 3.899, Average Loss: 4.174, avg. samples / sec: 18040.29
Iteration:   3580, Loss function: 4.019, Average Loss: 4.168, avg. samples / sec: 17923.85
Iteration:   3600, Loss function: 3.648, Average Loss: 4.164, avg. samples / sec: 17689.43
Iteration:   3620, Loss function: 3.768, Average Loss: 4.159, avg. samples / sec: 18003.78
Iteration:   3640, Loss function: 4.009, Average Loss: 4.156, avg. samples / sec: 18058.16
Iteration:   3660, Loss function: 3.894, Average Loss: 4.152, avg. samples / sec: 17969.12
:::MLLOG {"namespace": "", "time_ms": 1592975679174, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1592975679175, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 29, "current_iter_num": 3665}}
Iteration:   3680, Loss function: 4.147, Average Loss: 4.149, avg. samples / sec: 17980.66
Iteration:   3700, Loss function: 4.127, Average Loss: 4.145, avg. samples / sec: 17947.70
Iteration:   3720, Loss function: 3.305, Average Loss: 4.144, avg. samples / sec: 17890.04
Iteration:   3740, Loss function: 4.008, Average Loss: 4.140, avg. samples / sec: 17991.67
Iteration:   3760, Loss function: 3.816, Average Loss: 4.136, avg. samples / sec: 18002.73
Iteration:   3780, Loss function: 3.872, Average Loss: 4.134, avg. samples / sec: 18006.42
:::MLLOG {"namespace": "", "time_ms": 1592975685704, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 29}}
:::MLLOG {"namespace": "", "time_ms": 1592975685705, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 30, "current_iter_num": 3796}}
Iteration:   3800, Loss function: 3.867, Average Loss: 4.132, avg. samples / sec: 17857.33
Iteration:   3820, Loss function: 4.160, Average Loss: 4.128, avg. samples / sec: 17920.87
Iteration:   3840, Loss function: 3.959, Average Loss: 4.123, avg. samples / sec: 18021.08
Iteration:   3860, Loss function: 3.898, Average Loss: 4.120, avg. samples / sec: 18004.33
Iteration:   3880, Loss function: 4.086, Average Loss: 4.117, avg. samples / sec: 17973.01
Iteration:   3900, Loss function: 4.108, Average Loss: 4.114, avg. samples / sec: 18038.56
Iteration:   3920, Loss function: 4.060, Average Loss: 4.111, avg. samples / sec: 17911.28
:::MLLOG {"namespace": "", "time_ms": 1592975692239, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 30}}
:::MLLOG {"namespace": "", "time_ms": 1592975692240, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 31, "current_iter_num": 3927}}
Iteration:   3940, Loss function: 3.956, Average Loss: 4.108, avg. samples / sec: 17993.84
Iteration:   3960, Loss function: 3.380, Average Loss: 4.103, avg. samples / sec: 18005.50
Iteration:   3980, Loss function: 3.776, Average Loss: 4.096, avg. samples / sec: 17996.51
Iteration:   4000, Loss function: 3.861, Average Loss: 4.093, avg. samples / sec: 17990.87
Iteration:   4020, Loss function: 3.862, Average Loss: 4.092, avg. samples / sec: 17960.20
Iteration:   4040, Loss function: 3.754, Average Loss: 4.088, avg. samples / sec: 17647.25
:::MLLOG {"namespace": "", "time_ms": 1592975698791, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1592975698792, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 32, "current_iter_num": 4058}}
Iteration:   4060, Loss function: 3.306, Average Loss: 4.085, avg. samples / sec: 17862.57
Iteration:   4080, Loss function: 3.735, Average Loss: 4.083, avg. samples / sec: 18063.98
Iteration:   4100, Loss function: 3.471, Average Loss: 4.078, avg. samples / sec: 18078.78
Iteration:   4120, Loss function: 3.977, Average Loss: 4.075, avg. samples / sec: 18005.71
Iteration:   4140, Loss function: 4.058, Average Loss: 4.070, avg. samples / sec: 17753.04
Iteration:   4160, Loss function: 4.208, Average Loss: 4.068, avg. samples / sec: 18003.36
Iteration:   4180, Loss function: 4.255, Average Loss: 4.066, avg. samples / sec: 18027.62
:::MLLOG {"namespace": "", "time_ms": 1592975705268, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1592975705269, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 33, "current_iter_num": 4188}}
Iteration:   4200, Loss function: 3.843, Average Loss: 4.062, avg. samples / sec: 18006.79
Iteration:   4220, Loss function: 4.009, Average Loss: 4.058, avg. samples / sec: 17992.73
Iteration:   4240, Loss function: 3.422, Average Loss: 4.053, avg. samples / sec: 18012.84
Iteration:   4260, Loss function: 3.782, Average Loss: 4.051, avg. samples / sec: 17857.46
Iteration:   4280, Loss function: 3.736, Average Loss: 4.050, avg. samples / sec: 17971.17
Iteration:   4300, Loss function: 4.002, Average Loss: 4.046, avg. samples / sec: 17986.08
:::MLLOG {"namespace": "", "time_ms": 1592975711801, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 33}}
:::MLLOG {"namespace": "", "time_ms": 1592975711802, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 34, "current_iter_num": 4319}}
Iteration:   4320, Loss function: 3.936, Average Loss: 4.043, avg. samples / sec: 17926.11
Iteration:   4340, Loss function: 3.684, Average Loss: 4.039, avg. samples / sec: 17938.63
Iteration:   4360, Loss function: 3.594, Average Loss: 4.035, avg. samples / sec: 17717.23
Iteration:   4380, Loss function: 3.654, Average Loss: 4.032, avg. samples / sec: 17891.84
Iteration:   4400, Loss function: 3.933, Average Loss: 4.027, avg. samples / sec: 17774.44
Iteration:   4420, Loss function: 3.515, Average Loss: 4.025, avg. samples / sec: 17801.67
Iteration:   4440, Loss function: 3.719, Average Loss: 4.022, avg. samples / sec: 17789.21
:::MLLOG {"namespace": "", "time_ms": 1592975718391, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 34}}
:::MLLOG {"namespace": "", "time_ms": 1592975718392, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 35, "current_iter_num": 4450}}
Iteration:   4460, Loss function: 4.320, Average Loss: 4.019, avg. samples / sec: 17795.57
Iteration:   4480, Loss function: 3.496, Average Loss: 4.014, avg. samples / sec: 17815.59
Iteration:   4500, Loss function: 4.117, Average Loss: 4.012, avg. samples / sec: 17790.64
Iteration:   4520, Loss function: 4.288, Average Loss: 4.010, avg. samples / sec: 17843.45
Iteration:   4540, Loss function: 3.541, Average Loss: 4.005, avg. samples / sec: 17933.09
Iteration:   4560, Loss function: 3.868, Average Loss: 4.002, avg. samples / sec: 17923.00
Iteration:   4580, Loss function: 3.633, Average Loss: 4.000, avg. samples / sec: 17916.14
:::MLLOG {"namespace": "", "time_ms": 1592975724977, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1592975724978, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 36, "current_iter_num": 4581}}
Iteration:   4600, Loss function: 4.121, Average Loss: 3.996, avg. samples / sec: 17914.79
Iteration:   4620, Loss function: 3.237, Average Loss: 3.992, avg. samples / sec: 17902.83
Iteration:   4640, Loss function: 4.198, Average Loss: 3.990, avg. samples / sec: 17903.59
Iteration:   4660, Loss function: 3.797, Average Loss: 3.986, avg. samples / sec: 17771.62
Iteration:   4680, Loss function: 3.574, Average Loss: 3.984, avg. samples / sec: 17799.79
Iteration:   4700, Loss function: 3.959, Average Loss: 3.981, avg. samples / sec: 17761.58
:::MLLOG {"namespace": "", "time_ms": 1592975731542, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 36}}
:::MLLOG {"namespace": "", "time_ms": 1592975731543, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 37, "current_iter_num": 4712}}
Iteration:   4720, Loss function: 3.936, Average Loss: 3.978, avg. samples / sec: 17794.08
Iteration:   4740, Loss function: 3.854, Average Loss: 3.973, avg. samples / sec: 17152.07
Iteration:   4760, Loss function: 3.864, Average Loss: 3.970, avg. samples / sec: 17815.65
Iteration:   4780, Loss function: 3.733, Average Loss: 3.967, avg. samples / sec: 17800.01
Iteration:   4800, Loss function: 3.713, Average Loss: 3.963, avg. samples / sec: 17824.55
Iteration:   4820, Loss function: 4.040, Average Loss: 3.961, avg. samples / sec: 18050.75
Iteration:   4840, Loss function: 3.870, Average Loss: 3.959, avg. samples / sec: 18061.38
:::MLLOG {"namespace": "", "time_ms": 1592975738143, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 37}}
:::MLLOG {"namespace": "", "time_ms": 1592975738144, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 38, "current_iter_num": 4843}}
Iteration:   4860, Loss function: 4.034, Average Loss: 3.957, avg. samples / sec: 18095.69
Iteration:   4880, Loss function: 3.764, Average Loss: 3.954, avg. samples / sec: 18047.19
Iteration:   4900, Loss function: 3.809, Average Loss: 3.950, avg. samples / sec: 17949.54
Iteration:   4920, Loss function: 3.722, Average Loss: 3.946, avg. samples / sec: 18061.32
Iteration:   4940, Loss function: 3.331, Average Loss: 3.943, avg. samples / sec: 18050.74
Iteration:   4960, Loss function: 3.891, Average Loss: 3.941, avg. samples / sec: 17974.21
:::MLLOG {"namespace": "", "time_ms": 1592975744655, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 38}}
:::MLLOG {"namespace": "", "time_ms": 1592975744656, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 39, "current_iter_num": 4974}}
Iteration:   4980, Loss function: 3.600, Average Loss: 3.937, avg. samples / sec: 18014.71
Iteration:   5000, Loss function: 3.530, Average Loss: 3.934, avg. samples / sec: 18020.44
Iteration:   5020, Loss function: 3.546, Average Loss: 3.929, avg. samples / sec: 18090.12
Iteration:   5040, Loss function: 4.520, Average Loss: 3.928, avg. samples / sec: 18066.26
Iteration:   5060, Loss function: 3.728, Average Loss: 3.925, avg. samples / sec: 17418.64
Iteration:   5080, Loss function: 3.921, Average Loss: 3.924, avg. samples / sec: 18046.09
Iteration:   5100, Loss function: 3.441, Average Loss: 3.921, avg. samples / sec: 18085.94
:::MLLOG {"namespace": "", "time_ms": 1592975751191, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 39}}
:::MLLOG {"namespace": "", "time_ms": 1592975751192, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 40, "current_iter_num": 5105}}
Iteration:   5120, Loss function: 3.987, Average Loss: 3.918, avg. samples / sec: 18035.68
Iteration:   5140, Loss function: 3.808, Average Loss: 3.915, avg. samples / sec: 17982.77
Iteration:   5160, Loss function: 3.714, Average Loss: 3.910, avg. samples / sec: 17967.40
Iteration:   5180, Loss function: 4.028, Average Loss: 3.908, avg. samples / sec: 18026.53
Iteration:   5200, Loss function: 3.613, Average Loss: 3.908, avg. samples / sec: 18104.95
Iteration:   5220, Loss function: 3.718, Average Loss: 3.906, avg. samples / sec: 18071.02
:::MLLOG {"namespace": "", "time_ms": 1592975757650, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 40}}
averaging bn running means and vars
Predicting Ended, total time: 3.96 s
:::MLLOG {"namespace": "", "time_ms": 1592975761667, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 331, "first_epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1592975761707, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 338, "first_epoch_num": 41, "epoch_count": 10}}
:::MLLOG {"namespace": "", "time_ms": 1592975761707, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 41, "current_iter_num": 5235}}
Loading and preparing results...
Iteration:   5240, Loss function: 3.631, Average Loss: 3.904, avg. samples / sec: 3531.56
DONE (t=0.39s)
Running per image evaluation...
Evaluate annotation type *bbox*
Iteration:   5260, Loss function: 3.590, Average Loss: 3.900, avg. samples / sec: 17868.32
DONE (t=1.50s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.18542
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.33843
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.18329
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.27825
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.19231
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.28419
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.29809
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.29809
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
Current AP: 0.18542 AP goal: 0.23000
Iteration:   5280, Loss function: 3.921, Average Loss: 3.898, avg. samples / sec: 17877.01
:::MLLOG {"namespace": "", "time_ms": 1592975764036, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 85, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1592975764036, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.1854206986516138, "metadata": {"file": "train.py", "lineno": 88, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1592975764037, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 89, "epoch_num": 40}}
Iteration:   5300, Loss function: 3.878, Average Loss: 3.896, avg. samples / sec: 17869.67
Iteration:   5320, Loss function: 3.909, Average Loss: 3.894, avg. samples / sec: 17866.12
Iteration:   5340, Loss function: 3.560, Average Loss: 3.892, avg. samples / sec: 17799.60
Iteration:   5360, Loss function: 3.895, Average Loss: 3.890, avg. samples / sec: 17858.98
:::MLLOG {"namespace": "", "time_ms": 1592975768302, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1592975768303, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 42, "current_iter_num": 5366}}
Iteration:   5380, Loss function: 3.583, Average Loss: 3.885, avg. samples / sec: 17892.90
Iteration:   5400, Loss function: 3.824, Average Loss: 3.883, avg. samples / sec: 17918.14
Iteration:   5420, Loss function: 3.870, Average Loss: 3.880, avg. samples / sec: 17904.82
Iteration:   5440, Loss function: 3.761, Average Loss: 3.876, avg. samples / sec: 17952.69
Iteration:   5460, Loss function: 3.908, Average Loss: 3.873, avg. samples / sec: 17952.82
Iteration:   5480, Loss function: 3.604, Average Loss: 3.871, avg. samples / sec: 18008.81
:::MLLOG {"namespace": "", "time_ms": 1592975774842, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 42}}
:::MLLOG {"namespace": "", "time_ms": 1592975774843, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 43, "current_iter_num": 5497}}
Iteration:   5500, Loss function: 3.502, Average Loss: 3.869, avg. samples / sec: 18012.47
Iteration:   5520, Loss function: 3.981, Average Loss: 3.866, avg. samples / sec: 17960.58
Iteration:   5540, Loss function: 3.938, Average Loss: 3.866, avg. samples / sec: 18013.54
Iteration:   5560, Loss function: 4.120, Average Loss: 3.864, avg. samples / sec: 18001.77
Iteration:   5580, Loss function: 3.775, Average Loss: 3.863, avg. samples / sec: 17973.50
Iteration:   5600, Loss function: 3.472, Average Loss: 3.860, avg. samples / sec: 17931.87
Iteration:   5620, Loss function: 3.648, Average Loss: 3.858, avg. samples / sec: 17896.12
:::MLLOG {"namespace": "", "time_ms": 1592975781379, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 43}}
:::MLLOG {"namespace": "", "time_ms": 1592975781379, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 44, "current_iter_num": 5628}}
Iteration:   5640, Loss function: 4.111, Average Loss: 3.857, avg. samples / sec: 17859.48
Iteration:   5660, Loss function: 3.763, Average Loss: 3.853, avg. samples / sec: 17863.65
Iteration:   5680, Loss function: 4.340, Average Loss: 3.850, avg. samples / sec: 18003.34
Iteration:   5700, Loss function: 3.659, Average Loss: 3.846, avg. samples / sec: 17976.21
Iteration:   5720, Loss function: 3.774, Average Loss: 3.843, avg. samples / sec: 18032.44
Iteration:   5740, Loss function: 3.757, Average Loss: 3.841, avg. samples / sec: 18065.37
:::MLLOG {"namespace": "", "time_ms": 1592975787908, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 44}}
lr decay step #1
:::MLLOG {"namespace": "", "time_ms": 1592975787909, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 45, "current_iter_num": 5759}}
Iteration:   5760, Loss function: 3.622, Average Loss: 3.837, avg. samples / sec: 17997.36
Iteration:   5780, Loss function: 3.377, Average Loss: 3.831, avg. samples / sec: 18009.21
Iteration:   5800, Loss function: 3.674, Average Loss: 3.825, avg. samples / sec: 18026.98
Iteration:   5820, Loss function: 3.653, Average Loss: 3.818, avg. samples / sec: 18036.71
Iteration:   5840, Loss function: 3.160, Average Loss: 3.808, avg. samples / sec: 18050.80
Iteration:   5860, Loss function: 3.546, Average Loss: 3.800, avg. samples / sec: 18031.06
Iteration:   5880, Loss function: 3.362, Average Loss: 3.793, avg. samples / sec: 18039.40
:::MLLOG {"namespace": "", "time_ms": 1592975794418, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 45}}
:::MLLOG {"namespace": "", "time_ms": 1592975794418, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 46, "current_iter_num": 5890}}
Iteration:   5900, Loss function: 3.403, Average Loss: 3.786, avg. samples / sec: 17999.83
Iteration:   5920, Loss function: 3.460, Average Loss: 3.779, avg. samples / sec: 18053.80
Iteration:   5940, Loss function: 3.260, Average Loss: 3.771, avg. samples / sec: 17925.01
Iteration:   5960, Loss function: 2.910, Average Loss: 3.761, avg. samples / sec: 17819.84
Iteration:   5980, Loss function: 3.262, Average Loss: 3.754, avg. samples / sec: 17854.19
Iteration:   6000, Loss function: 3.023, Average Loss: 3.744, avg. samples / sec: 17903.98
Iteration:   6020, Loss function: 2.979, Average Loss: 3.737, avg. samples / sec: 18000.14
:::MLLOG {"namespace": "", "time_ms": 1592975800981, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 46}}
:::MLLOG {"namespace": "", "time_ms": 1592975800981, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 47, "current_iter_num": 6021}}
Iteration:   6040, Loss function: 3.362, Average Loss: 3.729, avg. samples / sec: 18020.83
Iteration:   6060, Loss function: 3.414, Average Loss: 3.720, avg. samples / sec: 17988.27
Iteration:   6080, Loss function: 3.086, Average Loss: 3.712, avg. samples / sec: 17945.08
Iteration:   6100, Loss function: 3.601, Average Loss: 3.707, avg. samples / sec: 17782.19
Iteration:   6120, Loss function: 3.332, Average Loss: 3.699, avg. samples / sec: 17834.80
Iteration:   6140, Loss function: 3.291, Average Loss: 3.693, avg. samples / sec: 17802.01
:::MLLOG {"namespace": "", "time_ms": 1592975807520, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 47}}
:::MLLOG {"namespace": "", "time_ms": 1592975807521, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 48, "current_iter_num": 6152}}
Iteration:   6160, Loss function: 3.247, Average Loss: 3.684, avg. samples / sec: 18013.79
Iteration:   6180, Loss function: 3.237, Average Loss: 3.679, avg. samples / sec: 18033.14
Iteration:   6200, Loss function: 3.399, Average Loss: 3.670, avg. samples / sec: 18017.08
Iteration:   6220, Loss function: 3.347, Average Loss: 3.663, avg. samples / sec: 18001.79
Iteration:   6240, Loss function: 3.316, Average Loss: 3.655, avg. samples / sec: 17995.28
Iteration:   6260, Loss function: 3.274, Average Loss: 3.648, avg. samples / sec: 18013.41
Iteration:   6280, Loss function: 3.245, Average Loss: 3.641, avg. samples / sec: 18002.60
:::MLLOG {"namespace": "", "time_ms": 1592975813988, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 48}}
:::MLLOG {"namespace": "", "time_ms": 1592975813988, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 49, "current_iter_num": 6282}}
Iteration:   6300, Loss function: 3.182, Average Loss: 3.635, avg. samples / sec: 18012.92
Iteration:   6320, Loss function: 3.256, Average Loss: 3.628, avg. samples / sec: 18018.02
Iteration:   6340, Loss function: 3.433, Average Loss: 3.622, avg. samples / sec: 17998.55
Iteration:   6360, Loss function: 3.168, Average Loss: 3.615, avg. samples / sec: 18032.23
Iteration:   6380, Loss function: 3.528, Average Loss: 3.609, avg. samples / sec: 18064.25
Iteration:   6400, Loss function: 3.385, Average Loss: 3.602, avg. samples / sec: 18019.05
:::MLLOG {"namespace": "", "time_ms": 1592975820500, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 49}}
:::MLLOG {"namespace": "", "time_ms": 1592975820501, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 50, "current_iter_num": 6413}}
Iteration:   6420, Loss function: 3.395, Average Loss: 3.595, avg. samples / sec: 18040.15
Iteration:   6440, Loss function: 2.976, Average Loss: 3.588, avg. samples / sec: 18032.44
Iteration:   6460, Loss function: 3.337, Average Loss: 3.584, avg. samples / sec: 18040.95
Iteration:   6480, Loss function: 3.006, Average Loss: 3.579, avg. samples / sec: 17990.61
Iteration:   6500, Loss function: 3.487, Average Loss: 3.575, avg. samples / sec: 18044.12
Iteration:   6520, Loss function: 3.108, Average Loss: 3.568, avg. samples / sec: 18069.01
Iteration:   6540, Loss function: 3.126, Average Loss: 3.562, avg. samples / sec: 18001.68
:::MLLOG {"namespace": "", "time_ms": 1592975827011, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 50}}
averaging bn running means and vars
Predicting Ended, total time: 3.12 s
:::MLLOG {"namespace": "", "time_ms": 1592975830142, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 331, "first_epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1592975830177, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 338, "first_epoch_num": 51, "epoch_count": 5}}
:::MLLOG {"namespace": "", "time_ms": 1592975830177, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 51, "current_iter_num": 6544}}
Loading and preparing results...
DONE (t=0.54s)
Running per image evaluation...
Evaluate annotation type *bbox*
Iteration:   6560, Loss function: 2.871, Average Loss: 3.556, avg. samples / sec: 4318.25
Iteration:   6580, Loss function: 3.586, Average Loss: 3.551, avg. samples / sec: 17921.09
DONE (t=1.84s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.23206
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.39717
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23701
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.31756
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22478
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32862
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.34513
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.34513
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
Current AP: 0.23206 AP goal: 0.23000
Iteration:   6600, Loss function: 2.983, Average Loss: 3.545, avg. samples / sec: 17969.95
:::MLLOG {"namespace": "", "time_ms": 1592975833008, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 85, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1592975833009, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.23206331152203477, "metadata": {"file": "train.py", "lineno": 88, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1592975833009, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 89, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1592975833180, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "train.py", "lineno": 449, "status": "success"}}
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2020-06-23 10:17:17 PM
RESULT,SINGLE_STAGE_DETECTOR,,368,nvidia,2020-06-23 10:11:09 PM
ENDING TIMING RUN AT 2020-06-23 10:17:17 PM
RESULT,SINGLE_STAGE_DETECTOR,,368,nvidia,2020-06-23 10:11:09 PM
ENDING TIMING RUN AT 2020-06-23 10:17:18 PM
RESULT,SINGLE_STAGE_DETECTOR,,369,nvidia,2020-06-23 10:11:09 PM
ENDING TIMING RUN AT 2020-06-23 10:17:18 PM
RESULT,SINGLE_STAGE_DETECTOR,,369,nvidia,2020-06-23 10:11:09 PM
ENDING TIMING RUN AT 2020-06-23 10:17:18 PM
RESULT,SINGLE_STAGE_DETECTOR,,369,nvidia,2020-06-23 10:11:09 PM
ENDING TIMING RUN AT 2020-06-23 10:17:18 PM
RESULT,SINGLE_STAGE_DETECTOR,,369,nvidia,2020-06-23 10:11:09 PM
ENDING TIMING RUN AT 2020-06-23 10:17:18 PM
ENDING TIMING RUN AT 2020-06-23 10:17:18 PM
RESULT,SINGLE_STAGE_DETECTOR,,369,nvidia,2020-06-23 10:11:09 PM
RESULT,SINGLE_STAGE_DETECTOR,,369,nvidia,2020-06-23 10:11:09 PM
ENDING TIMING RUN AT 2020-06-23 10:17:18 PM
RESULT,SINGLE_STAGE_DETECTOR,,369,nvidia,2020-06-23 10:11:09 PM
ENDING TIMING RUN AT 2020-06-23 10:17:18 PM
RESULT,SINGLE_STAGE_DETECTOR,,369,nvidia,2020-06-23 10:11:09 PM
ENDING TIMING RUN AT 2020-06-23 10:17:18 PM
RESULT,SINGLE_STAGE_DETECTOR,,369,nvidia,2020-06-23 10:11:09 PM
ENDING TIMING RUN AT 2020-06-23 10:17:18 PM
ENDING TIMING RUN AT 2020-06-23 10:17:18 PM
ENDING TIMING RUN AT 2020-06-23 10:17:18 PM
RESULT,SINGLE_STAGE_DETECTOR,,369,nvidia,2020-06-23 10:11:09 PM
RESULT,SINGLE_STAGE_DETECTOR,,369,nvidia,2020-06-23 10:11:09 PM
RESULT,SINGLE_STAGE_DETECTOR,,369,nvidia,2020-06-23 10:11:09 PM
ENDING TIMING RUN AT 2020-06-23 10:17:18 PM
RESULT,SINGLE_STAGE_DETECTOR,,369,nvidia,2020-06-23 10:11:09 PM
ENDING TIMING RUN AT 2020-06-23 10:17:19 PM
RESULT,SINGLE_STAGE_DETECTOR,,370,nvidia,2020-06-23 10:11:09 PM
