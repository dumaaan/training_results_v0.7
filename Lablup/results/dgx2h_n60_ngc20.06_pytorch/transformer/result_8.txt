+ echo 'Beginning trial 3 of 5'
Beginning trial 3 of 5
+ srun --ntasks=60 --container-name=translation python -c '
import mlperf_log_utils
from mlperf_logging.mllog import constants
mlperf_log_utils.mlperf_submission_log(constants.TRANSFORMER)'
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
:::MLLOG {"namespace": "", "time_ms": 1592872649645, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "transformer", "metadata": {"file": "/workspace/translation/mlperf_log_utils.py", "lineno": 84}}
:::MLLOG {"namespace": "", "time_ms": 1592872649678, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "NVIDIA", "metadata": {"file": "/workspace/translation/mlperf_log_utils.py", "lineno": 89}}
:::MLLOG {"namespace": "", "time_ms": 1592872649678, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/translation/mlperf_log_utils.py", "lineno": 93}}
:::MLLOG {"namespace": "", "time_ms": 1592872649678, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/translation/mlperf_log_utils.py", "lineno": 97}}
:::MLLOG {"namespace": "", "time_ms": 1592872649678, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "60xNVIDIA DGX-2H", "metadata": {"file": "/workspace/translation/mlperf_log_utils.py", "lineno": 101}}
+ '[' 1 -eq 1 ']'
+ srun --ntasks=60 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n046
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n005
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n047
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n039
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n058
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n022
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n052
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n032
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n016
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n034
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n028
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n012
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n014
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n020
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n010
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n026
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n033
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n053
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n055
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n015
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n027
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n029
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n057
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n025
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n013
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n017
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n059
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n045
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n021
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n019
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n040
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n042
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n036
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n056
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n050
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n054
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n044
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n048
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n038
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n008
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n060
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n018
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n006
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n030
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n023
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n037
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n009
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n035
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n051
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n041
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n003
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n011
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n049
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n031
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n007
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n001
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n043
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n002
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n004
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on circe-n024
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=60 --container-name=translation python -c '
from mlperf_logging.mllog import constants
from mlperf_log_utils import log_event
log_event(key=constants.CACHE_CLEAR, value=True)'
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
:::MLLOG {"namespace": "", "time_ms": 1592872656604, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656621, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656640, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656643, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656651, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656662, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656665, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656669, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656672, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656675, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656677, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656677, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656686, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656685, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656696, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656697, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656696, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656702, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656702, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656707, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656708, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656709, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656713, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656712, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656713, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656715, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656714, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656724, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656725, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656729, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656738, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656743, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656740, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656743, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656744, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656742, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656744, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656748, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656750, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656755, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656759, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656759, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656762, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656761, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656764, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656763, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656769, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656767, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656770, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656778, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656785, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656789, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656795, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656796, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656798, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656816, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656818, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656826, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656837, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872656854, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
+ export SEED=30970
+ SEED=30970
+ srun --mpi=none --ntasks=960 --ntasks-per-node=16 --container-name=translation --container-mounts=/raid/datasets/xformer_v0p6/utf8:/data,/gpfs/fs1/svcnvdlfw/14044047/results:/results ./run_and_time.sh
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: pyxis: starting container ...
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ SEED=30970
+ MAX_TOKENS=768
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ DATASET_DIR=/data
+ MODE=TRAIN
+ case "$MODE" in
+ NUMEPOCHS=30
+ source run_training.sh
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
+++ date +%s
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ START=1592872660
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
+++ date +%s
+ SEED=30970
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ MAX_TOKENS=768
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ DATASET_DIR=/data
+ MODE=TRAIN
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ NUMEPOCHS=30
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+++ date +%s
+ case "$MODE" in
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+++ date +%s
+ case "$MODE" in
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
++ START=1592872660
++ START=1592872660
+++ date +%s
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+++ date +%s
+ source run_training.sh
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
Run vars: id 392220 gpus 16 mparams
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ SEED=30970
+ MODE=TRAIN
+ NUMEPOCHS=30
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ case "$MODE" in
+ MODE=TRAIN
+ NUMEPOCHS=30
+ source run_training.sh
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
++ START=1592872660
+++ date +%s
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 15 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 11 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
++ '[' -n 2 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' 960 -gt 60 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date '+%Y-%m-%d %r'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+++ date '+%Y-%m-%d %r'
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
+++ date +%s
+ source run_training.sh
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 4 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+++ date '+%Y-%m-%d %r'
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
++ START=1592872660
+ DATASET_DIR=/data
+ MODE=TRAIN
++ START=1592872660
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
+ SEED=30970
++ START_FMT='2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ MODE=TRAIN
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
+ source run_training.sh
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NNODES
++ declare -a CMD
+ SEED=30970
++ [[ 960 -ne 1 ]]
+ MAX_TOKENS=768
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export DGXSYSTEM
+++ date +%s
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ declare -a CMD
+ case "$MODE" in
++ '[' -n 5 ']'
+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 7 ']'
+ SEED=30970
++ '[' 960 -gt 60 ']'
+ MAX_TOKENS=768
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ DATASET_DIR=/data
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MODE=TRAIN
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ NUMEPOCHS=30
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ case "$MODE" in
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+++ date '+%Y-%m-%d %r'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date +%s
++ START=1592872660
+++ date +%s
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ START=1592872660
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 10 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 0 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ START_FMT='2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START=1592872660
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
+ case "$MODE" in
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+++ date '+%Y-%m-%d %r'
++ export SLURM_NNODES
++ '[' -n 1 ']'
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 3 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ START=1592872660
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date '+%Y-%m-%d %r'
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
++ '[' -n 8 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 13 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 9 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+++ date '+%Y-%m-%d %r'
++ export SLURM_NNODES
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 6 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ [[ 960 -ne 1 ]]
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ export DGXSYSTEM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ declare -a CMD
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ declare -a CMD
++ '[' -n 14 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 9 ']'
++ '[' 960 -gt 60 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' -n 7 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ START=1592872660
++ START=1592872660
++ '[' -n 0 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
+++ date '+%Y-%m-%d %r'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+++ date '+%Y-%m-%d %r'
++ export SLURM_NNODES
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ '[' -n 8 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ SEED=30970
+ NUMEPOCHS=30
+ case "$MODE" in
+ MAX_TOKENS=768
+ source run_training.sh
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
++ START_FMT='2020-06-22 05:37:40 PM'
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 13 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
+++ date +%s
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export SLURM_NNODES
++ declare -a CMD
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' -n 12 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START_FMT='2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ [[ 960 -ne 1 ]]
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
+++ date +%s
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 11 ']'
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
+ MODE=TRAIN
+ NUMEPOCHS=30
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ case "$MODE" in
+ source run_training.sh
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date '+%Y-%m-%d %r'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 10 ']'
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ declare -a CMD
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 15 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 4 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 2 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 12 ']'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ [[ 960 -ne 1 ]]
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ '[' -n 1 ']'
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ case "$MODE" in
+ MAX_TOKENS=768
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ source run_training.sh
+ DATASET_DIR=/data
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ NUMEPOCHS=30
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export DGXSYSTEM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ MAX_TOKENS=768
++ export SLURM_NTASKS_PER_NODE
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NNODES
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ '[' -n 3 ']'
+ SEED=30970
+ MAX_TOKENS=768
+ case "$MODE" in
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ NUMEPOCHS=30
+++ date +%s
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
++ START_FMT='2020-06-22 05:37:40 PM'
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ SEED=30970
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
+ SEED=30970
Run vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ NUMEPOCHS=30
+ MAX_TOKENS=768
+ case "$MODE" in
+ MAX_TOKENS=768
++ [[ 960 -ne 1 ]]
+ DATASET_DIR=/data
+++ date +%s
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ source run_training.sh
+ DATASET_DIR=/data
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ SEED=30970
+++ date +%s
++ export SLURM_NNODES
+ MAX_TOKENS=768
+ MODE=TRAIN
+ NUMEPOCHS=30
+ DATASET_DIR=/data
+ MODE=TRAIN
+ MODE=TRAIN
+ NUMEPOCHS=30
+ NUMEPOCHS=30
+ case "$MODE" in
+ case "$MODE" in
+ case "$MODE" in
++ declare -a CMD
+ source run_training.sh
++ '[' -n 14 ']'
+ SEED=30970
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MAX_TOKENS=768
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ DATASET_DIR=/data
+ NUMEPOCHS=30
+ case "$MODE" in
+ MODE=TRAIN
+ source run_training.sh
+ NUMEPOCHS=30
+ case "$MODE" in
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ source run_training.sh
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+++ date +%s
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+++ date +%s
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ SEED=30970
+ NUMEPOCHS=30
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ case "$MODE" in
+++ date +%s
+ MODE=TRAIN
+ NUMEPOCHS=30
+ source run_training.sh
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
+++ date +%s
+++ date +%s
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ NUMEPOCHS=30
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ case "$MODE" in
++ START=1592872660
+ source run_training.sh
+ source run_training.sh
++ START=1592872660
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+++ date +%s
+ MODE=TRAIN
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
+++ date +%s
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ NUMEPOCHS=30
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
+++ date +%s
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
+++ date +%s
+ SEED=30970
++ export SLURM_NTASKS_PER_NODE
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NNODES
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
+++ date +%s
+ NUMEPOCHS=30
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
++ START=1592872660
+ source run_training.sh
+ SEED=30970
++ '[' -n 6 ']'
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
+ SEED=30970
+ MAX_TOKENS=768
+++ date +%s
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
++ START_FMT='2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
+ MODE=TRAIN
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
+ source run_training.sh
+ case "$MODE" in
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ [[ 960 -ne 1 ]]
+++ date +%s
+ source run_training.sh
+++ date +%s
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
++ export DGXSYSTEM
+ SEED=30970
+ SEED=30970
+ MAX_TOKENS=768
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ DATASET_DIR=/data
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ NUMEPOCHS=30
+ case "$MODE" in
+ MODE=TRAIN
+ SEED=30970
++ declare -a CMD
+ source run_training.sh
+ NUMEPOCHS=30
++ '[' -n 5 ']'
+ case "$MODE" in
++ '[' 960 -gt 60 ']'
+++ date '+%Y-%m-%d %r'
+++ date +%s
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
+ MODE=TRAIN
+ MAX_TOKENS=768
+ NUMEPOCHS=30
+ DATASET_DIR=/data
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
+ MODE=TRAIN
+ NUMEPOCHS=30
+ SEED=30970
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
+ case "$MODE" in
+ MAX_TOKENS=768
+ source run_training.sh
+++ date +%s
+ DATASET_DIR=/data
+ MODE=TRAIN
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+ NUMEPOCHS=30
+ MAX_TOKENS=768
+ case "$MODE" in
+ SEED=30970
+ DATASET_DIR=/data
+ source run_training.sh
+ MAX_TOKENS=768
+ MODE=TRAIN
+ SEED=30970
+ NUMEPOCHS=30
+ DATASET_DIR=/data
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
+ source run_training.sh
+ MAX_TOKENS=768
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
+ MODE=TRAIN
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
+ DATASET_DIR=/data
+ MODE=TRAIN
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
+ NUMEPOCHS=30
+ DATASET_DIR=/data
+ NUMEPOCHS=30
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ case "$MODE" in
+ case "$MODE" in
+ source run_training.sh
+ source run_training.sh
+++ date +%s
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+++ date +%s
++ [[ 960 -ne 1 ]]
+ SEED=30970
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MAX_TOKENS=768
+ MODE=TRAIN
+ NUMEPOCHS=30
+++ date '+%Y-%m-%d %r'
+++ date +%s
++ declare -a CMD
+ case "$MODE" in
+ DATASET_DIR=/data
+ source run_training.sh
+ MODE=TRAIN
+++ date +%s
+ NUMEPOCHS=30
+ case "$MODE" in
++ START=1592872660
+ source run_training.sh
++ '[' -n 1 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
++ START=1592872660
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
+++ date +%s
++ START=1592872660
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ START=1592872660
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
+ SEED=30970
+ DATASET_DIR=/data
+ MODE=TRAIN
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ NUMEPOCHS=30
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ case "$MODE" in
+ source run_training.sh
+ source run_training.sh
+++ date +%s
++ START=1592872660
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
++ START=1592872660
+++ date +%s
+++ date +%s
++ START=1592872660
+++ date +%s
+++ date +%s
+++ date '+%Y-%m-%d %r'
++ START=1592872660
+++ date '+%Y-%m-%d %r'
++ START=1592872660
++ START=1592872660
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ START=1592872660
++ START=1592872660
++ START=1592872660
++ START=1592872660
++ START=1592872660
++ START=1592872660
++ START=1592872660
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ START=1592872660
++ START=1592872660
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+++ date '+%Y-%m-%d %r'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 3 ']'
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ START=1592872660
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+ MAX_TOKENS=768
+++ date +%s
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date '+%Y-%m-%d %r'
++ START=1592872660
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
+ DATASET_DIR=/data
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
+ MODE=TRAIN
+ NUMEPOCHS=30
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
+++ date '+%Y-%m-%d %r'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date '+%Y-%m-%d %r'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
+ SEED=30970
++ START=1592872660
+ MAX_TOKENS=768
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+ MODE=TRAIN
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
+ NUMEPOCHS=30
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+ case "$MODE" in
+ SEED=30970
+ MAX_TOKENS=768
+++ date '+%Y-%m-%d %r'
+ source run_training.sh
+ DATASET_DIR=/data
+ MODE=TRAIN
++ START_FMT='2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
+++ date '+%Y-%m-%d %r'
++ START=1592872660
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ DATASET_DIR=/data
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ MODE=TRAIN
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date +%s
++ declare -a CMD
+ NUMEPOCHS=30
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ case "$MODE" in
++ export DGXSYSTEM
+ source run_training.sh
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 3 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
++ '[' -n 12 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 2 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+++ date +%s
++ START=1592872660
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ '[' -n 14 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ SEED=30970
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
+ case "$MODE" in
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 5 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ [[ 960 -ne 1 ]]
++ export SLURM_NNODES
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ declare -a CMD
++ [[ 960 -ne 1 ]]
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NNODES
+++ date '+%Y-%m-%d %r'
++ declare -a CMD
++ '[' -n 2 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+ SEED=30970
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
+ case "$MODE" in
+ source run_training.sh
++ '[' -n 8 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' -n 12 ']'
++ export DGXSYSTEM
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
++ declare -a CMD
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ [[ 960 -ne 1 ]]
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
++ '[' -n 11 ']'
++ '[' 960 -gt 60 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
++ declare -a CMD
++ '[' -n 8 ']'
Run vars: id 392220 gpus 16 mparams
++ '[' -n 0 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
++ '[' -n 6 ']'
++ export SLURM_NTASKS_PER_NODE
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NNODES
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 6 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 9 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date +%s
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+++ date +%s
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 7 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MAX_TOKENS=768
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export DGXSYSTEM
++ START=1592872660
+ NUMEPOCHS=30
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
+ case "$MODE" in
++ declare -a CMD
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ START=1592872660
+ source run_training.sh
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
++ '[' -n 4 ']'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MAX_TOKENS=768
++ '[' 960 -gt 60 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 2 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NNODES
+ MODE=TRAIN
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
+ NUMEPOCHS=30
++ declare -a CMD
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 15 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 11 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' 960 -gt 60 ']'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ SEED=30970
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NNODES
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ declare -a CMD
+ DATASET_DIR=/data
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 15 ']'
+ MODE=TRAIN
+ NUMEPOCHS=30
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ case "$MODE" in
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
++ [[ 960 -ne 1 ]]
+++ date +%s
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
++ export DGXSYSTEM
+++ date '+%Y-%m-%d %r'
+++ date +%s
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ export SLURM_NNODES
+ SEED=30970
++ declare -a CMD
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MODE=TRAIN
++ '[' -n 0 ']'
+ NUMEPOCHS=30
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ case "$MODE" in
++ '[' -n 15 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
+ SEED=30970
Run vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ NUMEPOCHS=30
++ [[ 960 -ne 1 ]]
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' -n 1 ']'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ SEED=30970
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export DGXSYSTEM
+ MAX_TOKENS=768
++ export SLURM_NTASKS_PER_NODE
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NNODES
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 0 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ [[ 960 -ne 1 ]]
++ export SLURM_NNODES
++ declare -a CMD
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 10 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 8 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' -n 0 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ [[ 960 -ne 1 ]]
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export SLURM_NNODES
++ declare -a CMD
++ export DGXSYSTEM
++ '[' -n 6 ']'
++ '[' 960 -gt 60 ']'
++ export SLURM_NTASKS_PER_NODE
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 12 ']'
++ '[' -n 5 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
++ '[' -n 14 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 7 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ '[' -n 10 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 14 ']'
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
++ export SLURM_NNODES
++ declare -a CMD
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ [[ 960 -ne 1 ]]
++ export SLURM_NTASKS_PER_NODE
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export SLURM_NNODES
++ export DGXSYSTEM
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 9 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NNODES
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 13 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
+ MAX_TOKENS=768
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
++ export DGXSYSTEM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NTASKS_PER_NODE
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NNODES
++ declare -a CMD
+ DATASET_DIR=/data
+ MODE=TRAIN
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
+ case "$MODE" in
++ '[' -n 8 ']'
++ '[' -n 9 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 4 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' -n 9 ']'
+ SEED=30970
+ MAX_TOKENS=768
++ export DGXSYSTEM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ MODE=TRAIN
++ declare -a CMD
+ NUMEPOCHS=30
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ case "$MODE" in
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
+++ date '+%Y-%m-%d %r'
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
++ '[' -n 1 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ case "$MODE" in
++ '[' -n 13 ']'
++ [[ 960 -ne 1 ]]
++ START_FMT='2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NNODES
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
+ MAX_TOKENS=768
++ [[ 960 -ne 1 ]]
+ SEED=30970
+ MAX_TOKENS=768
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' -n 14 ']'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ DATASET_DIR=/data
+ MODE=TRAIN
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ export SLURM_NNODES
++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ NUMEPOCHS=30
++ declare -a CMD
++ '[' -n 4 ']'
++ '[' -n 13 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ case "$MODE" in
++ '[' 960 -gt 60 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ source run_training.sh
++ '[' -n 11 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
+ SEED=30970
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
+ MODE=TRAIN
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ SEED=30970
++ export SLURM_NNODES
++ declare -a CMD
+ MAX_TOKENS=768
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ DATASET_DIR=/data
++ '[' -n 3 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ MODE=TRAIN
+ NUMEPOCHS=30
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ case "$MODE" in
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NNODES
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ [[ 960 -ne 1 ]]
++ declare -a CMD
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' -n 12 ']'
++ '[' 960 -gt 60 ']'
++ export DGXSYSTEM
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ '[' -n 10 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
+++ date +%s
++ '[' -n 7 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ '[' -n 5 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ declare -a CMD
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 6 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ [[ 960 -ne 1 ]]
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 1 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 5 ']'
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ DATASET_DIR=/data
+ MODE=TRAIN
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ NUMEPOCHS=30
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
++ '[' -n 3 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ MODE=TRAIN
+ NUMEPOCHS=30
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ MAX_TOKENS=768
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ DATASET_DIR=/data
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
+ MODE=TRAIN
+ NUMEPOCHS=30
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
+ case "$MODE" in
+ SEED=30970
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
+ source run_training.sh
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ MODE=TRAIN
+ NUMEPOCHS=30
+ SEED=30970
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ case "$MODE" in
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ source run_training.sh
+ source run_training.sh
+ DATASET_DIR=/data
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
+++ date +%s
+ source run_training.sh
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MAX_TOKENS=768
+++ date +%s
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
+ case "$MODE" in
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
++ START=1592872660
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
++ [[ 960 -ne 1 ]]
+++ date +%s
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date '+%Y-%m-%d %r'
+++ date +%s
++ START=1592872660
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ declare -a CMD
++ START=1592872660
++ [[ 960 -ne 1 ]]
++ '[' -n 11 ']'
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
++ '[' -n 7 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
+++ date '+%Y-%m-%d %r'
+++ date +%s
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
++ [[ 960 -ne 1 ]]
+ DATASET_DIR=/data
+ MODE=TRAIN
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ NUMEPOCHS=30
+ case "$MODE" in
+++ date +%s
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NNODES
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date +%s
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
++ declare -a CMD
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ '[' -n 2 ']'
++ '[' 960 -gt 60 ']'
+ SEED=30970
Run vars: id 392220 gpus 16 mparams
++ export DGXSYSTEM
+ MAX_TOKENS=768
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ DATASET_DIR=/data
+ MODE=TRAIN
++ '[' -n 10 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
++ '[' -n 15 ']'
+ case "$MODE" in
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ MODE=TRAIN
+++ date '+%Y-%m-%d %r'
+ NUMEPOCHS=30
++ START=1592872660
+ case "$MODE" in
++ START_FMT='2020-06-22 05:37:40 PM'
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
+ SEED=30970
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ MAX_TOKENS=768
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export SLURM_NNODES
++ declare -a CMD
+ SEED=30970
+ MAX_TOKENS=768
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
+ DATASET_DIR=/data
+ MODE=TRAIN
+ case "$MODE" in
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
+ MODE=TRAIN
+ NUMEPOCHS=30
+ source run_training.sh
++ export DGXSYSTEM
+ NUMEPOCHS=30
++ export SLURM_NTASKS_PER_NODE
++ '[' -n 3 ']'
++ '[' 960 -gt 60 ']'
++ export SLURM_NNODES
++ declare -a CMD
+ case "$MODE" in
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ case "$MODE" in
++ '[' -n 1 ']'
+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+++ date +%s
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ SEED=30970
+ MODE=TRAIN
+ NUMEPOCHS=30
+ MAX_TOKENS=768
+ case "$MODE" in
+ DATASET_DIR=/data
+ source run_training.sh
+ MODE=TRAIN
+ NUMEPOCHS=30
+ SEED=30970
+ case "$MODE" in
+ source run_training.sh
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ SEED=30970
+ MODE=TRAIN
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
+ case "$MODE" in
+ DATASET_DIR=/data
+ source run_training.sh
+ MODE=TRAIN
+ NUMEPOCHS=30
+ SEED=30970
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
+ source run_training.sh
+ MAX_TOKENS=768
+++ date +%s
+ DATASET_DIR=/data
+ MODE=TRAIN
+++ date +%s
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
+ source run_training.sh
++ START=1592872660
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+++ date +%s
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
+ DATASET_DIR=/data
+ MODE=TRAIN
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ NUMEPOCHS=30
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
+ source run_training.sh
+ MODE=TRAIN
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
+ MAX_TOKENS=768
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
++ [[ 960 -ne 1 ]]
++ START=1592872660
+ MAX_TOKENS=768
+++ date +%s
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
+ MODE=TRAIN
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START=1592872660
+ DATASET_DIR=/data
+ case "$MODE" in
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
+ MODE=TRAIN
+ SEED=30970
+ MAX_TOKENS=768
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+++ date '+%Y-%m-%d %r'
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
+ MODE=TRAIN
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NNODES
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
+ NUMEPOCHS=30
+ NUMEPOCHS=30
++ START=1592872660
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START=1592872660
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
++ export DGXSYSTEM
+ case "$MODE" in
+ case "$MODE" in
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ source run_training.sh
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ declare -a CMD
+++ date +%s
++ '[' -n 4 ']'
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ SEED=30970
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' -n 13 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ START=1592872660
+ NUMEPOCHS=30
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
+ case "$MODE" in
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
+ MODE=TRAIN
+ source run_training.sh
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ START=1592872660
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
++ START=1592872660
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
+ case "$MODE" in
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
+ DATASET_DIR=/data
+ MODE=TRAIN
+ source run_training.sh
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ NUMEPOCHS=30
++ START=1592872660
++ export DGXSYSTEM
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
+ source run_training.sh
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START_FMT='2020-06-22 05:37:40 PM'
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date '+%Y-%m-%d %r'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
++ declare -a CMD
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' -n 0 ']'
++ export DGXSYSTEM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ '[' -n 5 ']'
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NNODES
++ declare -a CMD
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ '[' -n 7 ']'
++ [[ 960 -ne 1 ]]
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ SEED=30970
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NNODES
+++ date '+%Y-%m-%d %r'
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MAX_TOKENS=768
++ '[' -n 9 ']'
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ DATASET_DIR=/data
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ MODE=TRAIN
+ NUMEPOCHS=30
++ export SLURM_NNODES
++ declare -a CMD
+ NUMEPOCHS=30
+ case "$MODE" in
+ case "$MODE" in
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
++ '[' -n 4 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ START=1592872660
++ START=1592872660
+++ date '+%Y-%m-%d %r'
+++ date +%s
+ SEED=30970
+++ date +%s
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
++ START=1592872660
+ SEED=30970
+++ date +%s
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date +%s
+ SEED=30970
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ START=1592872660
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
+++ date +%s
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+++ date +%s
+ SEED=30970
+++ date '+%Y-%m-%d %r'
+ source run_training.sh
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+++ date '+%Y-%m-%d %r'
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ MAX_TOKENS=768
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ DATASET_DIR=/data
+ MODE=TRAIN
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ NUMEPOCHS=30
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ [[ 960 -ne 1 ]]
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ START=1592872660
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export SLURM_NTASKS_PER_NODE
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NNODES
++ declare -a CMD
+ DATASET_DIR=/data
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
+ MAX_TOKENS=768
++ START_FMT='2020-06-22 05:37:40 PM'
+ case "$MODE" in
+ DATASET_DIR=/data
+ MODE=TRAIN
++ [[ 960 -ne 1 ]]
+ source run_training.sh
+ NUMEPOCHS=30
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
++ export DGXSYSTEM
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 6 ']'
++ '[' 960 -gt 60 ']'
++ START=1592872660
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
++ [[ 960 -ne 1 ]]
+ SEED=30970
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
++ START=1592872660
++ export DGXSYSTEM
+ MAX_TOKENS=768
++ START=1592872660
++ export SLURM_NTASKS_PER_NODE
+ DATASET_DIR=/data
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NNODES
+ DATASET_DIR=/data
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 11 ']'
++ '[' 960 -gt 60 ']'
++ declare -a CMD
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 2 ']'
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
+ MODE=TRAIN
+ NUMEPOCHS=30
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ case "$MODE" in
++ START_FMT='2020-06-22 05:37:40 PM'
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ [[ 960 -ne 1 ]]
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MAX_TOKENS=768
++ export SLURM_NTASKS_PER_NODE
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NNODES
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
+ MODE=TRAIN
++ START_FMT='2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
+ NUMEPOCHS=30
+++ date +%s
++ '[' -n 15 ']'
+ case "$MODE" in
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ source run_training.sh
++ START=1592872660
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ START=1592872660
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+++ date +%s
++ [[ 960 -ne 1 ]]
++ '[' -n 13 ']'
+++ date '+%Y-%m-%d %r'
++ '[' -n 8 ']'
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' -n 10 ']'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NNODES
++ declare -a CMD
+ SEED=30970
+ MAX_TOKENS=768
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ DATASET_DIR=/data
+ MODE=TRAIN
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ NUMEPOCHS=30
+++ date '+%Y-%m-%d %r'
+ case "$MODE" in
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 3 ']'
+ source run_training.sh
++ [[ 960 -ne 1 ]]
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date '+%Y-%m-%d %r'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MAX_TOKENS=768
++ export SLURM_NNODES
++ declare -a CMD
+ DATASET_DIR=/data
+ MODE=TRAIN
++ '[' -n 8 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ case "$MODE" in
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
+ SEED=30970
++ [[ 960 -ne 1 ]]
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MAX_TOKENS=768
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ DATASET_DIR=/data
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MODE=TRAIN
+ NUMEPOCHS=30
++ START=1592872660
++ '[' -n 14 ']'
+ case "$MODE" in
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 0 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MAX_TOKENS=768
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ DATASET_DIR=/data
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ SEED=30970
++ START=1592872660
+ MODE=TRAIN
+ NUMEPOCHS=30
+ MODE=TRAIN
+ NUMEPOCHS=30
+ MODE=TRAIN
+ NUMEPOCHS=30
+ MAX_TOKENS=768
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
+ case "$MODE" in
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
+ source run_training.sh
+ case "$MODE" in
+++ date +%s
+ source run_training.sh
+ MODE=TRAIN
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
+ source run_training.sh
+ case "$MODE" in
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ source run_training.sh
+++ date +%s
+++ date +%s
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+++ date +%s
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
++ '[' -n 15 ']'
++ export SLURM_NNODES
++ declare -a CMD
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
+ MAX_TOKENS=768
++ '[' -n 9 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ DATASET_DIR=/data
+ MODE=TRAIN
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ NUMEPOCHS=30
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date '+%Y-%m-%d %r'
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ [[ 960 -ne 1 ]]
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ SEED=30970
+ MAX_TOKENS=768
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
Run vars: id 392220 gpus 16 mparams
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 7 ']'
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
++ START=1592872660
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
Run vars: id 392220 gpus 16 mparams
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
++ '[' -n 12 ']'
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
+++ date +%s
+++ date +%s
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
+ SEED=30970
++ START=1592872660
+ MAX_TOKENS=768
++ START=1592872660
+ DATASET_DIR=/data
+ MODE=TRAIN
+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+ SEED=30970
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ START_FMT='2020-06-22 05:37:40 PM'
+ case "$MODE" in
+ MODE=TRAIN
+ NUMEPOCHS=30
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ source run_training.sh
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ START=1592872660
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
++ export SLURM_NNODES
++ declare -a CMD
+++ date +%s
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
++ '[' -n 9 ']'
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
++ '[' 960 -gt 60 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
+++ date '+%Y-%m-%d %r'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date '+%Y-%m-%d %r'
++ declare -a CMD
++ START=1592872660
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 8 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' -n 10 ']'
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
+++ date '+%Y-%m-%d %r'
++ START=1592872660
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
++ export DGXSYSTEM
++ declare -a CMD
++ export SLURM_NTASKS_PER_NODE
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NNODES
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 1 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' -n 6 ']'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
+ MAX_TOKENS=768
++ export SLURM_NNODES
++ declare -a CMD
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 5 ']'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 4 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ case "$MODE" in
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date '+%Y-%m-%d %r'
+ SEED=30970
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NNODES
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MAX_TOKENS=768
+ SEED=30970
+ MAX_TOKENS=768
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ DATASET_DIR=/data
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ '[' -n 12 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MODE=TRAIN
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ NUMEPOCHS=30
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
+ case "$MODE" in
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ source run_training.sh
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
++ START=1592872660
++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+++ date +%s
+ SEED=30970
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ DATASET_DIR=/data
+ NUMEPOCHS=30
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
+ SEED=30970
++ START_FMT='2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
+ source run_training.sh
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+++ date '+%Y-%m-%d %r'
++ export SLURM_NNODES
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
++ '[' -n 14 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
+++ date +%s
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
+++ date +%s
++ START=1592872660
++ START=1592872660
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ START_FMT='2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ START=1592872660
++ export SLURM_NNODES
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
+++ date +%s
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
+ MAX_TOKENS=768
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export DGXSYSTEM
++ START_FMT='2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 9 ']'
+ case "$MODE" in
++ declare -a CMD
++ [[ 960 -ne 1 ]]
+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
+ MAX_TOKENS=768
++ START=1592872660
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
+ DATASET_DIR=/data
++ START=1592872660
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ MODE=TRAIN
+ NUMEPOCHS=30
++ '[' -n 14 ']'
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
+ case "$MODE" in
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export DGXSYSTEM
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
+ source run_training.sh
++ [[ 960 -ne 1 ]]
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 15 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ export DGXSYSTEM
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
++ export SLURM_NTASKS_PER_NODE
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
++ export SLURM_NNODES
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ declare -a CMD
++ [[ 960 -ne 1 ]]
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 8 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ MODE=TRAIN
+ NUMEPOCHS=30
+++ date '+%Y-%m-%d %r'
++ export DGXSYSTEM
++ export DGXSYSTEM
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date '+%Y-%m-%d %r'
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NNODES
++ declare -a CMD
++ declare -a CMD
++ START=1592872660
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
++ '[' -n 7 ']'
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 2 ']'
++ START=1592872660
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 4 ']'
Run vars: id 392220 gpus 16 mparams
+++ date +%s
++ [[ 960 -ne 1 ]]
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
+++ date +%s
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export DGXSYSTEM
++ '[' -n 10 ']'
++ '[' 960 -gt 60 ']'
+ SEED=30970
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MAX_TOKENS=768
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
++ '[' -n 6 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ MODE=TRAIN
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date +%s
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 0 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
+ MODE=TRAIN
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ case "$MODE" in
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
+ DATASET_DIR=/data
+ MODE=TRAIN
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ NUMEPOCHS=30
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+++ date +%s
+ case "$MODE" in
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 12 ']'
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 3 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ [[ 960 -ne 1 ]]
++ export DGXSYSTEM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ SEED=30970
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ declare -a CMD
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
++ [[ 960 -ne 1 ]]
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ declare -a CMD
+ DATASET_DIR=/data
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 11 ']'
++ '[' 960 -gt 60 ']'
++ '[' -n 6 ']'
++ '[' 960 -gt 60 ']'
+ MODE=TRAIN
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ NUMEPOCHS=30
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 2 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export SLURM_NNODES
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NNODES
++ declare -a CMD
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' -n 1 ']'
+ case "$MODE" in
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ '[' -n 5 ']'
+ source run_training.sh
++ export DGXSYSTEM
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ [[ 960 -ne 1 ]]
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export DGXSYSTEM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' -n 0 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
++ declare -a CMD
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' -n 3 ']'
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 7 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
++ START=1592872660
+++ date '+%Y-%m-%d %r'
++ START=1592872660
++ START=1592872660
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
++ [[ 960 -ne 1 ]]
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ [[ 960 -ne 1 ]]
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
++ '[' -n 1 ']'
++ '[' -n 2 ']'
++ '[' 960 -gt 60 ']'
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 13 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 14 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+++ date '+%Y-%m-%d %r'
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date +%s
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
++ '[' -n 1 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
+ SEED=30970
++ START=1592872660
+ MAX_TOKENS=768
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
+ source run_training.sh
+ MODE=TRAIN
++ '[' -n 11 ']'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date +%s
++ [[ 960 -ne 1 ]]
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ SEED=30970
+++ date '+%Y-%m-%d %r'
++ export SLURM_NNODES
++ declare -a CMD
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
++ export SLURM_NNODES
+ MAX_TOKENS=768
+ source run_training.sh
++ '[' -n 13 ']'
+ DATASET_DIR=/data
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ declare -a CMD
+ MODE=TRAIN
+++ date '+%Y-%m-%d %r'
++ '[' -n 4 ']'
+ NUMEPOCHS=30
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ case "$MODE" in
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ source run_training.sh
+ SEED=30970
+++ date '+%Y-%m-%d %r'
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ START=1592872660
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+ SEED=30970
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START=1592872660
+++ date +%s
+ MAX_TOKENS=768
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ START_FMT='2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
++ '[' -n 12 ']'
+ source run_training.sh
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ SEED=30970
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ [[ 960 -ne 1 ]]
+ MAX_TOKENS=768
++ export SLURM_NNODES
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+ DATASET_DIR=/data
+ MODE=TRAIN
++ declare -a CMD
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ '[' -n 13 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ DATASET_DIR=/data
++ export DGXSYSTEM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MODE=TRAIN
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ NUMEPOCHS=30
++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ case "$MODE" in
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
++ '[' -n 9 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ export DGXSYSTEM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NTASKS_PER_NODE
++ export DGXSYSTEM
+ SEED=30970
++ export SLURM_NNODES
++ declare -a CMD
++ export SLURM_NTASKS_PER_NODE
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NNODES
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
++ '[' -n 14 ']'
++ START=1592872660
+ MODE=TRAIN
+ NUMEPOCHS=30
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 1 ']'
++ export SLURM_NNODES
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ declare -a CMD
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 11 ']'
+ SEED=30970
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MAX_TOKENS=768
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
+ DATASET_DIR=/data
+ MODE=TRAIN
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+ NUMEPOCHS=30
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ case "$MODE" in
+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
++ START_FMT='2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
++ '[' -n 15 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ DATASET_DIR=/data
+ MODE=TRAIN
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ NUMEPOCHS=30
++ export SLURM_NNODES
++ declare -a CMD
+ case "$MODE" in
+++ date +%s
++ '[' -n 10 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
+ MAX_TOKENS=768
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date +%s
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ START=1592872660
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NNODES
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ '[' -n 7 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+ MAX_TOKENS=768
+++ date +%s
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 3 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 9 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ source run_training.sh
+ SEED=30970
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MAX_TOKENS=768
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ DATASET_DIR=/data
+ MODE=TRAIN
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
++ START=1592872660
+++ date +%s
++ START=1592872660
+ SEED=30970
++ START_FMT='2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ case "$MODE" in
++ export SLURM_NTASKS_PER_NODE
+ source run_training.sh
++ export SLURM_NNODES
++ declare -a CMD
+++ date +%s
++ '[' -n 11 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ SEED=30970
++ declare -a CMD
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 15 ']'
++ '[' -n 10 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MODE=TRAIN
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ NUMEPOCHS=30
+ case "$MODE" in
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
++ export SLURM_NNODES
++ declare -a CMD
+ SEED=30970
++ START_FMT='2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ '[' -n 6 ']'
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ case "$MODE" in
+++ date +%s
++ [[ 960 -ne 1 ]]
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ source run_training.sh
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 3 ']'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ SEED=30970
++ '[' -n 10 ']'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' 960 -gt 60 ']'
+ MODE=TRAIN
+ NUMEPOCHS=30
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
+ case "$MODE" in
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ source run_training.sh
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
+++ date +%s
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
++ export SLURM_NNODES
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ '[' -n 14 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 5 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 13 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
++ START=1592872660
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date +%s
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' -n 5 ']'
++ '[' 960 -gt 60 ']'
+ SEED=30970
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ [[ 960 -ne 1 ]]
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ case "$MODE" in
++ START_FMT='2020-06-22 05:37:40 PM'
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 2 ']'
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
++ export DGXSYSTEM
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NNODES
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
Run vars: id 392220 gpus 16 mparams
++ '[' -n 5 ']'
Run vars: id 392220 gpus 16 mparams
++ '[' -n 7 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' -n 15 ']'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
++ export SLURM_NNODES
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ declare -a CMD
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 0 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 12 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 8 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+++ date +%s
++ export SLURM_NNODES
++ declare -a CMD
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date '+%Y-%m-%d %r'
+ SEED=30970
++ export DGXSYSTEM
+ MAX_TOKENS=768
++ '[' -n 13 ']'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export SLURM_NTASKS_PER_NODE
+ NUMEPOCHS=30
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ case "$MODE" in
++ export SLURM_NNODES
+ source run_training.sh
++ declare -a CMD
++ START=1592872660
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
Run vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
+++ date +%s
+++ date '+%Y-%m-%d %r'
++ START=1592872660
++ '[' -n 1 ']'
+++ date '+%Y-%m-%d %r'
++ '[' 960 -gt 60 ']'
++ START=1592872660
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NNODES
++ [[ 960 -ne 1 ]]
++ declare -a CMD
++ '[' -n 0 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
++ export DGXSYSTEM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
++ declare -a CMD
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START_FMT='2020-06-22 05:37:40 PM'
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 4 ']'
++ '[' -n 6 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ [[ 960 -ne 1 ]]
++ '[' -n 6 ']'
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' 960 -gt 60 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export DGXSYSTEM
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 2 ']'
++ [[ 960 -ne 1 ]]
++ '[' -n 11 ']'
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START_FMT='2020-06-22 05:37:40 PM'
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' -n 13 ']'
++ '[' 960 -gt 60 ']'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
+++ date +%s
++ export SLURM_NNODES
++ declare -a CMD
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 3 ']'
Run vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
+ MAX_TOKENS=768
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ DATASET_DIR=/data
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ MODE=TRAIN
+++ date '+%Y-%m-%d %r'
+ NUMEPOCHS=30
+ case "$MODE" in
++ START=1592872660
++ declare -a CMD
+ source run_training.sh
++ START=1592872660
++ '[' -n 12 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ [[ 960 -ne 1 ]]
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ declare -a CMD
++ export DGXSYSTEM
++ '[' -n 2 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ '[' 960 -gt 60 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ declare -a CMD
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' -n 12 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 8 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
++ [[ 960 -ne 1 ]]
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ [[ 960 -ne 1 ]]
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 14 ']'
++ '[' -n 7 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date '+%Y-%m-%d %r'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+++ date +%s
++ START=1592872660
+ MODE=TRAIN
+ NUMEPOCHS=30
+++ date '+%Y-%m-%d %r'
+ case "$MODE" in
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MAX_TOKENS=768
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
++ START=1592872660
+ case "$MODE" in
+ source run_training.sh
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date +%s
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START=1592872660
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ SEED=30970
+ MAX_TOKENS=768
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 0 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
+++ date +%s
++ START=1592872660
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ [[ 960 -ne 1 ]]
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START=1592872660
+ SEED=30970
+ MAX_TOKENS=768
++ export DGXSYSTEM
++ '[' -n 4 ']'
++ export SLURM_NTASKS_PER_NODE
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ DATASET_DIR=/data
++ export SLURM_NNODES
+ MODE=TRAIN
+ NUMEPOCHS=30
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
+ case "$MODE" in
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+++ date +%s
+ SEED=30970
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MAX_TOKENS=768
++ '[' -n 8 ']'
+ DATASET_DIR=/data
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
+ MODE=TRAIN
+ NUMEPOCHS=30
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 10 ']'
+ case "$MODE" in
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ [[ 960 -ne 1 ]]
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
+ MAX_TOKENS=768
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date '+%Y-%m-%d %r'
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
+ SEED=30970
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
+ MODE=TRAIN
++ [[ 960 -ne 1 ]]
+ NUMEPOCHS=30
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START=1592872660
+ case "$MODE" in
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 0 ']'
Run vars: id 392220 gpus 16 mparams
++ declare -a CMD
++ '[' 960 -gt 60 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
+++ date '+%Y-%m-%d %r'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
++ '[' -n 9 ']'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ declare -a CMD
++ '[' -n 5 ']'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ '[' 960 -gt 60 ']'
+ MODE=TRAIN
+ NUMEPOCHS=30
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ SEED=30970
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MAX_TOKENS=768
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ source run_training.sh
+ SEED=30970
+ case "$MODE" in
+ MAX_TOKENS=768
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
+++ date +%s
++ '[' -n 11 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
++ START=1592872660
+++ date +%s
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
++ START=1592872660
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ source run_training.sh
+++ date +%s
+ SEED=30970
+ SEED=30970
+++ date +%s
+ MAX_TOKENS=768
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ case "$MODE" in
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ MAX_TOKENS=768
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ DATASET_DIR=/data
+ MODE=TRAIN
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ NUMEPOCHS=30
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MODE=TRAIN
+ NUMEPOCHS=30
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ [[ 960 -ne 1 ]]
+ case "$MODE" in
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ source run_training.sh
++ export DGXSYSTEM
+++ date +%s
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
++ '[' -n 15 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MAX_TOKENS=768
++ START_FMT='2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
+ MODE=TRAIN
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
+ source run_training.sh
++ [[ 960 -ne 1 ]]
+++ date '+%Y-%m-%d %r'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ [[ 960 -ne 1 ]]
++ declare -a CMD
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' -n 4 ']'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NNODES
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+++ date +%s
+ MAX_TOKENS=768
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 7 ']'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NTASKS_PER_NODE
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export SLURM_NNODES
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
+ case "$MODE" in
+ source run_training.sh
++ '[' -n 0 ']'
++ START=1592872660
++ '[' 960 -gt 60 ']'
+ SEED=30970
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+++ date '+%Y-%m-%d %r'
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ export SLURM_NNODES
++ declare -a CMD
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 10 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ '[' -n 1 ']'
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ [[ 960 -ne 1 ]]
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ source run_training.sh
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 8 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
+ MAX_TOKENS=768
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' -n 5 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ '[' -n 2 ']'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NNODES
++ declare -a CMD
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ [[ 960 -ne 1 ]]
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ SEED=30970
+ MAX_TOKENS=768
++ '[' -n 11 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ DATASET_DIR=/data
++ '[' -n 7 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
++ declare -a CMD
+ source run_training.sh
++ '[' -n 14 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ [[ 960 -ne 1 ]]
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ declare -a CMD
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 5 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 9 ']'
++ '[' 960 -gt 60 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 13 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 7 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
+++ date +%s
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MAX_TOKENS=768
++ START_FMT='2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ source run_training.sh
+++ date +%s
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 3 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ [[ 960 -ne 1 ]]
+ MODE=TRAIN
+ NUMEPOCHS=30
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
++ export DGXSYSTEM
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ case "$MODE" in
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ SEED=30970
+++ date '+%Y-%m-%d %r'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ '[' -n 6 ']'
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
+++ date +%s
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MAX_TOKENS=768
+ SEED=30970
+ DATASET_DIR=/data
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
+ DATASET_DIR=/data
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
+ source run_training.sh
+++ date +%s
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
+ MAX_TOKENS=768
+++ date +%s
+ DATASET_DIR=/data
+ MODE=TRAIN
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
++ START=1592872660
+ case "$MODE" in
++ START=1592872660
+ source run_training.sh
++ START=1592872660
++ START=1592872660
++ START=1592872660
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
++ START=1592872660
+ SEED=30970
+ SEED=30970
+ MAX_TOKENS=768
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ DATASET_DIR=/data
+ NUMEPOCHS=30
+ MODE=TRAIN
+ case "$MODE" in
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
++ START_FMT='2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
+ case "$MODE" in
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ [[ 960 -ne 1 ]]
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
++ START=1592872660
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export DGXSYSTEM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export SLURM_NTASKS_PER_NODE
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export SLURM_NNODES
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ declare -a CMD
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' -n 5 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+++ date '+%Y-%m-%d %r'
+ case "$MODE" in
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ START=1592872660
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ START=1592872660
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
++ [[ 960 -ne 1 ]]
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ NUMEPOCHS=30
++ export DGXSYSTEM
+ case "$MODE" in
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
+++ date +%s
++ '[' -n 12 ']'
+ SEED=30970
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ START=1592872660
+ MODE=TRAIN
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
+++ date +%s
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
+ source run_training.sh
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
++ START=1592872660
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+++ date '+%Y-%m-%d %r'
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+++ date '+%Y-%m-%d %r'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+++ date '+%Y-%m-%d %r'
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ START=1592872660
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ SEED=30970
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ source run_training.sh
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
++ START=1592872660
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
+++ date +%s
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ START=1592872660
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NNODES
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ '[' -n 1 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START=1592872660
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ [[ 960 -ne 1 ]]
++ declare -a CMD
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' -n 15 ']'
+++ date '+%Y-%m-%d %r'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 13 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 10 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 9 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NNODES
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ START_FMT='2020-06-22 05:37:40 PM'
++ declare -a CMD
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 4 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 10 ']'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ declare -a CMD
++ '[' -n 8 ']'
++ [[ 960 -ne 1 ]]
++ '[' -n 4 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' 960 -gt 60 ']'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ '[' -n 12 ']'
++ '[' 960 -gt 60 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export DGXSYSTEM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date '+%Y-%m-%d %r'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ declare -a CMD
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' -n 2 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MAX_TOKENS=768
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ [[ 960 -ne 1 ]]
+ DATASET_DIR=/data
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ MODE=TRAIN
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START_FMT='2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ case "$MODE" in
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ export DGXSYSTEM
+++ date +%s
+ case "$MODE" in
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
+++ date +%s
+ source run_training.sh
++ '[' -n 3 ']'
++ START=1592872660
+ SEED=30970
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
+ MAX_TOKENS=768
++ [[ 960 -ne 1 ]]
Run vars: id 392220 gpus 16 mparams
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
++ export DGXSYSTEM
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date +%s
+ NUMEPOCHS=30
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date '+%Y-%m-%d %r'
+ case "$MODE" in
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
+ SEED=30970
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MAX_TOKENS=768
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+ MODE=TRAIN
+ NUMEPOCHS=30
++ '[' -n 3 ']'
++ '[' 960 -gt 60 ']'
++ START=1592872660
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 3 ']'
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START=1592872660
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START=1592872660
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+++ date '+%Y-%m-%d %r'
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' -n 2 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
++ '[' -n 6 ']'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ case "$MODE" in
+ source run_training.sh
++ [[ 960 -ne 1 ]]
+ SEED=30970
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ MAX_TOKENS=768
++ export DGXSYSTEM
+ DATASET_DIR=/data
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ MODE=TRAIN
+ NUMEPOCHS=30
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ source run_training.sh
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ MAX_TOKENS=768
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
+ MODE=TRAIN
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ NUMEPOCHS=30
++ '[' -n 14 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ source run_training.sh
++ '[' 960 -gt 60 ']'
+ SEED=30970
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date +%s
++ START=1592872660
+ SEED=30970
+++ date '+%Y-%m-%d %r'
+ MAX_TOKENS=768
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
+ MODE=TRAIN
+++ date '+%Y-%m-%d %r'
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
+ case "$MODE" in
++ START=1592872660
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ START=1592872660
++ export SLURM_NNODES
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 8 ']'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ [[ 960 -ne 1 ]]
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ declare -a CMD
++ export DGXSYSTEM
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ '[' -n 15 ']'
++ declare -a CMD
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 9 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date '+%Y-%m-%d %r'
++ START=1592872660
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 10 ']'
++ '[' 960 -gt 60 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
++ '[' -n 13 ']'
++ '[' 960 -gt 60 ']'
++ declare -a CMD
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 15 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ '[' -n 8 ']'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' 960 -gt 60 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 12 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
+ case "$MODE" in
++ '[' -n 11 ']'
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ SEED=30970
+++ date +%s
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
+++ date +%s
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ SEED=30970
+ MAX_TOKENS=768
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
+ MODE=TRAIN
++ START=1592872660
+ SEED=30970
++ START=1592872660
+ NUMEPOCHS=30
+ MAX_TOKENS=768
++ START=1592872660
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ DATASET_DIR=/data
+ MODE=TRAIN
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
+ DATASET_DIR=/data
+ NUMEPOCHS=30
+ MODE=TRAIN
+ case "$MODE" in
+ NUMEPOCHS=30
+ source run_training.sh
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
++ START=1592872660
+++ date +%s
+++ date '+%Y-%m-%d %r'
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
+ DATASET_DIR=/data
+ MODE=TRAIN
+++ date '+%Y-%m-%d %r'
+ NUMEPOCHS=30
+++ date +%s
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
+ SEED=30970
+ MAX_TOKENS=768
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ MODE=TRAIN
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+ NUMEPOCHS=30
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
+ case "$MODE" in
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ source run_training.sh
++ START=1592872660
+ SEED=30970
++ [[ 960 -ne 1 ]]
+ MAX_TOKENS=768
+++ date +%s
+ DATASET_DIR=/data
+ MODE=TRAIN
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
+ case "$MODE" in
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
++ declare -a CMD
++ '[' -n 3 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
++ '[' 960 -gt 60 ']'
+ MAX_TOKENS=768
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ SEED=30970
+ DATASET_DIR=/data
+ MODE=TRAIN
+ MAX_TOKENS=768
+ NUMEPOCHS=30
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
+ case "$MODE" in
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export DGXSYSTEM
++ export SLURM_NNODES
++ declare -a CMD
++ export SLURM_NTASKS_PER_NODE
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
++ '[' -n 12 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 11 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ [[ 960 -ne 1 ]]
++ export DGXSYSTEM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ declare -a CMD
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' -n 5 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ '[' 960 -gt 60 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ [[ 960 -ne 1 ]]
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ case "$MODE" in
+ source run_training.sh
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export DGXSYSTEM
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 1 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 0 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ [[ 960 -ne 1 ]]
++ START_FMT='2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ declare -a CMD
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 7 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 1 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 0 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ [[ 960 -ne 1 ]]
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START=1592872660
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ export SLURM_NNODES
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 9 ']'
++ [[ 960 -ne 1 ]]
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ '[' -n 2 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+++ date +%s
+++ date +%s
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+++ date +%s
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ SEED=30970
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ SEED=30970
+ MAX_TOKENS=768
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ export SLURM_NNODES
+ MAX_TOKENS=768
++ declare -a CMD
+ DATASET_DIR=/data
+ MODE=TRAIN
++ '[' -n 13 ']'
+ NUMEPOCHS=30
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ DATASET_DIR=/data
+ MODE=TRAIN
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ case "$MODE" in
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ NUMEPOCHS=30
++ '[' -n 4 ']'
++ '[' 960 -gt 60 ']'
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
++ '[' -n 6 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ DATASET_DIR=/data
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MODE=TRAIN
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
+ case "$MODE" in
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
+ MODE=TRAIN
+ NUMEPOCHS=30
+ DATASET_DIR=/data
+ MODE=TRAIN
+ case "$MODE" in
+ NUMEPOCHS=30
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ case "$MODE" in
+ source run_training.sh
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+++ date +%s
++ export DGXSYSTEM
+++ date +%s
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START=1592872660
++ declare -a CMD
++ '[' -n 14 ']'
+ SEED=30970
++ export SLURM_NNODES
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MAX_TOKENS=768
++ declare -a CMD
++ '[' -n 11 ']'
+++ date +%s
++ '[' -n 1 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ '[' 960 -gt 60 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ case "$MODE" in
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ '[' -n 5 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ '[' -n 10 ']'
++ declare -a CMD
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 2 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ MODE=TRAIN
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ case "$MODE" in
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ declare -a CMD
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' -n 4 ']'
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 7 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NNODES
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' -n 14 ']'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NNODES
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ NUMEPOCHS=30
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export SLURM_NTASKS_PER_NODE
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export DGXSYSTEM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export SLURM_NNODES
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
++ '[' -n 6 ']'
++ '[' 960 -gt 60 ']'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
++ '[' -n 9 ']'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
+ MODE=TRAIN
+ NUMEPOCHS=30
+ SEED=30970
++ '[' -n 12 ']'
+ case "$MODE" in
++ '[' 960 -gt 60 ']'
+ source run_training.sh
+ MAX_TOKENS=768
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MODE=TRAIN
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
+ DATASET_DIR=/data
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ MODE=TRAIN
+ source run_training.sh
+ NUMEPOCHS=30
+ SEED=30970
+ case "$MODE" in
+ MAX_TOKENS=768
+ source run_training.sh
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
++ START=1592872660
++ START=1592872660
+ SEED=30970
+++ date +%s
+ MAX_TOKENS=768
++ START=1592872660
+ DATASET_DIR=/data
+ MODE=TRAIN
+++ date '+%Y-%m-%d %r'
+ NUMEPOCHS=30
+++ date '+%Y-%m-%d %r'
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
+ source run_training.sh
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 12 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+++ date +%s
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
+++ date +%s
+++ date +%s
+ SEED=30970
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ START=1592872660
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
+++ date +%s
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 14 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ START=1592872660
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
+ SEED=30970
+ MAX_TOKENS=768
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+ MAX_TOKENS=768
+ MAX_TOKENS=768
++ START=1592872660
+ source run_training.sh
+ DATASET_DIR=/data
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ MODE=TRAIN
+ NUMEPOCHS=30
++ START=1592872660
+ NUMEPOCHS=30
+ case "$MODE" in
++ START=1592872660
+ case "$MODE" in
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
+ source run_training.sh
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ SEED=30970
++ [[ 960 -ne 1 ]]
++ START_FMT='2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 13 ']'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
++ export SLURM_NNODES
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ case "$MODE" in
++ declare -a CMD
+ source run_training.sh
++ '[' -n 15 ']'
++ [[ 960 -ne 1 ]]
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date '+%Y-%m-%d %r'
++ export DGXSYSTEM
+ SEED=30970
+++ date '+%Y-%m-%d %r'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ MAX_TOKENS=768
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ declare -a CMD
+ DATASET_DIR=/data
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 8 ']'
+ MODE=TRAIN
++ '[' 960 -gt 60 ']'
+ NUMEPOCHS=30
+++ date +%s
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ case "$MODE" in
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MAX_TOKENS=768
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ DATASET_DIR=/data
+ MODE=TRAIN
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
+ NUMEPOCHS=30
++ [[ 960 -ne 1 ]]
+ DATASET_DIR=/data
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
++ export DGXSYSTEM
+ NUMEPOCHS=30
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ SEED=30970
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ source run_training.sh
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ NUMEPOCHS=30
+++ date +%s
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
++ '[' -n 0 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
+ SEED=30970
+ MAX_TOKENS=768
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ case "$MODE" in
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ declare -a CMD
+++ date +%s
+++ date +%s
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
++ '[' -n 11 ']'
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export DGXSYSTEM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 3 ']'
++ [[ 960 -ne 1 ]]
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 11 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 2 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ SEED=30970
+ MAX_TOKENS=768
+ source run_training.sh
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ START=1592872660
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
++ export SLURM_NNODES
++ declare -a CMD
++ START=1592872660
++ '[' -n 1 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ SEED=30970
+ MAX_TOKENS=768
+ source run_training.sh
+ DATASET_DIR=/data
+ MODE=TRAIN
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ NUMEPOCHS=30
++ export SLURM_NNODES
++ declare -a CMD
+ case "$MODE" in
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
++ [[ 960 -ne 1 ]]
+ MAX_TOKENS=768
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ DATASET_DIR=/data
++ '[' -n 5 ']'
+++ date '+%Y-%m-%d %r'
+ MODE=TRAIN
+ NUMEPOCHS=30
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ case "$MODE" in
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ SEED=30970
++ export SLURM_NNODES
++ declare -a CMD
+ MAX_TOKENS=768
++ [[ 960 -ne 1 ]]
+ DATASET_DIR=/data
+ MODE=TRAIN
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date +%s
++ export DGXSYSTEM
+ NUMEPOCHS=30
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
+ source run_training.sh
++ '[' -n 10 ']'
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
+ SEED=30970
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MAX_TOKENS=768
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
+ case "$MODE" in
++ '[' -n 4 ']'
+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
+++ date +%s
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date +%s
++ START=1592872660
++ export DGXSYSTEM
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date +%s
+++ date +%s
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
++ declare -a CMD
+ SEED=30970
++ [[ 960 -ne 1 ]]
+++ date '+%Y-%m-%d %r'
+ MAX_TOKENS=768
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ NUMEPOCHS=30
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ case "$MODE" in
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
+ source run_training.sh
++ '[' -n 8 ']'
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
++ '[' -n 0 ']'
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START=1592872660
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ declare -a CMD
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 4 ']'
+ SEED=30970
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ MAX_TOKENS=768
++ '[' -n 7 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
++ START=1592872660
+ source run_training.sh
++ START=1592872660
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 13 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ SEED=30970
+ MAX_TOKENS=768
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ START_FMT='2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
++ export SLURM_NNODES
++ declare -a CMD
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' -n 6 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 9 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
+ MAX_TOKENS=768
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
+++ date +%s
++ START=1592872660
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ MAX_TOKENS=768
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ MAX_TOKENS=768
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ case "$MODE" in
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
++ [[ 960 -ne 1 ]]
+ source run_training.sh
+ MAX_TOKENS=768
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export DGXSYSTEM
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ SEED=30970
+ MAX_TOKENS=768
+ source run_training.sh
+ DATASET_DIR=/data
+ MODE=TRAIN
+++ date '+%Y-%m-%d %r'
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
++ START=1592872660
+ DATASET_DIR=/data
+ MODE=TRAIN
++ START=1592872660
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ SEED=30970
+++ date +%s
+++ date +%s
+ source run_training.sh
+ MAX_TOKENS=768
+ case "$MODE" in
+ source run_training.sh
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
++ START=1592872660
+++ date '+%Y-%m-%d %r'
++ START=1592872660
+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+ MAX_TOKENS=768
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date +%s
++ [[ 960 -ne 1 ]]
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date +%s
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date +%s
++ export SLURM_NNODES
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
+++ date +%s
++ '[' -n 1 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+++ date '+%Y-%m-%d %r'
++ export SLURM_NNODES
++ START=1592872660
++ declare -a CMD
++ '[' -n 13 ']'
+ SEED=30970
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MAX_TOKENS=768
++ '[' -n 3 ']'
+ DATASET_DIR=/data
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MODE=TRAIN
++ START_FMT='2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
+ case "$MODE" in
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ source run_training.sh
++ START=1592872660
++ [[ 960 -ne 1 ]]
++ START=1592872660
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ export DGXSYSTEM
++ START=1592872660
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date '+%Y-%m-%d %r'
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
+++ date +%s
+ source run_training.sh
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ START=1592872660
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date '+%Y-%m-%d %r'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date '+%Y-%m-%d %r'
++ export DGXSYSTEM
+++ date +%s
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
++ START=1592872660
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ '[' -n 11 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ '[' -n 8 ']'
++ START=1592872660
++ '[' 960 -gt 60 ']'
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 5 ']'
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ '[' -n 7 ']'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export DGXSYSTEM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ START=1592872660
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
++ '[' -n 6 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 9 ']'
+++ date '+%Y-%m-%d %r'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' -n 15 ']'
++ '[' 960 -gt 60 ']'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ [[ 960 -ne 1 ]]
++ export SLURM_NNODES
++ declare -a CMD
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' -n 2 ']'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 14 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ [[ 960 -ne 1 ]]
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
++ export DGXSYSTEM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' -n 8 ']'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ SEED=30970
+ MAX_TOKENS=768
++ export DGXSYSTEM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START_FMT='2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ declare -a CMD
+ case "$MODE" in
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
++ '[' -n 2 ']'
++ '[' -n 7 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
++ START=1592872660
++ [[ 960 -ne 1 ]]
++ '[' -n 14 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ [[ 960 -ne 1 ]]
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export DGXSYSTEM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export SLURM_NNODES
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ declare -a CMD
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' -n 0 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date '+%Y-%m-%d %r'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' -n 0 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' 960 -gt 60 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date +%s
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ START=1592872660
++ '[' -n 7 ']'
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ MAX_TOKENS=768
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START_FMT='2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ declare -a CMD
+ DATASET_DIR=/data
+ MODE=TRAIN
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ NUMEPOCHS=30
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ case "$MODE" in
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' -n 10 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' 960 -gt 60 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 11 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 0 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date +%s
++ START=1592872660
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 13 ']'
++ START=1592872660
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NNODES
++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 6 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START=1592872660
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 10 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
+ SEED=30970
+ MAX_TOKENS=768
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ DATASET_DIR=/data
+ MODE=TRAIN
+ source run_training.sh
+ NUMEPOCHS=30
+++ date '+%Y-%m-%d %r'
+ case "$MODE" in
++ START=1592872660
+ source run_training.sh
++ START=1592872660
+++ date '+%Y-%m-%d %r'
++ START=1592872660
++ '[' -n 3 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 5 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
++ START_FMT='2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ DATASET_DIR=/data
+ MODE=TRAIN
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date +%s
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ NUMEPOCHS=30
++ export DGXSYSTEM
++ declare -a CMD
+ case "$MODE" in
++ export SLURM_NTASKS_PER_NODE
++ '[' -n 9 ']'
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NNODES
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ '[' -n 15 ']'
++ '[' 960 -gt 60 ']'
++ export DGXSYSTEM
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ declare -a CMD
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ '[' -n 15 ']'
++ declare -a CMD
++ '[' 960 -gt 60 ']'
++ '[' -n 12 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ START_FMT='2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date +%s
++ [[ 960 -ne 1 ]]
++ export DGXSYSTEM
+ SEED=30970
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export SLURM_NTASKS_PER_NODE
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NNODES
+ MAX_TOKENS=768
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ DATASET_DIR=/data
+ MODE=TRAIN
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
+ NUMEPOCHS=30
++ export SLURM_NNODES
++ declare -a CMD
+ SEED=30970
+ MAX_TOKENS=768
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ case "$MODE" in
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ DATASET_DIR=/data
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ source run_training.sh
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ MODE=TRAIN
+ NUMEPOCHS=30
++ declare -a CMD
+ case "$MODE" in
++ '[' -n 12 ']'
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 12 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
++ '[' -n 4 ']'
+++ date '+%Y-%m-%d %r'
++ '[' 960 -gt 60 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 5 ']'
++ [[ 960 -ne 1 ]]
++ START_FMT='2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export DGXSYSTEM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
++ [[ 960 -ne 1 ]]
+ SEED=30970
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ export DGXSYSTEM
+ MODE=TRAIN
+ NUMEPOCHS=30
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ case "$MODE" in
+ source run_training.sh
++ declare -a CMD
++ '[' -n 8 ']'
++ START=1592872660
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 2 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 6 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START_FMT='2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ declare -a CMD
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' -n 14 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 3 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ SEED=30970
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+++ date +%s
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+ MAX_TOKENS=768
+++ date +%s
++ START=1592872660
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
+++ date +%s
++ START=1592872660
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ case "$MODE" in
+ source run_training.sh
++ export SLURM_NTASKS_PER_NODE
++ START_FMT='2020-06-22 05:37:40 PM'
+ MODE=TRAIN
+ NUMEPOCHS=30
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 4 ']'
+ case "$MODE" in
++ '[' -n 0 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
+++ date '+%Y-%m-%d %r'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ SEED=30970
+ MAX_TOKENS=768
++ export DGXSYSTEM
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
+ MODE=TRAIN
++ declare -a CMD
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ NUMEPOCHS=30
++ '[' -n 10 ']'
++ '[' 960 -gt 60 ']'
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ case "$MODE" in
+ source run_training.sh
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
++ START_FMT='2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ export DGXSYSTEM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
++ '[' -n 13 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MAX_TOKENS=768
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ '[' -n 1 ']'
+ DATASET_DIR=/data
++ declare -a CMD
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MODE=TRAIN
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ NUMEPOCHS=30
++ [[ 960 -ne 1 ]]
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' -n 9 ']'
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
+ source run_training.sh
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ SEED=30970
++ export SLURM_NNODES
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
+ SEED=30970
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ MAX_TOKENS=768
++ export DGXSYSTEM
+ DATASET_DIR=/data
++ START=1592872660
+ MODE=TRAIN
+ NUMEPOCHS=30
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ case "$MODE" in
++ START=1592872660
+++ date +%s
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
++ '[' -n 12 ']'
++ '[' 960 -gt 60 ']'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
++ declare -a CMD
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 13 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date +%s
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date '+%Y-%m-%d %r'
++ '[' -n 6 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START_FMT='2020-06-22 05:37:40 PM'
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ '[' -n 11 ']'
++ '[' 960 -gt 60 ']'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 5 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export DGXSYSTEM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 8 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
+++ date +%s
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START_FMT='2020-06-22 05:37:40 PM'
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
+ case "$MODE" in
+ source run_training.sh
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ SEED=30970
++ '[' -n 15 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MAX_TOKENS=768
++ [[ 960 -ne 1 ]]
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ DATASET_DIR=/data
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ MODE=TRAIN
++ declare -a CMD
++ declare -a CMD
+ NUMEPOCHS=30
++ '[' -n 11 ']'
+ case "$MODE" in
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 1 ']'
+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ SEED=30970
+ MAX_TOKENS=768
++ '[' -n 3 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 7 ']'
+++ date '+%Y-%m-%d %r'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
++ START=1592872660
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
+ case "$MODE" in
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ [[ 960 -ne 1 ]]
++ export SLURM_NNODES
++ START=1592872660
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
++ START=1592872660
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ source run_training.sh
++ declare -a CMD
++ declare -a CMD
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ START=1592872660
++ export SLURM_NNODES
+++ date '+%Y-%m-%d %r'
+ SEED=30970
++ declare -a CMD
++ '[' -n 6 ']'
+ MAX_TOKENS=768
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ DATASET_DIR=/data
+ MODE=TRAIN
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+ NUMEPOCHS=30
++ '[' -n 10 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 14 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
+++ date '+%Y-%m-%d %r'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' -n 9 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' 960 -gt 60 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ case "$MODE" in
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+++ date +%s
++ '[' -n 2 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 1 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 4 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
++ START=1592872660
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ START=1592872660
++ START=1592872660
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
+++ date '+%Y-%m-%d %r'
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ '[' -n 3 ']'
++ '[' 960 -gt 60 ']'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 14 ']'
++ START=1592872660
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ START=1592872660
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ '[' -n 7 ']'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
+ SEED=30970
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ export DGXSYSTEM
+ MAX_TOKENS=768
++ '[' -n 12 ']'
+ case "$MODE" in
+ DATASET_DIR=/data
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MODE=TRAIN
++ declare -a CMD
+ NUMEPOCHS=30
++ START=1592872660
+ case "$MODE" in
++ START_FMT='2020-06-22 05:37:40 PM'
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' -n 5 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export SLURM_NNODES
++ declare -a CMD
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ declare -a CMD
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' -n 2 ']'
++ '[' 960 -gt 60 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' -n 11 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ declare -a CMD
++ '[' -n 0 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' -n 15 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date +%s
++ [[ 960 -ne 1 ]]
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 4 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 9 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ START=1592872660
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 1 ']'
++ '[' 960 -gt 60 ']'
+++ date '+%Y-%m-%d %r'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 8 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ [[ 960 -ne 1 ]]
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date +%s
+ SEED=30970
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
++ export DGXSYSTEM
+ DATASET_DIR=/data
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ [[ 960 -ne 1 ]]
+ MODE=TRAIN
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ case "$MODE" in
++ '[' -n 5 ']'
Run vars: id 392220 gpus 16 mparams
++ export DGXSYSTEM
+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 13 ']'
+++ date '+%Y-%m-%d %r'
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' -n 4 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+++ date +%s
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 10 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ START=1592872660
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
+ source run_training.sh
++ START=1592872660
++ START=1592872660
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ SEED=30970
+ MAX_TOKENS=768
+ case "$MODE" in
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ START_FMT='2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ case "$MODE" in
+ source run_training.sh
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 3 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ [[ 960 -ne 1 ]]
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+ MAX_TOKENS=768
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ case "$MODE" in
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ MODE=TRAIN
+ NUMEPOCHS=30
++ export SLURM_NNODES
+ source run_training.sh
++ declare -a CMD
+ case "$MODE" in
++ '[' -n 1 ']'
+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 6 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date +%s
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 7 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
++ export DGXSYSTEM
+ SEED=30970
+ SEED=30970
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
+ DATASET_DIR=/data
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NTASKS_PER_NODE
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export SLURM_NNODES
+ SEED=30970
+ MAX_TOKENS=768
+ MAX_TOKENS=768
++ declare -a CMD
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ MODE=TRAIN
+ DATASET_DIR=/data
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ NUMEPOCHS=30
++ '[' -n 9 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MODE=TRAIN
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ DATASET_DIR=/data
+ MODE=TRAIN
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ NUMEPOCHS=30
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ case "$MODE" in
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ NUMEPOCHS=30
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ case "$MODE" in
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ [[ 960 -ne 1 ]]
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export SLURM_NNODES
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ declare -a CMD
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 10 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date '+%Y-%m-%d %r'
++ START=1592872660
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ SEED=30970
++ [[ 960 -ne 1 ]]
+ source run_training.sh
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ MAX_TOKENS=768
++ export SLURM_NTASKS_PER_NODE
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export SLURM_NNODES
+ NUMEPOCHS=30
++ declare -a CMD
+ case "$MODE" in
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 0 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ SEED=30970
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ MAX_TOKENS=768
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ DATASET_DIR=/data
+ MODE=TRAIN
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ NUMEPOCHS=30
++ '[' -n 14 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ MODE=TRAIN
+ NUMEPOCHS=30
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+ MODE=TRAIN
+ NUMEPOCHS=30
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
+++ date +%s
+ case "$MODE" in
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+ source run_training.sh
++ START=1592872660
+ SEED=30970
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
+++ date '+%Y-%m-%d %r'
++ START=1592872660
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ START=1592872660
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ SEED=30970
+ MODE=TRAIN
+ NUMEPOCHS=30
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+ source run_training.sh
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
+ source run_training.sh
+++ date +%s
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
+ MAX_TOKENS=768
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
+ MODE=TRAIN
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ source run_training.sh
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ NUMEPOCHS=30
+++ date +%s
+ case "$MODE" in
+ case "$MODE" in
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ SEED=30970
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
++ export SLURM_NNODES
++ declare -a CMD
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export DGXSYSTEM
+ MODE=TRAIN
+ NUMEPOCHS=30
++ export SLURM_NTASKS_PER_NODE
+ NUMEPOCHS=30
+ case "$MODE" in
++ export SLURM_NNODES
+ case "$MODE" in
+ source run_training.sh
++ declare -a CMD
+ source run_training.sh
+++ date +%s
++ '[' -n 11 ']'
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' -n 4 ']'
+++ date '+%Y-%m-%d %r'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ SEED=30970
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ MAX_TOKENS=768
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ DATASET_DIR=/data
+ MODE=TRAIN
+ MODE=TRAIN
+ NUMEPOCHS=30
++ START=1592872660
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
+ NUMEPOCHS=30
+ MAX_TOKENS=768
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ MODE=TRAIN
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ source run_training.sh
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
++ START=1592872660
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ [[ 960 -ne 1 ]]
+ case "$MODE" in
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ SEED=30970
+ MAX_TOKENS=768
+ source run_training.sh
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ case "$MODE" in
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date +%s
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
+ SEED=30970
+ MAX_TOKENS=768
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
++ export DGXSYSTEM
+ DATASET_DIR=/data
+ MODE=TRAIN
++ '[' -n 15 ']'
+ NUMEPOCHS=30
+ case "$MODE" in
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
+ source run_training.sh
++ '[' -n 2 ']'
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date '+%Y-%m-%d %r'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+++ date +%s
+ case "$MODE" in
+ source run_training.sh
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
+++ date '+%Y-%m-%d %r'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
++ '[' -n 15 ']'
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ SEED=30970
+ MAX_TOKENS=768
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ NUMEPOCHS=30
++ declare -a CMD
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
++ '[' -n 6 ']'
+ SEED=30970
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
+++ date +%s
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+++ date +%s
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ START=1592872660
+++ date +%s
+++ date '+%Y-%m-%d %r'
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
Run vars: id 392220 gpus 16 mparams
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ SEED=30970
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
+ DATASET_DIR=/data
+ MODE=TRAIN
++ START_FMT='2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ case "$MODE" in
+ source run_training.sh
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NNODES
++ declare -a CMD
++ [[ 960 -ne 1 ]]
Run vars: id 392220 gpus 16 mparams
++ '[' -n 0 ']'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 8 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
+ NUMEPOCHS=30
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ SEED=30970
++ '[' -n 2 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ MAX_TOKENS=768
+ case "$MODE" in
+ DATASET_DIR=/data
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
+++ date +%s
++ '[' -n 12 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
+++ date '+%Y-%m-%d %r'
+++ date +%s
+ MODE=TRAIN
+ NUMEPOCHS=30
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
+ SEED=30970
++ START=1592872660
+ source run_training.sh
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+++ date +%s
+++ date +%s
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
+ source run_training.sh
+ MAX_TOKENS=768
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
+ MODE=TRAIN
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+++ date +%s
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ DATASET_DIR=/data
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ MODE=TRAIN
+ SEED=30970
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
+ DATASET_DIR=/data
+ source run_training.sh
+ source run_training.sh
++ START=1592872660
+ MODE=TRAIN
+ NUMEPOCHS=30
+ SEED=30970
+ case "$MODE" in
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ DATASET_DIR=/data
+ MODE=TRAIN
+++ date '+%Y-%m-%d %r'
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
++ '[' -n 13 ']'
+ case "$MODE" in
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ source run_training.sh
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
+++ date +%s
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ START=1592872660
+ SEED=30970
+++ date +%s
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
+ MAX_TOKENS=768
+ SEED=30970
+ MAX_TOKENS=768
+ source run_training.sh
+ DATASET_DIR=/data
+ MAX_TOKENS=768
++ START_FMT='2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ DATASET_DIR=/data
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
+ MODE=TRAIN
+ NUMEPOCHS=30
+ MODE=TRAIN
+ NUMEPOCHS=30
+ MODE=TRAIN
+ case "$MODE" in
+ NUMEPOCHS=30
+ source run_training.sh
+ case "$MODE" in
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
++ START_FMT='2020-06-22 05:37:40 PM'
+ case "$MODE" in
+ SEED=30970
+ SEED=30970
+ MAX_TOKENS=768
+ MAX_TOKENS=768
+ source run_training.sh
+ DATASET_DIR=/data
+ MODE=TRAIN
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
+ NUMEPOCHS=30
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ MAX_TOKENS=768
+ case "$MODE" in
++ START=1592872660
+ DATASET_DIR=/data
+ DATASET_DIR=/data
+ MODE=TRAIN
+ source run_training.sh
++ export SLURM_NNODES
++ declare -a CMD
+ MODE=TRAIN
+ NUMEPOCHS=30
+ NUMEPOCHS=30
+++ date +%s
++ START=1592872660
+ case "$MODE" in
+ case "$MODE" in
+++ date +%s
+ source run_training.sh
+++ date +%s
+++ date +%s
++ '[' -n 13 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ source run_training.sh
++ START=1592872660
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ MAX_TOKENS=768
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ [[ 960 -ne 1 ]]
+ NUMEPOCHS=30
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+++ date +%s
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ case "$MODE" in
++ START_FMT='2020-06-22 05:37:40 PM'
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+++ date +%s
+ SEED=30970
++ START=1592872660
+ source run_training.sh
+ source run_training.sh
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ MAX_TOKENS=768
++ START=1592872660
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ '[' -n 3 ']'
++ export SLURM_NNODES
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ declare -a CMD
++ '[' -n 5 ']'
+++ date '+%Y-%m-%d %r'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
+++ date +%s
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
+ MODE=TRAIN
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ NUMEPOCHS=30
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 13 ']'
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+++ date +%s
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+++ date +%s
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ SEED=30970
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
+ source run_training.sh
+ MAX_TOKENS=768
+++ date +%s
+ DATASET_DIR=/data
+ MODE=TRAIN
+ SEED=30970
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
+ DATASET_DIR=/data
+ case "$MODE" in
+ MODE=TRAIN
+ NUMEPOCHS=30
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
++ START=1592872660
+++ date +%s
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
+ DATASET_DIR=/data
Run vars: id 392220 gpus 16 mparams
+ MODE=TRAIN
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ SEED=30970
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ MAX_TOKENS=768
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ DATASET_DIR=/data
+ MODE=TRAIN
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
++ START=1592872660
+ DATASET_DIR=/data
+ MODE=TRAIN
+ case "$MODE" in
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+ NUMEPOCHS=30
+ case "$MODE" in
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
+ case "$MODE" in
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
++ [[ 960 -ne 1 ]]
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ MODE=TRAIN
+ NUMEPOCHS=30
++ export DGXSYSTEM
+ case "$MODE" in
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 11 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
+ MAX_TOKENS=768
++ export SLURM_NNODES
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ '[' -n 6 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
++ '[' 960 -gt 60 ']'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
+ source run_training.sh
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export DGXSYSTEM
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NTASKS_PER_NODE
+ SEED=30970
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NNODES
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MODE=TRAIN
+ NUMEPOCHS=30
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
++ '[' -n 0 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ source run_training.sh
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MODE=TRAIN
+ NUMEPOCHS=30
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
+ source run_training.sh
+ MAX_TOKENS=768
+ case "$MODE" in
+ DATASET_DIR=/data
+ MODE=TRAIN
+ SEED=30970
+ MAX_TOKENS=768
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
+ DATASET_DIR=/data
+ MODE=TRAIN
+ SEED=30970
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
+ source run_training.sh
+ MAX_TOKENS=768
++ START=1592872660
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
++ START=1592872660
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
+ NUMEPOCHS=30
+++ date +%s
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+++ date +%s
+++ date '+%Y-%m-%d %r'
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
+ source run_training.sh
+++ date +%s
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
+++ date +%s
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
++ export DGXSYSTEM
++ START=1592872660
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ SEED=30970
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
++ declare -a CMD
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 3 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
+++ date +%s
++ [[ 960 -ne 1 ]]
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
+++ date +%s
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
++ '[' -n 9 ']'
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ declare -a CMD
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ SEED=30970
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ MAX_TOKENS=768
++ declare -a CMD
++ '[' -n 14 ']'
+++ date +%s
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
++ '[' -n 7 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MODE=TRAIN
+ NUMEPOCHS=30
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
++ START=1592872660
+++ date +%s
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
++ export DGXSYSTEM
+++ date +%s
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ export DGXSYSTEM
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ export SLURM_NTASKS_PER_NODE
+ case "$MODE" in
+ source run_training.sh
++ export SLURM_NNODES
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 12 ']'
++ '[' -n 4 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' 960 -gt 60 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ [[ 960 -ne 1 ]]
++ START_FMT='2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ export SLURM_NTASKS_PER_NODE
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ export SLURM_NNODES
++ declare -a CMD
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
++ '[' -n 13 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ source run_training.sh
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
++ '[' -n 1 ']'
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' 960 -gt 60 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ declare -a CMD
+++ date +%s
++ [[ 960 -ne 1 ]]
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ SEED=30970
++ '[' -n 5 ']'
++ declare -a CMD
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MAX_TOKENS=768
++ '[' -n 15 ']'
+++ date +%s
+ DATASET_DIR=/data
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MODE=TRAIN
+ NUMEPOCHS=30
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ case "$MODE" in
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ source run_training.sh
++ '[' -n 1 ']'
Run vars: id 392220 gpus 16 mparams
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
+ SEED=30970
+ MAX_TOKENS=768
+ MAX_TOKENS=768
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
+ DATASET_DIR=/data
+ DATASET_DIR=/data
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+ MODE=TRAIN
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
+ case "$MODE" in
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
++ [[ 960 -ne 1 ]]
+++ date '+%Y-%m-%d %r'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date '+%Y-%m-%d %r'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export SLURM_NNODES
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
++ '[' -n 8 ']'
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 14 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
+ MODE=TRAIN
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
+ MODE=TRAIN
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NNODES
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ '[' -n 15 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 12 ']'
++ '[' 960 -gt 60 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 2 ']'
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 4 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
++ '[' -n 11 ']'
Run vars: id 392220 gpus 16 mparams
++ '[' -n 5 ']'
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
+ MODE=TRAIN
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
Run vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 10 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
+++ date +%s
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
++ '[' -n 1 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
+ MODE=TRAIN
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NNODES
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 4 ']'
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NNODES
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
++ '[' -n 7 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
++ '[' -n 4 ']'
Run vars: id 392220 gpus 16 mparams
+++ date +%s
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
++ '[' -n 7 ']'
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
++ [[ 960 -ne 1 ]]
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ MAX_TOKENS=768
+ SEED=30970
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ declare -a CMD
+ MODE=TRAIN
+ NUMEPOCHS=30
+++ date '+%Y-%m-%d %r'
+ MAX_TOKENS=768
++ '[' -n 9 ']'
+ DATASET_DIR=/data
+ DATASET_DIR=/data
+ MODE=TRAIN
+ case "$MODE" in
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
++ '[' 960 -gt 60 ']'
+ source run_training.sh
+ case "$MODE" in
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ SEED=30970
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NNODES
++ declare -a CMD
+ source run_training.sh
+ MAX_TOKENS=768
++ '[' -n 9 ']'
+ DATASET_DIR=/data
++ START_FMT='2020-06-22 05:37:40 PM'
+ MODE=TRAIN
+ NUMEPOCHS=30
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ case "$MODE" in
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ source run_training.sh
++ '[' -n 10 ']'
+ SEED=30970
++ START=1592872660
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
++ [[ 960 -ne 1 ]]
+++ date '+%Y-%m-%d %r'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date +%s
Run vars: id 392220 gpus 16 mparams
++ export DGXSYSTEM
+++ date +%s
++ export SLURM_NTASKS_PER_NODE
+ MAX_TOKENS=768
+++ date '+%Y-%m-%d %r'
++ export SLURM_NNODES
++ declare -a CMD
+ DATASET_DIR=/data
++ START=1592872660
+ MODE=TRAIN
+ NUMEPOCHS=30
++ START=1592872660
++ '[' -n 6 ']'
+ case "$MODE" in
++ START=1592872660
+ SEED=30970
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
+ MAX_TOKENS=768
++ START=1592872660
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+++ date +%s
+++ date +%s
++ START=1592872660
+ MODE=TRAIN
+ NUMEPOCHS=30
+++ date '+%Y-%m-%d %r'
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
+++ date +%s
++ START=1592872660
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MODE=TRAIN
+ NUMEPOCHS=30
++ START=1592872660
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MAX_TOKENS=768
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
++ START=1592872660
+ MAX_TOKENS=768
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
+ source run_training.sh
++ START=1592872660
++ START=1592872660
+ DATASET_DIR=/data
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+ MODE=TRAIN
+ MODE=TRAIN
+ NUMEPOCHS=30
+++ date '+%Y-%m-%d %r'
+ SEED=30970
++ START_FMT='2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
+ source run_training.sh
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
+ case "$MODE" in
+ SEED=30970
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ [[ 960 -ne 1 ]]
+ MAX_TOKENS=768
++ START_FMT='2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date '+%Y-%m-%d %r'
+ MAX_TOKENS=768
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
++ export DGXSYSTEM
++ '[' -n 12 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export SLURM_NTASKS_PER_NODE
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ DATASET_DIR=/data
+ NUMEPOCHS=30
++ START=1592872660
+ source run_training.sh
++ export SLURM_NNODES
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MODE=TRAIN
+ case "$MODE" in
++ [[ 960 -ne 1 ]]
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
+ source run_training.sh
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date +%s
++ declare -a CMD
+ case "$MODE" in
+++ date +%s
++ START=1592872660
++ '[' -n 1 ']'
+ source run_training.sh
++ export DGXSYSTEM
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ declare -a CMD
++ START=1592872660
++ [[ 960 -ne 1 ]]
++ '[' -n 2 ']'
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START=1592872660
+++ date '+%Y-%m-%d %r'
++ declare -a CMD
+++ date +%s
++ '[' -n 2 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MAX_TOKENS=768
++ START=1592872660
+++ date +%s
++ START=1592872660
+ DATASET_DIR=/data
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MODE=TRAIN
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
+ case "$MODE" in
+ SEED=30970
+ MAX_TOKENS=768
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ case "$MODE" in
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
Run vars: id 392220 gpus 16 mparams
++ '[' -n 13 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' -n 8 ']'
++ '[' -n 2 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+ MAX_TOKENS=768
+ SEED=30970
+ SEED=30970
+ DATASET_DIR=/data
+ MODE=TRAIN
+ MAX_TOKENS=768
+ MAX_TOKENS=768
+ NUMEPOCHS=30
+ DATASET_DIR=/data
+ case "$MODE" in
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ MODE=TRAIN
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+++ date +%s
+ case "$MODE" in
+ case "$MODE" in
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ source run_training.sh
+ SEED=30970
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START_FMT='2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
+ case "$MODE" in
+ source run_training.sh
++ declare -a CMD
++ START=1592872660
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
++ '[' -n 14 ']'
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ MODE=TRAIN
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ START=1592872660
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MAX_TOKENS=768
+++ date '+%Y-%m-%d %r'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ DATASET_DIR=/data
+ case "$MODE" in
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date +%s
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MODE=TRAIN
+ NUMEPOCHS=30
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ SEED=30970
++ export DGXSYSTEM
++ '[' -n 6 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ case "$MODE" in
++ START_FMT='2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
+ source run_training.sh
+ SEED=30970
+ DATASET_DIR=/data
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date +%s
+ MAX_TOKENS=768
+++ date +%s
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
++ '[' -n 0 ']'
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
++ export SLURM_NNODES
++ declare -a CMD
+ MODE=TRAIN
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ NUMEPOCHS=30
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ [[ 960 -ne 1 ]]
+ DATASET_DIR=/data
+ MODE=TRAIN
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ case "$MODE" in
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START=1592872660
+ MODE=TRAIN
+ NUMEPOCHS=30
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
++ '[' -n 12 ']'
++ '[' 960 -gt 60 ']'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ case "$MODE" in
++ '[' -n 8 ']'
++ '[' 960 -gt 60 ']'
+++ date +%s
+ case "$MODE" in
++ declare -a CMD
++ export SLURM_NNODES
++ declare -a CMD
+ source run_training.sh
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
+++ date +%s
+++ date +%s
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
++ export DGXSYSTEM
++ '[' -n 11 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+ MAX_TOKENS=768
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ DATASET_DIR=/data
+ MODE=TRAIN
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date +%s
++ '[' -n 0 ']'
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ NUMEPOCHS=30
++ '[' 960 -gt 60 ']'
+ case "$MODE" in
++ [[ 960 -ne 1 ]]
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' -n 15 ']'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+ SEED=30970
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
++ START=1592872660
+ MAX_TOKENS=768
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+ DATASET_DIR=/data
+ MODE=TRAIN
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 10 ']'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export DGXSYSTEM
++ START=1592872660
+ case "$MODE" in
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START=1592872660
+ SEED=30970
++ export DGXSYSTEM
++ START=1592872660
+ MAX_TOKENS=768
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ declare -a CMD
++ '[' -n 11 ']'
+++ date '+%Y-%m-%d %r'
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ NUMEPOCHS=30
++ '[' -n 5 ']'
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ DATASET_DIR=/data
+ case "$MODE" in
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
+ MODE=TRAIN
+ source run_training.sh
++ '[' -n 9 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
+ NUMEPOCHS=30
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ case "$MODE" in
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date +%s
Run vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
+++ date '+%Y-%m-%d %r'
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ declare -a CMD
++ '[' -n 2 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ SEED=30970
+ MAX_TOKENS=768
+ SEED=30970
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 10 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
++ START=1592872660
+ MAX_TOKENS=768
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ MODE=TRAIN
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ export DGXSYSTEM
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
+ case "$MODE" in
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date '+%Y-%m-%d %r'
+ NUMEPOCHS=30
++ declare -a CMD
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ source run_training.sh
+ case "$MODE" in
+ SEED=30970
+ MAX_TOKENS=768
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ export DGXSYSTEM
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
++ '[' -n 3 ']'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ case "$MODE" in
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
++ '[' 960 -gt 60 ']'
++ declare -a CMD
+++ date +%s
+ SEED=30970
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 11 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
+ MAX_TOKENS=768
+++ date '+%Y-%m-%d %r'
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ DATASET_DIR=/data
+ MODE=TRAIN
++ [[ 960 -ne 1 ]]
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ NUMEPOCHS=30
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
+ case "$MODE" in
++ export DGXSYSTEM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
+ source run_training.sh
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
++ declare -a CMD
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+++ date +%s
+ MAX_TOKENS=768
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
++ '[' -n 8 ']'
+++ date '+%Y-%m-%d %r'
+ MODE=TRAIN
+ NUMEPOCHS=30
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 10 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ case "$MODE" in
++ [[ 960 -ne 1 ]]
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
++ [[ 960 -ne 1 ]]
+ SEED=30970
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
+ source run_training.sh
++ export DGXSYSTEM
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ MAX_TOKENS=768
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ MAX_TOKENS=768
++ export DGXSYSTEM
+ DATASET_DIR=/data
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ DATASET_DIR=/data
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ MODE=TRAIN
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ MODE=TRAIN
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
++ declare -a CMD
+ case "$MODE" in
++ '[' -n 14 ']'
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 8 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ declare -a CMD
+ case "$MODE" in
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date +%s
++ '[' -n 14 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ SEED=30970
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ case "$MODE" in
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MAX_TOKENS=768
++ [[ 960 -ne 1 ]]
+ DATASET_DIR=/data
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ declare -a CMD
++ '[' -n 0 ']'
+ MODE=TRAIN
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ NUMEPOCHS=30
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ START=1592872660
+ case "$MODE" in
++ '[' -n 7 ']'
++ export SLURM_NNODES
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ declare -a CMD
++ '[' -n 15 ']'
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
++ '[' -n 7 ']'
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ DATASET_DIR=/data
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ NUMEPOCHS=30
++ [[ 960 -ne 1 ]]
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ case "$MODE" in
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ [[ 960 -ne 1 ]]
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
+++ date +%s
+ MAX_TOKENS=768
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START_FMT='2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ NUMEPOCHS=30
++ '[' -n 1 ']'
++ [[ 960 -ne 1 ]]
+ case "$MODE" in
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
++ export SLURM_NTASKS_PER_NODE
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NNODES
++ declare -a CMD
++ [[ 960 -ne 1 ]]
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 1 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ '[' 960 -gt 60 ']'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
+++ date +%s
++ declare -a CMD
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
+ SEED=30970
++ [[ 960 -ne 1 ]]
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MAX_TOKENS=768
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export SLURM_NTASKS_PER_NODE
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
++ export DGXSYSTEM
++ export SLURM_NNODES
++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ '[' -n 10 ']'
+ NUMEPOCHS=30
+++ date +%s
++ '[' -n 3 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ case "$MODE" in
+ source run_training.sh
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
+++ date +%s
++ '[' -n 6 ']'
++ START=1592872660
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
++ [[ 960 -ne 1 ]]
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MAX_TOKENS=768
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
++ START_FMT='2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ DATASET_DIR=/data
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
++ export DGXSYSTEM
+++ date '+%Y-%m-%d %r'
+ NUMEPOCHS=30
++ [[ 960 -ne 1 ]]
++ export SLURM_NTASKS_PER_NODE
++ [[ 960 -ne 1 ]]
+ case "$MODE" in
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ source run_training.sh
++ export DGXSYSTEM
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
++ declare -a CMD
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ NUMEPOCHS=30
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START=1592872660
++ '[' -n 12 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NNODES
++ declare -a CMD
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ case "$MODE" in
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export DGXSYSTEM
+ source run_training.sh
++ '[' -n 7 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
+ case "$MODE" in
++ export SLURM_NTASKS_PER_NODE
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ START=1592872660
++ export SLURM_NNODES
++ START_FMT='2020-06-22 05:37:40 PM'
+ source run_training.sh
++ declare -a CMD
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 4 ']'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ [[ 960 -ne 1 ]]
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ [[ 960 -ne 1 ]]
Run vars: id 392220 gpus 16 mparams
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START=1592872660
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
+++ date +%s
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ '[' -n 15 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ '[' -n 0 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 15 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NNODES
++ declare -a CMD
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' -n 4 ']'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NNODES
+ SEED=30970
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ START=1592872660
++ declare -a CMD
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MAX_TOKENS=768
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' -n 0 ']'
+ DATASET_DIR=/data
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 13 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 14 ']'
+ MODE=TRAIN
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
++ export SLURM_NNODES
++ declare -a CMD
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ NUMEPOCHS=30
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ case "$MODE" in
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ '[' -n 8 ']'
+ source run_training.sh
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START=1592872660
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
++ '[' -n 6 ']'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ [[ 960 -ne 1 ]]
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+ MODE=TRAIN
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START=1592872660
+ case "$MODE" in
+ source run_training.sh
+ case "$MODE" in
++ '[' -n 12 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
++ '[' -n 11 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ export SLURM_NNODES
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' -n 13 ']'
++ '[' -n 5 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date +%s
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ [[ 960 -ne 1 ]]
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ export DGXSYSTEM
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ source run_training.sh
++ declare -a CMD
+++ date +%s
++ START=1592872660
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ '[' -n 15 ']'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ SEED=30970
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
+ case "$MODE" in
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ SEED=30970
+ MAX_TOKENS=768
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export DGXSYSTEM
+ DATASET_DIR=/data
+++ date '+%Y-%m-%d %r'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START=1592872660
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
++ START=1592872660
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 9 ']'
++ '[' 960 -gt 60 ']'
++ START=1592872660
++ '[' -n 6 ']'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+++ date +%s
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date '+%Y-%m-%d %r'
++ declare -a CMD
++ '[' -n 5 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 9 ']'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MODE=TRAIN
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
+ case "$MODE" in
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ source run_training.sh
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NNODES
++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
++ START_FMT='2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
+ DATASET_DIR=/data
+ MODE=TRAIN
+++ date +%s
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ NUMEPOCHS=30
++ declare -a CMD
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 14 ']'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
++ START=1592872660
+++ date '+%Y-%m-%d %r'
++ '[' -n 9 ']'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START=1592872660
+++ date '+%Y-%m-%d %r'
++ declare -a CMD
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 3 ']'
+++ date '+%Y-%m-%d %r'
+ NUMEPOCHS=30
++ '[' 960 -gt 60 ']'
+ SEED=30970
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
+ case "$MODE" in
+ NUMEPOCHS=30
+ source run_training.sh
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
+++ date +%s
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
++ '[' -n 1 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
+++ date +%s
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NNODES
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
+ MAX_TOKENS=768
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ DATASET_DIR=/data
+ MODE=TRAIN
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+ NUMEPOCHS=30
+ case "$MODE" in
+ MAX_TOKENS=768
++ [[ 960 -ne 1 ]]
+ source run_training.sh
+ DATASET_DIR=/data
+ MODE=TRAIN
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
+ NUMEPOCHS=30
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 15 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ case "$MODE" in
++ '[' -n 1 ']'
+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
++ START_FMT='2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
++ START=1592872660
++ [[ 960 -ne 1 ]]
++ export SLURM_NNODES
++ declare -a CMD
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ [[ 960 -ne 1 ]]
++ declare -a CMD
++ '[' -n 2 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date '+%Y-%m-%d %r'
++ declare -a CMD
+++ date +%s
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+++ date '+%Y-%m-%d %r'
++ START=1592872660
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
++ '[' -n 4 ']'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
++ '[' -n 8 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
+ case "$MODE" in
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+++ date '+%Y-%m-%d %r'
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ MODE=TRAIN
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
+ NUMEPOCHS=30
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ declare -a CMD
++ START=1592872660
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' -n 13 ']'
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' -n 5 ']'
++ '[' 960 -gt 60 ']'
++ START=1592872660
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
++ START=1592872660
++ '[' -n 12 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MAX_TOKENS=768
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
++ export SLURM_NNODES
++ declare -a CMD
+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
++ [[ 960 -ne 1 ]]
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ [[ 960 -ne 1 ]]
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+++ date '+%Y-%m-%d %r'
+++ date +%s
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+++ date +%s
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ SEED=30970
++ '[' -n 3 ']'
++ '[' 960 -gt 60 ']'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ SEED=30970
+ MAX_TOKENS=768
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ declare -a CMD
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
Run vars: id 392220 gpus 16 mparams
++ '[' -n 10 ']'
+++ date +%s
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
+ NUMEPOCHS=30
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' -n 10 ']'
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ case "$MODE" in
+ source run_training.sh
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ source run_training.sh
+++ date +%s
+++ date +%s
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 1 ']'
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
+ SEED=30970
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MAX_TOKENS=768
+ SEED=30970
++ START_FMT='2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ MAX_TOKENS=768
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
+ MODE=TRAIN
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ source run_training.sh
+ NUMEPOCHS=30
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export DGXSYSTEM
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ case "$MODE" in
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
+ source run_training.sh
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
+++ date '+%Y-%m-%d %r'
+ SEED=30970
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ DATASET_DIR=/data
++ '[' -n 9 ']'
++ START=1592872660
+ MODE=TRAIN
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
+ NUMEPOCHS=30
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
+ case "$MODE" in
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ source run_training.sh
+ SEED=30970
++ [[ 960 -ne 1 ]]
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ MODE=TRAIN
++ START_FMT='2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
+ NUMEPOCHS=30
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
++ declare -a CMD
+ source run_training.sh
+ SEED=30970
++ '[' -n 3 ']'
++ START=1592872660
+ MAX_TOKENS=768
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date +%s
+ DATASET_DIR=/data
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+++ date +%s
+ MODE=TRAIN
+++ date '+%Y-%m-%d %r'
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
+ DATASET_DIR=/data
+ MODE=TRAIN
+++ date '+%Y-%m-%d %r'
+ case "$MODE" in
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ NUMEPOCHS=30
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
++ START=1592872660
+ source run_training.sh
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date '+%Y-%m-%d %r'
++ START=1592872660
++ export DGXSYSTEM
+++ date '+%Y-%m-%d %r'
+++ date +%s
++ [[ 960 -ne 1 ]]
+ SEED=30970
+++ date '+%Y-%m-%d %r'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
++ declare -a CMD
+ MAX_TOKENS=768
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ DATASET_DIR=/data
+ SEED=30970
+ MAX_TOKENS=768
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
+ MODE=TRAIN
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ export SLURM_NTASKS_PER_NODE
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
++ export SLURM_NNODES
+ SEED=30970
+ case "$MODE" in
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date +%s
+ DATASET_DIR=/data
+ MODE=TRAIN
++ declare -a CMD
+ source run_training.sh
++ '[' -n 11 ']'
+ MAX_TOKENS=768
++ '[' -n 7 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
+ MODE=TRAIN
++ '[' -n 2 ']'
+ case "$MODE" in
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
+ case "$MODE" in
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NNODES
+ source run_training.sh
++ declare -a CMD
+++ date +%s
+ SEED=30970
++ [[ 960 -ne 1 ]]
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NTASKS_PER_NODE
++ START=1592872660
+ DATASET_DIR=/data
++ export SLURM_NNODES
++ declare -a CMD
+ MODE=TRAIN
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ NUMEPOCHS=30
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
+ source run_training.sh
++ '[' -n 6 ']'
+++ date '+%Y-%m-%d %r'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 9 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export SLURM_NNODES
++ declare -a CMD
+ NUMEPOCHS=30
++ '[' -n 8 ']'
+ case "$MODE" in
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
+ case "$MODE" in
+ source run_training.sh
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ SEED=30970
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ MAX_TOKENS=768
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
++ START=1592872660
++ declare -a CMD
++ START=1592872660
+ MODE=TRAIN
+ NUMEPOCHS=30
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ '[' -n 0 ']'
+ case "$MODE" in
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ [[ 960 -ne 1 ]]
++ START=1592872660
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START=1592872660
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
+++ date +%s
+ MAX_TOKENS=768
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date +%s
+ DATASET_DIR=/data
++ declare -a CMD
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ SEED=30970
+ MAX_TOKENS=768
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
++ '[' -n 12 ']'
+++ date +%s
++ export DGXSYSTEM
+ DATASET_DIR=/data
+ NUMEPOCHS=30
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ MODE=TRAIN
+ NUMEPOCHS=30
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
Run vars: id 392220 gpus 16 mparams
++ declare -a CMD
+ case "$MODE" in
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
+ case "$MODE" in
+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 5 ']'
+++ date +%s
+ MODE=TRAIN
+ NUMEPOCHS=30
++ START=1592872660
+ case "$MODE" in
++ [[ 960 -ne 1 ]]
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export SLURM_NNODES
++ declare -a CMD
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' -n 4 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START_FMT='2020-06-22 05:37:40 PM'
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ [[ 960 -ne 1 ]]
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MODE=TRAIN
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' -n 11 ']'
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MAX_TOKENS=768
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ DATASET_DIR=/data
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ case "$MODE" in
+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
+ MODE=TRAIN
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
++ START=1592872660
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+ SEED=30970
+ SEED=30970
+ MAX_TOKENS=768
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ SEED=30970
+ MAX_TOKENS=768
+ MAX_TOKENS=768
+ source run_training.sh
+ NUMEPOCHS=30
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ DATASET_DIR=/data
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
+ MODE=TRAIN
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
+ case "$MODE" in
+ MODE=TRAIN
+ NUMEPOCHS=30
+ NUMEPOCHS=30
+ source run_training.sh
+ source run_training.sh
+ case "$MODE" in
+ case "$MODE" in
+ source run_training.sh
+ source run_training.sh
+ SEED=30970
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+++ date +%s
+++ date +%s
+ MAX_TOKENS=768
+ MAX_TOKENS=768
++ START=1592872660
+ DATASET_DIR=/data
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+++ date +%s
+ SEED=30970
+ MODE=TRAIN
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
+ MAX_TOKENS=768
+ NUMEPOCHS=30
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
+ MODE=TRAIN
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ NUMEPOCHS=30
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
+ case "$MODE" in
+ source run_training.sh
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ MAX_TOKENS=768
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ SEED=30970
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ source run_training.sh
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ MAX_TOKENS=768
+ source run_training.sh
+ SEED=30970
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ DATASET_DIR=/data
+ MODE=TRAIN
+ MAX_TOKENS=768
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ NUMEPOCHS=30
+ MAX_TOKENS=768
+ MODE=TRAIN
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ case "$MODE" in
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ NUMEPOCHS=30
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ case "$MODE" in
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ MODE=TRAIN
+ NUMEPOCHS=30
+ SEED=30970
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ case "$MODE" in
+ source run_training.sh
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
+ DATASET_DIR=/data
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ MAX_TOKENS=768
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ DATASET_DIR=/data
+ case "$MODE" in
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ MODE=TRAIN
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ NUMEPOCHS=30
+++ date +%s
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
++ START=1592872660
+ DATASET_DIR=/data
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
+++ date +%s
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ NUMEPOCHS=30
+ SEED=30970
+ MAX_TOKENS=768
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ MAX_TOKENS=768
+ case "$MODE" in
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ DATASET_DIR=/data
+ MODE=TRAIN
+ source run_training.sh
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ NUMEPOCHS=30
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ case "$MODE" in
+ SEED=30970
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
+ MAX_TOKENS=768
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ MODE=TRAIN
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
+ NUMEPOCHS=30
+ SEED=30970
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ case "$MODE" in
+ MAX_TOKENS=768
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ source run_training.sh
+ DATASET_DIR=/data
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
+ MODE=TRAIN
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ MODE=TRAIN
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
+ NUMEPOCHS=30
+ MAX_TOKENS=768
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ case "$MODE" in
+ DATASET_DIR=/data
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ MAX_TOKENS=768
+++ date +%s
+ MODE=TRAIN
+ NUMEPOCHS=30
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ DATASET_DIR=/data
+ MODE=TRAIN
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ NUMEPOCHS=30
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
+ source run_training.sh
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ MAX_TOKENS=768
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+ DATASET_DIR=/data
+ MODE=TRAIN
+ source run_training.sh
+ case "$MODE" in
+++ date +%s
+ NUMEPOCHS=30
++ START=1592872660
+ source run_training.sh
+++ date +%s
+ case "$MODE" in
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ MAX_TOKENS=768
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ MAX_TOKENS=768
+ SEED=30970
+ DATASET_DIR=/data
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ DATASET_DIR=/data
+ MODE=TRAIN
+ MAX_TOKENS=768
+ MODE=TRAIN
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ NUMEPOCHS=30
+ DATASET_DIR=/data
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
+ MODE=TRAIN
+ NUMEPOCHS=30
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ MAX_TOKENS=768
+ SEED=30970
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ DATASET_DIR=/data
+ MODE=TRAIN
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ NUMEPOCHS=30
+ DATASET_DIR=/data
+ MODE=TRAIN
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ case "$MODE" in
+++ date +%s
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ source run_training.sh
+ NUMEPOCHS=30
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
+ case "$MODE" in
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ MODE=TRAIN
+ NUMEPOCHS=30
+++ date +%s
+ SEED=30970
+ case "$MODE" in
+ source run_training.sh
+ case "$MODE" in
+ SEED=30970
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
+ source run_training.sh
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ SEED=30970
+ MODE=TRAIN
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
+ MAX_TOKENS=768
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ MAX_TOKENS=768
+ DATASET_DIR=/data
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ MODE=TRAIN
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ source run_training.sh
+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ MAX_TOKENS=768
+ SEED=30970
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ DATASET_DIR=/data
+ MODE=TRAIN
+ MAX_TOKENS=768
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ DATASET_DIR=/data
+ MODE=TRAIN
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MAX_TOKENS=768
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
+ case "$MODE" in
+ DATASET_DIR=/data
+ source run_training.sh
+ MODE=TRAIN
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ NUMEPOCHS=30
+ SEED=30970
+ DATASET_DIR=/data
+ MODE=TRAIN
+ case "$MODE" in
+ SEED=30970
+ MAX_TOKENS=768
+ source run_training.sh
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ START=1592872660
+ case "$MODE" in
+++ date +%s
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ source run_training.sh
+ SEED=30970
+ case "$MODE" in
+ NUMEPOCHS=30
+ MAX_TOKENS=768
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ SEED=30970
+ case "$MODE" in
+ case "$MODE" in
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
+ DATASET_DIR=/data
+ MODE=TRAIN
+++ date +%s
+++ date +%s
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
+ source run_training.sh
++ START=1592872660
+ SEED=30970
+ MAX_TOKENS=768
++ START=1592872660
+ DATASET_DIR=/data
+ MODE=TRAIN
+++ date +%s
+ NUMEPOCHS=30
+++ date +%s
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ source run_training.sh
++ START=1592872660
+ MAX_TOKENS=768
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
+ NUMEPOCHS=30
++ START=1592872660
+ case "$MODE" in
++ START=1592872660
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
+++ date +%s
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+++ date +%s
+++ date '+%Y-%m-%d %r'
+ MAX_TOKENS=768
++ START=1592872660
+ DATASET_DIR=/data
+ MODE=TRAIN
++ START=1592872660
+++ date +%s
+++ date '+%Y-%m-%d %r'
+ NUMEPOCHS=30
++ START=1592872660
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
++ START=1592872660
+ DATASET_DIR=/data
+ SEED=30970
+ MAX_TOKENS=768
+ NUMEPOCHS=30
++ [[ 960 -ne 1 ]]
+ MODE=TRAIN
+ NUMEPOCHS=30
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ source run_training.sh
++ declare -a CMD
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 13 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ START=1592872660
+++ date +%s
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
++ START=1592872660
+ MAX_TOKENS=768
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+++ date '+%Y-%m-%d %r'
+ MODE=TRAIN
++ START_FMT='2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
++ START=1592872660
++ START=1592872660
+ SEED=30970
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ MAX_TOKENS=768
+ SEED=30970
++ export DGXSYSTEM
+ DATASET_DIR=/data
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ MODE=TRAIN
++ declare -a CMD
+ NUMEPOCHS=30
++ '[' -n 6 ']'
+ case "$MODE" in
++ START_FMT='2020-06-22 05:37:40 PM'
+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MAX_TOKENS=768
++ [[ 960 -ne 1 ]]
+ DATASET_DIR=/data
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ MODE=TRAIN
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ case "$MODE" in
++ declare -a CMD
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
++ '[' -n 4 ']'
+ SEED=30970
+ DATASET_DIR=/data
+ MODE=TRAIN
++ '[' 960 -gt 60 ']'
+ MAX_TOKENS=768
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ DATASET_DIR=/data
+ MODE=TRAIN
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ NUMEPOCHS=30
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
+ case "$MODE" in
++ [[ 960 -ne 1 ]]
+ case "$MODE" in
+ source run_training.sh
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ SEED=30970
++ export DGXSYSTEM
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ SEED=30970
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ NUMEPOCHS=30
+ case "$MODE" in
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
++ [[ 960 -ne 1 ]]
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ MODE=TRAIN
+ NUMEPOCHS=30
++ export DGXSYSTEM
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ export SLURM_NTASKS_PER_NODE
+ source run_training.sh
++ export SLURM_NNODES
+ MODE=TRAIN
+ NUMEPOCHS=30
++ declare -a CMD
+ case "$MODE" in
++ '[' -n 7 ']'
+ case "$MODE" in
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
++ '[' -n 1 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
+ MODE=TRAIN
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date +%s
++ [[ 960 -ne 1 ]]
+ SEED=30970
+ NUMEPOCHS=30
+ source run_training.sh
++ [[ 960 -ne 1 ]]
+ MAX_TOKENS=768
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
+ MODE=TRAIN
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ source run_training.sh
++ export SLURM_NNODES
+++ date +%s
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ declare -a CMD
+ SEED=30970
+ case "$MODE" in
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
++ '[' -n 11 ']'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ NUMEPOCHS=30
++ '[' -n 8 ']'
+ case "$MODE" in
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MODE=TRAIN
++ START_FMT='2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ case "$MODE" in
+ source run_training.sh
++ [[ 960 -ne 1 ]]
+++ date +%s
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ SEED=30970
+++ date +%s
++ export DGXSYSTEM
+ MAX_TOKENS=768
++ export SLURM_NTASKS_PER_NODE
+++ date +%s
++ export SLURM_NNODES
++ declare -a CMD
+ DATASET_DIR=/data
+ MODE=TRAIN
++ '[' -n 2 ']'
+ NUMEPOCHS=30
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+++ date +%s
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+++ date +%s
+ DATASET_DIR=/data
+ MODE=TRAIN
++ [[ 960 -ne 1 ]]
+ NUMEPOCHS=30
+++ date +%s
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ case "$MODE" in
++ export DGXSYSTEM
+ source run_training.sh
++ '[' -n 12 ']'
+++ date '+%Y-%m-%d %r'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
+++ date +%s
+++ date '+%Y-%m-%d %r'
++ '[' -n 0 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MODE=TRAIN
+ NUMEPOCHS=30
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ case "$MODE" in
+++ date +%s
++ [[ 960 -ne 1 ]]
+ source run_training.sh
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
+++ date +%s
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START=1592872660
++ declare -a CMD
+++ date +%s
++ '[' -n 9 ']'
+++ date '+%Y-%m-%d %r'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START=1592872660
+++ date '+%Y-%m-%d %r'
+ SEED=30970
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
+ MAX_TOKENS=768
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START=1592872660
++ export DGXSYSTEM
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 14 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
+++ date +%s
++ '[' -n 3 ']'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ '[' 960 -gt 60 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NNODES
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ declare -a CMD
++ '[' -n 12 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
++ [[ 960 -ne 1 ]]
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date '+%Y-%m-%d %r'
++ export DGXSYSTEM
++ START=1592872660
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 15 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ MODE=TRAIN
+ NUMEPOCHS=30
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ [[ 960 -ne 1 ]]
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ case "$MODE" in
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ declare -a CMD
++ export DGXSYSTEM
++ '[' -n 8 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 5 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ START=1592872660
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ '[' -n 10 ']'
++ START=1592872660
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ SEED=30970
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
+ MAX_TOKENS=768
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ DATASET_DIR=/data
+ MODE=TRAIN
+++ date +%s
++ '[' -n 13 ']'
+ NUMEPOCHS=30
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ SEED=30970
+ MAX_TOKENS=768
++ START_FMT='2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
++ START=1592872660
+ case "$MODE" in
+ MODE=TRAIN
+ NUMEPOCHS=30
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
++ [[ 960 -ne 1 ]]
+ case "$MODE" in
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MAX_TOKENS=768
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+++ date '+%Y-%m-%d %r'
+ MODE=TRAIN
+ NUMEPOCHS=30
++ '[' -n 9 ']'
+ case "$MODE" in
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
++ START=1592872660
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
++ START=1592872660
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ START=1592872660
+ MODE=TRAIN
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date '+%Y-%m-%d %r'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ START=1592872660
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+++ date '+%Y-%m-%d %r'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+++ date +%s
++ export SLURM_NNODES
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ '[' -n 5 ']'
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
++ '[' -n 3 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export DGXSYSTEM
++ export SLURM_NNODES
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ '[' -n 10 ']'
++ declare -a CMD
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 4 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
++ START=1592872660
++ [[ 960 -ne 1 ]]
+++ date '+%Y-%m-%d %r'
+ source run_training.sh
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
++ export SLURM_NTASKS_PER_NODE
+++ date '+%Y-%m-%d %r'
++ export SLURM_NNODES
++ declare -a CMD
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
++ '[' -n 0 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ [[ 960 -ne 1 ]]
++ START=1592872660
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ declare -a CMD
++ export DGXSYSTEM
++ '[' -n 11 ']'
++ export SLURM_NTASKS_PER_NODE
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NNODES
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 8 ']'
++ '[' 960 -gt 60 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ [[ 960 -ne 1 ]]
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
++ export SLURM_NNODES
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ MAX_TOKENS=768
++ export SLURM_NTASKS_PER_NODE
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ [[ 960 -ne 1 ]]
+ DATASET_DIR=/data
+ MODE=TRAIN
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NNODES
++ declare -a CMD
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ '[' -n 7 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ export DGXSYSTEM
++ declare -a CMD
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
++ declare -a CMD
++ [[ 960 -ne 1 ]]
++ '[' -n 4 ']'
++ '[' -n 9 ']'
++ '[' 960 -gt 60 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' -n 2 ']'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NNODES
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 15 ']'
++ '[' 960 -gt 60 ']'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ source run_training.sh
++ [[ 960 -ne 1 ]]
++ '[' -n 14 ']'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 6 ']'
++ '[' -n 12 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MAX_TOKENS=768
++ [[ 960 -ne 1 ]]
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START_FMT='2020-06-22 05:37:40 PM'
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 15 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ [[ 960 -ne 1 ]]
+ DATASET_DIR=/data
+ MODE=TRAIN
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ export DGXSYSTEM
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
++ '[' -n 3 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
+ NUMEPOCHS=30
++ '[' -n 2 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' 960 -gt 60 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NNODES
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ case "$MODE" in
++ [[ 960 -ne 1 ]]
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ source run_training.sh
++ [[ 960 -ne 1 ]]
++ export DGXSYSTEM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 10 ']'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ declare -a CMD
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 1 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 0 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+ DATASET_DIR=/data
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
++ START=1592872660
+ NUMEPOCHS=30
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
++ '[' -n 11 ']'
++ '[' 960 -gt 60 ']'
+ MODE=TRAIN
+ NUMEPOCHS=30
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ case "$MODE" in
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
+ source run_training.sh
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
++ export DGXSYSTEM
+ SEED=30970
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 14 ']'
Run vars: id 392220 gpus 16 mparams
++ '[' -n 1 ']'
++ '[' 960 -gt 60 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date +%s
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
++ declare -a CMD
+ DATASET_DIR=/data
+ MODE=TRAIN
++ '[' -n 7 ']'
+ NUMEPOCHS=30
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ case "$MODE" in
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date +%s
+ case "$MODE" in
++ [[ 960 -ne 1 ]]
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date +%s
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ source run_training.sh
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
++ '[' -n 14 ']'
+ DATASET_DIR=/data
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MODE=TRAIN
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ case "$MODE" in
+ DATASET_DIR=/data
+ MODE=TRAIN
++ START_FMT='2020-06-22 05:37:40 PM'
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
++ [[ 960 -ne 1 ]]
+ NUMEPOCHS=30
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
++ export DGXSYSTEM
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export SLURM_NTASKS_PER_NODE
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NNODES
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NNODES
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ export DGXSYSTEM
++ '[' -n 4 ']'
++ export SLURM_NTASKS_PER_NODE
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NNODES
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
++ '[' -n 6 ']'
+++ date '+%Y-%m-%d %r'
++ '[' 960 -gt 60 ']'
+++ date +%s
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 13 ']'
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 9 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
+ NUMEPOCHS=30
+ case "$MODE" in
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ [[ 960 -ne 1 ]]
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ DATASET_DIR=/data
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
+ MODE=TRAIN
+ NUMEPOCHS=30
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ case "$MODE" in
++ declare -a CMD
+ source run_training.sh
++ '[' -n 5 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
+ DATASET_DIR=/data
++ START=1592872660
+ MODE=TRAIN
+ NUMEPOCHS=30
+ source run_training.sh
+ case "$MODE" in
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ source run_training.sh
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ SEED=30970
+ MAX_TOKENS=768
++ export SLURM_NNODES
++ declare -a CMD
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
+ MODE=TRAIN
++ START=1592872660
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
+ case "$MODE" in
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
+ MAX_TOKENS=768
+++ date +%s
+ DATASET_DIR=/data
++ START=1592872660
+ MODE=TRAIN
+ NUMEPOCHS=30
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
++ '[' -n 13 ']'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+ case "$MODE" in
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ source run_training.sh
+++ date +%s
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
+ MAX_TOKENS=768
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
+++ date +%s
+ DATASET_DIR=/data
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MODE=TRAIN
+ NUMEPOCHS=30
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ START=1592872660
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
+ source run_training.sh
++ [[ 960 -ne 1 ]]
+ MAX_TOKENS=768
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ DATASET_DIR=/data
+ MODE=TRAIN
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 12 ']'
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
++ START=1592872660
++ [[ 960 -ne 1 ]]
++ START_FMT='2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
++ export DGXSYSTEM
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ '[' -n 10 ']'
++ export DGXSYSTEM
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date '+%Y-%m-%d %r'
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
++ START=1592872660
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
++ [[ 960 -ne 1 ]]
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ case "$MODE" in
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' -n 9 ']'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ export SLURM_NTASKS_PER_NODE
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NNODES
+++ date '+%Y-%m-%d %r'
++ declare -a CMD
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ '[' -n 5 ']'
++ '[' -n 0 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
+ source run_training.sh
++ START=1592872660
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+++ date '+%Y-%m-%d %r'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START_FMT='2020-06-22 05:37:40 PM'
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ [[ 960 -ne 1 ]]
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' -n 12 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export DGXSYSTEM
+++ date '+%Y-%m-%d %r'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START=1592872660
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 8 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ [[ 960 -ne 1 ]]
++ START=1592872660
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
+++ date +%s
++ [[ 960 -ne 1 ]]
++ '[' -n 3 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' 960 -gt 60 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NTASKS_PER_NODE
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NNODES
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ '[' -n 11 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
+++ date '+%Y-%m-%d %r'
++ export SLURM_NTASKS_PER_NODE
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ export SLURM_NNODES
++ declare -a CMD
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ '[' -n 1 ']'
+++ date +%s
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ '[' 960 -gt 60 ']'
++ declare -a CMD
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' -n 5 ']'
++ '[' 960 -gt 60 ']'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+++ date +%s
++ export DGXSYSTEM
++ START=1592872660
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 14 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 1 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date +%s
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ declare -a CMD
++ '[' -n 6 ']'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+++ date '+%Y-%m-%d %r'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NNODES
++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export DGXSYSTEM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ '[' -n 7 ']'
++ START=1592872660
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' 960 -gt 60 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 2 ']'
++ '[' -n 13 ']'
++ '[' 960 -gt 60 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
++ [[ 960 -ne 1 ]]
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' -n 2 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NNODES
++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 15 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ START=1592872660
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 4 ']'
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NNODES
++ declare -a CMD
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NNODES
++ declare -a CMD
++ [[ 960 -ne 1 ]]
+++ date '+%Y-%m-%d %r'
++ '[' -n 3 ']'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export DGXSYSTEM
++ '[' -n 15 ']'
++ export SLURM_NTASKS_PER_NODE
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NNODES
++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' -n 6 ']'
++ '[' 960 -gt 60 ']'
++ [[ 960 -ne 1 ]]
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export DGXSYSTEM
++ export SLURM_NNODES
++ declare -a CMD
++ export SLURM_NTASKS_PER_NODE
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NNODES
++ '[' -n 8 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ declare -a CMD
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 7 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
+++ date '+%Y-%m-%d %r'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NNODES
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 11 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
+ source run_training.sh
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
+ MAX_TOKENS=768
++ export DGXSYSTEM
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ START=1592872660
++ export SLURM_NNODES
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ declare -a CMD
++ '[' -n 10 ']'
Run vars: id 392220 gpus 16 mparams
++ '[' -n 3 ']'
++ '[' 960 -gt 60 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date '+%Y-%m-%d %r'
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START=1592872660
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ '[' -n 0 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-nRun vars: id 392220 gpus 16 mparams
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NNODES
++ declare -a CMD
++ declare -a CMD
+ SEED=30970
++ '[' -n 12 ']'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ SEED=30970
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ NUMEPOCHS=30
++ '[' -n 15 ']'
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ [[ 960 -ne 1 ]]
+ DATASET_DIR=/data
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ SEED=30970
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export SLURM_NNODES
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
++ declare -a CMD
+ case "$MODE" in
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
+ NUMEPOCHS=30
++ '[' -n 2 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ SEED=30970
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
+ DATASET_DIR=/data
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ MODE=TRAIN
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
++ declare -a CMD
+ SEED=30970
+ SEED=30970
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
+ MAX_TOKENS=768
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MODE=TRAIN
+ NUMEPOCHS=30
++ '[' -n 6 ']'
++ '[' 960 -gt 60 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MODE=TRAIN
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 10 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
+ MODE=TRAIN
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MODE=TRAIN
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
+ SEED=30970
+ case "$MODE" in
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ MAX_TOKENS=768
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ case "$MODE" in
++ START_FMT='2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export SLURM_NNODES
++ declare -a CMD
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ NUMEPOCHS=30
+ case "$MODE" in
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
+ source run_training.sh
+ source run_training.sh
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
+++ date +%s
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ '[' -n 5 ']'
+ SEED=30970
+++ date +%s
++ export SLURM_NNODES
+ MAX_TOKENS=768
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ DATASET_DIR=/data
++ declare -a CMD
+ MODE=TRAIN
+ NUMEPOCHS=30
++ '[' -n 14 ']'
+ case "$MODE" in
++ '[' 960 -gt 60 ']'
+ source run_training.sh
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
+ SEED=30970
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MODE=TRAIN
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
++ declare -a CMD
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuRun vars: id 392220 gpus 16 mparams
++ '[' -n 9 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ [[ 960 -ne 1 ]]
+++ date +%s
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+++ date +%s
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
++ '[' -n 7 ']'
++ [[ 960 -ne 1 ]]
++ '[' 960 -gt 60 ']'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 0 ']'
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ SEED=30970
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 8 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 4 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
+ DATASET_DIR=/data
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MODE=TRAIN
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
+++ date +%s
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START=1592872660
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export DGXSYSTEM
++ START=1592872660
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ SEED=30970
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MAX_TOKENS=768
+ NUMEPOCHS=30
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ NUMEPOCHS=30
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
++ '[' -n 11 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
+ SEED=30970
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START=1592872660
+ MAX_TOKENS=768
++ export DGXSYSTEM
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
+ source run_training.sh
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date '+%Y-%m-%d %r'
++ export DGXSYSTEM
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START=1592872660
++ declare -a CMD
+++ date +%s
++ '[' -n 13 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 1 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
+ DATASET_DIR=/data
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NTASKS_PER_NODE
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NNODES
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 4 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MODE=TRAIN
+ NUMEPOCHS=30
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' -n 0 ']'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
+ MODE=TRAIN
num_sockets = 2 num_nodes=2 cores_per_socket=24
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NNODES
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ declare -a CMD
+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 12 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 13 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
+ NUMEPOCHS=30
++ START=1592872660
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ [[ 960 -ne 1 ]]
+++ date +%s
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ SEED=30970
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ MAX_TOKENS=768
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ DATASET_DIR=/data
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ MODE=TRAIN
++ export SLURM_NNODES
++ declare -a CMD
+ NUMEPOCHS=30
++ declare -a CMD
+ case "$MODE" in
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 2 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' -n 8 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ SEED=30970
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MAX_TOKENS=768
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ DATASET_DIR=/data
+ MODE=TRAIN
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
+ MODE=TRAIN
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ NUMEPOCHS=30
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ case "$MODE" in
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+++ date +%s
++ export SLURM_NNODES
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
++ '[' -n 7 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ declare -a CMD
+ SEED=30970
++ '[' -n 3 ']'
++ START=1592872660
++ '[' 960 -gt 60 ']'
+ SEED=30970
+ MAX_TOKENS=768
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ SEED=30970
+ MAX_TOKENS=768
++ START_FMT='2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ SEED=30970
+ MAX_TOKENS=768
++ declare -a CMD
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ '[' -n 10 ']'
+ case "$MODE" in
+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ DATASET_DIR=/data
+ MODE=TRAIN
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+++ date '+%Y-%m-%d %r'
+ NUMEPOCHS=30
+ case "$MODE" in
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date +%s
++ export DGXSYSTEM
+++ date +%s
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 5 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
+++ date +%s
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
+++ date '+%Y-%m-%d %r'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date '+%Y-%m-%d %r'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ START=1592872660
++ export SLURM_NNODES
++ START=1592872660
++ declare -a CMD
++ START=1592872660
++ '[' -n 1 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
+++ date +%s
++ '[' -n 9 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' -n 14 ']'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NNODES
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 15 ']'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NNODES
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' -n 8 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START=1592872660
++ export DGXSYSTEM
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NNODES
++ declare -a CMD
++ [[ 960 -ne 1 ]]
+ DATASET_DIR=/data
++ '[' -n 14 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ MODE=TRAIN
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
+ NUMEPOCHS=30
++ export SLURM_NTASKS_PER_NODE
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export SLURM_NNODES
++ declare -a CMD
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 11 ']'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 1 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' -n 2 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ declare -a CMD
++ '[' -n 6 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-nnum_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ declare -a CMD
+ MAX_TOKENS=768
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 3 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ DATASET_DIR=/data
+ MODE=TRAIN
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ NUMEPOCHS=30
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
++ START=1592872660
+ source run_training.sh
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
+ SEED=30970
++ START_FMT='2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ MAX_TOKENS=768
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ source run_training.sh
+ DATASET_DIR=/data
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
+++ date +%s
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date +%s
+ MODE=TRAIN
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NNODES
++ declare -a CMD
+ SEED=30970
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ MAX_TOKENS=768
++ export SLURM_NNODES
++ declare -a CMD
+ DATASET_DIR=/data
++ '[' -n 0 ']'
+ MODE=TRAIN
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ NUMEPOCHS=30
++ '[' -n 10 ']'
+ case "$MODE" in
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
+ MODE=TRAIN
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ NUMEPOCHS=30
+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
+ MODE=TRAIN
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 5 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MODE=TRAIN
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MODE=TRAIN
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NNODES
++ declare -a CMD
+ SEED=30970
+ MAX_TOKENS=768
++ '[' -n 15 ']'
+ DATASET_DIR=/data
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ DATASET_DIR=/data
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MODE=TRAIN
+ NUMEPOCHS=30
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ case "$MODE" in
+ case "$MODE" in
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ source run_training.sh
++ export SLURM_NNODES
++ declare -a CMD
+ source run_training.sh
++ '[' -n 7 ']'
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date +%s
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+++ date +%s
+ source run_training.sh
+++ date +%s
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+++ date +%s
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date '+%Y-%m-%d %r'
+ SEED=30970
++ declare -a CMD
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
++ '[' -n 12 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ '[' -n 4 ']'
+ MAX_TOKENS=768
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ MODE=TRAIN
+ NUMEPOCHS=30
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MAX_TOKENS=768
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
+ DATASET_DIR=/data
+ MODE=TRAIN
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ DATASET_DIR=/data
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 11 ']'
+ MODE=TRAIN
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ case "$MODE" in
++ [[ 960 -ne 1 ]]
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
+ source run_training.sh
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ MAX_TOKENS=768
++ declare -a CMD
+ DATASET_DIR=/data
++ '[' -n 6 ']'
+ MODE=TRAIN
++ '[' 960 -gt 60 ']'
+ NUMEPOCHS=30
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ case "$MODE" in
++ START_FMT='2020-06-22 05:37:40 PM'
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
+++ date +%s
++ [[ 960 -ne 1 ]]
+ MAX_TOKENS=768
+++ date +%s
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export DGXSYSTEM
+ NUMEPOCHS=30
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ case "$MODE" in
++ declare -a CMD
+ source run_training.sh
++ '[' -n 13 ']'
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
++ START=1592872660
++ [[ 960 -ne 1 ]]
+++ date +%s
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date '+%Y-%m-%d %r'
+ SEED=30970
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+++ date '+%Y-%m-%d %r'
++ export SLURM_NNODES
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
++ '[' -n 9 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
+ MAX_TOKENS=768
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export DGXSYSTEM
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ '[' -n 1 ']'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ case "$MODE" in
++ START_FMT='2020-06-22 05:37:40 PM'
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
+ SEED=30970
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ MODE=TRAIN
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+ NUMEPOCHS=30
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ case "$MODE" in
++ export SLURM_NNODES
++ declare -a CMD
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MAX_TOKENS=768
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ '[' -n 4 ']'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ NUMEPOCHS=30
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ case "$MODE" in
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
+++ date +%s
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
++ START=1592872660
+++ date '+%Y-%m-%d %r'
+ MAX_TOKENS=768
++ START=1592872660
+ SEED=30970
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START=1592872660
+ DATASET_DIR=/data
+++ date '+%Y-%m-%d %r'
+ MAX_TOKENS=768
++ START=1592872660
+ MODE=TRAIN
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ MODE=TRAIN
+++ date '+%Y-%m-%d %r'
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
+++ date '+%Y-%m-%d %r'
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ source run_training.sh
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ SEED=30970
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export SLURM_NTASKS_PER_NODE
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
++ export SLURM_NNODES
+ DATASET_DIR=/data
+ MODE=TRAIN
++ declare -a CMD
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
++ '[' -n 12 ']'
+++ date +%s
++ '[' 960 -gt 60 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
+++ date +%s
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ SEED=30970
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
+ MODE=TRAIN
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ SEED=30970
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ MAX_TOKENS=768
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
+ MODE=TRAIN
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 2 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ NUMEPOCHS=30
++ '[' -n 3 ']'
++ '[' 960 -gt 60 ']'
+ case "$MODE" in
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
+ SEED=30970
+ MAX_TOKENS=768
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ START_FMT='2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ case "$MODE" in
++ export SLURM_NNODES
+ source run_training.sh
++ declare -a CMD
++ START=1592872660
++ START=1592872660
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
++ export DGXSYSTEM
+++ date '+%Y-%m-%d %r'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
++ '[' -n 10 ']'
++ '[' 960 -gt 60 ']'
+++ date +%s
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
++ '[' -n 14 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
+++ date '+%Y-%m-%d %r'
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export SLURM_NTASKS_PER_NODE
+++ date '+%Y-%m-%d %r'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NNODES
++ declare -a CMD
++ START=1592872660
++ '[' -n 6 ']'
++ START=1592872660
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ declare -a CMD
++ export DGXSYSTEM
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 13 ']'
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NNODES
++ declare -a CMD
++ '[' 960 -gt 60 ']'
++ '[' -n 8 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ [[ 960 -ne 1 ]]
++ export DGXSYSTEM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 6 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 11 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
++ export SLURM_NTASKS_PER_NODE
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export SLURM_NNODES
++ export DGXSYSTEM
++ declare -a CMD
++ export SLURM_NTASKS_PER_NODE
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NNODES
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
++ declare -a CMD
++ '[' -n 5 ']'
++ '[' -n 12 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ START_FMT='2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export SLURM_NNODES
++ [[ 960 -ne 1 ]]
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ [[ 960 -ne 1 ]]
++ [[ 960 -ne 1 ]]
++ '[' -n 0 ']'
++ '[' 960 -gt 60 ']'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ declare -a CMD
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NNODES
++ declare -a CMD
++ export SLURM_NTASKS_PER_NODE
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ declare -a CMD
++ [[ 960 -ne 1 ]]
++ '[' -n 2 ']'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' 960 -gt 60 ']'
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuRun vars: id 392220 gpus 16 mparams
++ '[' -n 13 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NNODES
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 15 ']'
++ [[ 960 -ne 1 ]]
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 10 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export DGXSYSTEM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
Run vars: id 392220 gpus 16 mparams
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ [[ 960 -ne 1 ]]
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ SEED=30970
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
++ export DGXSYSTEM
++ '[' -n 5 ']'
++ export SLURM_NTASKS_PER_NODE
++ '[' -n 15 ']'
++ export SLURM_NNODES
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ declare -a CMD
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 9 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ [[ 960 -ne 1 ]]
+ MAX_TOKENS=768
+ SEED=30970
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ export SLURM_NNODES
++ declare -a CMD
++ declare -a CMD
++ '[' -n 7 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' -n 14 ']'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
++ [[ 960 -ne 1 ]]
+ SEED=30970
+ MAX_TOKENS=768
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ export DGXSYSTEM
+ DATASET_DIR=/data
++ export SLURM_NTASKS_PER_NODE
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MODE=TRAIN
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ NUMEPOCHS=30
++ declare -a CMD
+ case "$MODE" in
++ '[' -n 1 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
+ MODE=TRAIN
+ NUMEPOCHS=30
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MAX_TOKENS=768
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ DATASET_DIR=/data
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ MODE=TRAIN
+ NUMEPOCHS=30
++ [[ 960 -ne 1 ]]
+ case "$MODE" in
+ case "$MODE" in
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date +%s
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date +%s
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ declare -a CMD
+++ date +%s
+++ date +%s
++ export DGXSYSTEM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ declare -a CMD
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 4 ']'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ SEED=30970
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MAX_TOKENS=768
+ SEED=30970
++ export DGXSYSTEM
++ '[' -n 7 ']'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
+ MAX_TOKENS=768
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
+ case "$MODE" in
++ declare -a CMD
+ source run_training.sh
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ MAX_TOKENS=768
++ '[' -n 11 ']'
+ DATASET_DIR=/data
+ MODE=TRAIN
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
+ NUMEPOCHS=30
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' -n 3 ']'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 8 ']'
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuRun vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ case "$MODE" in
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
++ [[ 960 -ne 1 ]]
+++ date +%s
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
+ MAX_TOKENS=768
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NNODES
++ declare -a CMD
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 9 ']'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
+ MODE=TRAIN
+ NUMEPOCHS=30
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MAX_TOKENS=768
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ case "$MODE" in
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ case "$MODE" in
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
++ [[ 960 -ne 1 ]]
+ DATASET_DIR=/data
+ MODE=TRAIN
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ NUMEPOCHS=30
+ SEED=30970
++ export SLURM_NTASKS_PER_NODE
+ case "$MODE" in
++ export SLURM_NNODES
++ declare -a CMD
+ source run_training.sh
++ '[' -n 7 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ SEED=30970
+ MAX_TOKENS=768
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MAX_TOKENS=768
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ DATASET_DIR=/data
++ START_FMT='2020-06-22 05:37:40 PM'
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ source run_training.sh
+ DATASET_DIR=/data
+ MODE=TRAIN
++ [[ 960 -ne 1 ]]
+++ date +%s
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+++ date +%s
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date +%s
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
++ '[' -n 0 ']'
++ START=1592872660
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ SEED=30970
+ NUMEPOCHS=30
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ case "$MODE" in
+ case "$MODE" in
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ SEED=30970
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ START=1592872660
+ MODE=TRAIN
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+++ date +%s
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
+ source run_training.sh
++ START=1592872660
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date +%s
++ START=1592872660
++ START=1592872660
++ START=1592872660
+++ date +%s
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
+ SEED=30970
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
+ MODE=TRAIN
++ START=1592872660
+ NUMEPOCHS=30
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ SEED=30970
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
+ case "$MODE" in
+ source run_training.sh
+ DATASET_DIR=/data
++ START=1592872660
+ MODE=TRAIN
+ NUMEPOCHS=30
++ START=1592872660
++ START=1592872660
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
+ SEED=30970
++ START=1592872660
+ MAX_TOKENS=768
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ START=1592872660
+ NUMEPOCHS=30
+++ date '+%Y-%m-%d %r'
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ START=1592872660
+++ date +%s
++ START=1592872660
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date '+%Y-%m-%d %r'
++ START=1592872660
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
Run vars: id 392220 gpus 16 mparams
+++ date +%s
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date '+%Y-%m-%d %r'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NNODES
+++ date '+%Y-%m-%d %r'
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ '[' -n 2 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
++ START=1592872660
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+++ date '+%Y-%m-%d %r'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ [[ 960 -ne 1 ]]
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ declare -a CMD
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 0 ']'
++ export DGXSYSTEM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ START=1592872660
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START=1592872660
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 7 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ declare -a CMD
++ [[ 960 -ne 1 ]]
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 10 ']'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export DGXSYSTEM
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export DGXSYSTEM
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ '[' -n 14 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export SLURM_NNODES
++ declare -a CMD
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 3 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ declare -a CMD
++ '[' -n 11 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 13 ']'
++ '[' 960 -gt 60 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
++ declare -a CMD
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
++ '[' -n 4 ']'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ [[ 960 -ne 1 ]]
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NNODES
++ declare -a CMD
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START=1592872660
++ declare -a CMD
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 14 ']'
++ '[' 960 -gt 60 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NNODES
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 1 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 6 ']'
++ '[' 960 -gt 60 ']'
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ [[ 960 -ne 1 ]]
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
++ [[ 960 -ne 1 ]]
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 6 ']'
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 3 ']'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START_FMT='2020-06-22 05:37:40 PM'
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 9 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-nSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ declare -a CMD
++ '[' -n 0 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 8 ']'
++ [[ 960 -ne 1 ]]
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' -n 13 ']'
++ export DGXSYSTEM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NTASKS_PER_NODE
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 5 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NNODES
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 11 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
++ '[' -n 1 ']'
++ [[ 960 -ne 1 ]]
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export DGXSYSTEM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 15 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ [[ 960 -ne 1 ]]
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ [[ 960 -ne 1 ]]
++ export SLURM_NTASKS_PER_NODE
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export SLURM_NNODES
++ declare -a CMD
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 8 ']'
++ export DGXSYSTEM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NTASKS_PER_NODE
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NNODES
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 5 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 4 ']'
++ [[ 960 -ne 1 ]]
++ '[' 960 -gt 60 ']'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export DGXSYSTEM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ [[ 960 -ne 1 ]]
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ declare -a CMD
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ '[' -n 2 ']'
++ export SLURM_NTASKS_PER_NODE
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ export SLURM_NNODES
++ declare -a CMD
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 12 ']'
++ '[' -n 12 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' -n 10 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-nnum_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export DGXSYSTEM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 9 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START_FMT='2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export DGXSYSTEM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ '[' -n 15 ']'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ source run_training.sh
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date +%s
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ MAX_TOKENS=768
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ DATASET_DIR=/data
+ MODE=TRAIN
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ MAX_TOKENS=768
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-nslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ case "$MODE" in
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-nslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ MAX_TOKENS=768
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
+ MODE=TRAIN
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ NUMEPOCHS=30
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-nslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ source run_training.sh
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ SEED=30970
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ MODE=TRAIN
+ case "$MODE" in
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ NUMEPOCHS=30
+ case "$MODE" in
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
+++ date +%s
+++ date +%s
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
+ SEED=30970
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MODE=TRAIN
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ NUMEPOCHS=30
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ source run_training.sh
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MAX_TOKENS=768
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-Run vars: id 392220 gpus 16 mparams
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date +%s
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ MAX_TOKENS=768
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ DATASET_DIR=/data
+ MODE=TRAIN
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ SEED=30970
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ source run_training.sh
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ NUMEPOCHS=30
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ case "$MODE" in
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
+++ date +%s
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuRun vars: id 392220 gpus 16 mparams
+ SEED=30970
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
+ MAX_TOKENS=768
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ DATASET_DIR=/data
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MODE=TRAIN
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ case "$MODE" in
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date '+%Y-%m-%d %r'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuRun vars: id 392220 gpus 16 mparams
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date '+%Y-%m-%d %r'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date +%s
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START=1592872660
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ SEED=30970
+ SEED=30970
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ DATASET_DIR=/data
+ MODE=TRAIN
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
+ source run_training.sh
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ NUMEPOCHS=30
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-+ case "$MODE" in
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+++ date '+%Y-%m-%d %r'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ SEED=30970
+ DATASET_DIR=/data
+ MODE=TRAIN
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ DATASET_DIR=/data
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuRun vars: id 392220 gpus 16 mparams
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
+ MODE=TRAIN
+ NUMEPOCHS=30
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu--num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ DATASET_DIR=/data
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MODE=TRAIN
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ NUMEPOCHS=30
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ NUMEPOCHS=30
+++ date +%s
+ case "$MODE" in
+ source run_training.sh
+ SEED=30970
+++ date +%s
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MAX_TOKENS=768
+++ date +%s
+ DATASET_DIR=/data
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MODE=TRAIN
+ NUMEPOCHS=30
+ SEED=30970
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
+ source run_training.sh
+ MAX_TOKENS=768
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ MODE=TRAIN
+++ date +%s
+ NUMEPOCHS=30
+++ date +%s
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date +%s
+ case "$MODE" in
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu--num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START_FMT='2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ export DGXSYSTEM
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu--num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ declare -a CMD
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+++ date '+%Y-%m-%d %r'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 13 ']'
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu--num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num_sockets = 2 num_nodes=2 cores_per_socket=24
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START=1592872660
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date '+%Y-%m-%d %r'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-nnum_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
+ source run_training.sh
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ SEED=30970
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
+ DATASET_DIR=/data
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NNODES
+ MODE=TRAIN
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-nRun vars: id 392220 gpus 16 mparams
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
+ case "$MODE" in
++ START_FMT='2020-06-22 05:37:40 PM'
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 9 ']'
+ SEED=30970
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ [[ 960 -ne 1 ]]
+ SEED=30970
+ MAX_TOKENS=768
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MAX_TOKENS=768
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ export DGXSYSTEM
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+++ date '+%Y-%m-%d %r'
+ NUMEPOCHS=30
++ export SLURM_NTASKS_PER_NODE
+ case "$MODE" in
++ export SLURM_NNODES
+ case "$MODE" in
++ declare -a CMD
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date '+%Y-%m-%d %r'
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
+ DATASET_DIR=/data
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ MODE=TRAIN
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
+ case "$MODE" in
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
+++ date +%s
++ '[' -n 6 ']'
+++ date +%s
++ declare -a CMD
+++ date +%s
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
++ '[' -n 10 ']'
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
Run vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ DATASET_DIR=/data
+ MODE=TRAIN
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ case "$MODE" in
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ [[ 960 -ne 1 ]]
+ source run_training.sh
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START=1592872660
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export SLURM_NNODES
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 2 ']'
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date '+%Y-%m-%d %r'
+ MAX_TOKENS=768
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
+ MODE=TRAIN
+ NUMEPOCHS=30
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ case "$MODE" in
+ source run_training.sh
++ [[ 960 -ne 1 ]]
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-nnum_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuRun vars: id 392220 gpus 16 mparams
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NNODES
++ declare -a CMD
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
++ '[' -n 0 ']'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+++ date '+%Y-%m-%d %r'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuRun vars: id 392220 gpus 16 mparams
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-nRun vars: id 392220 gpus 16 mparams
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ MAX_TOKENS=768
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ DATASET_DIR=/data
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MODE=TRAIN
+ NUMEPOCHS=30
++ '[' -n 1 ']'
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ source run_training.sh
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ START_FMT='2020-06-22 05:37:40 PM'
+ MODE=TRAIN
+ NUMEPOCHS=30
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-Run vars: id 392220 gpus 16 mparams
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ [[ 960 -ne 1 ]]
+ source run_training.sh
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ SEED=30970
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NNODES
++ declare -a CMD
+ MAX_TOKENS=768
++ '[' -n 5 ']'
+ DATASET_DIR=/data
+ MODE=TRAIN
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ case "$MODE" in
+ source run_training.sh
++ [[ 960 -ne 1 ]]
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu--num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export DGXSYSTEM
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export SLURM_NNODES
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 3 ']'
+ SEED=30970
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MAX_TOKENS=768
++ START_FMT='2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
+ case "$MODE" in
++ [[ 960 -ne 1 ]]
+ source run_training.sh
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NNODES
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuRun vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuRun vars: id 392220 gpus 16 mparams
++ '[' -n 4 ']'
++ '[' 960 -gt 60 ']'
+++ date '+%Y-%m-%d %r'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 11 ']'
++ '[' 960 -gt 60 ']'
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ START=1592872660
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 15 ']'
+++ date '+%Y-%m-%d %r'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date +%s
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ START=1592872660
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date '+%Y-%m-%d %r'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ START=1592872660
++ export SLURM_NNODES
+++ date '+%Y-%m-%d %r'
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ declare -a CMD
++ START=1592872660
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' -n 7 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NNODES
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ declare -a CMD
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 14 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ [[ 960 -ne 1 ]]
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
++ '[' -n 8 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NNODES
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export DGXSYSTEM
++ '[' -n 13 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NTASKS_PER_NODE
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ export SLURM_NNODES
++ '[' -n 12 ']'
++ START=1592872660
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' -n 3 ']'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date '+%Y-%m-%d %r'
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NNODES
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ [[ 960 -ne 1 ]]
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-Run vars: id 392220 gpus 16 mparams
++ '[' -n 11 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ declare -a CMD
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' -n 7 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-nSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ [[ 960 -ne 1 ]]
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export DGXSYSTEM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ declare -a CMD
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' -n 12 ']'
Run vars: id 392220 gpus 16 mparams
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START_FMT='2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ [[ 960 -ne 1 ]]
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
+ case "$MODE" in
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
++ '[' -n 10 ']'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MODE=TRAIN
+ NUMEPOCHS=30
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ case "$MODE" in
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
+++ date +%s
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
++ export SLURM_NNODES
+ MAX_TOKENS=768
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-nnum_sockets = 2 num_nodes=2 cores_per_socket=24
++ declare -a CMD
+ DATASET_DIR=/data
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
+ MODE=TRAIN
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ NUMEPOCHS=30
++ '[' -n 8 ']'
++ '[' 960 -gt 60 ']'
+ case "$MODE" in
+ source run_training.sh
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
+ MAX_TOKENS=768
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
++ '[' -n 4 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ DATASET_DIR=/data
+ MODE=TRAIN
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ declare -a CMD
+ source run_training.sh
++ '[' -n 6 ']'
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ START_FMT='2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ source run_training.sh
++ START=1592872660
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ [[ 960 -ne 1 ]]
+ MAX_TOKENS=768
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ NUMEPOCHS=30
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+++ date '+%Y-%m-%d %r'
++ export DGXSYSTEM
+ case "$MODE" in
+ source run_training.sh
++ export SLURM_NNODES
++ declare -a CMD
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ SEED=30970
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ '[' -n 9 ']'
+ MAX_TOKENS=768
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 15 ']'
++ '[' 960 -gt 60 ']'
+ DATASET_DIR=/data
+ MODE=TRAIN
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ source run_training.sh
++ [[ 960 -ne 1 ]]
+ SEED=30970
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
+ MODE=TRAIN
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ NUMEPOCHS=30
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ case "$MODE" in
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
++ export SLURM_NNODES
++ declare -a CMD
++ START=1592872660
++ '[' -n 2 ']'
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
++ START_FMT='2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
++ [[ 960 -ne 1 ]]
+ source run_training.sh
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date +%s
++ export DGXSYSTEM
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' -n 5 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
++ '[' -n 0 ']'
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
Run vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
+ MAX_TOKENS=768
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ case "$MODE" in
+ source run_training.sh
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
+ SEED=30970
Run vars: id 392220 gpus 16 mparams
++ '[' -n 14 ']'
+ MAX_TOKENS=768
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ DATASET_DIR=/data
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MODE=TRAIN
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MODE=TRAIN
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 1 ']'
+ NUMEPOCHS=30
+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-nnum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
++ export DGXSYSTEM
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ declare -a CMD
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export SLURM_NTASKS_PER_NODE
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export SLURM_NNODES
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' -n 12 ']'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' -n 3 ']'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START_FMT='2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date +%s
Run vars: id 392220 gpus 16 mparams
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ SEED=30970
++ export SLURM_NNODES
+ MAX_TOKENS=768
++ [[ 960 -ne 1 ]]
++ declare -a CMD
+ DATASET_DIR=/data
++ '[' -n 0 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MODE=TRAIN
+++ date '+%Y-%m-%d %r'
+ NUMEPOCHS=30
+++ date '+%Y-%m-%d %r'
+ case "$MODE" in
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
+ case "$MODE" in
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
++ export DGXSYSTEM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ [[ 960 -ne 1 ]]
+ MODE=TRAIN
+ NUMEPOCHS=30
++ export SLURM_NTASKS_PER_NODE
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ case "$MODE" in
++ export DGXSYSTEM
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ SEED=30970
++ export SLURM_NNODES
++ START=1592872660
+ MAX_TOKENS=768
++ '[' -n 11 ']'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ NUMEPOCHS=30
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ case "$MODE" in
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ SEED=30970
++ declare -a CMD
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ MAX_TOKENS=768
++ START=1592872660
+ DATASET_DIR=/data
+ MODE=TRAIN
++ '[' -n 15 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ case "$MODE" in
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
+ SEED=30970
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export SLURM_NTASKS_PER_NODE
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NNODES
++ declare -a CMD
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-nSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 4 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date '+%Y-%m-%d %r'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+++ date '+%Y-%m-%d %r'
+ MODE=TRAIN
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ NUMEPOCHS=30
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
+ source run_training.sh
++ [[ 960 -ne 1 ]]
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 3 ']'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+++ date +%s
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ '[' -n 2 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ SEED=30970
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ START_FMT='2020-06-22 05:37:40 PM'
+ MODE=TRAIN
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ declare -a CMD
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ DATASET_DIR=/data
+ MODE=TRAIN
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 5 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 13 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ DATASET_DIR=/data
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ MODE=TRAIN
+ NUMEPOCHS=30
++ [[ 960 -ne 1 ]]
+ NUMEPOCHS=30
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ case "$MODE" in
++ export DGXSYSTEM
+ case "$MODE" in
++ export SLURM_NTASKS_PER_NODE
+ source run_training.sh
++ export SLURM_NNODES
++ declare -a CMD
+ source run_training.sh
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
++ [[ 960 -ne 1 ]]
++ '[' -n 8 ']'
+ MAX_TOKENS=768
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ DATASET_DIR=/data
++ START_FMT='2020-06-22 05:37:40 PM'
+ MODE=TRAIN
+ NUMEPOCHS=30
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ case "$MODE" in
+ source run_training.sh
++ [[ 960 -ne 1 ]]
+++ date +%s
++ export DGXSYSTEM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date '+%Y-%m-%d %r'
++ export DGXSYSTEM
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date +%s
++ declare -a CMD
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date +%s
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 14 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
+ MODE=TRAIN
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
+ NUMEPOCHS=30
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ case "$MODE" in
++ export DGXSYSTEM
+ source run_training.sh
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ SEED=30970
++ '[' -n 7 ']'
+ MAX_TOKENS=768
++ '[' 960 -gt 60 ']'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ NUMEPOCHS=30
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ case "$MODE" in
+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MAX_TOKENS=768
++ START_FMT='2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ MODE=TRAIN
+ NUMEPOCHS=30
++ [[ 960 -ne 1 ]]
+ case "$MODE" in
++ declare -a CMD
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ declare -a CMD
++ START=1592872660
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 9 ']'
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NNODES
++ declare -a CMD
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ SEED=30970
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 6 ']'
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ declare -a CMD
+ case "$MODE" in
++ '[' -n 6 ']'
+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
++ '[' 960 -gt 60 ']'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ [[ 960 -ne 1 ]]
++ '[' -n 5 ']'
++ '[' -n 10 ']'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NTASKS_PER_NODE
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NNODES
++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 5 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 1 ']'
++ START=1592872660
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+++ date +%s
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date '+%Y-%m-%d %r'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ START=1592872660
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ [[ 960 -ne 1 ]]
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ declare -a CMD
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export SLURM_NNODES
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' -n 11 ']'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ '[' -n 9 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START_FMT='2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ [[ 960 -ne 1 ]]
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export SLURM_NTASKS_PER_NODE
++ export DGXSYSTEM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ declare -a CMD
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 14 ']'
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NNODES
++ declare -a CMD
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-nnum_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NNODES
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' -n 13 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 6 ']'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 12 ']'
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ declare -a CMD
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 15 ']'
++ '[' 960 -gt 60 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ declare -a CMD
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' -n 14 ']'
++ '[' 960 -gt 60 ']'
++ '[' -n 8 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ '[' -n 13 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NNODES
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 7 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ declare -a CMD
++ '[' -n 7 ']'
++ [[ 960 -ne 1 ]]
++ '[' 960 -gt 60 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START_FMT='2020-06-22 05:37:40 PM'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-nslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ declare -a CMD
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START_FMT='2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-nslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NNODES
++ declare -a CMD
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ '[' -n 1 ']'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ [[ 960 -ne 1 ]]
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
++ '[' -n 15 ']'
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-++ START=1592872660
++ '[' -n 4 ']'
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MAX_TOKENS=768
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ [[ 960 -ne 1 ]]
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ declare -a CMD
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' -n 2 ']'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export SLURM_NNODES
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 0 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
+ MODE=TRAIN
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 7 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ export SLURM_NNODES
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
++ '[' -n 3 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ DATASET_DIR=/data
+ MODE=TRAIN
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
++ export DGXSYSTEM
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ NUMEPOCHS=30
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ case "$MODE" in
++ START_FMT='2020-06-22 05:37:40 PM'
++ declare -a CMD
+ source run_training.sh
++ '[' -n 10 ']'
+ SEED=30970
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
++ '[' -n 12 ']'
++ '[' 960 -gt 60 ']'
+ DATASET_DIR=/data
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MODE=TRAIN
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ NUMEPOCHS=30
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 1 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ case "$MODE" in
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
++ START=1592872660
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MODE=TRAIN
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ SEED=30970
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
++ '[' -n 8 ']'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
++ START=1592872660
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuRun vars: id 392220 gpus 16 mparams
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
+ DATASET_DIR=/data
+ MODE=TRAIN
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ SEED=30970
++ export DGXSYSTEM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
++ export SLURM_NTASKS_PER_NODE
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export SLURM_NNODES
++ declare -a CMD
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-+ NUMEPOCHS=30
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ source run_training.sh
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START=1592872660
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date +%s
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+++ date +%s
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-nnum_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
++ '[' -n 4 ']'
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
+ MODE=TRAIN
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ source run_training.sh
+ SEED=30970
++ [[ 960 -ne 1 ]]
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ DATASET_DIR=/data
++ export DGXSYSTEM
+ MODE=TRAIN
++ export SLURM_NTASKS_PER_NODE
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NNODES
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
++ '[' -n 2 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ DATASET_DIR=/data
+ MODE=TRAIN
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
+ case "$MODE" in
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
+ source run_training.sh
+ case "$MODE" in
++ [[ 960 -ne 1 ]]
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date +%s
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date +%s
+++ date +%s
++ export DGXSYSTEM
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START=1592872660
++ [[ 960 -ne 1 ]]
+++ date +%s
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date '+%Y-%m-%d %r'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ declare -a CMD
+ SEED=30970
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ MAX_TOKENS=768
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NNODES
+ DATASET_DIR=/data
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MODE=TRAIN
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ declare -a CMD
+ NUMEPOCHS=30
++ '[' -n 15 ']'
+ case "$MODE" in
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 11 ']'
++ START=1592872660
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ [[ 960 -ne 1 ]]
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
++ export DGXSYSTEM
+++ date '+%Y-%m-%d %r'
++ export SLURM_NTASKS_PER_NODE
+++ date +%s
++ export SLURM_NNODES
++ '[' -n 6 ']'
++ '[' 960 -gt 60 ']'
++ declare -a CMD
++ START=1592872660
++ '[' -n 6 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ [[ 960 -ne 1 ]]
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ '[' -n 3 ']'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' -n 10 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ '[' -n 14 ']'
++ START=1592872660
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START=1592872660
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
++ START_FMT='2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ declare -a CMD
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ case "$MODE" in
+ source run_training.sh
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ [[ 960 -ne 1 ]]
++ '[' -n 3 ']'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START_FMT='2020-06-22 05:37:40 PM'
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' -n 13 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 12 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+++ date '+%Y-%m-%d %r'
++ export SLURM_NNODES
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NNODES
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 0 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ declare -a CMD
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ [[ 960 -ne 1 ]]
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ '[' -n 5 ']'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' 960 -gt 60 ']'
++ export DGXSYSTEM
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ declare -a CMD
++ '[' -n 14 ']'
++ [[ 960 -ne 1 ]]
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 5 ']'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export DGXSYSTEM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 13 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ declare -a CMD
++ [[ 960 -ne 1 ]]
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 15 ']'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ declare -a CMD
++ '[' -n 1 ']'
++ [[ 960 -ne 1 ]]
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
++ '[' -n 8 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ [[ 960 -ne 1 ]]
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu--num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ declare -a CMD
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export SLURM_NNODES
++ declare -a CMD
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 2 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 11 ']'
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+++ date '+%Y-%m-%d %r'
+ MODE=TRAIN
+ NUMEPOCHS=30
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export SLURM_NNODES
++ declare -a CMD
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export DGXSYSTEM
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ export SLURM_NTASKS_PER_NODE
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NNODES
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ declare -a CMD
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 0 ']'
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 4 ']'
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' 960 -gt 60 ']'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ DATASET_DIR=/data
+ MODE=TRAIN
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 7 ']'
+ NUMEPOCHS=30
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ case "$MODE" in
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ source run_training.sh
++ export DGXSYSTEM
+ SEED=30970
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
+ MODE=TRAIN
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
++ declare -a CMD
+ source run_training.sh
++ '[' -n 9 ']'
+ SEED=30970
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
++ '[' -n 10 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MODE=TRAIN
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ NUMEPOCHS=30
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NNODES
++ declare -a CMD
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ MAX_TOKENS=768
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ DATASET_DIR=/data
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ MODE=TRAIN
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ NUMEPOCHS=30
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
++ [[ 960 -ne 1 ]]
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date '+%Y-%m-%d %r'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ MAX_TOKENS=768
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 0 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
++ declare -a CMD
+ SEED=30970
++ START=1592872660
+ SEED=30970
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
++ '[' -n 9 ']'
++ '[' 960 -gt 60 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-nnum_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ SEED=30970
+ MAX_TOKENS=768
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ [[ 960 -ne 1 ]]
+ DATASET_DIR=/data
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ case "$MODE" in
+ source run_training.sh
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ MODE=TRAIN
+ NUMEPOCHS=30
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ MAX_TOKENS=768
+ DATASET_DIR=/data
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ SEED=30970
++ export SLURM_NNODES
++ declare -a CMD
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ SEED=30970
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MODE=TRAIN
+ NUMEPOCHS=30
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ case "$MODE" in
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 7 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MODE=TRAIN
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MODE=TRAIN
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NNODES
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 1 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MAX_TOKENS=768
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
++ [[ 960 -ne 1 ]]
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ MAX_TOKENS=768
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export DGXSYSTEM
+ NUMEPOCHS=30
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ case "$MODE" in
++ declare -a CMD
+++ date +%s
+++ date '+%Y-%m-%d %r'
+ source run_training.sh
++ START=1592872660
++ START=1592872660
++ '[' -n 15 ']'
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+++ date '+%Y-%m-%d %r'
++ START=1592872660
++ START=1592872660
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NNODES
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
++ '[' -n 8 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ declare -a CMD
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 6 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
++ '[' -n 11 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NNODES
++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 10 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
Run vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 14 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MODE=TRAIN
+ NUMEPOCHS=30
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
Run vars: id 392220 gpus 16 mparams
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
+ case "$MODE" in
++ export SLURM_NNODES
++ declare -a CMD
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ [[ 960 -ne 1 ]]
++ declare -a CMD
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ '[' -n 13 ']'
++ export SLURM_NNODES
++ declare -a CMD
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 8 ']'
++ '[' 960 -gt 60 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 7 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date +%s
++ export DGXSYSTEM
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ declare -a CMD
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' -n 5 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 9 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START=1592872660
++ export DGXSYSTEM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NTASKS_PER_NODE
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NNODES
++ START_FMT='2020-06-22 05:37:40 PM'
++ declare -a CMD
++ '[' -n 4 ']'
Run vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MAX_TOKENS=768
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ DATASET_DIR=/data
+ MODE=TRAIN
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
++ declare -a CMD
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date '+%Y-%m-%d %r'
++ declare -a CMD
++ [[ 960 -ne 1 ]]
++ START_FMT='2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 4 ']'
++ [[ 960 -ne 1 ]]
++ export SLURM_NTASKS_PER_NODE
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
+ case "$MODE" in
++ export SLURM_NNODES
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 10 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 1 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
++ '[' -n 3 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
+ source run_training.sh
++ [[ 960 -ne 1 ]]
++ '[' -n 12 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ declare -a CMD
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NNODES
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 0 ']'
++ '[' -n 6 ']'
++ '[' 960 -gt 60 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
Run vars: id 392220 gpus 16 mparams
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 2 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatRun vars: id 392220 gpus 16 mparams
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 2 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export DGXSYSTEM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export DGXSYSTEM
++ '[' -n 12 ']'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ export SLURM_NTASKS_PER_NODE
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
Run vars: id 392220 gpus 16 mparams
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ export SLURM_NNODES
+ SEED=30970
+ MAX_TOKENS=768
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ declare -a CMD
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 14 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 12 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
Run vars: id 392220 gpus 16 mparams
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NNODES
++ declare -a CMD
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ declare -a CMD
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 5 ']'
Run vars: id 392220 gpus 16 mparams
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ SEED=30970
+ source run_training.sh
++ '[' -n 13 ']'
++ '[' 960 -gt 60 ']'
+ MAX_TOKENS=768
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ DATASET_DIR=/data
+ MODE=TRAIN
++ START_FMT='2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ START_FMT='2020-06-22 05:37:40 PM'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ NUMEPOCHS=30
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NNODES
++ declare -a CMD
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
+ case "$MODE" in
++ '[' -n 15 ']'
+ source run_training.sh
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 3 ']'
+ SEED=30970
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ MAX_TOKENS=768
+ SEED=30970
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ NUMEPOCHS=30
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ source run_training.sh
+++ date +%s
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
+ DATASET_DIR=/data
+ MODE=TRAIN
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ declare -a CMD
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 11 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ DATASET_DIR=/data
+ MODE=TRAIN
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ NUMEPOCHS=30
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ source run_training.sh
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ NUMEPOCHS=30
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START=1592872660
+ case "$MODE" in
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ SEED=30970
+ source run_training.sh
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
+ MODE=TRAIN
+ NUMEPOCHS=30
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ case "$MODE" in
+ SEED=30970
+ MAX_TOKENS=768
+ source run_training.sh
+ DATASET_DIR=/data
+ MODE=TRAIN
+ SEED=30970
+ NUMEPOCHS=30
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ MAX_TOKENS=768
+ case "$MODE" in
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ case "$MODE" in
+ source run_training.sh
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
++ START=1592872660
++ START=1592872660
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+ MAX_TOKENS=768
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date +%s
+ DATASET_DIR=/data
+ MODE=TRAIN
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
Run vars: id 392220 gpus 16 mparams
+++ date +%s
+++ date +%s
+++ date +%s
+++ date '+%Y-%m-%d %r'
+ NUMEPOCHS=30
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
+++ date +%s
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuRun vars: id 392220 gpus 16 mparams
++ START=1592872660
+++ date +%s
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START=1592872660
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ START=1592872660
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-+++ date '+%Y-%m-%d %r'
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuRun vars: id 392220 gpus 16 mparams
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ [[ 960 -ne 1 ]]
+ MAX_TOKENS=768
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuRun vars: id 392220 gpus 16 mparams
+++ date '+%Y-%m-%d %r'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NNODES
++ declare -a CMD
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-nRun vars: id 392220 gpus 16 mparams
++ '[' -n 7 ']'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START=1592872660
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ DATASET_DIR=/data
++ START=1592872660
+ MODE=TRAIN
+++ date '+%Y-%m-%d %r'
+ NUMEPOCHS=30
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+++ date +%s
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ START=1592872660
+++ date '+%Y-%m-%d %r'
+ SEED=30970
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
++ '[' -n 5 ']'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
Run vars: id 392220 gpus 16 mparams
+ NUMEPOCHS=30
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ [[ 960 -ne 1 ]]
+ MAX_TOKENS=768
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ case "$MODE" in
++ export DGXSYSTEM
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export SLURM_NTASKS_PER_NODE
+ NUMEPOCHS=30
++ export SLURM_NNODES
++ declare -a CMD
+ source run_training.sh
++ '[' -n 1 ']'
+ case "$MODE" in
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
+ SEED=30970
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+ MAX_TOKENS=768
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ [[ 960 -ne 1 ]]
+ case "$MODE" in
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
Run vars: id 392220 gpus 16 mparams
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ MAX_TOKENS=768
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ '[' -n 4 ']'
+ NUMEPOCHS=30
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
++ START=1592872660
Run vars: id 392220 gpus 16 mparams
+ source run_training.sh
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ [[ 960 -ne 1 ]]
+ MODE=TRAIN
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ NUMEPOCHS=30
++ export DGXSYSTEM
+ case "$MODE" in
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NTASKS_PER_NODE
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
++ export SLURM_NNODES
++ declare -a CMD
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 6 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
Run vars: id 392220 gpus 16 mparams
+ case "$MODE" in
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ SEED=30970
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ source run_training.sh
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ DATASET_DIR=/data
+ MODE=TRAIN
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
+ case "$MODE" in
++ '[' -n 10 ']'
++ '[' 960 -gt 60 ']'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ source run_training.sh
Run vars: id 392220 gpus 16 mparams
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ SEED=30970
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
+ MAX_TOKENS=768
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ MODE=TRAIN
++ [[ 960 -ne 1 ]]
+ NUMEPOCHS=30
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ case "$MODE" in
++ export DGXSYSTEM
+ source run_training.sh
++ '[' -n 15 ']'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date +%s
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ SEED=30970
++ declare -a CMD
+ MAX_TOKENS=768
++ START_FMT='2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ NUMEPOCHS=30
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ case "$MODE" in
++ '[' -n 8 ']'
+ source run_training.sh
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuRun vars: id 392220 gpus 16 mparams
++ [[ 960 -ne 1 ]]
+++ date +%s
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START=1592872660
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ SEED=30970
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
+ MAX_TOKENS=768
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ DATASET_DIR=/data
+ MODE=TRAIN
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date +%s
++ '[' -n 14 ']'
+ NUMEPOCHS=30
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ case "$MODE" in
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date +%s
++ [[ 960 -ne 1 ]]
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ SEED=30970
+ MAX_TOKENS=768
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ DATASET_DIR=/data
++ export SLURM_NTASKS_PER_NODE
+ MODE=TRAIN
+ NUMEPOCHS=30
++ export SLURM_NNODES
+ case "$MODE" in
++ declare -a CMD
+ source run_training.sh
++ '[' -n 2 ']'
+++ date '+%Y-%m-%d %r'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+++ date +%s
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' -n 13 ']'
+++ date '+%Y-%m-%d %r'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
++ START=1592872660
++ [[ 960 -ne 1 ]]
++ START=1592872660
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START=1592872660
++ export DGXSYSTEM
+++ date '+%Y-%m-%d %r'
++ export SLURM_NTASKS_PER_NODE
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NNODES
++ START=1592872660
++ declare -a CMD
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 0 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 11 ']'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NNODES
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 0 ']'
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ '[' -n 3 ']'
++ '[' 960 -gt 60 ']'
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date '+%Y-%m-%d %r'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NNODES
++ declare -a CMD
++ [[ 960 -ne 1 ]]
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-nnum_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' -n 9 ']'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NNODES
num_sockets = 2 num_nodes=2 cores_per_socket=24
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' -n 14 ']'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START=1592872660
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START_FMT='2020-06-22 05:37:40 PM'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ declare -a CMD
++ '[' -n 8 ']'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-nnum_sockets = 2 num_nodes=2 cores_per_socket=24
++ '[' 960 -gt 60 ']'
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START_FMT='2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export SLURM_NTASKS_PER_NODE
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NNODES
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 7 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-nSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ export SLURM_NNODES
++ declare -a CMD
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START_FMT='2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ [[ 960 -ne 1 ]]
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ '[' -n 9 ']'
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' -n 2 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 4 ']'
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ [[ 960 -ne 1 ]]
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatSTARTING TIMING RUN AT 2020-06-22 05:37:40 PM
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START_FMT='2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 1 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NNODES
++ declare -a CMD
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' -n 3 ']'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
STARTING TIMING RUN AT 2020-06-22 05:37:40 PM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ [[ 960 -ne 1 ]]
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ '[' -n 2 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ declare -a CMD
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 5 ']'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num_sockets = 2 num_nodes=2 cores_per_socket=24
+++ date '+%Y-%m-%d %r'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ [[ 960 -ne 1 ]]
num_sockets = 2 num_nodes=2 cores_per_socket=24
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum_sockets = 2 num_nodes=2 cores_per_socket=24
++ export DGXSYSTEM
num_sockets = 2 num_nodes=2 cores_per_socket=24
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num_sockets = 2 num_nodes=2 cores_per_socket=24
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
num_sockets = 2 num_nodes=2 cores_per_socket=24
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ declare -a CMD
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 11 ']'
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ '[' 960 -gt 60 ']'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ START_FMT='2020-06-22 05:37:40 PM'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START_FMT='2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ declare -a CMD
++ [[ 960 -ne 1 ]]
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NNODES
++ declare -a CMD
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ '[' -n 10 ']'
++ declare -a CMD
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ '[' -n 9 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ declare -a CMD
++ '[' -n 8 ']'
++ '[' -n 15 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 13 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ [[ 960 -ne 1 ]]
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export DGXSYSTEM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NNODES
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ '[' -n 4 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 12 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START_FMT='2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ [[ 960 -ne 1 ]]
++ declare -a CMD
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export DGXSYSTEM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 14 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 6 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ export SLURM_NNODES
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
++ '[' -n 7 ']'
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ [[ 960 -ne 1 ]]
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export DGXSYSTEM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' -n 10 ']'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
+ case "$MODE" in
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ source run_training.sh
+++ date +%s
++ [[ 960 -ne 1 ]]
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ export DGXSYSTEM
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ SEED=30970
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
+ MAX_TOKENS=768
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ DATASET_DIR=/data
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' -n 12 ']'
++ '[' 960 -gt 60 ']'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START_FMT='2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
+ MODE=TRAIN
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ declare -a CMD
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 13 ']'
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ NUMEPOCHS=30
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ case "$MODE" in
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
++ declare -a CMD
+++ date +%s
++ '[' -n 15 ']'
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ SEED=30970
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ DATASET_DIR=/data
+ MODE=TRAIN
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ NUMEPOCHS=30
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 6 ']'
+ case "$MODE" in
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date +%s
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ [[ 960 -ne 1 ]]
+ DATASET_DIR=/data
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ MODE=TRAIN
++ export DGXSYSTEM
+ NUMEPOCHS=30
++ export SLURM_NTASKS_PER_NODE
+ case "$MODE" in
++ export SLURM_NNODES
+ source run_training.sh
++ declare -a CMD
++ '[' -n 11 ']'
+ SEED=30970
++ '[' 960 -gt 60 ']'
+ MAX_TOKENS=768
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ DATASET_DIR=/data
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MODE=TRAIN
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
+ case "$MODE" in
+ source run_training.sh
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ SEED=30970
++ export DGXSYSTEM
+ MAX_TOKENS=768
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export SLURM_NTASKS_PER_NODE
+ DATASET_DIR=/data
++ export SLURM_NNODES
+ MODE=TRAIN
++ declare -a CMD
+ NUMEPOCHS=30
++ '[' -n 0 ']'
+ case "$MODE" in
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-+ NUMEPOCHS=30
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatnum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
+ source run_training.sh
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ START=1592872660
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ SEED=30970
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ MODE=TRAIN
+ NUMEPOCHS=30
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
+ source run_training.sh
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START=1592872660
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ MODE=TRAIN
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ NUMEPOCHS=30
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ case "$MODE" in
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date +%s
+++ date '+%Y-%m-%d %r'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ SEED=30970
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ case "$MODE" in
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date +%s
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+++ date +%s
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ SEED=30970
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ DATASET_DIR=/data
+ MODE=TRAIN
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ NUMEPOCHS=30
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ source run_training.sh
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ MAX_TOKENS=768
+ DATASET_DIR=/data
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MODE=TRAIN
+ NUMEPOCHS=30
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ case "$MODE" in
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
+++ date +%s
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ SEED=30970
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ MAX_TOKENS=768
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START=1592872660
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-+ case "$MODE" in
+ source run_training.sh
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ SEED=30970
+ MAX_TOKENS=768
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date +%s
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ START=1592872660
+++ date +%s
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ SEED=30970
+ SEED=30970
+ MAX_TOKENS=768
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
++ [[ 960 -ne 1 ]]
+ DATASET_DIR=/data
+ MODE=TRAIN
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ NUMEPOCHS=30
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export SLURM_NNODES
++ declare -a CMD
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' -n 4 ']'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START=1592872660
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START=1592872660
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-++ [[ 960 -ne 1 ]]
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export DGXSYSTEM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NNODES
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
+ case "$MODE" in
+++ date +%s
+ source run_training.sh
++ START=1592872660
+++ date +%s
++ START=1592872660
+++ date '+%Y-%m-%d %r'
++ '[' -n 8 ']'
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+++ date '+%Y-%m-%d %r'
++ '[' 960 -gt 60 ']'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date '+%Y-%m-%d %r'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START=1592872660
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
+ SEED=30970
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ MAX_TOKENS=768
++ export DGXSYSTEM
+ DATASET_DIR=/data
++ export SLURM_NTASKS_PER_NODE
+ MODE=TRAIN
+ NUMEPOCHS=30
++ export SLURM_NNODES
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' -n 3 ']'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START=1592872660
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date '+%Y-%m-%d %r'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+ source run_training.sh
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-++ [[ 960 -ne 1 ]]
+ DATASET_DIR=/data
+ MODE=TRAIN
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ NUMEPOCHS=30
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ case "$MODE" in
+ source run_training.sh
++ declare -a CMD
+++ date +%s
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ '[' -n 10 ']'
+ SEED=30970
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MAX_TOKENS=768
+++ date '+%Y-%m-%d %r'
+ DATASET_DIR=/data
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MODE=TRAIN
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ START=1592872660
+ NUMEPOCHS=30
+ case "$MODE" in
++ START=1592872660
+ source run_training.sh
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date +%s
++ START=1592872660
+++ date '+%Y-%m-%d %r'
+ SEED=30970
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+ MAX_TOKENS=768
++ START=1592872660
+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
++ [[ 960 -ne 1 ]]
+ source run_training.sh
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START=1592872660
++ export DGXSYSTEM
++ START=1592872660
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date +%s
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ '[' -n 5 ']'
++ START=1592872660
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ declare -a CMD
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date '+%Y-%m-%d %r'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' -n 4 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ START=1592872660
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ START=1592872660
++ export SLURM_NNODES
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NNODES
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' -n 0 ']'
++ '[' -n 2 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date '+%Y-%m-%d %r'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ export SLURM_NNODES
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ '[' -n 6 ']'
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' -n 9 ']'
++ '[' 960 -gt 60 ']'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 7 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ [[ 960 -ne 1 ]]
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START=1592872660
++ declare -a CMD
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' -n 3 ']'
++ export DGXSYSTEM
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 11 ']'
++ '[' 960 -gt 60 ']'
+++ date '+%Y-%m-%d %r'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ START=1592872660
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ declare -a CMD
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 1 ']'
+++ date '+%Y-%m-%d %r'
++ '[' 960 -gt 60 ']'
++ START=1592872660
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START=1592872660
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
+++ date '+%Y-%m-%d %r'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ [[ 960 -ne 1 ]]
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ declare -a CMD
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' -n 9 ']'
++ declare -a CMD
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 10 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NNODES
++ declare -a CMD
++ [[ 960 -ne 1 ]]
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' -n 15 ']'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export DGXSYSTEM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NTASKS_PER_NODE
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NNODES
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ declare -a CMD
++ [[ 960 -ne 1 ]]
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ [[ 960 -ne 1 ]]
++ export DGXSYSTEM
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ export SLURM_NTASKS_PER_NODE
++ export DGXSYSTEM
++ export SLURM_NNODES
++ declare -a CMD
++ export SLURM_NTASKS_PER_NODE
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NNODES
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
++ '[' -n 7 ']'
++ '[' -n 8 ']'
++ '[' 960 -gt 60 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 2 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export SLURM_NTASKS_PER_NODE
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ export SLURM_NNODES
++ declare -a CMD
++ declare -a CMD
++ '[' -n 14 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 15 ']'
++ '[' 960 -gt 60 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 12 ']'
++ [[ 960 -ne 1 ]]
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export DGXSYSTEM
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ START_FMT='2020-06-22 05:37:40 PM'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 0 ']'
++ [[ 960 -ne 1 ]]
++ START_FMT='2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export DGXSYSTEM
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ [[ 960 -ne 1 ]]
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 13 ']'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export DGXSYSTEM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NTASKS_PER_NODE
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 11 ']'
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-++ START_FMT='2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
++ START_FMT='2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' -n 6 ']'
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NNODES
++ declare -a CMD
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ '[' -n 1 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NNODES
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ [[ 960 -ne 1 ]]
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' -n 13 ']'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' -n 14 ']'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ export DGXSYSTEM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 5 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu--num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu--mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' -n 12 ']'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-nnum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu--num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' -n 3 ']'
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date +%s
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ SEED=30970
+ MAX_TOKENS=768
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ SEED=30970
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwunum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ DATASET_DIR=/data
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ MODE=TRAIN
+ NUMEPOCHS=30
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ source run_training.sh
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ NUMEPOCHS=30
+ MODE=TRAIN
+ NUMEPOCHS=30
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ case "$MODE" in
+ case "$MODE" in
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ source run_training.sh
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date +%s
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date +%s
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ SEED=30970
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ DATASET_DIR=/data
+ MODE=TRAIN
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ NUMEPOCHS=30
+ case "$MODE" in
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-+ source run_training.sh
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ SEED=30970
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ DATASET_DIR=/data
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MODE=TRAIN
+ NUMEPOCHS=30
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ case "$MODE" in
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+++ date +%s
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ case "$MODE" in
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MAX_TOKENS=768
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ DATASET_DIR=/data
+ MODE=TRAIN
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ NUMEPOCHS=30
+ case "$MODE" in
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
++ START=1592872660
++ START=1592872660
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+++ date +%s
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ SEED=30970
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ NUMEPOCHS=30
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ case "$MODE" in
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date +%s
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ SEED=30970
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ MODE=TRAIN
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ NUMEPOCHS=30
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ source run_training.sh
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+++ date '+%Y-%m-%d %r'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MAX_TOKENS=768
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ DATASET_DIR=/data
+ MODE=TRAIN
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ NUMEPOCHS=30
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ source run_training.sh
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date +%s
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date +%s
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ SEED=30970
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ DATASET_DIR=/data
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MODE=TRAIN
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ NUMEPOCHS=30
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ case "$MODE" in
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-+ source run_training.sh
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START=1592872660
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ DATASET_DIR=/data
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MODE=TRAIN
+ NUMEPOCHS=30
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ case "$MODE" in
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START=1592872660
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date '+%Y-%m-%d %r'
++ START=1592872660
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ START=1592872660
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
+ MAX_TOKENS=768
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ DATASET_DIR=/data
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MODE=TRAIN
+ NUMEPOCHS=30
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n+ case "$MODE" in
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date '+%Y-%m-%d %r'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date +%s
++ START_FMT='2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ declare -a CMD
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' -n 15 ']'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START_FMT='2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date '+%Y-%m-%d %r'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' -n 5 ']'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
+++ date '+%Y-%m-%d %r'
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export DGXSYSTEM
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwuslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date +%s
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 6 ']'
++ '[' 960 -gt 60 ']'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-nslurmstepd: task_p_pre_launch: Using sched_affinity for tasks
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START=1592872660
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date '+%Y-%m-%d %r'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date '+%Y-%m-%d %r'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ [[ 960 -ne 1 ]]
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ '[' -n 14 ']'
++ export DGXSYSTEM
+ case "$MODE" in
++ export SLURM_NTASKS_PER_NODE
+ source run_training.sh
++ export SLURM_NNODES
++ declare -a CMD
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ '[' -n 10 ']'
+ SEED=30970
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' 960 -gt 60 ']'
+ MAX_TOKENS=768
+ SEED=30970
+ MAX_TOKENS=768
+ SEED=30970
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ DATASET_DIR=/data
+ MODE=TRAIN
+ DATASET_DIR=/data
+ MODE=TRAIN
+ MAX_TOKENS=768
+ NUMEPOCHS=30
+ NUMEPOCHS=30
+ case "$MODE" in
+ DATASET_DIR=/data
+ MODE=TRAIN
+ source run_training.sh
+ case "$MODE" in
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date +%s
+++ date +%s
++ [[ 960 -ne 1 ]]
+++ date +%s
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date +%s
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NNODES
++ declare -a CMD
+ SEED=30970
+ MAX_TOKENS=768
++ START_FMT='2020-06-22 05:37:40 PM'
+ case "$MODE" in
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ source run_training.sh
+++ date +%s
+ case "$MODE" in
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 2 ']'
++ '[' 960 -gt 60 ']'
+ source run_training.sh
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ NUMEPOCHS=30
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export SLURM_NNODES
+ case "$MODE" in
++ declare -a CMD
+ source run_training.sh
++ '[' -n 11 ']'
+++ date +%s
++ '[' 960 -gt 60 ']'
+++ date +%s
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date +%s
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ SEED=30970
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ MAX_TOKENS=768
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ DATASET_DIR=/data
++ START=1592872660
+ MODE=TRAIN
++ START=1592872660
+ NUMEPOCHS=30
++ START_FMT='2020-06-22 05:37:40 PM'
+ case "$MODE" in
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ source run_training.sh
++ [[ 960 -ne 1 ]]
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START=1592872660
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ SEED=30970
++ export SLURM_NNODES
+ MAX_TOKENS=768
+ DATASET_DIR=/data
++ declare -a CMD
++ START=1592872660
++ '[' -n 1 ']'
+ MODE=TRAIN
+ NUMEPOCHS=30
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ case "$MODE" in
+++ date '+%Y-%m-%d %r'
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
+++ date +%s
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ SEED=30970
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ export DGXSYSTEM
+ MAX_TOKENS=768
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date +%s
++ declare -a CMD
+ DATASET_DIR=/data
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
++ '[' -n 9 ']'
+ MODE=TRAIN
+ NUMEPOCHS=30
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ case "$MODE" in
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ source run_training.sh
+++ date +%s
++ [[ 960 -ne 1 ]]
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ SEED=30970
++ export DGXSYSTEM
+ MAX_TOKENS=768
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export SLURM_NTASKS_PER_NODE
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export SLURM_NNODES
+ NUMEPOCHS=30
++ declare -a CMD
+ case "$MODE" in
++ '[' -n 7 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ source run_training.sh
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ MAX_TOKENS=768
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
+ DATASET_DIR=/data
+ MODE=TRAIN
++ export SLURM_NNODES
++ declare -a CMD
+ NUMEPOCHS=30
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ case "$MODE" in
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ source run_training.sh
++ '[' -n 8 ']'
+++ date +%s
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
+++ date +%s
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ SEED=30970
+ MAX_TOKENS=768
+ DATASET_DIR=/data
+ MODE=TRAIN
++ [[ 960 -ne 1 ]]
++ START=1592872660
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ NUMEPOCHS=30
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export DGXSYSTEM
+ case "$MODE" in
++ export SLURM_NTASKS_PER_NODE
+ source run_training.sh
++ export SLURM_NNODES
+++ date +%s
++ declare -a CMD
++ START=1592872660
++ START_FMT='2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date +%s
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date +%s
+++ date '+%Y-%m-%d %r'
++ '[' -n 12 ']'
+++ date '+%Y-%m-%d %r'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ [[ 960 -ne 1 ]]
+ SEED=30970
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ MAX_TOKENS=768
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
++ export DGXSYSTEM
+ case "$MODE" in
+ source run_training.sh
++ export SLURM_NTASKS_PER_NODE
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NNODES
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ declare -a CMD
++ '[' -n 4 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ [[ 960 -ne 1 ]]
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
+++ date '+%Y-%m-%d %r'
++ '[' -n 10 ']'
++ START=1592872660
++ '[' 960 -gt 60 ']'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ [[ 960 -ne 1 ]]
++ export SLURM_NTASKS_PER_NODE
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export SLURM_NNODES
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ declare -a CMD
++ export SLURM_NNODES
++ declare -a CMD
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-++ START_FMT='2020-06-22 05:37:40 PM'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' -n 0 ']'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ '[' -n 12 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START=1592872660
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ [[ 960 -ne 1 ]]
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ START_FMT='2020-06-22 05:37:40 PM'
++ export SLURM_NTASKS_PER_NODE
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ export SLURM_NNODES
++ declare -a CMD
++ [[ 960 -ne 1 ]]
++ '[' -n 3 ']'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' 960 -gt 60 ']'
+++ date '+%Y-%m-%d %r'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NNODES
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' -n 11 ']'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ START=1592872660
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
+++ date +%s
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ '[' -n 14 ']'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+++ date '+%Y-%m-%d %r'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+++ date '+%Y-%m-%d %r'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ START=1592872660
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ [[ 960 -ne 1 ]]
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ export SLURM_NNODES
++ declare -a CMD
++ [[ 960 -ne 1 ]]
++ '[' -n 13 ']'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ export SLURM_NNODES
++ declare -a CMD
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ declare -a CMD
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' -n 1 ']'
++ '[' -n 3 ']'
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START_FMT='2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ [[ 960 -ne 1 ]]
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ declare -a CMD
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' -n 14 ']'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START=1592872660
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flatum-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ START_FMT='2020-06-22 05:37:40 PM'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ [[ 960 -ne 1 ]]
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ '[' -n 15 ']'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu+++ date '+%Y-%m-%d %r'
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-n++ START=1592872660
um-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START=1592872660
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ [[ 960 -ne 1 ]]
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu++ export DGXSYSTEM
-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 4 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
+++ date '+%Y-%m-%d %r'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+++ date '+%Y-%m-%d %r'
++ '[' -n 0 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 9 ']'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ START_FMT='2020-06-22 05:37:40 PM'
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ START_FMT='2020-06-22 05:37:40 PM'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ '[' -n 2 ']'
++ '[' 960 -gt 60 ']'
++ declare -a CMD
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ '[' -n 7 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 5 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 13 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 8 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
++ START_FMT='2020-06-22 05:37:40 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-22 05:37:40 PM'
++ [[ 960 -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export DGXSYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n 6 ']'
++ '[' 960 -gt 60 ']'
++ CMD=('./bind.sh' '--cpu=exclusive' '--' 'python' '-u')
++ ./bind.sh --cpu=exclusive -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=36-38,84-86 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=30-32,78-80 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=33-35,81-83 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=9-11,57-59 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=27-29,75-77 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=6-8,54-56 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=0-2,48-50 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=42-44,90-92 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=21-23,69-71 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=18-20,66-68 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=3-5,51-53 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=45-47,93-95 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=15-17,63-65 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=39-41,87-89 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=12-14,60-62 --membind=0 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
+ exec numactl --physcpubind=24-26,72-74 --membind=1 -- python -u train.py /data --seed 30970 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 400 --lr 1.732e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 768 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 76 --max-target-positions 76 --adam-betas '(0.86,0.92)'
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 492
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 487
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 647
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 887
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 192
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 197
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 763
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 181
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 228
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 563
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 284
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 485
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 374
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 225
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 26
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 287
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 845
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 823
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 885
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 533
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 406
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 834
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 737
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 258
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 59
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 596
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 707
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 444
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 777
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 572
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 28
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 369
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 52
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 277
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 416
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 50
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 115
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 860
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 9
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 816
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 93
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 739
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 195
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 680
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 65
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 191
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 117
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 536
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 902
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 592
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 912
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 642
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 429
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 950
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 179
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 440
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 768
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 198
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 561
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 945
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 196
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 27
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 166
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 264
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 345
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 14
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 635
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 741
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 859
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 279
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 490
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 560
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 809
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 222
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 357
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 67
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 656
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 705
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 89
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 590
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 920
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 593
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 711
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 489
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 227
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 910
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 678
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 775
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 594
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 376
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 640
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 556
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 233
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 177
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 827
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 136
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 767
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 953
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 296
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 423
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 493
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 186
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 893
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 120
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 51
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 921
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 756
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 147
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 245
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 11
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 377
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 898
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 55
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 199
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 19
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 168
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 895
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 541
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 791
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 542
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 626
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 847
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 4
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 922
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 854
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 202
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 130
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 341
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 380
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 599
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 289
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 170
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 629
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 96
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 246
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 483
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 414
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 891
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 90
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 570
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 461
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 797
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 747
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 951
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 250
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 779
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 239
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 549
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 539
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 267
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 848
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 882
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 361
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 365
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 617
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 486
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 36
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 434
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 18
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 913
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 218
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 317
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 557
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 33
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 98
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 579
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 132
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 857
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 17
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 661
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 519
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 757
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 896
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 230
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 751
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 121
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 652
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 5
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 49
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 188
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 843
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 64
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 281
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 786
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 436
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 456
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 80
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 919
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 262
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 743
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 826
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 569
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 716
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 415
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 123
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 484
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 285
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 383
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 193
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 70
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 172
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 825
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 597
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 639
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 672
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 771
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 410
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 799
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 899
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 822
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 430
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 311
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 580
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 681
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 438
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 648
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 926
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 808
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 356
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 107
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 772
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 886
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 553
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 491
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 209
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 644
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 269
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 431
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 310
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 185
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 927
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 530
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 445
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 428
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 215
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 949
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 504
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 704
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 488
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 54
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 633
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 244
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 343
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 721
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 382
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 558
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 302
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 182
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 838
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 670
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 138
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 268
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 344
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 242
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 828
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 460
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 381
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 481
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 719
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 110
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 178
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 340
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 379
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 237
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 95
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 6
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 894
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 712
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 784
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 155
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 830
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 40
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 298
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 761
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 502
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 762
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 844
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 959
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 610
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 135
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 803
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 439
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 77
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 717
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 119
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 658
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 649
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 112
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 25
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 660
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 273
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 455
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 603
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 687
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 411
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 97
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 1
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 174
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 82
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 203
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 35
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 545
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 494
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 863
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 755
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 625
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 220
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 272
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 205
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 194
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 167
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 853
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 312
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 229
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 609
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 482
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 435
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 364
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 718
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 495
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 480
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 571
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 846
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 815
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 288
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 537
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 437
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 591
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 946
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 253
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 180
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 782
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 564
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 201
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 607
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 675
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 655
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 405
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 855
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 742
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 900
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 575
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 888
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 247
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 23
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 204
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 581
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 275
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 78
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 736
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 144
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 650
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 523
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 12
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 849
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 184
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 48
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 714
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 314
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 299
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 248
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 234
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 911
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 207
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 503
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 105
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 631
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 276
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 175
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 206
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 63
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 190
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 602
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 15
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 31
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 598
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 667
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 158
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 278
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 543
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 837
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 200
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 818
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 589
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 368
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 685
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 286
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 427
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 568
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 187
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 75
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 749
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 956
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 56
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 259
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 351
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 811
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 46
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 654
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 684
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 183
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 889
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 243
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 790
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 538
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 810
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 618
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 496
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 562
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 760
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 829
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 515
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 366
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 60
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 554
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 189
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 817
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 905
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 274
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 128
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 611
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 574
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 126
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 282
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 176
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 925
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 783
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 283
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 53
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 16
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 402
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 84
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 232
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 424
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 947
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 819
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 57
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 735
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 42
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 636
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 22
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 836
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 748
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 709
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 881
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 342
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 663
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 257
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 280
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 907
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 150
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 802
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 69
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 372
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 254
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 367
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 528
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 924
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 271
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 880
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 400
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 595
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 83
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 226
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 824
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 567
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 13
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 776
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 224
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 884
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 764
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 448
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 531
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 62
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 540
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 641
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 261
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 99
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 565
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 573
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 91
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 453
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 566
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 355
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 646
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 725
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 883
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 58
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 236
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 30
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 766
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 370
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 890
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 831
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 861
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 295
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 820
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 906
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 929
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 915
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 371
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 706
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 892
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 113
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 235
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 653
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 61
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 550
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 841
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 605
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 420
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 852
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 850
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 373
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 715
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 238
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 750
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 378
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 833
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 606
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 832
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 908
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 643
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 765
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 745
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 821
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 21
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 901
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 313
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 163
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 738
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 129
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 753
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 375
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 529
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 710
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 231
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 713
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 645
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 839
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 354
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 20
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 835
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 668
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 260
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 634
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 71
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 315
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 418
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 24
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 604
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 29
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 518
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 862
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 758
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 842
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 535
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 600
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 917
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 353
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 733
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 111
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 840
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 403
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 740
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 778
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 708
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 552
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 781
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 746
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 116
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 916
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 673
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 459
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 38
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 851
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 789
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 914
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 332
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 534
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 621
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 918
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 419
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 744
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 601
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 620
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 532
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 858
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 446
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 141
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 2
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 856
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 8
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 774
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 263
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 124
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 323
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 752
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 628
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 958
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 955
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 171
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 88
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 651
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 933
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 522
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 754
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 270
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 118
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 408
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 10
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 794
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 944
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 773
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 425
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 255
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 143
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 162
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 303
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 346
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 266
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 433
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 256
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 223
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 904
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 441
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 74
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 948
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 122
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 770
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 897
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 7
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 691
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 442
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 780
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 512
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 759
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 0
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 426
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 249
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 801
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 451
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 265
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 86
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 729
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 3
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 546
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 909
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 443
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 627
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 208
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 125
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 127
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 674
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 769
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 66
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 954
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 795
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 923
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 637
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 957
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 251
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 114
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 903
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 165
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 421
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 447
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 669
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 92
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 682
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 630
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 290
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 221
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 463
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 422
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 352
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 578
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 339
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 140
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 417
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 804
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 240
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 952
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 81
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 336
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 686
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 360
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 169
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 153
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 109
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 241
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 413
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 723
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 43
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 133
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 94
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 632
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 475
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 87
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 404
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 252
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 679
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 638
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 362
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 676
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 548
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 401
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 785
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 412
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 500
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 68
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 326
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 217
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 85
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 476
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 683
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 497
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 409
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 677
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 219
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 623
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 79
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 359
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872667917, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 358
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 407
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 551
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 467
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 363
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 555
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 173
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872667921, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872667920, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 588
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872667921, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 665
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 73
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 788
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872667925, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 664
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 159
:::MLLOG {"namespace": "", "time_ms": 1592872667929, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872667930, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872667927, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 161
:::MLLOG {"namespace": "", "time_ms": 1592872667927, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 805
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 870
:::MLLOG {"namespace": "", "time_ms": 1592872667929, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 291
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 76
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 47
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 72
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 350
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 734
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 164
:::MLLOG {"namespace": "", "time_ms": 1592872667940, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872667940, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872667939, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 514
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872667942, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 559
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 657
:::MLLOG {"namespace": "", "time_ms": 1592872667944, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 347
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 624
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 214
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 458
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 813
:::MLLOG {"namespace": "", "time_ms": 1592872667954, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872667948, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872667948, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 293
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 587
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 337
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 324
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 37
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 348
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872667960, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872667963, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 142
:::MLLOG {"namespace": "", "time_ms": 1592872667963, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872667962, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872667963, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872667962, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 305
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 134
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 106
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 39
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 432
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872667969, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 868
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 787
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 671
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 210
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872667964, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872667973, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 349
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 102
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872667975, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872667969, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872667979, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 338
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872667980, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 32
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 139
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 547
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 131
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 211
:::MLLOG {"namespace": "", "time_ms": 1592872667986, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 449
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 473
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 792
:::MLLOG {"namespace": "", "time_ms": 1592872667991, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872667993, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872667993, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 294
:::MLLOG {"namespace": "", "time_ms": 1592872667990, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 659
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 583
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 212
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 585
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 300
:::MLLOG {"namespace": "", "time_ms": 1592872668001, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 397
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 798
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 137
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668006, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 666
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 213
:::MLLOG {"namespace": "", "time_ms": 1592872668004, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 935
:::MLLOG {"namespace": "", "time_ms": 1592872668013, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 662
:::MLLOG {"namespace": "", "time_ms": 1592872668013, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 44
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 796
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 104
:::MLLOG {"namespace": "", "time_ms": 1592872668013, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 608
:::MLLOG {"namespace": "", "time_ms": 1592872668012, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 301
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 160
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 793
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 297
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 576
:::MLLOG {"namespace": "", "time_ms": 1592872668021, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 108
:::MLLOG {"namespace": "", "time_ms": 1592872668023, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668022, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668028, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 292
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 100
:::MLLOG {"namespace": "", "time_ms": 1592872668026, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668029, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668026, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668030, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 513
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 807
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 309
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 544
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 943
:::MLLOG {"namespace": "", "time_ms": 1592872668031, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 101
:::MLLOG {"namespace": "", "time_ms": 1592872668030, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 103
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 934
:::MLLOG {"namespace": "", "time_ms": 1592872668033, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 307
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668038, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 41
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 582
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 814
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 688
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 45
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 316
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 577
:::MLLOG {"namespace": "", "time_ms": 1592872668049, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668051, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668057, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 584
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 586
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 34
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 877
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 145
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668064, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 499
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668066, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 812
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 800
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 320
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 697
:::MLLOG {"namespace": "", "time_ms": 1592872668061, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 726
:::MLLOG {"namespace": "", "time_ms": 1592872668070, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 152
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 450
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 806
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 318
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 308
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668079, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 510
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 457
:::MLLOG {"namespace": "", "time_ms": 1592872668086, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668089, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668088, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 319
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 462
:::MLLOG {"namespace": "", "time_ms": 1592872668095, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668095, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 454
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 452
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 306
:::MLLOG {"namespace": "", "time_ms": 1592872668108, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 156
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668112, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668111, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 216
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 698
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 304
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 613
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668125, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 527
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668126, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668124, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 931
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668133, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668136, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 478
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 615
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 154
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 506
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 612
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 148
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 157
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 696
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668155, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 472
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 619
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668159, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668162, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668169, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 616
:::MLLOG {"namespace": "", "time_ms": 1592872668168, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 511
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 516
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668172, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 151
:::MLLOG {"namespace": "", "time_ms": 1592872668175, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668173, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668176, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed init done!
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 614
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 724
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 622
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 149
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668176, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668180, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668184, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668186, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 146
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668189, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 395
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668194, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 525
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 930
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668205, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668205, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 942
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 331
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668213, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 501
:::MLLOG {"namespace": "", "time_ms": 1592872668214, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 864
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 507
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668221, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668215, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668214, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668221, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668220, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668220, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668226, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668228, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668230, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668232, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 524
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668236, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668236, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 508
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668239, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668230, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668240, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668237, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668243, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668240, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668242, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 517
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668246, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668248, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 521
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668242, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 520
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668253, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668252, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 498
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 526
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 505
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668256, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668261, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668258, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668256, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 509
:::MLLOG {"namespace": "", "time_ms": 1592872668259, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 722
:::MLLOG {"namespace": "", "time_ms": 1592872668263, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668262, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668269, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 728
:::MLLOG {"namespace": "", "time_ms": 1592872668267, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668261, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 700
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668266, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668271, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668282, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668279, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 873
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 732
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668291, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668287, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668293, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 391
:::MLLOG {"namespace": "", "time_ms": 1592872668293, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668296, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668288, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668293, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668298, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668302, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668313, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 720
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 321
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668317, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 730
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 731
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 699
:::MLLOG {"namespace": "", "time_ms": 1592872668340, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668341, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 727
:::MLLOG {"namespace": "", "time_ms": 1592872668345, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668349, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 386
:::MLLOG {"namespace": "", "time_ms": 1592872668345, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 937
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 385
:::MLLOG {"namespace": "", "time_ms": 1592872668361, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 874
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668368, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668376, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668377, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668379, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668385, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668389, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668392, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 875
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668401, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668404, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668405, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668406, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668413, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 329
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 879
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 322
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668424, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668424, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668425, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 327
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668431, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668434, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668433, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668433, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668435, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 695
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 330
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668446, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668443, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 938
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 865
:::MLLOG {"namespace": "", "time_ms": 1592872668445, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668454, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 471
:::MLLOG {"namespace": "", "time_ms": 1592872668458, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668452, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668453, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668459, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668460, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668455, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668464, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668464, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668470, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668466, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668468, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 932
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 390
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668480, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 689
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668484, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668485, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668486, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668488, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668488, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668490, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668486, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 941
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668496, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668505, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668504, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668499, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668507, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668509, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668509, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668508, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668514, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668516, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 333
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668517, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668526, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668529, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668528, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 876
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668542, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668543, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668546, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668544, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 466
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668547, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668550, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668551, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668554, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 325
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668560, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668556, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 940
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 939
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668571, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 479
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 701
:::MLLOG {"namespace": "", "time_ms": 1592872668575, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668572, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668576, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed init done!
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 936
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668578, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 388
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 468
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 693
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668584, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668588, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 328
:::MLLOG {"namespace": "", "time_ms": 1592872668590, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 928
:::MLLOG {"namespace": "", "time_ms": 1592872668585, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668594, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 334
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668597, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 464
:::MLLOG {"namespace": "", "time_ms": 1592872668604, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668607, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 392
:::MLLOG {"namespace": "", "time_ms": 1592872668605, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668609, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668611, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668609, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668611, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668612, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 335
:::MLLOG {"namespace": "", "time_ms": 1592872668613, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668612, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668623, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668625, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668625, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668620, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668626, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668627, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 469
:::MLLOG {"namespace": "", "time_ms": 1592872668631, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 867
:::MLLOG {"namespace": "", "time_ms": 1592872668635, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668636, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668637, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668640, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668636, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668642, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668653, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668661, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 399
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 694
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668673, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668669, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668677, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 389
:::MLLOG {"namespace": "", "time_ms": 1592872668680, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 703
:::MLLOG {"namespace": "", "time_ms": 1592872668681, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668680, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 474
| distributed init (rank 0): env://
:::MLLOG {"namespace": "", "time_ms": 1592872668680, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 702
:::MLLOG {"namespace": "", "time_ms": 1592872668683, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668686, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 692
:::MLLOG {"namespace": "", "time_ms": 1592872668690, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668693, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668696, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668703, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668702, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668700, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668707, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668708, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 869
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668710, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 878
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 394
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668723, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668726, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668725, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668728, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 690
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668731, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668737, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 872
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668740, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668742, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668744, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 871
:::MLLOG {"namespace": "", "time_ms": 1592872668746, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 866
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668751, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668754, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668759, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668763, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 465
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668769, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668771, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 470
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 477
:::MLLOG {"namespace": "", "time_ms": 1592872668780, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668782, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668782, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668792, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668796, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668797, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668803, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668801, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668805, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668805, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 387
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668812, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668812, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668815, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668816, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 398
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668823, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668830, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668833, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668835, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 393
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 396
:::MLLOG {"namespace": "", "time_ms": 1592872668835, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init done!
| distributed init done!
:::MLLOG {"namespace": "", "time_ms": 1592872668842, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668848, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668853, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668865, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668870, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668871, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668874, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668874, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668875, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668876, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668876, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668877, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668877, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668882, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668882, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668883, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668887, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668890, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668892, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668892, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668897, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668899, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: circe-n001, MASTER_PORT: 64540, WORLD_SIZE: 960, RANK: 384
| distributed init done!
| distributed init done!
| initialized host circe-n001 as rank 0 and device id 0
:::MLLOG {"namespace": "", "time_ms": 1592872668910, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668909, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668908, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668909, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668908, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668915, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668919, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668919, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668926, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668929, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668925, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668925, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668926, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668933, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668933, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668936, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668943, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668943, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668947, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668949, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668953, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668959, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668955, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668955, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668955, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668964, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668970, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668975, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668975, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668972, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668985, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668986, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668992, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668999, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668999, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872668999, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669007, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669013, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669018, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669016, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669023, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669023, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669024, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669026, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669032, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669042, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669044, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669042, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669045, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669051, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669053, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669056, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669056, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669056, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669064, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669062, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669062, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669074, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669071, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669069, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669076, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669079, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669080, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669090, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669093, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669095, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669097, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669100, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669101, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669105, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669112, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669118, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669120, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669126, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669133, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669142, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669144, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669143, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669146, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669148, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669149, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669148, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669149, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669153, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669159, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669160, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669165, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669160, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669168, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669170, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669175, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669183, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669186, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669192, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669194, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669191, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669200, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669203, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669201, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669205, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669210, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669214, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669216, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669219, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669225, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669224, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669225, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669236, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669231, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669237, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669240, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669243, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669241, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669249, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669255, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669261, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669265, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669267, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669267, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669270, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669273, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669276, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669279, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669274, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669288, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669293, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669295, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669301, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669302, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669298, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669305, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669310, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669309, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669309, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669304, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669307, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669309, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669314, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669314, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669318, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669318, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669319, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669323, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669327, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669331, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669340, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669341, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669342, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669342, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669349, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669355, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669362, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669377, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669376, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669377, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669383, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669386, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669391, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669392, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669396, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669390, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669396, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669403, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669397, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669397, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669397, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669406, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669407, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669408, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669411, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669411, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669412, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669421, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669419, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669424, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669420, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669431, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669431, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669447, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669444, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669447, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669449, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669451, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669456, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669453, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669458, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669459, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669464, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669465, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669467, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669468, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669472, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669474, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669478, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669480, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669483, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669487, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669502, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669508, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669507, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669507, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669512, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669513, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669513, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669516, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669532, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669531, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669534, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669538, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669539, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669541, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669543, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669549, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669548, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669551, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669553, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669555, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669554, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669559, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669564, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669564, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669566, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669569, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669573, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669569, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669573, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669577, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669572, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669584, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669586, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669586, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669585, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669590, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669592, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669597, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669600, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669603, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669606, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669604, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669608, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669609, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669614, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669608, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669614, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669618, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669618, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669621, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669621, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669625, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669623, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669625, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669630, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669637, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669644, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669643, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669642, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669650, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669646, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669646, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669652, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669657, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669658, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669659, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669653, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669661, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669664, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669656, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669657, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669672, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669673, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669672, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669677, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669676, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669678, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669678, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669681, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669685, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669685, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669681, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669683, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669687, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669687, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669690, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669692, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669693, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669690, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669695, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669698, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669696, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669693, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669700, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669699, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669699, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669700, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669700, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669703, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669698, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669699, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669706, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669708, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669710, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669707, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669714, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669715, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669716, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669719, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669721, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669726, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669728, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669729, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669729, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669731, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669724, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669732, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669729, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669736, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669735, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669739, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669740, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669740, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669740, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669732, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669742, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669742, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669742, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669744, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669741, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669744, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669748, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669747, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669748, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669756, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669756, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669755, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669756, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669757, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669755, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669760, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669762, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669759, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669763, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669765, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669762, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669769, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669763, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669770, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669771, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669770, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669771, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669775, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669772, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669773, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669777, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669775, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669776, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669780, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669780, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669778, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669778, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669786, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669785, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669788, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669789, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669782, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669786, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669790, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669791, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669782, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669794, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669796, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669795, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669796, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669797, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669797, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669798, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669800, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669801, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669804, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669801, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669804, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669803, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669805, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669805, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669803, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669808, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669810, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669811, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669811, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669808, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669813, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669813, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669816, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669812, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669821, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669817, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669819, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669817, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669823, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669822, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669827, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669827, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669829, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669826, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669831, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669832, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669827, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669828, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669832, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669828, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669828, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669835, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669832, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669838, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669833, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669834, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669834, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669835, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669843, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669846, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669847, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669848, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669848, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669850, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669853, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669851, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669853, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669846, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669853, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669856, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669848, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669848, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669856, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669852, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669860, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669855, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669863, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669868, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669861, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669866, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669865, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669864, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669870, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669863, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669867, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669874, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669877, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669871, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669871, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669878, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669879, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669880, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669881, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669882, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669874, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669884, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669884, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669883, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669883, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669883, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669888, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669892, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669888, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669897, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669895, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669892, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669896, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669894, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669899, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669899, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669900, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669902, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669901, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669898, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669903, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669904, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669905, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669898, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669904, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669900, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669902, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669911, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669903, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669910, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669913, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669905, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669914, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669912, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669918, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669920, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669918, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669921, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669914, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669921, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669923, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669917, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669926, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669928, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669923, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669929, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669927, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669931, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669932, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669932, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669929, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669924, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669932, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669933, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669932, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669932, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669936, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669934, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669937, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669934, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669939, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669940, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669946, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669948, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669943, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669951, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669954, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669951, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669952, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669950, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669952, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669955, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669954, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669952, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669955, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669960, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669961, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669961, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669965, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669965, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669966, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669971, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669969, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669968, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669967, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669970, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669974, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669971, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669978, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669978, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669978, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669974, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669979, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669979, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669982, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669981, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669984, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669984, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669987, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669982, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669980, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669985, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669984, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669996, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669998, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872669999, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670002, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670003, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670007, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670006, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670009, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670009, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670016, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670013, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670013, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670014, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670017, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670011, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670011, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670017, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670018, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670015, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670021, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670025, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670026, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670020, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670031, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670029, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670029, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670035, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670041, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670037, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670041, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670048, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670060, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670060, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670061, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670066, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670066, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670074, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670070, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670073, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670085, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670085, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670085, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670090, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
Namespace(adam_betas='(0.86,0.92)', adam_eps=1e-09, adaptive_softmax_cutoff=None, arch='transformer_wmt_en_de_big_t2t', attention_dropout=0.1, batch_multiple_strategy='dynamic', batching_scheme='v0p5_better', beam=4, bucket_growth_factor=1.035, clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', data='/data', dataloader_num_workers=2, decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, device_id=0, distributed_backend='nccl', distributed_init_method='env://', distributed_port=-1, distributed_rank=0, distributed_weight_update=2, distributed_world_size=960, dropout=0.1, dwu_compute_L2_grad_norm=True, dwu_do_not_flatten_model=False, dwu_e5m2_allgather=False, dwu_flat_mt=True, dwu_full_pipeline=False, dwu_group_size=0, dwu_num_ag_pg=0, dwu_num_ar_pg=2, dwu_num_blocks=4, dwu_num_chunks=1, dwu_num_rs_pg=2, dwu_overlap_reductions=True, enable_dataloader_pin_memory=True, enable_global_stats=False, enable_parallel_backward_allred_opt=False, enable_parallel_backward_allred_opt_correctness_check=False, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layers=6, encoder_learned_pos=False, encoder_normalize_before=True, fast_xentropy=True, fp16=True, gen_subset='test', ignore_case=True, keep_interval_updates=-1, label_smoothing=0.1, left_pad_source='True', left_pad_target='False', lenpen=0.6, local_rank=0, log_format=None, log_interval=1000, log_translations=False, lr=[0.001732], lr_scheduler='inverse_sqrt', lr_shrink=0.1, max_epoch=30, max_len_a=1.0, max_len_b=50, max_sentences=None, max_sentences_valid=None, max_source_positions=76, max_target_positions=76, max_tokens=768, max_update=0, min_len=1, min_loss_scale=0.0001, min_lr=0.0, model_overrides='{}', momentum=0.99, multihead_attn_impl='fast_with_lyrnrm_and_dropoutadd', nbest=1, no_beamable_mm=False, no_early_stop=False, no_epoch_checkpoints=False, no_progress_bar=True, no_save=True, no_token_positional_embeddings=False, num_shards=1, online_eval=False, optimizer='adam', parallel_backward_allred_cuda_nstreams=1, parallel_backward_allred_opt_threshold=0, path=None, prefix_size=0, print_alignment=False, profile=None, quiet=False, raw_text=False, relu_dropout=0.1, remove_bpe=None, replace_unk=None, restore_file='checkpoint_last.pt', sampling=False, sampling_temperature=1, sampling_topk=-1, save_dir='checkpoints', save_interval=1, save_interval_updates=0, score_reference=False, seed=30970, sentence_avg=False, seq_len_multiple=2, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang='en', target_bleu=25.0, target_lang='de', task='translation', time_step=False, train_subset='train', uniform_n_seq_in_dataset=None, uniform_n_seq_per_batch=None, uniform_seq_len_per_batch=None, unkpen=0, unnormalized=False, update_freq=[1], valid_subset='valid', validate_interval=1, warmup_init_lr=0.0, warmup_updates=400, weight_decay=0.0)
:::MLLOG {"namespace": "", "time_ms": 1592872670127, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 737280, "metadata": {"file": "/workspace/translation/train.py", "lineno": 133}}
:::MLLOG {"namespace": "", "time_ms": 1592872670127, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "adam", "metadata": {"file": "/workspace/translation/train.py", "lineno": 134}}
:::MLLOG {"namespace": "", "time_ms": 1592872670127, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.001732, "metadata": {"file": "/workspace/translation/train.py", "lineno": 136}}
:::MLLOG {"namespace": "", "time_ms": 1592872670127, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 400, "metadata": {"file": "/workspace/translation/train.py", "lineno": 137}}
:::MLLOG {"namespace": "", "time_ms": 1592872670127, "event_type": "POINT_IN_TIME", "key": "max_sequence_length", "value": 76, "metadata": {"file": "/workspace/translation/train.py", "lineno": 139, "method": "discard"}}
:::MLLOG {"namespace": "", "time_ms": 1592872670127, "event_type": "POINT_IN_TIME", "key": "opt_adam_beta_1", "value": 0.86, "metadata": {"file": "/workspace/translation/train.py", "lineno": 140}}
:::MLLOG {"namespace": "", "time_ms": 1592872670127, "event_type": "POINT_IN_TIME", "key": "opt_adam_beta_2", "value": 0.92, "metadata": {"file": "/workspace/translation/train.py", "lineno": 141}}
:::MLLOG {"namespace": "", "time_ms": 1592872670128, "event_type": "POINT_IN_TIME", "key": "opt_adam_epsilon", "value": 1e-09, "metadata": {"file": "/workspace/translation/train.py", "lineno": 142}}
:::MLLOG {"namespace": "", "time_ms": 1592872670128, "event_type": "POINT_IN_TIME", "key": "seed", "value": 30970, "metadata": {"file": "/workspace/translation/train.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1592872670088, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670095, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670104, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670098, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670099, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670112, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670113, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670116, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670116, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670123, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670123, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670129, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670131, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670130, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670132, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670140, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670132, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670137, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670147, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670146, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670145, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670150, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670158, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670175, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670186, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670198, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670205, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670224, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670227, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670243, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1592872670268, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
Using master seed from command line: 30970
Worker 0 is using worker seed: 2963455234
| [en] dictionary: 33712 types
| [de] dictionary: 33712 types
| model transformer_wmt_en_de_big_t2t, criterion LabelSmoothedCrossEntropyCriterion
| num. model params: 210808832
| training on 960 GPUs
| max tokens per GPU = 768 and max sentences per GPU = None
DistributedFusedAdam {'distributed_weight_update': 2, 'dwu_group_size': 0, 'dwu_num_blocks': 4, 'dwu_num_chunks': 1, 'dwu_num_rs_pg': 2, 'dwu_num_ar_pg': 2, 'dwu_num_ag_pg': 0, 'overlap_reductions': True, 'full_pipeline': False, 'compute_L2_grad_norm': True, 'flat_mt': True, 'e5m2_allgather': False, 'do_not_flatten_model': False}
self._net_total_param_size=210808832, self._total_param_size=210812928, dwu_min_page_size=16384, self._block_size=52703232, self._chunk_size=52703232, self._shard_size=3293952
[0, 15, 55, 104]
model_param_fragment.size()=torch.Size([3293952]), new_param_packed_fragment.size()=torch.Size([3293952]), master_param_fragment.size()=torch.Size([3293952])
model_param_fragment.size()=torch.Size([2800640]), new_param_packed_fragment.size()=torch.Size([2800640]), master_param_fragment.size()=torch.Size([2800640])
model_param_fragment.size()=torch.Size([4096]), new_param_packed_fragment.size()=torch.Size([4096]), master_param_fragment.size()=torch.Size([4096])
model_param_fragment.size()=torch.Size([489216]), new_param_packed_fragment.size()=torch.Size([489216]), master_param_fragment.size()=torch.Size([489216])
model_param_fragment.size()=torch.Size([465920]), new_param_packed_fragment.size()=torch.Size([465920]), master_param_fragment.size()=torch.Size([465920])
model_param_fragment.size()=torch.Size([4096]), new_param_packed_fragment.size()=torch.Size([4096]), master_param_fragment.size()=torch.Size([4096])
model_param_fragment.size()=torch.Size([2823936]), new_param_packed_fragment.size()=torch.Size([2823936]), master_param_fragment.size()=torch.Size([2823936])
model_param_fragment.size()=torch.Size([2328576]), new_param_packed_fragment.size()=torch.Size([2328576]), master_param_fragment.size()=torch.Size([2328576])
model_param_fragment.size()=torch.Size([1024]), new_param_packed_fragment.size()=torch.Size([1024]), master_param_fragment.size()=torch.Size([1024])
model_param_fragment.size()=torch.Size([1024]), new_param_packed_fragment.size()=torch.Size([1024]), master_param_fragment.size()=torch.Size([1024])
model_param_fragment.size()=torch.Size([1024]), new_param_packed_fragment.size()=torch.Size([1024]), master_param_fragment.size()=torch.Size([1024])
model_param_fragment.size()=torch.Size([962304]), new_param_packed_fragment.size()=torch.Size([962304]), master_param_fragment.size()=torch.Size([962304])
:::MLLOG {"namespace": "", "time_ms": 1592872735815, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 212}}
:::MLLOG {"namespace": "", "time_ms": 1592872735816, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 214}}
filename: /data/train.en-de.en
raw_text: False
| /data train 4590101 examples
filename: /data/train1.en-de.en
raw_text: False
filename: /data/train1.de-en.en
raw_text: False
srcline: tensor([  855,     3,    45,    96,   156,    10,  2688,   177,  5596,   163,     5,  9336, 14909, 12630,   527,   297, 15690,    70,     3,    68,    17,   927,    45,   482,   151,   283,  3551,  2091,     7,     5,   546,    24, 26623,  1617,  5440,    86,    15,  1524,  3522,   434,     3,   264,   199,   182,    86,    15,  4489,  8360,    69,   114,     5,   253,    41,    69,  3823,   203,     8,     5,  9336, 14909, 12630,   527,     4,     2])
| Sentences are being padded to multiples of: 2
filename: /data/test.en-de.en
raw_text: False
| /data test 3003 examples
srcline: tensor([ 7549,  4344,    64, 32364,  1259,    20, 13504,  8959,  3868,     2])
| Sentences are being padded to multiples of: 2
filename: /data/test1.en-de.en
raw_text: False
filename: /data/test1.de-en.en
raw_text: False
:::MLLOG {"namespace": "", "time_ms": 1592872736884, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 4590101, "metadata": {"file": "/workspace/translation/train.py", "lineno": 224}}
:::MLLOG {"namespace": "", "time_ms": 1592872736884, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 3003, "metadata": {"file": "/workspace/translation/train.py", "lineno": 227}}
self.dataset.src_sizes 4590101
self.dataset.tgt_sizes 4590101
generated 202088 batches in 2.883163s
got epoch iterator 2.8848633766174316
:::MLLOG {"namespace": "", "time_ms": 1592872739769, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 257, "first_epoch_num": 1, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1592872739772, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 258, "epoch_num": 1}}
| WARNING: overflow detected, setting loss scale to: 64.0
| WARNING: overflow detected, setting loss scale to: 32.0
| epoch 001 | loss 4800.923 | nll_loss 0.000 | ppl 1.00 | wps 1.52431e+07 | ups 3.5 | wpb 630550 | bsz 22 | num_updates 209 | lr 0.00090497 | gnorm 33563.247 | clip 100% | oom 0 | loss_scale 32.000 | wall 60
epoch time  9.048789501190186
:::MLLOG {"namespace": "", "time_ms": 1592872748821, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 273, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1592872748821, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 640, "epoch_num": 1}}
self.dataset.src_sizes 3003
self.dataset.tgt_sizes 3003
generated 376 batches in 0.000951s
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
| Translated 8 sentences (53 tokens) in 0.3s (27.32 sentences/s, 180.97 tokens/s)
| Generate test with beam=4: bleu_score=1.2268
| Eval completed in: 0.85s
:::MLLOG {"namespace": "", "time_ms": 1592872749672, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 751, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1592872749675, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.012268424965441227, "metadata": {"file": "/workspace/translation/train.py", "lineno": 280, "epoch_num": 1}}
validation and scoring  0.8546488285064697
:::MLLOG {"namespace": "", "time_ms": 1592872749675, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 295, "first_epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1592872749682, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 257, "first_epoch_num": 2, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1592872749682, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 258, "epoch_num": 2}}
| epoch 002 | loss 3209.693 | nll_loss 0.000 | ppl 1.00 | wps 1.69328e+07 | ups 23.9 | wpb 630524 | bsz 20 | num_updates 420 | lr 0.00169026 | gnorm 22728.388 | clip 100% | oom 0 | loss_scale 32.000 | wall 69
epoch time  7.973379611968994
:::MLLOG {"namespace": "", "time_ms": 1592872757655, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 273, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1592872757656, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 640, "epoch_num": 2}}
self.dataset.src_sizes 3003
self.dataset.tgt_sizes 3003
generated 376 batches in 0.000863s
| Translated 8 sentences (40 tokens) in 0.1s (139.91 sentences/s, 699.55 tokens/s)
| Generate test with beam=4: bleu_score=16.4651
| Eval completed in: 0.86s
:::MLLOG {"namespace": "", "time_ms": 1592872758516, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 751, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1592872758519, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.16465145349502563, "metadata": {"file": "/workspace/translation/train.py", "lineno": 280, "epoch_num": 2}}
validation and scoring  0.8642020225524902
:::MLLOG {"namespace": "", "time_ms": 1592872758520, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 295, "first_epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1592872758520, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 257, "first_epoch_num": 3, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1592872758520, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 258, "epoch_num": 3}}
| WARNING: overflow detected, setting loss scale to: 16.0
| epoch 003 | loss 2348.188 | nll_loss 0.000 | ppl 1.00 | wps 1.71762e+07 | ups 24.1 | wpb 630521 | bsz 22 | num_updates 630 | lr 0.00138009 | gnorm 16303.286 | clip 100% | oom 0 | loss_scale 16.000 | wall 78
epoch time  7.832889556884766
:::MLLOG {"namespace": "", "time_ms": 1592872766353, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 273, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592872766353, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 640, "epoch_num": 3}}
self.dataset.src_sizes 3003
self.dataset.tgt_sizes 3003
generated 376 batches in 0.000835s
| Translated 8 sentences (44 tokens) in 0.0s (170.44 sentences/s, 937.41 tokens/s)
| Generate test with beam=4: bleu_score=22.4670
| Eval completed in: 0.91s
:::MLLOG {"namespace": "", "time_ms": 1592872767263, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 751, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592872767266, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.2246696501970291, "metadata": {"file": "/workspace/translation/train.py", "lineno": 280, "epoch_num": 3}}
validation and scoring  0.913236141204834
:::MLLOG {"namespace": "", "time_ms": 1592872767266, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 295, "first_epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592872767267, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 257, "first_epoch_num": 4, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1592872767267, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 258, "epoch_num": 4}}
| WARNING: overflow detected, setting loss scale to: 8.0
| epoch 004 | loss 2085.732 | nll_loss 0.000 | ppl 1.00 | wps 1.71794e+07 | ups 24.0 | wpb 630542 | bsz 22 | num_updates 840 | lr 0.00119519 | gnorm 12580.582 | clip 100% | oom 0 | loss_scale 8.000 | wall 86
epoch time  7.833299160003662
:::MLLOG {"namespace": "", "time_ms": 1592872775100, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 273, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872775100, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 640, "epoch_num": 4}}
self.dataset.src_sizes 3003
self.dataset.tgt_sizes 3003
generated 376 batches in 0.000831s
| Translated 8 sentences (45 tokens) in 0.0s (185.29 sentences/s, 1042.25 tokens/s)
| Generate test with beam=4: bleu_score=24.4370
| Eval completed in: 0.90s
:::MLLOG {"namespace": "", "time_ms": 1592872776000, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 751, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872776002, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.24436980485916138, "metadata": {"file": "/workspace/translation/train.py", "lineno": 280, "epoch_num": 4}}
validation and scoring  0.902702808380127
:::MLLOG {"namespace": "", "time_ms": 1592872776003, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 295, "first_epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592872776003, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 257, "first_epoch_num": 5, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1592872776003, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 258, "epoch_num": 5}}
| epoch 005 | loss 2018.228 | nll_loss 0.000 | ppl 1.00 | wps 1.72649e+07 | ups 24.1 | wpb 630524 | bsz 22 | num_updates 1051 | lr 0.0010685 | gnorm 10239.995 | clip 100% | oom 0 | loss_scale 8.000 | wall 95
epoch time  7.845149278640747
:::MLLOG {"namespace": "", "time_ms": 1592872783848, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 273, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1592872783849, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 640, "epoch_num": 5}}
self.dataset.src_sizes 3003
self.dataset.tgt_sizes 3003
generated 376 batches in 0.000848s
| Translated 8 sentences (42 tokens) in 0.1s (155.34 sentences/s, 815.54 tokens/s)
| Generate test with beam=4: bleu_score=25.0875
| Eval completed in: 0.92s
:::MLLOG {"namespace": "", "time_ms": 1592872784770, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 751, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1592872784772, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.2508750259876251, "metadata": {"file": "/workspace/translation/train.py", "lineno": 280, "epoch_num": 5}}
validation and scoring  0.9245655536651611
:::MLLOG {"namespace": "", "time_ms": 1592872784773, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 295, "first_epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1592872784773, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 300, "status": "success"}}
| done training in 49.0 seconds
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ END=1592872796
++ END=1592872796
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:39:56 PM
++ END_FMT='2020-06-22 05:39:56 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:56 PM'
++ RESULT=136
++ END_FMT='2020-06-22 05:39:56 PM'
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:39:56 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:56 PM'
++ RESULT=136
++ RESULT_NAME=transformer
RESULT,transformer,30970,136,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,136,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,136,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,136,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872796
++ END=1592872796
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:39:56 PM
++ END_FMT='2020-06-22 05:39:56 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:56 PM'
++ RESULT=136
++ RESULT_NAME=transformer
RESULT,transformer,30970,136,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,136,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:56 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:56 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:56 PM
++ RESULT=136
++ RESULT_NAME=transformer
RESULT,transformer,30970,136,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,136,root,2020-06-22 05:37:40 PM'
+ set +x
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ sleep 3
++ sleep 3
++ sleep 3
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ [[ 0 != 0 ]]
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ sleep 3
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ END=1592872797
+++ date +%s
++ END=1592872797
++ [[ 0 != 0 ]]
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date +%s
++ END=1592872797
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
+++ date '+%Y-%m-%d %r'
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872797
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ sleep 3
++ sleep 3
++ sleep 3
++ END=1592872797
++ END=1592872797
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ END=1592872797
+++ date '+%Y-%m-%d %r'
++ END=1592872797
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ END=1592872797
++ ret_code=0
++ ret_code=0
+++ date '+%Y-%m-%d %r'
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ END=1592872797
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ END=1592872797
++ END=1592872797
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872797
++ END=1592872797
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ END=1592872797
++ END=1592872797
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
++ [[ 0 != 0 ]]
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ END=1592872797
+++ date '+%Y-%m-%d %r'
++ END=1592872797
+++ date '+%Y-%m-%d %r'
++ END=1592872797
++ END=1592872797
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ [[ 0 != 0 ]]
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date +%s
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ [[ 0 != 0 ]]
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date +%s
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:39:57 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872797
+++ date '+%Y-%m-%d %r'
++ END=1592872797
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
++ RESULT=137
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ END=1592872797
++ END=1592872797
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
++ END_FMT='2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872797
+++ date '+%Y-%m-%d %r'
++ END=1592872797
++ END=1592872797
+++ date '+%Y-%m-%d %r'
++ END=1592872797
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ [[ 0 != 0 ]]
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ RESULT=137
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
++ END_FMT='2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
+++ date +%s
++ RESULT=137
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872797
++ END=1592872797
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872797
++ END=1592872797
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872797
++ END=1592872797
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ END=1592872797
++ END=1592872797
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
+++ date +%s
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date +%s
++ END=1592872797
+++ date '+%Y-%m-%d %r'
++ END=1592872797
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ END=1592872797
++ END=1592872797
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872797
+++ date '+%Y-%m-%d %r'
++ END=1592872797
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
++ RESULT=137
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ END=1592872797
++ END=1592872797
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ END=1592872797
+++ date '+%Y-%m-%d %r'
++ END=1592872797
++ [[ 0 != 0 ]]
++ END=1592872797
+++ date +%s
+++ date '+%Y-%m-%d %r'
++ END=1592872797
++ END=1592872797
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
++ RESULT=137
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872797
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:57 PM'
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
++ RESULT=137
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
+ set +x
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ ret_code=0
++ sleep 3
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872797
++ END=1592872797
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872797
+++ date '+%Y-%m-%d %r'
++ ret_code=0
++ END=1592872797
++ sleep 3
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
++ RESULT=137
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ END=1592872797
++ ret_code=0
++ sleep 3
+++ date '+%Y-%m-%d %r'
++ END=1592872797
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ END=1592872797
++ END=1592872797
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872797
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ [[ 0 != 0 ]]
+++ date +%s
++ ret_code=0
++ sleep 3
++ END=1592872797
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ END_FMT='2020-06-22 05:39:57 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
++ RESULT=137
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ ret_code=0
++ sleep 3
++ END=1592872797
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:57 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:57 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:57 PM'
++ RESULT=137
++ RESULT_NAME=transformer
RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,137,root,2020-06-22 05:37:40 PM'
+ set +x
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ END=1592872798
++ END=1592872798
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ END=1592872798
++ END=1592872798
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
+++ date +%s
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
++ RESULT=138
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:39:58 PM'
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872798
+++ date '+%Y-%m-%d %r'
++ END=1592872798
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ sleep 3
++ sleep 3
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872798
+++ date '+%Y-%m-%d %r'
++ END=1592872798
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872798
++ END=1592872798
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872798
+++ date '+%Y-%m-%d %r'
++ END=1592872798
++ END_FMT='2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
+++ date '+%Y-%m-%d %r'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
++ RESULT=138
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ RESULT=138
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872798
+++ date '+%Y-%m-%d %r'
++ END=1592872798
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872798
++ [[ 0 != 0 ]]
++ END=1592872798
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date '+%Y-%m-%d %r'
++ END=1592872798
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ END=1592872798
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
++ RESULT=138
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ RESULT=138
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ END=1592872798
++ END=1592872798
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ RESULT=138
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872798
++ END=1592872798
++ END=1592872798
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
++ END=1592872798
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
+++ date +%s
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ END=1592872798
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872798
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
++ RESULT=138
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
++ RESULT=138
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ END=1592872798
+++ date '+%Y-%m-%d %r'
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ RESULT=138
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872798
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ RESULT=138
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ RESULT=138
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ RESULT=138
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ END=1592872798
++ END=1592872798
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ RESULT=138
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ END=1592872798
+++ date '+%Y-%m-%d %r'
++ END=1592872798
++ END=1592872798
++ END=1592872798
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872798
+++ date '+%Y-%m-%d %r'
++ END=1592872798
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
+++ date '+%Y-%m-%d %r'
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ [[ 0 != 0 ]]
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
++ END_FMT='2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
+++ date +%s
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ RESULT=138
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date +%s
++ END_FMT='2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ ret_code=0
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ sleep 3
++ sleep 3
++ ret_code=0
++ sleep 3
++ END=1592872798
++ END=1592872798
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ RESULT=138
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:39:58 PM'
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872798
++ END=1592872798
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ END=1592872798
++ END=1592872798
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
++ RESULT=138
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872798
+++ date '+%Y-%m-%d %r'
++ END=1592872798
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
++ RESULT=138
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
+ set +x
++ END=1592872798
++ END=1592872798
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
++ RESULT=138
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:39:58 PM'
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ END=1592872798
++ END=1592872798
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ ret_code=0
++ sleep 3
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
++ RESULT=138
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ RESULT=138
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ END=1592872798
++ END=1592872798
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ END=1592872798
++ END=1592872798
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:39:58 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ END=1592872798
++ END=1592872798
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ END_FMT='2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
+++ date +%s
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date +%s
++ END_FMT='2020-06-22 05:39:58 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ ret_code=0
++ sleep 3
++ END=1592872798
+++ date '+%Y-%m-%d %r'
++ END=1592872798
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
++ RESULT=138
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:39:58 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:58 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:58 PM'
++ RESULT=138
++ RESULT_NAME=transformer
RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,138,root,2020-06-22 05:37:40 PM'
+ set +x
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END=1592872799
++ END=1592872799
++ END=1592872799
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872799
++ END=1592872799
+++ date '+%Y-%m-%d %r'
++ END=1592872799
++ END=1592872799
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872799
++ END=1592872799
++ END=1592872799
++ END=1592872799
++ END=1592872799
++ END=1592872799
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:59 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:59 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:59 PM
++ RESULT=139
++ RESULT_NAME=transformer
RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:59 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:59 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:59 PM
++ RESULT=139
++ RESULT_NAME=transformer
RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:59 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:59 PM
RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:59 PM'
++ RESULT=139
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:59 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:59 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:59 PM
++ RESULT=139
++ RESULT_NAME=transformer
RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:59 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:59 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:59 PM
++ RESULT=139
++ RESULT_NAME=transformer
RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:59 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:59 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:59 PM
++ RESULT=139
++ RESULT_NAME=transformer
RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:59 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:59 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:59 PM
++ RESULT=139
++ RESULT_NAME=transformer
RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:59 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:59 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:59 PM'
++ RESULT=139
++ RESULT_NAME=transformer
RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:59 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:59 PM'
++ RESULT=139
++ END_FMT='2020-06-22 05:39:59 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:59 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:59 PM
RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:59 PM
+ set +x
RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM
++ RESULT=139
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:59 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:59 PM
RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:39:59 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:59 PM'
++ RESULT=139
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:39:59 PM
RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:59 PM'
++ RESULT=139
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:59 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:59 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:59 PM
++ RESULT=139
++ RESULT_NAME=transformer
RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM'
+ set +x
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ ret_code=0
++ sleep 3
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END=1592872799
++ END=1592872799
++ END=1592872799
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872799
+++ date '+%Y-%m-%d %r'
++ END=1592872799
++ END=1592872799
+++ date '+%Y-%m-%d %r'
++ END=1592872799
++ END=1592872799
++ END=1592872799
++ END=1592872799
+++ date '+%Y-%m-%d %r'
++ END=1592872799
++ END=1592872799
++ END=1592872799
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:59 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:59 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:59 PM
++ RESULT=139
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:39:59 PM'
RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:39:59 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:59 PM'
++ RESULT=139
++ RESULT_NAME=transformer
RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:39:59 PM
++ END_FMT='2020-06-22 05:39:59 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:59 PM'
++ RESULT=139
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:59 PM
RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:39:59 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:59 PM'
++ RESULT=139
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:39:59 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:59 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:59 PM
++ RESULT=139
++ RESULT_NAME=transformer
RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:59 PM'
++ END_FMT='2020-06-22 05:39:59 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:59 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:59 PM'
++ RESULT=139
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:59 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:59 PM
RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM'
++ RESULT=139
++ RESULT_NAME=transformer
+ set +x
RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:59 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:59 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:59 PM
++ RESULT=139
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:39:59 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:59 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:59 PM
++ RESULT=139
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:39:59 PM'
++ END_FMT='2020-06-22 05:39:59 PM'
RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:39:59 PM'
++ END_FMT='2020-06-22 05:39:59 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:59 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:59 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:59 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:59 PM'
++ RESULT=139
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:39:59 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:59 PM'
++ RESULT=139
++ RESULT_NAME=transformer
++ RESULT=139
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:39:59 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:59 PM'
++ RESULT=139
++ RESULT_NAME=transformer
RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ ret_code=0
++ sleep 3
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872799
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:59 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:59 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:59 PM
++ RESULT=139
++ RESULT_NAME=transformer
RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872799
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:39:59 PM'
ENDING TIMING RUN AT 2020-06-22 05:39:59 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:39:59 PM'
++ RESULT=139
++ RESULT_NAME=transformer
RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,139,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:00 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ RESULT=140
++ END_FMT='2020-06-22 05:40:00 PM'
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT=140
++ RESULT_NAME=transformer
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
+ set +x
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END_FMT='2020-06-22 05:40:00 PM'
+++ date +%s
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
+++ date +%s
++ END_FMT='2020-06-22 05:40:00 PM'
+++ date +%s
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
+++ date +%s
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ RESULT=140
++ RESULT_NAME=transformer
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ RESULT=140
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
+ set +x
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
+ set +x
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
+ set +x
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END=1592872800
++ [[ 0 != 0 ]]
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
++ END=1592872800
++ [[ 0 != 0 ]]
++ END=1592872800
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ END=1592872800
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ END=1592872800
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ END=1592872800
++ [[ 0 != 0 ]]
++ END=1592872800
++ [[ 0 != 0 ]]
++ END=1592872800
+++ date +%s
++ END=1592872800
+++ date +%s
++ END=1592872800
++ END=1592872800
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date +%s
+++ date +%s
++ END=1592872800
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date +%s
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END=1592872800
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ END=1592872800
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ RESULT=140
++ RESULT_NAME=transformer
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ RESULT=140
++ RESULT_NAME=transformer
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT_NAME=transformer
++ RESULT=140
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ RESULT_NAME=transformer
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT=140
++ RESULT_NAME=transformer
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
slurmstepd: error: _is_a_lwp: open() /proc/93292/status failed: No such file or directory
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:00 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
+ set +x
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT=140
++ RESULT_NAME=transformer
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ RESULT=140
+ set +x
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ END_FMT='2020-06-22 05:40:00 PM'
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
+ set +x
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ RESULT_NAME=transformer
+ set +x
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:00 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ [[ 0 != 0 ]]
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
+ set +x
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ [[ 0 != 0 ]]
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ [[ 0 != 0 ]]
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ [[ 0 != 0 ]]
++ RESULT=140
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ [[ 0 != 0 ]]
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ [[ 0 != 0 ]]
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ [[ 0 != 0 ]]
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
+ set +x
++ [[ 0 != 0 ]]
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ [[ 0 != 0 ]]
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ [[ 0 != 0 ]]
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ [[ 0 != 0 ]]
++ RESULT=140
++ [[ 0 != 0 ]]
++ RESULT_NAME=transformer
++ [[ 0 != 0 ]]
+ set +x
+++ date +%s
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
+ set +x
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ RESULT=140
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+++ date +%s
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+++ date +%s
+ set +x
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
+++ date +%s
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
+ set +x
+++ date +%s
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+++ date +%s
++ RESULT=140
++ RESULT=140
++ RESULT_NAME=transformer
++ RESULT_NAME=transformer
+++ date +%s
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+++ date +%s
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date +%s
+++ date +%s
++ END_FMT='2020-06-22 05:40:00 PM'
+++ date +%s
+++ date +%s
+++ date +%s
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ RESULT=140
++ RESULT_NAME=transformer
+ set +x
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ END_FMT='2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ RESULT_NAME=transformer
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END=1592872800
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
+ set +x
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ END=1592872800
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:00 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ RESULT=140
++ END_FMT='2020-06-22 05:40:00 PM'
++ RESULT_NAME=transformer
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
+ set +x
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT=140
++ RESULT_NAME=transformer
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ [[ 0 != 0 ]]
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ [[ 0 != 0 ]]
++ RESULT=140
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ [[ 0 != 0 ]]
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
++ [[ 0 != 0 ]]
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ [[ 0 != 0 ]]
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ [[ 0 != 0 ]]
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
+ set +x
+ set +x
+++ date +%s
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+++ date +%s
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
+++ date +%s
+++ date +%s
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+++ date +%s
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date +%s
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ RESULT=140
++ RESULT_NAME=transformer
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
+ set +x
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ END_FMT='2020-06-22 05:40:00 PM'
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ [[ 0 != 0 ]]
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ RESULT=140
++ RESULT_NAME=transformer
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ [[ 0 != 0 ]]
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ [[ 0 != 0 ]]
++ RESULT=140
++ RESULT_NAME=transformer
++ [[ 0 != 0 ]]
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ [[ 0 != 0 ]]
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ [[ 0 != 0 ]]
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ [[ 0 != 0 ]]
+++ date +%s
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+++ date +%s
+++ date +%s
+++ date +%s
+ set +x
+++ date +%s
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
+ set +x
+++ date +%s
++ END_FMT='2020-06-22 05:40:00 PM'
++ [[ 0 != 0 ]]
+++ date +%s
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ [[ 0 != 0 ]]
++ RESULT=140
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ [[ 0 != 0 ]]
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
+++ date +%s
++ [[ 0 != 0 ]]
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+++ date +%s
+++ date +%s
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
+ set +x
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ END=1592872800
++ END=1592872800
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ RESULT=140
+ set +x
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ END_FMT='2020-06-22 05:40:00 PM'
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ RESULT=140
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ RESULT=140
++ RESULT_NAME=transformer
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
+ set +x
+++ date '+%Y-%m-%d %r'
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ RESULT=140
+ set +x
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
+ set +x
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT=140
++ RESULT_NAME=transformer
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ [[ 0 != 0 ]]
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ [[ 0 != 0 ]]
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ [[ 0 != 0 ]]
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
slurmstepd: error: _is_a_lwp: open() /proc/14626/status failed: No such file or directory
+++ date +%s
++ END_FMT='2020-06-22 05:40:00 PM'
+++ date +%s
++ END_FMT='2020-06-22 05:40:00 PM'
+++ date +%s
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+++ date +%s
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
+++ date +%s
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+++ date +%s
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
+++ date +%s
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+++ date +%s
+ set +x
+++ date +%s
+++ date +%s
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ RESULT=140
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
+ set +x
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ RESULT=140
++ RESULT_NAME=transformer
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ RESULT=140
++ RESULT_NAME=transformer
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ RESULT=140
++ RESULT_NAME=transformer
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
++ END_FMT='2020-06-22 05:40:00 PM'
+++ date +%s
+++ date +%s
+++ date +%s
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
+++ date +%s
++ RESULT=140
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date +%s
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872800
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END_FMT='2020-06-22 05:40:00 PM'
+++ date +%s
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT_NAME=transformer
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END=1592872800
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ END=1592872800
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ END=1592872800
+ set +x
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ END=1592872800
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ END=1592872800
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ RESULT=140
+ set +x
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ END_FMT='2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
+ set +x
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
+ set +x
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
+++ date +%s
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
+++ date +%s
++ END_FMT='2020-06-22 05:40:00 PM'
+++ date +%s
++ END_FMT='2020-06-22 05:40:00 PM'
+++ date +%s
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
+++ date +%s
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
+ set +x
+++ date +%s
+++ date +%s
+++ date +%s
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872800
++ END=1592872800
++ [[ 0 != 0 ]]
++ END=1592872800
++ END=1592872800
+++ date +%s
++ END=1592872800
+++ date +%s
+++ date +%s
++ END=1592872800
+++ date +%s
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date +%s
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END=1592872800
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END=1592872800
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ END=1592872800
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END=1592872800
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ END=1592872800
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END=1592872800
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
+++ date '+%Y-%m-%d %r'
++ RESULT=140
++ END_FMT='2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ RESULT=140
++ RESULT_NAME=transformer
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ END=1592872800
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
+++ date '+%Y-%m-%d %r'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
+++ date '+%Y-%m-%d %r'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT=140
++ RESULT_NAME=transformer
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
+ set +x
+ set +x
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:00 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ RESULT=140
++ RESULT_NAME=transformer
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date +%s
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ END=1592872800
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:00 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
++ RESULT=140
++ RESULT_NAME=transformer
+ set +x
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ END=1592872800
+++ date +%s
+++ date '+%Y-%m-%d %r'
++ END=1592872800
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
+ set +x
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
+++ date +%s
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
+++ date +%s
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872800
++ [[ 0 != 0 ]]
+++ date '+%Y-%m-%d %r'
+++ date +%s
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872800
++ END_FMT='2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ END=1592872800
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
+++ date +%s
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872800
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872800
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:40:00 PM
++ END_FMT='2020-06-22 05:40:00 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:00 PM'
++ RESULT=140
++ RESULT_NAME=transformer
RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,140,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872801
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
+++ date +%s
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT_NAME=transformer
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ RESULT=141
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
+ set +x
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ END=1592872801
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ [[ 0 != 0 ]]
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ END_FMT='2020-06-22 05:40:01 PM'
+++ date +%s
+++ date +%s
+++ date +%s
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ [[ 0 != 0 ]]
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
+++ date +%s
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ [[ 0 != 0 ]]
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ END_FMT='2020-06-22 05:40:01 PM'
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ [[ 0 != 0 ]]
++ END_FMT='2020-06-22 05:40:01 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+++ date +%s
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
+++ date +%s
+++ date +%s
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
+++ date +%s
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+ set +x
++ END=1592872801
+++ date +%s
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END=1592872801
++ [[ 0 != 0 ]]
+++ date +%s
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ [[ 0 != 0 ]]
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ [[ 0 != 0 ]]
++ END_FMT='2020-06-22 05:40:01 PM'
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+++ date +%s
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ END=1592872801
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT=141
+++ date +%s
++ RESULT_NAME=transformer
+++ date +%s
+++ date +%s
+++ date +%s
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ END=1592872801
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date +%s
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ END=1592872801
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ END=1592872801
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872801
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
+++ date +%s
+ set +x
+++ date '+%Y-%m-%d %r'
+ set +x
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END_FMT='2020-06-22 05:40:01 PM'
+++ date +%s
++ END=1592872801
+++ date +%s
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ END=1592872801
+++ date +%s
++ RESULT=141
+++ date +%s
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
++ END=1592872801
+++ date +%s
+++ date +%s
+++ date +%s
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END=1592872801
++ RESULT=141
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
+++ date '+%Y-%m-%d %r'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ END=1592872801
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ END=1592872801
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872801
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
+++ date '+%Y-%m-%d %r'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ END=1592872801
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ END=1592872801
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872801
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ END=1592872801
++ END=1592872801
++ END_FMT='2020-06-22 05:40:01 PM'
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END=1592872801
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
+++ date '+%Y-%m-%d %r'
++ RESULT=141
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
++ END=1592872801
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ END=1592872801
+ set +x
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END_FMT='2020-06-22 05:40:01 PM'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
+++ date '+%Y-%m-%d %r'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:01 PM'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END=1592872801
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
+ set +x
++ RESULT=141
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
+++ date '+%Y-%m-%d %r'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
+++ date '+%Y-%m-%d %r'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT=141
++ RESULT_NAME=transformer
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
+++ date '+%Y-%m-%d %r'
++ RESULT=141
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT=141
++ RESULT_NAME=transformer
+ set +x
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
+++ date '+%Y-%m-%d %r'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ END_FMT='2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date '+%Y-%m-%d %r'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
+ set +x
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
+ set +x
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT=141
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:01 PM'
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT=141
++ RESULT_NAME=transformer
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
+ set +x
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ RESULT=141
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT_NAME=transformer
++ RESULT=141
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
+ set +x
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
+ set +x
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
+ set +x
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
+ set +x
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT_NAME=transformer
++ RESULT=141
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ RESULT_NAME=transformer
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ END_FMT='2020-06-22 05:40:01 PM'
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
+ set +x
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ RESULT=141
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ RESULT=141
++ RESULT_NAME=transformer
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END=1592872801
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ END=1592872801
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END=1592872801
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ RESULT=141
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ END=1592872801
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
+ set +x
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ [[ 0 != 0 ]]
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ [[ 0 != 0 ]]
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ END_FMT='2020-06-22 05:40:01 PM'
++ [[ 0 != 0 ]]
++ END_FMT='2020-06-22 05:40:01 PM'
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ [[ 0 != 0 ]]
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ END_FMT='2020-06-22 05:40:01 PM'
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT=141
++ RESULT_NAME=transformer
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END_FMT='2020-06-22 05:40:01 PM'
+++ date +%s
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
+++ date +%s
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ RESULT=141
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
+ set +x
++ RESULT_NAME=transformer
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872801
++ END=1592872801
++ END=1592872801
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END=1592872801
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ END=1592872801
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ END=1592872801
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ [[ 0 != 0 ]]
++ END=1592872801
++ RESULT=141
+++ date '+%Y-%m-%d %r'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872801
++ [[ 0 != 0 ]]
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ END=1592872801
++ [[ 0 != 0 ]]
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date +%s
+++ date +%s
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date +%s
++ END=1592872801
+++ date +%s
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date +%s
++ END=1592872801
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ RESULT=141
++ END=1592872801
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ END=1592872801
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872801
++ END=1592872801
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END=1592872801
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ END=1592872801
++ RESULT=141
++ RESULT_NAME=transformer
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ END=1592872801
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ END=1592872801
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ END=1592872801
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END=1592872801
++ END=1592872801
++ RESULT=141
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ END=1592872801
++ RESULT_NAME=transformer
+++ date '+%Y-%m-%d %r'
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
+ set +x
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ END=1592872801
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
+++ date '+%Y-%m-%d %r'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
+++ date '+%Y-%m-%d %r'
++ RESULT=141
++ RESULT_NAME=transformer
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
+ set +x
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT_NAME=transformer
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ RESULT=141
++ RESULT_NAME=transformer
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ END=1592872801
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ END=1592872801
+++ date +%s
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ END=1592872801
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date +%s
+++ date +%s
++ END=1592872801
+++ date +%s
+++ date +%s
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ RESULT=141
++ RESULT_NAME=transformer
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ END=1592872801
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ END=1592872801
++ RESULT_NAME=transformer
++ END=1592872801
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ END=1592872801
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872801
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ END=1592872801
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+ set +x
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
+++ date '+%Y-%m-%d %r'
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
slurmstepd: error: _is_a_lwp: open() /proc/62116/status failed: No such file or directory
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ RESULT=141
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date '+%Y-%m-%d %r'
+ set +x
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
+++ date '+%Y-%m-%d %r'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
+++ date '+%Y-%m-%d %r'
++ RESULT=141
++ RESULT=141
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
+ set +x
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT=141
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
+ set +x
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ RESULT_NAME=transformer
++ RESULT=141
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ RESULT_NAME=transformer
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ RESULT=141
++ RESULT_NAME=transformer
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT_NAME=transformer
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ END_FMT='2020-06-22 05:40:01 PM'
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ END=1592872801
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT=141
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
+ set +x
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
+++ date +%s
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ [[ 0 != 0 ]]
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
slurmstepd: error: _is_a_lwp: open() /proc/96348/status failed: No such file or directory
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
++ END_FMT='2020-06-22 05:40:01 PM'
+++ date +%s
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+++ date +%s
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
+++ date +%s
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
+++ date +%s
+++ date +%s
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date +%s
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date +%s
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872801
++ END_FMT='2020-06-22 05:40:01 PM'
++ END=1592872801
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT=141
++ RESULT_NAME=transformer
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ RESULT=141
++ RESULT_NAME=transformer
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
+ set +x
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ RESULT=141
++ RESULT_NAME=transformer
+ set +x
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ END=1592872801
++ END=1592872801
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
++ END=1592872801
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date +%s
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date +%s
++ END=1592872801
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872801
++ END=1592872801
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date +%s
+++ date +%s
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date +%s
+++ date +%s
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ END=1592872801
++ RESULT=141
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
slurmstepd: error: _is_a_lwp: open() /proc/47574/status failed: No such file or directory
++ END_FMT='2020-06-22 05:40:01 PM'
+++ date '+%Y-%m-%d %r'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ END=1592872801
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END=1592872801
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
+ set +x
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END=1592872801
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ END=1592872801
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ END=1592872801
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT_NAME=transformer
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ END=1592872801
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ END=1592872801
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
slurmstepd: error: _is_a_lwp: open() /proc/47580/status failed: No such file or directory
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ END=1592872801
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+++ date '+%Y-%m-%d %r'
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END_FMT='2020-06-22 05:40:01 PM'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ END=1592872801
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
+++ date +%s
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
+++ date +%s
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+++ date +%s
+++ date +%s
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+++ date +%s
+ set +x
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ [[ 0 != 0 ]]
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
+++ date +%s
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
+++ date +%s
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
+++ date +%s
+++ date +%s
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+++ date +%s
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
+++ date +%s
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT_NAME=transformer
++ END_FMT='2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
+++ date '+%Y-%m-%d %r'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
+++ date '+%Y-%m-%d %r'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT=141
++ RESULT_NAME=transformer
+++ date '+%Y-%m-%d %r'
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ RESULT_NAME=transformer
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT=141
++ RESULT_NAME=transformer
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ RESULT=141
++ RESULT_NAME=transformer
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ RESULT=141
++ RESULT_NAME=transformer
+ set +x
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ RESULT=141
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
+ set +x
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ RESULT=141
++ RESULT_NAME=transformer
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
slurmstepd: error: _is_a_lwp: open() /proc/95085/status failed: No such file or directory
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT=141
++ RESULT_NAME=transformer
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
+ set +x
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
+++ date +%s
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
++ END=1592872801
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
+ set +x
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
+++ date '+%Y-%m-%d %r'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ END_FMT='2020-06-22 05:40:01 PM'
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
+ set +x
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ RESULT=141
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
+ set +x
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872801
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872801
++ END=1592872801
+++ date '+%Y-%m-%d %r'
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
+++ date +%s
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
++ END=1592872801
+++ date +%s
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ END=1592872801
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
++ [[ 0 != 0 ]]
+++ date +%s
+++ date +%s
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
++ END_FMT='2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
+++ date +%s
++ RESULT=141
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ END=1592872801
+++ date '+%Y-%m-%d %r'
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
ENDING TIMING RUN AT 2020-06-22 05:40:01 PM
++ END_FMT='2020-06-22 05:40:01 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:01 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872801
+++ date '+%Y-%m-%d %r'
++ [[ 0 != 0 ]]
+++ date +%s
++ END_FMT='2020-06-22 05:40:02 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:02 PM
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:02 PM'
++ RESULT=141
++ RESULT_NAME=transformer
RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,141,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872802
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:02 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:02 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:02 PM
++ RESULT=142
++ RESULT_NAME=transformer
RESULT,transformer,30970,142,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,142,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872802
++ [[ 0 != 0 ]]
+++ date '+%Y-%m-%d %r'
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ [[ 0 != 0 ]]
+++ date +%s
++ END_FMT='2020-06-22 05:40:02 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:02 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:02 PM
++ RESULT=142
++ RESULT_NAME=transformer
RESULT,transformer,30970,142,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,142,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872802
++ [[ 0 != 0 ]]
+++ date '+%Y-%m-%d %r'
+++ date +%s
++ END=1592872802
+++ date '+%Y-%m-%d %r'
++ END=1592872802
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:02 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:02 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:02 PM
++ RESULT=142
++ RESULT_NAME=transformer
RESULT,transformer,30970,142,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,142,root,2020-06-22 05:37:40 PM'
+ set +x
++ END=1592872802
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:02 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:02 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:02 PM
++ RESULT=142
++ RESULT_NAME=transformer
RESULT,transformer,30970,142,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,142,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:02 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:02 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:02 PM
++ RESULT=142
++ RESULT_NAME=transformer
RESULT,transformer,30970,142,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,142,root,2020-06-22 05:37:40 PM'
+ set +x
++ END_FMT='2020-06-22 05:40:02 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:02 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:02 PM
++ RESULT=142
++ RESULT_NAME=transformer
RESULT,transformer,30970,142,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,142,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872802
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:02 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:02 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:02 PM
++ RESULT=142
++ RESULT_NAME=transformer
RESULT,transformer,30970,142,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,142,root,2020-06-22 05:37:40 PM'
+ set +x
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1592872802
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-22 05:40:02 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-22 05:40:02 PM'
ENDING TIMING RUN AT 2020-06-22 05:40:02 PM
++ RESULT=142
++ RESULT_NAME=transformer
RESULT,transformer,30970,142,root,2020-06-22 05:37:40 PM
++ echo 'RESULT,transformer,30970,142,root,2020-06-22 05:37:40 PM'
+ set +x
