+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ srun --nodes=1 --ntasks=1 --container-name=single_stage_detector python -c '
import mlperf_log_utils
from mlperf_logging.mllog import constants
mlperf_log_utils.mlperf_submission_log(constants.SSD)'
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
:::MLLOG {"namespace": "", "time_ms": 1592669903805, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "ssd", "metadata": {"file": "/workspace/single_stage_detector/mlperf_log_utils.py", "lineno": 17}}
:::MLLOG {"namespace": "", "time_ms": 1592669903845, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "NVIDIA", "metadata": {"file": "/workspace/single_stage_detector/mlperf_log_utils.py", "lineno": 22}}
:::MLLOG {"namespace": "", "time_ms": 1592669903845, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/single_stage_detector/mlperf_log_utils.py", "lineno": 26}}
:::MLLOG {"namespace": "", "time_ms": 1592669903845, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/single_stage_detector/mlperf_log_utils.py", "lineno": 30}}
:::MLLOG {"namespace": "", "time_ms": 1592669903845, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "1xNVIDIA DGX A100", "metadata": {"file": "/workspace/single_stage_detector/mlperf_log_utils.py", "lineno": 34}}
+ '[' 1 -eq 1 ']'
+ srun --ntasks=1 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0146
vm.drop_caches = 3
+ srun --ntasks=1 --container-name=single_stage_detector python -c '
from mlperf_logging.mllog import constants
from mlperf_logger import log_event
log_event(key=constants.CACHE_CLEAR, value=True)'
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
:::MLLOG {"namespace": "", "time_ms": 1592669909601, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
+ srun --mpi=none --ntasks=8 --ntasks-per-node=8 --container-name=single_stage_detector --container-mounts=/raid/datasets/coco/coco-2017:/data,/lustre/fsw/mlperf-ci/13964269/results:/results ./run_and_time.sh
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-20 09:18:31 AM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
++ pwd
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 8 -gt 1 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
STARTING TIMING RUN AT 2020-06-20 09:18:31 AM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
STARTING TIMING RUN AT 2020-06-20 09:18:31 AM
STARTING TIMING RUN AT 2020-06-20 09:18:31 AM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
STARTING TIMING RUN AT 2020-06-20 09:18:31 AM
++ pwd
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
+ '[' -n 3 ']'
++ pwd
+ '[' 8 -gt 1 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
++ pwd
STARTING TIMING RUN AT 2020-06-20 09:18:31 AM
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ NUMEPOCHS=80
+ declare -a CMD
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ '[' -n 2 ']'
++ pwd
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ '[' 8 -gt 1 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ declare -a CMD
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
+ '[' -n 1 ']'
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ '[' 8 -gt 1 ']'
+ declare -a CMD
+ CMD=('./bind.sh' '--' 'python' '-u')
+ '[' -n 7 ']'
+ '[' 8 -gt 1 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
++ pwd
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 8 -gt 1 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
STARTING TIMING RUN AT 2020-06-20 09:18:31 AM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
++ pwd
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 8 -gt 1 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
STARTING TIMING RUN AT 2020-06-20 09:18:31 AM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
++ pwd
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 8 -gt 1 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=6 --membind=6 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=3 --membind=3 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=4 --membind=4 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
+ exec numactl --cpunodebind=1 --membind=1 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
+ exec numactl --cpunodebind=7 --membind=7 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
:::MLLOG {"namespace": "", "time_ms": 1592669913539, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592669913629, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592669913650, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592669913712, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592669913814, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592669913850, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592669913858, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592669913858, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592669916251, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2812561658, "metadata": {"file": "/workspace/single_stage_detector/mlperf_logger.py", "lineno": 92}}
0 Using seed = 2812561658
2 Using seed = 2812561660
1 Using seed = 2812561659
3 Using seed = 2812561661
4 Using seed = 2812561662
5 Using seed = 2812561663
7 Using seed = 2812561665
6 Using seed = 2812561664
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 35%|      | 28.8M/83.3M [00:00<00:00, 302MB/s]
 74%|  | 61.6M/83.3M [00:00<00:00, 314MB/s]
100%|| 83.3M/83.3M [00:00<00:00, 323MB/s]

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 37%|      | 30.6M/83.3M [00:00<00:00, 321MB/s]
 75%|  | 62.6M/83.3M [00:00<00:00, 325MB/s]
100%|| 83.3M/83.3M [00:00<00:00, 326MB/s]

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 30%|       | 25.1M/83.3M [00:00<00:00, 263MB/s]
 65%|   | 54.2M/83.3M [00:00<00:00, 274MB/s]
100%|| 83.3M/83.3M [00:00<00:00, 292MB/s]

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 27%|       | 22.8M/83.3M [00:00<00:00, 239MB/s]
 58%|    | 48.6M/83.3M [00:00<00:00, 248MB/s]
 95%|| 79.0M/83.3M [00:00<00:00, 266MB/s]
100%|| 83.3M/83.3M [00:00<00:00, 280MB/s]

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 32%|      | 26.9M/83.3M [00:00<00:00, 281MB/s]
 63%|   | 52.2M/83.3M [00:00<00:00, 276MB/s]
 98%|| 81.4M/83.3M [00:00<00:00, 284MB/s]
100%|| 83.3M/83.3M [00:00<00:00, 274MB/s]

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 38%|      | 31.6M/83.3M [00:00<00:00, 310MB/s]
 70%|   | 58.6M/83.3M [00:00<00:00, 301MB/s]
 95%|| 79.4M/83.3M [00:00<00:00, 271MB/s]
100%|| 83.3M/83.3M [00:00<00:00, 274MB/s]

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 13%|        | 11.1M/83.3M [00:00<00:00, 116MB/s]
 28%|       | 23.2M/83.3M [00:00<00:00, 119MB/s]
 46%|     | 38.3M/83.3M [00:00<00:00, 129MB/s]
 90%| | 75.1M/83.3M [00:00<00:00, 161MB/s]
100%|| 83.3M/83.3M [00:00<00:00, 200MB/s]

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 17%|        | 14.2M/83.3M [00:00<00:00, 149MB/s]
 34%|      | 27.9M/83.3M [00:00<00:00, 147MB/s]
 52%|    | 43.0M/83.3M [00:00<00:00, 150MB/s]
 83%| | 69.5M/83.3M [00:00<00:00, 174MB/s]
100%|| 83.3M/83.3M [00:00<00:00, 193MB/s]
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
:::MLLOG {"namespace": "", "time_ms": 1592669922911, "event_type": "POINT_IN_TIME", "key": "model_bn_span", "value": 114, "metadata": {"file": "train.py", "lineno": 170}}
:::MLLOG {"namespace": "", "time_ms": 1592669922911, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 912, "metadata": {"file": "train.py", "lineno": 171}}
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : 128.0
Delaying allreduces to the end of backward()
:::MLLOG {"namespace": "", "time_ms": 1592669922921, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.09, "metadata": {"file": "train.py", "lineno": 199}}
:::MLLOG {"namespace": "", "time_ms": 1592669922921, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_boundary_epochs", "value": [44, 55], "metadata": {"file": "train.py", "lineno": 200}}
:::MLLOG {"namespace": "", "time_ms": 1592669922921, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_steps", "value": [44, 55], "metadata": {"file": "train.py", "lineno": 201}}
:::MLLOG {"namespace": "", "time_ms": 1592669922921, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.00013, "metadata": {"file": "train.py", "lineno": 202}}
:::MLLOG {"namespace": "", "time_ms": 1592669922921, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 650, "metadata": {"file": "train.py", "lineno": 204}}
:::MLLOG {"namespace": "", "time_ms": 1592669922922, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_factor", "value": 0, "metadata": {"file": "train.py", "lineno": 205}}
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
epoch nbatch loss
:::MLLOG {"namespace": "", "time_ms": 1592669946266, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "train.py", "lineno": 267}}
:::MLLOG {"namespace": "", "time_ms": 1592669946266, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "train.py", "lineno": 274}}
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
:::MLLOG {"namespace": "", "time_ms": 1592669948371, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 117266, "metadata": {"file": "/workspace/single_stage_detector/data/build_pipeline.py", "lineno": 48}}
epoch size is:  117266  images
:::MLLOG {"namespace": "", "time_ms": 1592669948372, "event_type": "POINT_IN_TIME", "key": "max_samples", "value": 1, "metadata": {"file": "/workspace/single_stage_detector/utils.py", "lineno": 156}}
loading annotations into memory...
Done (t=0.12s)
creating index...
Done (t=0.12s)
creating index...
Done (t=0.11s)
creating index...
Done (t=0.11s)
creating index...
Done (t=0.12s)
creating index...
Done (t=0.11s)
creating index...
Done (t=0.12s)
creating index...
Done (t=0.12s)
creating index...
:::MLLOG {"namespace": "", "time_ms": 1592669948602, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 4952, "metadata": {"file": "/workspace/single_stage_detector/data/native_pipeline.py", "lineno": 97}}
:::MLLOG {"namespace": "", "time_ms": 1592669948603, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 293, "first_epoch_num": 1, "epoch_count": 40}}
:::MLLOG {"namespace": "", "time_ms": 1592669948604, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 1, "current_iter_num": 0}}
Iteration:      0, Loss function: 22.718, Average Loss: 0.023, avg. samples / sec: 35.66
Iteration:     20, Loss function: 20.688, Average Loss: 0.443, avg. samples / sec: 8131.04
Iteration:     40, Loss function: 19.040, Average Loss: 0.832, avg. samples / sec: 8788.64
Iteration:     60, Loss function: 14.524, Average Loss: 1.104, avg. samples / sec: 9239.10
Iteration:     80, Loss function: 11.929, Average Loss: 1.314, avg. samples / sec: 9214.34
Iteration:    100, Loss function: 9.369, Average Loss: 1.484, avg. samples / sec: 9304.31
Iteration:    120, Loss function: 9.199, Average Loss: 1.637, avg. samples / sec: 9336.04
:::MLLOG {"namespace": "", "time_ms": 1592669961832, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1592669961833, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 2, "current_iter_num": 129}}
Iteration:    140, Loss function: 9.159, Average Loss: 1.782, avg. samples / sec: 9313.53
Iteration:    160, Loss function: 8.531, Average Loss: 1.919, avg. samples / sec: 9451.79
Iteration:    180, Loss function: 8.248, Average Loss: 2.051, avg. samples / sec: 9471.54
Iteration:    200, Loss function: 8.040, Average Loss: 2.173, avg. samples / sec: 9403.79
Iteration:    220, Loss function: 7.841, Average Loss: 2.291, avg. samples / sec: 9452.67
Iteration:    240, Loss function: 7.890, Average Loss: 2.405, avg. samples / sec: 9455.32
:::MLLOG {"namespace": "", "time_ms": 1592669974285, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1592669974286, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 3, "current_iter_num": 258}}
Iteration:    260, Loss function: 7.841, Average Loss: 2.511, avg. samples / sec: 9549.73
Iteration:    280, Loss function: 7.601, Average Loss: 2.615, avg. samples / sec: 9547.83
Iteration:    300, Loss function: 7.117, Average Loss: 2.711, avg. samples / sec: 9549.43
Iteration:    320, Loss function: 7.498, Average Loss: 2.800, avg. samples / sec: 9472.42
Iteration:    340, Loss function: 6.835, Average Loss: 2.889, avg. samples / sec: 9601.50
Iteration:    360, Loss function: 6.804, Average Loss: 2.972, avg. samples / sec: 9545.92
Iteration:    380, Loss function: 7.171, Average Loss: 3.051, avg. samples / sec: 9627.46
:::MLLOG {"namespace": "", "time_ms": 1592669986496, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592669986497, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 4, "current_iter_num": 386}}
Iteration:    400, Loss function: 6.928, Average Loss: 3.135, avg. samples / sec: 9592.24
Iteration:    420, Loss function: 6.817, Average Loss: 3.207, avg. samples / sec: 9587.22
Iteration:    440, Loss function: 6.594, Average Loss: 3.274, avg. samples / sec: 9679.46
Iteration:    460, Loss function: 6.795, Average Loss: 3.338, avg. samples / sec: 9626.81
Iteration:    480, Loss function: 6.354, Average Loss: 3.405, avg. samples / sec: 9700.03
Iteration:    500, Loss function: 6.436, Average Loss: 3.465, avg. samples / sec: 9630.26
:::MLLOG {"namespace": "", "time_ms": 1592669998705, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592669998706, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 5, "current_iter_num": 515}}
Iteration:    520, Loss function: 6.298, Average Loss: 3.522, avg. samples / sec: 9678.02
Iteration:    540, Loss function: 6.244, Average Loss: 3.577, avg. samples / sec: 9635.91
Iteration:    560, Loss function: 6.400, Average Loss: 3.628, avg. samples / sec: 9658.67
Iteration:    580, Loss function: 6.026, Average Loss: 3.677, avg. samples / sec: 9699.57
Iteration:    600, Loss function: 6.000, Average Loss: 3.725, avg. samples / sec: 9718.71
Iteration:    620, Loss function: 6.119, Average Loss: 3.770, avg. samples / sec: 9758.34
Iteration:    640, Loss function: 6.129, Average Loss: 3.812, avg. samples / sec: 9699.33
:::MLLOG {"namespace": "", "time_ms": 1592670010742, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1592670010743, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 6, "current_iter_num": 643}}
Iteration:    660, Loss function: 5.938, Average Loss: 3.853, avg. samples / sec: 9739.87
Iteration:    680, Loss function: 5.962, Average Loss: 3.891, avg. samples / sec: 9704.40
Iteration:    700, Loss function: 5.601, Average Loss: 3.926, avg. samples / sec: 9760.42
Iteration:    720, Loss function: 5.260, Average Loss: 3.961, avg. samples / sec: 9737.21
Iteration:    740, Loss function: 5.412, Average Loss: 3.993, avg. samples / sec: 9763.64
Iteration:    760, Loss function: 5.668, Average Loss: 4.023, avg. samples / sec: 9747.98
:::MLLOG {"namespace": "", "time_ms": 1592670022816, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 6}}
:::MLLOG {"namespace": "", "time_ms": 1592670022817, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 7, "current_iter_num": 772}}
Iteration:    780, Loss function: 5.515, Average Loss: 4.051, avg. samples / sec: 9758.51
Iteration:    800, Loss function: 5.867, Average Loss: 4.079, avg. samples / sec: 9782.90
Iteration:    820, Loss function: 5.291, Average Loss: 4.104, avg. samples / sec: 9767.08
Iteration:    840, Loss function: 5.291, Average Loss: 4.126, avg. samples / sec: 9782.76
Iteration:    860, Loss function: 5.479, Average Loss: 4.151, avg. samples / sec: 9779.43
Iteration:    880, Loss function: 5.383, Average Loss: 4.172, avg. samples / sec: 9797.05
Iteration:    900, Loss function: 5.138, Average Loss: 4.193, avg. samples / sec: 9737.67
:::MLLOG {"namespace": "", "time_ms": 1592670034903, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1592670034904, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 8, "current_iter_num": 901}}
Iteration:    920, Loss function: 5.090, Average Loss: 4.211, avg. samples / sec: 9768.93
Iteration:    940, Loss function: 4.842, Average Loss: 4.229, avg. samples / sec: 9761.59
Iteration:    960, Loss function: 5.119, Average Loss: 4.247, avg. samples / sec: 9796.16
Iteration:    980, Loss function: 4.978, Average Loss: 4.264, avg. samples / sec: 9780.88
Iteration:   1000, Loss function: 5.023, Average Loss: 4.278, avg. samples / sec: 9776.00
Iteration:   1020, Loss function: 4.821, Average Loss: 4.292, avg. samples / sec: 9772.32
:::MLLOG {"namespace": "", "time_ms": 1592670046796, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 8}}
:::MLLOG {"namespace": "", "time_ms": 1592670046797, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 9, "current_iter_num": 1029}}
Iteration:   1040, Loss function: 4.859, Average Loss: 4.306, avg. samples / sec: 9772.86
Iteration:   1060, Loss function: 4.806, Average Loss: 4.318, avg. samples / sec: 9772.01
Iteration:   1080, Loss function: 4.723, Average Loss: 4.329, avg. samples / sec: 9788.88
Iteration:   1100, Loss function: 4.694, Average Loss: 4.340, avg. samples / sec: 9813.76
Iteration:   1120, Loss function: 5.052, Average Loss: 4.351, avg. samples / sec: 9752.75
Iteration:   1140, Loss function: 4.851, Average Loss: 4.362, avg. samples / sec: 9771.77
:::MLLOG {"namespace": "", "time_ms": 1592670058826, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 9}}
:::MLLOG {"namespace": "", "time_ms": 1592670058827, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 10, "current_iter_num": 1158}}
Iteration:   1160, Loss function: 4.711, Average Loss: 4.371, avg. samples / sec: 9808.77
Iteration:   1180, Loss function: 4.472, Average Loss: 4.380, avg. samples / sec: 9785.09
Iteration:   1200, Loss function: 4.700, Average Loss: 4.387, avg. samples / sec: 9830.08
Iteration:   1220, Loss function: 5.014, Average Loss: 4.395, avg. samples / sec: 9851.06
Iteration:   1240, Loss function: 4.884, Average Loss: 4.404, avg. samples / sec: 9837.67
Iteration:   1260, Loss function: 4.890, Average Loss: 4.411, avg. samples / sec: 9862.15
Iteration:   1280, Loss function: 4.636, Average Loss: 4.418, avg. samples / sec: 9846.36
:::MLLOG {"namespace": "", "time_ms": 1592670070697, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 10}}
:::MLLOG {"namespace": "", "time_ms": 1592670070698, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 11, "current_iter_num": 1286}}
Iteration:   1300, Loss function: 4.930, Average Loss: 4.424, avg. samples / sec: 9826.51
Iteration:   1320, Loss function: 4.988, Average Loss: 4.430, avg. samples / sec: 9817.20
Iteration:   1340, Loss function: 4.717, Average Loss: 4.432, avg. samples / sec: 9807.82
Iteration:   1360, Loss function: 4.800, Average Loss: 4.437, avg. samples / sec: 9839.33
Iteration:   1380, Loss function: 4.675, Average Loss: 4.441, avg. samples / sec: 9799.75
Iteration:   1400, Loss function: 4.836, Average Loss: 4.444, avg. samples / sec: 9847.41
:::MLLOG {"namespace": "", "time_ms": 1592670082667, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1592670082668, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 12, "current_iter_num": 1415}}
Iteration:   1420, Loss function: 4.641, Average Loss: 4.448, avg. samples / sec: 9862.80
Iteration:   1440, Loss function: 4.540, Average Loss: 4.451, avg. samples / sec: 9840.32
Iteration:   1460, Loss function: 4.689, Average Loss: 4.454, avg. samples / sec: 9843.00
Iteration:   1480, Loss function: 4.415, Average Loss: 4.456, avg. samples / sec: 9852.94
Iteration:   1500, Loss function: 4.693, Average Loss: 4.459, avg. samples / sec: 9836.71
Iteration:   1520, Loss function: 4.301, Average Loss: 4.461, avg. samples / sec: 9840.87
Iteration:   1540, Loss function: 4.279, Average Loss: 4.463, avg. samples / sec: 9840.69
:::MLLOG {"namespace": "", "time_ms": 1592670094526, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1592670094527, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 13, "current_iter_num": 1543}}
Iteration:   1560, Loss function: 4.304, Average Loss: 4.464, avg. samples / sec: 9818.42
Iteration:   1580, Loss function: 4.386, Average Loss: 4.465, avg. samples / sec: 9835.56
Iteration:   1600, Loss function: 4.342, Average Loss: 4.465, avg. samples / sec: 9837.06
Iteration:   1620, Loss function: 4.207, Average Loss: 4.466, avg. samples / sec: 9822.07
Iteration:   1640, Loss function: 4.567, Average Loss: 4.466, avg. samples / sec: 9813.25
Iteration:   1660, Loss function: 4.496, Average Loss: 4.468, avg. samples / sec: 9839.73
:::MLLOG {"namespace": "", "time_ms": 1592670106500, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 13}}
:::MLLOG {"namespace": "", "time_ms": 1592670106501, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 14, "current_iter_num": 1672}}
Iteration:   1680, Loss function: 4.357, Average Loss: 4.467, avg. samples / sec: 9839.66
Iteration:   1700, Loss function: 4.169, Average Loss: 4.465, avg. samples / sec: 9825.12
Iteration:   1720, Loss function: 4.201, Average Loss: 4.466, avg. samples / sec: 9833.42
Iteration:   1740, Loss function: 4.602, Average Loss: 4.466, avg. samples / sec: 9835.77
Iteration:   1760, Loss function: 4.539, Average Loss: 4.465, avg. samples / sec: 9847.37
Iteration:   1780, Loss function: 4.187, Average Loss: 4.464, avg. samples / sec: 9843.45
Iteration:   1800, Loss function: 4.078, Average Loss: 4.462, avg. samples / sec: 9849.91
:::MLLOG {"namespace": "", "time_ms": 1592670118498, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 14}}
:::MLLOG {"namespace": "", "time_ms": 1592670118499, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 15, "current_iter_num": 1801}}
Iteration:   1820, Loss function: 4.102, Average Loss: 4.461, avg. samples / sec: 9828.88
Iteration:   1840, Loss function: 4.436, Average Loss: 4.458, avg. samples / sec: 9828.02
Iteration:   1860, Loss function: 4.420, Average Loss: 4.458, avg. samples / sec: 9828.17
Iteration:   1880, Loss function: 4.504, Average Loss: 4.456, avg. samples / sec: 9841.66
Iteration:   1900, Loss function: 4.325, Average Loss: 4.455, avg. samples / sec: 9830.67
Iteration:   1920, Loss function: 4.658, Average Loss: 4.452, avg. samples / sec: 9852.64
:::MLLOG {"namespace": "", "time_ms": 1592670130326, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1592670130327, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 16, "current_iter_num": 1929}}
Iteration:   1940, Loss function: 4.617, Average Loss: 4.450, avg. samples / sec: 9822.03
Iteration:   1960, Loss function: 4.429, Average Loss: 4.448, avg. samples / sec: 9782.91
Iteration:   1980, Loss function: 4.509, Average Loss: 4.445, avg. samples / sec: 9809.31
Iteration:   2000, Loss function: 4.243, Average Loss: 4.443, avg. samples / sec: 9848.43
Iteration:   2020, Loss function: 4.311, Average Loss: 4.440, avg. samples / sec: 9833.15
Iteration:   2040, Loss function: 4.354, Average Loss: 4.438, avg. samples / sec: 9844.54
:::MLLOG {"namespace": "", "time_ms": 1592670142301, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1592670142302, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 17, "current_iter_num": 2058}}
Iteration:   2060, Loss function: 4.524, Average Loss: 4.436, avg. samples / sec: 9828.29
Iteration:   2080, Loss function: 4.043, Average Loss: 4.433, avg. samples / sec: 9825.99
Iteration:   2100, Loss function: 4.474, Average Loss: 4.432, avg. samples / sec: 9831.71
Iteration:   2120, Loss function: 4.360, Average Loss: 4.429, avg. samples / sec: 9838.04
Iteration:   2140, Loss function: 4.051, Average Loss: 4.426, avg. samples / sec: 9862.75
Iteration:   2160, Loss function: 4.439, Average Loss: 4.421, avg. samples / sec: 9852.86
Iteration:   2180, Loss function: 4.279, Average Loss: 4.418, avg. samples / sec: 9851.51
:::MLLOG {"namespace": "", "time_ms": 1592670154163, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 17}}
:::MLLOG {"namespace": "", "time_ms": 1592670154163, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 18, "current_iter_num": 2186}}
Iteration:   2200, Loss function: 4.137, Average Loss: 4.415, avg. samples / sec: 9857.93
Iteration:   2220, Loss function: 3.978, Average Loss: 4.411, avg. samples / sec: 9847.14
Iteration:   2240, Loss function: 4.152, Average Loss: 4.408, avg. samples / sec: 9838.95
Iteration:   2260, Loss function: 4.343, Average Loss: 4.406, avg. samples / sec: 9870.24
Iteration:   2280, Loss function: 4.074, Average Loss: 4.404, avg. samples / sec: 9861.92
Iteration:   2300, Loss function: 4.123, Average Loss: 4.400, avg. samples / sec: 9861.73
:::MLLOG {"namespace": "", "time_ms": 1592670166100, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1592670166101, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 19, "current_iter_num": 2315}}
Iteration:   2320, Loss function: 3.994, Average Loss: 4.397, avg. samples / sec: 9848.26
Iteration:   2340, Loss function: 4.446, Average Loss: 4.393, avg. samples / sec: 9837.10
Iteration:   2360, Loss function: 4.179, Average Loss: 4.389, avg. samples / sec: 9866.57
Iteration:   2380, Loss function: 4.229, Average Loss: 4.385, avg. samples / sec: 9843.60
Iteration:   2400, Loss function: 4.073, Average Loss: 4.379, avg. samples / sec: 9851.29
Iteration:   2420, Loss function: 4.227, Average Loss: 4.375, avg. samples / sec: 9860.58
Iteration:   2440, Loss function: 4.241, Average Loss: 4.371, avg. samples / sec: 9845.53
:::MLLOG {"namespace": "", "time_ms": 1592670177952, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1592670177953, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 20, "current_iter_num": 2443}}
Iteration:   2460, Loss function: 3.788, Average Loss: 4.365, avg. samples / sec: 9846.67
Iteration:   2480, Loss function: 4.133, Average Loss: 4.361, avg. samples / sec: 9864.43
Iteration:   2500, Loss function: 4.003, Average Loss: 4.358, avg. samples / sec: 9863.56
Iteration:   2520, Loss function: 4.026, Average Loss: 4.353, avg. samples / sec: 9847.81
Iteration:   2540, Loss function: 4.150, Average Loss: 4.350, avg. samples / sec: 9851.04
Iteration:   2560, Loss function: 4.584, Average Loss: 4.346, avg. samples / sec: 9862.63
:::MLLOG {"namespace": "", "time_ms": 1592670189888, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1592670189889, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 21, "current_iter_num": 2572}}
Iteration:   2580, Loss function: 4.112, Average Loss: 4.342, avg. samples / sec: 9857.32
Iteration:   2600, Loss function: 4.028, Average Loss: 4.338, avg. samples / sec: 9824.34
Iteration:   2620, Loss function: 4.316, Average Loss: 4.334, avg. samples / sec: 9805.20
Iteration:   2640, Loss function: 4.127, Average Loss: 4.329, avg. samples / sec: 9834.13
Iteration:   2660, Loss function: 4.200, Average Loss: 4.324, avg. samples / sec: 9847.22
Iteration:   2680, Loss function: 4.031, Average Loss: 4.319, avg. samples / sec: 9863.53
Iteration:   2700, Loss function: 3.756, Average Loss: 4.315, avg. samples / sec: 9860.96
:::MLLOG {"namespace": "", "time_ms": 1592670201886, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 21}}
:::MLLOG {"namespace": "", "time_ms": 1592670201887, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 22, "current_iter_num": 2701}}
Iteration:   2720, Loss function: 4.277, Average Loss: 4.311, avg. samples / sec: 9850.52
Iteration:   2740, Loss function: 3.890, Average Loss: 4.306, avg. samples / sec: 9848.37
Iteration:   2760, Loss function: 3.924, Average Loss: 4.302, avg. samples / sec: 9841.87
Iteration:   2780, Loss function: 3.939, Average Loss: 4.299, avg. samples / sec: 9865.06
Iteration:   2800, Loss function: 3.891, Average Loss: 4.296, avg. samples / sec: 9856.51
Iteration:   2820, Loss function: 4.198, Average Loss: 4.293, avg. samples / sec: 9844.57
:::MLLOG {"namespace": "", "time_ms": 1592670213693, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 22}}
:::MLLOG {"namespace": "", "time_ms": 1592670213694, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 23, "current_iter_num": 2829}}
Iteration:   2840, Loss function: 4.193, Average Loss: 4.287, avg. samples / sec: 9851.75
Iteration:   2860, Loss function: 3.708, Average Loss: 4.282, avg. samples / sec: 9851.15
Iteration:   2880, Loss function: 4.077, Average Loss: 4.278, avg. samples / sec: 9843.85
Iteration:   2900, Loss function: 3.951, Average Loss: 4.274, avg. samples / sec: 9852.67
Iteration:   2920, Loss function: 4.011, Average Loss: 4.270, avg. samples / sec: 9857.99
Iteration:   2940, Loss function: 4.036, Average Loss: 4.266, avg. samples / sec: 9858.26
:::MLLOG {"namespace": "", "time_ms": 1592670225637, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1592670225637, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 24, "current_iter_num": 2958}}
Iteration:   2960, Loss function: 3.879, Average Loss: 4.261, avg. samples / sec: 9837.60
Iteration:   2980, Loss function: 4.229, Average Loss: 4.256, avg. samples / sec: 9857.99
Iteration:   3000, Loss function: 3.916, Average Loss: 4.251, avg. samples / sec: 9848.11
Iteration:   3020, Loss function: 4.092, Average Loss: 4.248, avg. samples / sec: 9854.78
Iteration:   3040, Loss function: 3.924, Average Loss: 4.243, avg. samples / sec: 9832.76
Iteration:   3060, Loss function: 3.946, Average Loss: 4.239, avg. samples / sec: 9855.55
Iteration:   3080, Loss function: 3.771, Average Loss: 4.235, avg. samples / sec: 9850.15
:::MLLOG {"namespace": "", "time_ms": 1592670237488, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1592670237489, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 25, "current_iter_num": 3086}}
Iteration:   3100, Loss function: 3.896, Average Loss: 4.231, avg. samples / sec: 9844.32
Iteration:   3120, Loss function: 3.727, Average Loss: 4.225, avg. samples / sec: 9856.11
Iteration:   3140, Loss function: 4.057, Average Loss: 4.221, avg. samples / sec: 9861.24
Iteration:   3160, Loss function: 3.964, Average Loss: 4.216, avg. samples / sec: 9844.38
Iteration:   3180, Loss function: 4.149, Average Loss: 4.212, avg. samples / sec: 9854.59
Iteration:   3200, Loss function: 3.838, Average Loss: 4.208, avg. samples / sec: 9850.71
:::MLLOG {"namespace": "", "time_ms": 1592670249434, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 25}}
:::MLLOG {"namespace": "", "time_ms": 1592670249434, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 26, "current_iter_num": 3215}}
Iteration:   3220, Loss function: 4.164, Average Loss: 4.204, avg. samples / sec: 9838.86
Iteration:   3240, Loss function: 3.938, Average Loss: 4.202, avg. samples / sec: 9832.18
Iteration:   3260, Loss function: 3.786, Average Loss: 4.197, avg. samples / sec: 9847.22
Iteration:   3280, Loss function: 4.092, Average Loss: 4.194, avg. samples / sec: 9839.57
Iteration:   3300, Loss function: 4.086, Average Loss: 4.190, avg. samples / sec: 9847.68
Iteration:   3320, Loss function: 3.967, Average Loss: 4.184, avg. samples / sec: 9858.45
Iteration:   3340, Loss function: 4.028, Average Loss: 4.181, avg. samples / sec: 9838.43
:::MLLOG {"namespace": "", "time_ms": 1592670261385, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 26}}
:::MLLOG {"namespace": "", "time_ms": 1592670261386, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 27, "current_iter_num": 3344}}
Iteration:   3360, Loss function: 3.806, Average Loss: 4.176, avg. samples / sec: 9833.00
Iteration:   3380, Loss function: 3.894, Average Loss: 4.172, avg. samples / sec: 9855.35
Iteration:   3400, Loss function: 3.893, Average Loss: 4.166, avg. samples / sec: 9846.04
Iteration:   3420, Loss function: 4.075, Average Loss: 4.163, avg. samples / sec: 9857.34
Iteration:   3440, Loss function: 3.905, Average Loss: 4.160, avg. samples / sec: 9852.19
Iteration:   3460, Loss function: 4.067, Average Loss: 4.156, avg. samples / sec: 9855.90
:::MLLOG {"namespace": "", "time_ms": 1592670273235, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1592670273236, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 28, "current_iter_num": 3472}}
Iteration:   3480, Loss function: 3.817, Average Loss: 4.152, avg. samples / sec: 9849.72
Iteration:   3500, Loss function: 4.029, Average Loss: 4.147, avg. samples / sec: 9842.75
Iteration:   3520, Loss function: 4.120, Average Loss: 4.143, avg. samples / sec: 9853.00
Iteration:   3540, Loss function: 4.279, Average Loss: 4.139, avg. samples / sec: 9843.38
Iteration:   3560, Loss function: 4.078, Average Loss: 4.134, avg. samples / sec: 9849.73
Iteration:   3580, Loss function: 3.950, Average Loss: 4.131, avg. samples / sec: 9853.87
Iteration:   3600, Loss function: 3.643, Average Loss: 4.127, avg. samples / sec: 9851.43
:::MLLOG {"namespace": "", "time_ms": 1592670285225, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1592670285226, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 29, "current_iter_num": 3601}}
Iteration:   3620, Loss function: 4.323, Average Loss: 4.124, avg. samples / sec: 9854.35
Iteration:   3640, Loss function: 3.860, Average Loss: 4.120, avg. samples / sec: 9860.52
Iteration:   3660, Loss function: 3.968, Average Loss: 4.116, avg. samples / sec: 9858.89
Iteration:   3680, Loss function: 3.756, Average Loss: 4.112, avg. samples / sec: 9840.47
Iteration:   3700, Loss function: 3.905, Average Loss: 4.108, avg. samples / sec: 9858.84
Iteration:   3720, Loss function: 3.954, Average Loss: 4.105, avg. samples / sec: 9847.39
:::MLLOG {"namespace": "", "time_ms": 1592670297031, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 29}}
:::MLLOG {"namespace": "", "time_ms": 1592670297032, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 30, "current_iter_num": 3729}}
Iteration:   3740, Loss function: 3.784, Average Loss: 4.101, avg. samples / sec: 9826.34
Iteration:   3760, Loss function: 3.991, Average Loss: 4.098, avg. samples / sec: 9848.07
Iteration:   3780, Loss function: 3.952, Average Loss: 4.094, avg. samples / sec: 9843.78
Iteration:   3800, Loss function: 4.062, Average Loss: 4.091, avg. samples / sec: 9852.04
Iteration:   3820, Loss function: 4.203, Average Loss: 4.086, avg. samples / sec: 9838.04
Iteration:   3840, Loss function: 4.036, Average Loss: 4.081, avg. samples / sec: 9841.36
:::MLLOG {"namespace": "", "time_ms": 1592670308983, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 30}}
:::MLLOG {"namespace": "", "time_ms": 1592670308983, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 31, "current_iter_num": 3858}}
Iteration:   3860, Loss function: 3.932, Average Loss: 4.079, avg. samples / sec: 9848.74
Iteration:   3880, Loss function: 3.663, Average Loss: 4.073, avg. samples / sec: 9846.03
Iteration:   3900, Loss function: 3.935, Average Loss: 4.069, avg. samples / sec: 9806.46
Iteration:   3920, Loss function: 3.933, Average Loss: 4.066, avg. samples / sec: 9810.46
Iteration:   3940, Loss function: 4.182, Average Loss: 4.063, avg. samples / sec: 9805.43
Iteration:   3960, Loss function: 3.848, Average Loss: 4.060, avg. samples / sec: 9822.70
Iteration:   3980, Loss function: 3.850, Average Loss: 4.058, avg. samples / sec: 9856.76
:::MLLOG {"namespace": "", "time_ms": 1592670320865, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1592670320866, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 32, "current_iter_num": 3986}}
Iteration:   4000, Loss function: 3.620, Average Loss: 4.054, avg. samples / sec: 9840.21
Iteration:   4020, Loss function: 3.781, Average Loss: 4.049, avg. samples / sec: 9851.07
Iteration:   4040, Loss function: 4.223, Average Loss: 4.046, avg. samples / sec: 9860.37
Iteration:   4060, Loss function: 4.012, Average Loss: 4.044, avg. samples / sec: 9843.69
Iteration:   4080, Loss function: 3.839, Average Loss: 4.041, avg. samples / sec: 9848.91
Iteration:   4100, Loss function: 3.368, Average Loss: 4.037, avg. samples / sec: 9860.74
:::MLLOG {"namespace": "", "time_ms": 1592670332809, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1592670332810, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 33, "current_iter_num": 4115}}
Iteration:   4120, Loss function: 4.179, Average Loss: 4.034, avg. samples / sec: 9846.40
Iteration:   4140, Loss function: 3.965, Average Loss: 4.030, avg. samples / sec: 9850.92
Iteration:   4160, Loss function: 3.494, Average Loss: 4.028, avg. samples / sec: 9853.75
Iteration:   4180, Loss function: 4.009, Average Loss: 4.026, avg. samples / sec: 9856.09
Iteration:   4200, Loss function: 3.641, Average Loss: 4.022, avg. samples / sec: 9858.11
Iteration:   4220, Loss function: 4.197, Average Loss: 4.020, avg. samples / sec: 9851.20
Iteration:   4240, Loss function: 3.959, Average Loss: 4.016, avg. samples / sec: 9853.55
:::MLLOG {"namespace": "", "time_ms": 1592670344749, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 33}}
:::MLLOG {"namespace": "", "time_ms": 1592670344750, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 34, "current_iter_num": 4244}}
Iteration:   4260, Loss function: 3.841, Average Loss: 4.012, avg. samples / sec: 9835.27
Iteration:   4280, Loss function: 3.563, Average Loss: 4.008, avg. samples / sec: 9847.41
Iteration:   4300, Loss function: 4.036, Average Loss: 4.004, avg. samples / sec: 9857.94
Iteration:   4320, Loss function: 3.900, Average Loss: 4.000, avg. samples / sec: 9850.90
Iteration:   4340, Loss function: 3.579, Average Loss: 3.997, avg. samples / sec: 9832.39
Iteration:   4360, Loss function: 3.686, Average Loss: 3.994, avg. samples / sec: 9864.94
:::MLLOG {"namespace": "", "time_ms": 1592670356603, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 34}}
:::MLLOG {"namespace": "", "time_ms": 1592670356604, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 35, "current_iter_num": 4372}}
Iteration:   4380, Loss function: 3.816, Average Loss: 3.992, avg. samples / sec: 9852.00
Iteration:   4400, Loss function: 3.550, Average Loss: 3.988, avg. samples / sec: 9856.12
Iteration:   4420, Loss function: 4.045, Average Loss: 3.985, avg. samples / sec: 9853.39
Iteration:   4440, Loss function: 3.754, Average Loss: 3.984, avg. samples / sec: 9857.02
Iteration:   4460, Loss function: 4.022, Average Loss: 3.981, avg. samples / sec: 9856.66
Iteration:   4480, Loss function: 3.753, Average Loss: 3.977, avg. samples / sec: 9849.51
Iteration:   4500, Loss function: 3.801, Average Loss: 3.974, avg. samples / sec: 9803.32
:::MLLOG {"namespace": "", "time_ms": 1592670368596, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1592670368597, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 36, "current_iter_num": 4501}}
Iteration:   4520, Loss function: 3.702, Average Loss: 3.970, avg. samples / sec: 9799.37
Iteration:   4540, Loss function: 3.734, Average Loss: 3.965, avg. samples / sec: 9836.61
Iteration:   4560, Loss function: 4.058, Average Loss: 3.963, avg. samples / sec: 9845.83
Iteration:   4580, Loss function: 4.068, Average Loss: 3.960, avg. samples / sec: 9826.74
Iteration:   4600, Loss function: 3.763, Average Loss: 3.959, avg. samples / sec: 9852.48
Iteration:   4620, Loss function: 3.780, Average Loss: 3.956, avg. samples / sec: 9851.77
:::MLLOG {"namespace": "", "time_ms": 1592670380422, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 36}}
:::MLLOG {"namespace": "", "time_ms": 1592670380423, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 37, "current_iter_num": 4629}}
Iteration:   4640, Loss function: 3.773, Average Loss: 3.952, avg. samples / sec: 9830.45
Iteration:   4660, Loss function: 3.822, Average Loss: 3.949, avg. samples / sec: 9853.15
Iteration:   4680, Loss function: 3.820, Average Loss: 3.946, avg. samples / sec: 9839.37
Iteration:   4700, Loss function: 3.936, Average Loss: 3.943, avg. samples / sec: 9838.12
Iteration:   4720, Loss function: 3.601, Average Loss: 3.942, avg. samples / sec: 9842.72
Iteration:   4740, Loss function: 3.969, Average Loss: 3.941, avg. samples / sec: 9773.49
:::MLLOG {"namespace": "", "time_ms": 1592670392387, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 37}}
:::MLLOG {"namespace": "", "time_ms": 1592670392388, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 38, "current_iter_num": 4758}}
Iteration:   4760, Loss function: 3.830, Average Loss: 3.938, avg. samples / sec: 9839.53
Iteration:   4780, Loss function: 3.770, Average Loss: 3.934, avg. samples / sec: 9843.43
Iteration:   4800, Loss function: 4.097, Average Loss: 3.932, avg. samples / sec: 9830.19
Iteration:   4820, Loss function: 3.472, Average Loss: 3.929, avg. samples / sec: 9826.38
Iteration:   4840, Loss function: 3.680, Average Loss: 3.925, avg. samples / sec: 9843.87
Iteration:   4860, Loss function: 4.127, Average Loss: 3.923, avg. samples / sec: 9840.60
Iteration:   4880, Loss function: 3.741, Average Loss: 3.920, avg. samples / sec: 9853.09
:::MLLOG {"namespace": "", "time_ms": 1592670404252, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 38}}
:::MLLOG {"namespace": "", "time_ms": 1592670404253, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 39, "current_iter_num": 4886}}
Iteration:   4900, Loss function: 3.695, Average Loss: 3.918, avg. samples / sec: 9844.77
Iteration:   4920, Loss function: 3.825, Average Loss: 3.915, avg. samples / sec: 9847.90
Iteration:   4940, Loss function: 3.934, Average Loss: 3.913, avg. samples / sec: 9842.22
Iteration:   4960, Loss function: 3.708, Average Loss: 3.909, avg. samples / sec: 9851.44
Iteration:   4980, Loss function: 3.862, Average Loss: 3.906, avg. samples / sec: 9843.46
Iteration:   5000, Loss function: 3.933, Average Loss: 3.903, avg. samples / sec: 9854.20
:::MLLOG {"namespace": "", "time_ms": 1592670416200, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 39}}
:::MLLOG {"namespace": "", "time_ms": 1592670416201, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 40, "current_iter_num": 5015}}
Iteration:   5020, Loss function: 3.988, Average Loss: 3.900, avg. samples / sec: 9844.29
Iteration:   5040, Loss function: 3.613, Average Loss: 3.897, avg. samples / sec: 9861.16
Iteration:   5060, Loss function: 3.869, Average Loss: 3.894, avg. samples / sec: 9862.40
Iteration:   5080, Loss function: 3.707, Average Loss: 3.892, avg. samples / sec: 9867.91
Iteration:   5100, Loss function: 3.685, Average Loss: 3.890, avg. samples / sec: 9839.85
Iteration:   5120, Loss function: 3.553, Average Loss: 3.888, avg. samples / sec: 9855.31
Iteration:   5140, Loss function: 3.649, Average Loss: 3.886, avg. samples / sec: 9862.10
:::MLLOG {"namespace": "", "time_ms": 1592670428136, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 40}}
averaging bn running means and vars
Predicting Ended, total time: 4.40 s
:::MLLOG {"namespace": "", "time_ms": 1592670432577, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 331, "first_epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1592670432620, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 338, "first_epoch_num": 41, "epoch_count": 10}}
:::MLLOG {"namespace": "", "time_ms": 1592670432620, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 41, "current_iter_num": 5144}}
Loading and preparing results...
DONE (t=0.55s)
Running per image evaluation...
Evaluate annotation type *bbox*
Iteration:   5160, Loss function: 3.897, Average Loss: 3.883, avg. samples / sec: 2816.17
DONE (t=1.72s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.17952
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.32953
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.17738
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.26371
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.18673
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.27486
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.29069
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.29069
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
Current AP: 0.17952 AP goal: 0.23000
Iteration:   5180, Loss function: 3.590, Average Loss: 3.881, avg. samples / sec: 9798.40
:::MLLOG {"namespace": "", "time_ms": 1592670436198, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 85, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1592670436198, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.17951707084281954, "metadata": {"file": "train.py", "lineno": 88, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1592670436199, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 89, "epoch_num": 40}}
Iteration:   5200, Loss function: 3.566, Average Loss: 3.878, avg. samples / sec: 9833.61
Iteration:   5220, Loss function: 3.512, Average Loss: 3.874, avg. samples / sec: 9842.47
Iteration:   5240, Loss function: 3.638, Average Loss: 3.872, avg. samples / sec: 9823.11
Iteration:   5260, Loss function: 3.640, Average Loss: 3.869, avg. samples / sec: 9820.39
:::MLLOG {"namespace": "", "time_ms": 1592670444639, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1592670444640, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 42, "current_iter_num": 5272}}
Iteration:   5280, Loss function: 3.953, Average Loss: 3.866, avg. samples / sec: 9846.39
Iteration:   5300, Loss function: 3.769, Average Loss: 3.863, avg. samples / sec: 9835.62
Iteration:   5320, Loss function: 4.100, Average Loss: 3.860, avg. samples / sec: 9848.94
Iteration:   5340, Loss function: 3.665, Average Loss: 3.857, avg. samples / sec: 9838.43
Iteration:   5360, Loss function: 4.050, Average Loss: 3.856, avg. samples / sec: 9845.96
Iteration:   5380, Loss function: 3.734, Average Loss: 3.854, avg. samples / sec: 9836.09
Iteration:   5400, Loss function: 3.688, Average Loss: 3.851, avg. samples / sec: 9838.78
:::MLLOG {"namespace": "", "time_ms": 1592670456636, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 42}}
:::MLLOG {"namespace": "", "time_ms": 1592670456637, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 43, "current_iter_num": 5401}}
Iteration:   5420, Loss function: 3.868, Average Loss: 3.849, avg. samples / sec: 9826.49
Iteration:   5440, Loss function: 3.751, Average Loss: 3.846, avg. samples / sec: 9847.95
Iteration:   5460, Loss function: 3.811, Average Loss: 3.844, avg. samples / sec: 9845.06
Iteration:   5480, Loss function: 3.535, Average Loss: 3.843, avg. samples / sec: 9827.20
Iteration:   5500, Loss function: 3.882, Average Loss: 3.841, avg. samples / sec: 9851.54
Iteration:   5520, Loss function: 3.703, Average Loss: 3.839, avg. samples / sec: 9849.31
:::MLLOG {"namespace": "", "time_ms": 1592670468453, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 43}}
:::MLLOG {"namespace": "", "time_ms": 1592670468454, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 44, "current_iter_num": 5529}}
Iteration:   5540, Loss function: 3.681, Average Loss: 3.836, avg. samples / sec: 9859.73
Iteration:   5560, Loss function: 3.418, Average Loss: 3.832, avg. samples / sec: 9862.91
Iteration:   5580, Loss function: 3.862, Average Loss: 3.829, avg. samples / sec: 9846.37
Iteration:   5600, Loss function: 3.658, Average Loss: 3.827, avg. samples / sec: 9840.82
Iteration:   5620, Loss function: 3.868, Average Loss: 3.826, avg. samples / sec: 9811.04
Iteration:   5640, Loss function: 3.568, Average Loss: 3.824, avg. samples / sec: 9828.87
:::MLLOG {"namespace": "", "time_ms": 1592670480411, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 44}}
lr decay step #1
:::MLLOG {"namespace": "", "time_ms": 1592670480412, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 45, "current_iter_num": 5658}}
Iteration:   5660, Loss function: 3.551, Average Loss: 3.822, avg. samples / sec: 9835.59
Iteration:   5680, Loss function: 3.509, Average Loss: 3.818, avg. samples / sec: 9835.93
Iteration:   5700, Loss function: 3.484, Average Loss: 3.809, avg. samples / sec: 9840.18
Iteration:   5720, Loss function: 3.746, Average Loss: 3.803, avg. samples / sec: 9837.00
Iteration:   5740, Loss function: 3.253, Average Loss: 3.794, avg. samples / sec: 9834.13
Iteration:   5760, Loss function: 3.312, Average Loss: 3.786, avg. samples / sec: 9845.36
Iteration:   5780, Loss function: 3.451, Average Loss: 3.779, avg. samples / sec: 9837.11
:::MLLOG {"namespace": "", "time_ms": 1592670492371, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 45}}
:::MLLOG {"namespace": "", "time_ms": 1592670492371, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 46, "current_iter_num": 5787}}
Iteration:   5800, Loss function: 3.497, Average Loss: 3.772, avg. samples / sec: 9839.12
Iteration:   5820, Loss function: 3.227, Average Loss: 3.763, avg. samples / sec: 9829.64
Iteration:   5840, Loss function: 3.214, Average Loss: 3.754, avg. samples / sec: 9828.70
Iteration:   5860, Loss function: 3.006, Average Loss: 3.747, avg. samples / sec: 9853.92
Iteration:   5880, Loss function: 3.390, Average Loss: 3.738, avg. samples / sec: 9854.86
Iteration:   5900, Loss function: 3.174, Average Loss: 3.730, avg. samples / sec: 9860.77
:::MLLOG {"namespace": "", "time_ms": 1592670504225, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 46}}
:::MLLOG {"namespace": "", "time_ms": 1592670504226, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 47, "current_iter_num": 5915}}
Iteration:   5920, Loss function: 3.349, Average Loss: 3.723, avg. samples / sec: 9866.88
Iteration:   5940, Loss function: 3.231, Average Loss: 3.714, avg. samples / sec: 9875.20
Iteration:   5960, Loss function: 3.640, Average Loss: 3.707, avg. samples / sec: 9868.90
Iteration:   5980, Loss function: 3.333, Average Loss: 3.701, avg. samples / sec: 9878.04
Iteration:   6000, Loss function: 3.219, Average Loss: 3.693, avg. samples / sec: 9862.21
Iteration:   6020, Loss function: 3.455, Average Loss: 3.685, avg. samples / sec: 9869.51
Iteration:   6040, Loss function: 3.274, Average Loss: 3.679, avg. samples / sec: 9871.88
:::MLLOG {"namespace": "", "time_ms": 1592670516145, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 47}}
:::MLLOG {"namespace": "", "time_ms": 1592670516146, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 48, "current_iter_num": 6044}}
Iteration:   6060, Loss function: 3.241, Average Loss: 3.673, avg. samples / sec: 9868.19
Iteration:   6080, Loss function: 3.358, Average Loss: 3.665, avg. samples / sec: 9854.79
Iteration:   6100, Loss function: 3.065, Average Loss: 3.657, avg. samples / sec: 9862.50
Iteration:   6120, Loss function: 3.558, Average Loss: 3.650, avg. samples / sec: 9847.50
Iteration:   6140, Loss function: 2.882, Average Loss: 3.641, avg. samples / sec: 9863.93
Iteration:   6160, Loss function: 3.540, Average Loss: 3.634, avg. samples / sec: 9854.74
:::MLLOG {"namespace": "", "time_ms": 1592670527986, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 48}}
:::MLLOG {"namespace": "", "time_ms": 1592670527987, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 49, "current_iter_num": 6172}}
Iteration:   6180, Loss function: 3.299, Average Loss: 3.627, avg. samples / sec: 9861.11
Iteration:   6200, Loss function: 3.239, Average Loss: 3.620, avg. samples / sec: 9851.71
Iteration:   6220, Loss function: 3.380, Average Loss: 3.613, avg. samples / sec: 9847.74
Iteration:   6240, Loss function: 3.225, Average Loss: 3.607, avg. samples / sec: 9855.58
Iteration:   6260, Loss function: 3.104, Average Loss: 3.600, avg. samples / sec: 9857.76
Iteration:   6280, Loss function: 3.031, Average Loss: 3.593, avg. samples / sec: 9853.15
Iteration:   6300, Loss function: 2.825, Average Loss: 3.586, avg. samples / sec: 9857.88
:::MLLOG {"namespace": "", "time_ms": 1592670539968, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 49}}
:::MLLOG {"namespace": "", "time_ms": 1592670539968, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 50, "current_iter_num": 6301}}
Iteration:   6320, Loss function: 3.233, Average Loss: 3.580, avg. samples / sec: 9830.07
Iteration:   6340, Loss function: 3.096, Average Loss: 3.574, avg. samples / sec: 9808.97
Iteration:   6360, Loss function: 3.493, Average Loss: 3.567, avg. samples / sec: 9806.48
Iteration:   6380, Loss function: 3.519, Average Loss: 3.562, avg. samples / sec: 9810.15
Iteration:   6400, Loss function: 3.197, Average Loss: 3.557, avg. samples / sec: 9814.74
Iteration:   6420, Loss function: 3.262, Average Loss: 3.552, avg. samples / sec: 9809.01
:::MLLOG {"namespace": "", "time_ms": 1592670551822, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 50}}
averaging bn running means and vars
Predicting Ended, total time: 4.11 s
:::MLLOG {"namespace": "", "time_ms": 1592670555950, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 331, "first_epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1592670555986, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 338, "first_epoch_num": 51, "epoch_count": 5}}
:::MLLOG {"namespace": "", "time_ms": 1592670555986, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 51, "current_iter_num": 6429}}
Loading and preparing results...
DONE (t=0.53s)
Running per image evaluation...
Evaluate annotation type *bbox*
Iteration:   6440, Loss function: 3.400, Average Loss: 3.545, avg. samples / sec: 3048.13
DONE (t=1.71s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.23276
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.39853
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23828
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.31591
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22539
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32695
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.34397
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.34397
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
Current AP: 0.23276 AP goal: 0.23000
Iteration:   6460, Loss function: 3.289, Average Loss: 3.539, avg. samples / sec: 9826.91
:::MLLOG {"namespace": "", "time_ms": 1592670558917, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 85, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1592670558918, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.23276483638019446, "metadata": {"file": "train.py", "lineno": 88, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1592670558918, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 89, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1592670559195, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "train.py", "lineno": 449, "status": "success"}}
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2020-06-20 09:29:23 AM
RESULT,SINGLE_STAGE_DETECTOR,,652,nvidia,2020-06-20 09:18:31 AM
ENDING TIMING RUN AT 2020-06-20 09:29:24 AM
RESULT,SINGLE_STAGE_DETECTOR,,653,nvidia,2020-06-20 09:18:31 AM
ENDING TIMING RUN AT 2020-06-20 09:29:24 AM
RESULT,SINGLE_STAGE_DETECTOR,,653,nvidia,2020-06-20 09:18:31 AM
ENDING TIMING RUN AT 2020-06-20 09:29:24 AM
RESULT,SINGLE_STAGE_DETECTOR,,653,nvidia,2020-06-20 09:18:31 AM
ENDING TIMING RUN AT 2020-06-20 09:29:24 AM
ENDING TIMING RUN AT 2020-06-20 09:29:24 AM
RESULT,SINGLE_STAGE_DETECTOR,,653,nvidia,2020-06-20 09:18:31 AM
RESULT,SINGLE_STAGE_DETECTOR,,653,nvidia,2020-06-20 09:18:31 AM
ENDING TIMING RUN AT 2020-06-20 09:29:24 AM
RESULT,SINGLE_STAGE_DETECTOR,,653,nvidia,2020-06-20 09:18:31 AM
ENDING TIMING RUN AT 2020-06-20 09:29:25 AM
RESULT,SINGLE_STAGE_DETECTOR,,654,nvidia,2020-06-20 09:18:31 AM
