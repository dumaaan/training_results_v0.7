+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ srun --nodes=1 --ntasks=1 --container-name=single_stage_detector python -c '
import mlperf_log_utils
from mlperf_logging.mllog import constants
mlperf_log_utils.mlperf_submission_log(constants.SSD)'
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
:::MLLOG {"namespace": "", "time_ms": 1592669894732, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "ssd", "metadata": {"file": "/workspace/single_stage_detector/mlperf_log_utils.py", "lineno": 17}}
:::MLLOG {"namespace": "", "time_ms": 1592669894771, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "NVIDIA", "metadata": {"file": "/workspace/single_stage_detector/mlperf_log_utils.py", "lineno": 22}}
:::MLLOG {"namespace": "", "time_ms": 1592669894771, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/single_stage_detector/mlperf_log_utils.py", "lineno": 26}}
:::MLLOG {"namespace": "", "time_ms": 1592669894771, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/single_stage_detector/mlperf_log_utils.py", "lineno": 30}}
:::MLLOG {"namespace": "", "time_ms": 1592669894771, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "1xNVIDIA DGX A100", "metadata": {"file": "/workspace/single_stage_detector/mlperf_log_utils.py", "lineno": 34}}
+ '[' 1 -eq 1 ']'
+ srun --ntasks=1 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0178
vm.drop_caches = 3
+ srun --ntasks=1 --container-name=single_stage_detector python -c '
from mlperf_logging.mllog import constants
from mlperf_logger import log_event
log_event(key=constants.CACHE_CLEAR, value=True)'
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
:::MLLOG {"namespace": "", "time_ms": 1592669900030, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
+ srun --mpi=none --ntasks=8 --ntasks-per-node=8 --container-name=single_stage_detector --container-mounts=/raid/datasets/coco/coco-2017:/data,/lustre/fsw/mlperf-ci/13964267/results:/results ./run_and_time.sh
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-20 09:18:22 AM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
++ pwd
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 8 -gt 1 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
STARTING TIMING RUN AT 2020-06-20 09:18:22 AM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
++ pwd
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 8 -gt 1 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
STARTING TIMING RUN AT 2020-06-20 09:18:22 AM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
++ pwd
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 8 -gt 1 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
STARTING TIMING RUN AT 2020-06-20 09:18:22 AM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
STARTING TIMING RUN AT 2020-06-20 09:18:22 AM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
++ pwd
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
++ pwd
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 8 -gt 1 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 8 -gt 1 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
STARTING TIMING RUN AT 2020-06-20 09:18:22 AM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
STARTING TIMING RUN AT 2020-06-20 09:18:22 AM
STARTING TIMING RUN AT 2020-06-20 09:18:22 AM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
++ pwd
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 8 -gt 1 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
++ pwd
++ pwd
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 8 -gt 1 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
+ '[' -n 7 ']'
+ '[' 8 -gt 1 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=6 --membind=6 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=2 --membind=2 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=7 --membind=7 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
+ exec numactl --cpunodebind=3 --membind=3 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
+ exec numactl --cpunodebind=5 --membind=5 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
+ exec numactl --cpunodebind=4 --membind=4 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
:::MLLOG {"namespace": "", "time_ms": 1592669904358, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592669904358, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592669904391, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592669904401, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592669904415, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592669904435, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592669904463, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592669904539, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592669907077, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2333201044, "metadata": {"file": "/workspace/single_stage_detector/mlperf_logger.py", "lineno": 92}}
0 Using seed = 2333201044
1 Using seed = 2333201045
4 Using seed = 2333201048
5 Using seed = 2333201049
6 Using seed = 2333201050
7 Using seed = 2333201051
3 Using seed = 2333201047
2 Using seed = 2333201046
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 31%|      | 26.2M/83.3M [00:00<00:00, 269MB/s]
 67%|   | 55.8M/83.3M [00:00<00:00, 280MB/s]
 97%|| 80.7M/83.3M [00:00<00:00, 274MB/s]
100%|| 83.3M/83.3M [00:00<00:00, 282MB/s]

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 35%|      | 29.3M/83.3M [00:00<00:00, 307MB/s]
 61%|   | 51.0M/83.3M [00:00<00:00, 275MB/s]
 93%|| 77.1M/83.3M [00:00<00:00, 274MB/s]
100%|| 83.3M/83.3M [00:00<00:00, 259MB/s]
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 14%|        | 11.8M/83.3M [00:00<00:00, 123MB/s]
 26%|       | 21.7M/83.3M [00:00<00:00, 116MB/s]
 37%|      | 30.6M/83.3M [00:00<00:00, 108MB/s]
 45%|     | 37.1M/83.3M [00:00<00:00, 73.2MB/s]
 51%|    | 42.8M/83.3M [00:00<00:01, 36.6MB/s]
 57%|    | 47.3M/83.3M [00:01<00:01, 30.0MB/s]
 61%|   | 51.1M/83.3M [00:01<00:01, 25.4MB/s]
 65%|   | 54.2M/83.3M [00:01<00:01, 16.7MB/s]
 68%|   | 56.7M/83.3M [00:01<00:01, 14.1MB/s]
 71%|   | 58.7M/83.3M [00:02<00:01, 13.0MB/s]
 73%|  | 60.5M/83.3M [00:02<00:02, 11.5MB/s]
 74%|  | 61.9M/83.3M [00:02<00:01, 12.3MB/s]
 76%|  | 63.4M/83.3M [00:02<00:01, 13.0MB/s]
 78%|  | 64.9M/83.3M [00:02<00:01, 13.8MB/s]
 80%|  | 66.4M/83.3M [00:02<00:01, 10.6MB/s]
  0%|          | 0.00/83.3M [00:00<?, ?B/s]
  9%|         | 7.49M/83.3M [00:00<00:01, 78.5MB/s]
 17%|        | 13.8M/83.3M [00:00<00:00, 74.1MB/s]
 28%|       | 22.9M/83.3M [00:00<00:00, 79.3MB/s]
 39%|      | 32.7M/83.3M [00:00<00:00, 85.0MB/s]
 47%|     | 39.2M/83.3M [00:00<00:00, 58.7MB/s]
 54%|    | 44.7M/83.3M [00:00<00:01, 36.9MB/s]
 59%|    | 49.2M/83.3M [00:01<00:01, 28.9MB/s]
 63%|   | 52.8M/83.3M [00:01<00:01, 21.5MB/s]
 67%|   | 55.8M/83.3M [00:01<00:01, 15.7MB/s]
 70%|   | 58.1M/83.3M [00:01<00:01, 13.6MB/s]
 72%|  | 60.0M/83.3M [00:02<00:01, 12.4MB/s]
 74%|  | 61.7M/83.3M [00:02<00:01, 12.1MB/s]
 76%|  | 63.2M/83.3M [00:02<00:01, 12.9MB/s]
 78%|  | 64.8M/83.3M [00:02<00:01, 13.8MB/s]
 80%|  | 66.3M/83.3M [00:02<00:01, 13.1MB/s]
 81%|
  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 12%|        | 10.3M/83.3M [00:00<00:00, 108MB/s]
 24%|       | 20.1M/83.3M [00:00<00:00, 106MB/s]
 31%|      | 26.1M/83.3M [00:00<00:00, 88.0MB/s]
 43%|     | 35.8M/83.3M [00:00<00:00, 91.4MB/s]
 51%|     | 42.4M/83.3M [00:00<00:01, 41.4MB/s]
 57%|    | 47.6M/83.3M [00:01<00:01, 32.1MB/s]
 62%|   | 51.8M/83.3M [00:01<00:01, 25.3MB/s]
 66%|   | 55.2M/83.3M [00:01<00:01, 16.8MB/s]
 70%|   | 57.9M/83.3M [00:01<00:01, 14.1MB/s]
 72%|  | 60.1M/83.3M [00:02<00:01, 12.7MB/s]
 74%|  | 61.9M/83.3M [00:02<00:01, 12.5MB/s]
 76%|  | 63.5M/83.3M [00:02<00:01, 13.2MB/s]
 78%|  | 65.1M/83.3M [00:02<00:01, 13.9MB/s]
 80%|  | 66.6M/83.3M [00:02<00:01, 12.8MB/s]
 82%| | 68.0M/83.3M [00:02<00:01, 10.8MB
  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 12%|        | 10.3M/83.3M [00:00<00:00, 108MB/s]
 22%|       | 18.3M/83.3M [00:00<00:00, 99.4MB/s]
 34%|      | 28.0M/83.3M [00:00<00:00, 100MB/s]
 43%|     | 36.0M/83.3M [00:00<00:00, 94.4MB/s]
 51%|     | 42.6M/83.3M [00:00<00:01, 40.2MB/s]
 57%|    | 47.8M/83.3M [00:01<00:01, 31.2MB/s]
 62%|   | 52.0M/83.3M [00:01<00:01, 24.4MB/s]
 67%|   | 55.4M/83.3M [00:01<00:01, 16.6MB/s]
 70%|   | 58.1M/83.3M [00:01<00:01, 14.1MB/s]
 72%|  | 60.2M/83.3M [00:02<00:01, 12.5MB/s]
 74%|  | 62.0M/83.3M [00:02<00:01, 12.6MB/s]
 76%|  | 63.6M/83.3M [00:02<00:01, 13.3MB/s]
 78%|  | 65.2M/83.3M [00:02<00:01, 14.0MB/s]
 80%|  | 66.8M/83.3M [00:02<00:01, 12.6MB/s]
 82%| | 68.2M/83.3M [00:02<00:01, 10.8M
  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 11%|         | 9.00M/83.3M [00:00<00:00, 93.7MB/s]
 22%|       | 18.6M/83.3M [00:00<00:00, 95.2MB/s]
 30%|       | 25.4M/83.3M [00:00<00:00, 85.8MB/s]
 43%|     | 35.6M/83.3M [00:00<00:00, 91.3MB/s]
 51%|     | 42.4M/83.3M [00:00<00:01, 40.7MB/s]
 57%|    | 47.6M/83.3M [00:01<00:01, 31.8MB/s]
 62%|   | 51.9M/83.3M [00:01<00:01, 25.0MB/s]
 67%|   | 55.4M/83.3M [00:01<00:01, 16.7MB/s]
 70%|   | 58.1M/83.3M [00:01<00:01, 14.2MB/s]
 72%|  | 60.3M/83.3M [00:02<00:01, 12.3MB/s]
 75%|  | 62.1M/83.3M [00:02<00:01, 12.8MB/s]
 77%|  | 63.8M/83.3M [00:02<00:01, 13.5MB/s]
 79%|  | 65.4M/83.3M [00:02<00:01, 14.0MB/s]
 80%|  | 67.0M/83.3M [00:02<00:01, 12.0MB/s]
 82%| | 68.3M/83.3M [00:02<00:01, 10.9MB/s
  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 11%|        | 9.44M/83.3M [00:00<00:00, 98.9MB/s]
 20%|        | 17.1M/83.3M [00:00<00:00, 89.8MB/s]
 30%|       | 25.2M/83.3M [00:00<00:00, 88.3MB/s]
 43%|     | 36.2M/83.3M [00:00<00:00, 94.9MB/s]
 52%|    | 43.2M/83.3M [00:00<00:01, 40.8MB/s]
 58%|    | 48.6M/83.3M [00:01<00:01, 30.0MB/s]
 64%|   | 52.9M/83.3M [00:01<00:01, 22.9MB/s]
 68%|   | 56.3M/83.3M [00:01<00:01, 16.1MB/s]
 71%|   | 59.0M/83.3M [00:02<00:01, 14.1MB/s]
 74%|  | 61.2M/83.3M [00:02<00:01, 12.5MB/s]
 76%|  | 63.0M/83.3M [00:02<00:01, 13.1MB/s]
 78%|  | 64.8M/83.3M [00:02<00:01, 14.2MB/s]
 80%|  | 66.5M/83.3M [00:02<00:01, 12.6MB/s]
 82%| | 67.9M/83.3M [00:02<00:01, 11.4MB/s]
 83%| | 69.2M/83.3M [00:03<00:01, 11.1B/s]
 83%| | 69.4M/83.3M [00:03<00:01, 10.8MB/s]
 85%| | 70.5M/83.3M [00:03<00:01, 10.5MB/s]
 86%| | 71.6M/83.3M [00:03<00:01, 10.6MB/s]
 87%| | 72.7M/83.3M [00:03<00:01, 10.9MB/s]
 89%| | 73.8M/83.3M [00:03<00:00, 10.2MB/s]
 90%| | 74.8M/83.3M [00:03<00:00, 10.0MB/s]
 91%| | 75.8M/83.3M [00:03<00:00, 9.59MB/s]
 92%|| 76.7M/83.3M [00:03<00:00, 9.46MB/s]
 93%|| 77.6M/83.3M [00:03<00:00, 9.51MB/s]
 94%|| 78.6M/83.3M [00:04<00:00, 9.40MB/s]
 95%|| 79.5M/83.3M [00:04<00:00, 9.04MB/s]
 97%|| 80.4M/83.3M [00:04<00:00, 9.06MB/s]
 98%|| 81.2M/83.3M [00:04<00:00, 8.96MB/s]
 99%|| 82.2M/83.3M [00:04<00:00, 9.32MB/s]
100%|| 83.2M/83.3M [00:04<00:00, 9.67MB/s]
100%|| 83.3M/83.3M [00:04<00:00, 19.2MB/s]
/s]
 83%| | 69.2M/83.3M [00:02<00:01, 10.9MB/s]
 85%| | 70.4M/83.3M [00:03<00:01, 10.5MB/s]
 86%| | 71.5M/83.3M [00:03<00:01, 10.6MB/s]
 87%| | 72.6M/83.3M [00:03<00:01, 10.9MB/s]
 89%| | 73.7M/83.3M [00:03<00:00, 10.2MB/s]
 90%| | 74.8M/83.3M [00:03<00:00, 10.0MB/s]
 91%| | 75.8M/83.3M [00:03<00:00, 9.55MB/s]
 92%|| 76.7M/83.3M [00:03<00:00, 9.43MB/s]
 93%|| 77.6M/83.3M [00:03<00:00, 9.52MB/s]
 94%|| 78.5M/83.3M [00:04<00:00, 9.41MB/s]
 95%|| 79.5M/83.3M [00:04<00:00, 8.99MB/s]
 97%|| 80.4M/83.3M [00:04<00:00, 9.08MB/s]
 98%|| 81.2M/83.3M [00:04<00:00, 9.00MB/s]
 99%|| 82.2M/83.3M [00:04<00:00, 9.34MB/s]
100%| | 67.7M/83.3M [00:02<00:01, 11.2MB/s]
 83%| | 68.9M/83.3M [00:02<00:01, 10.6MB/s]
 84%| | 70.0M/83.3M [00:03<00:01, 10.6MB/s]
 85%| | 71.1M/83.3M [00:03<00:01, 10.4MB/s]
 87%| | 72.3M/83.3M [00:03<00:01, 10.9MB/s]
 88%| | 73.4M/83.3M [00:03<00:02, 5.10MB/s]
 89%| | 74.2M/83.3M [00:03<00:01, 5.78MB/s]
 92%|| 76.6M/83.3M [00:04<00:00, 7.50MB/s]
 95%|| 79.2M/83.3M [00:04<00:00, 9.58MB/s]
 97%|| 80.9M/83.3M [00:04<00:00, 9.47MB/s]
 99%|| 82.4M/83.3M [00:04<00:00, 9.58MB/s]
100%|| 83.3M/83.3M [00:04<00:00, 19.2MB/s]
| 83.2M/83.3M [00:04<00:00, 9.65MB/s]
100%|| 83.3M/83.3M [00:04<00:00, 19.2MB/s]
MB/s]
 85%| | 70.4M/83.3M [00:03<00:01, 10.7MB/s]
 86%| | 71.6M/83.3M [00:03<00:01, 10.6MB/s]
 87%| | 72.7M/83.3M [00:03<00:01, 10.9MB/s]
 89%| | 73.8M/83.3M [00:03<00:00, 10.4MB/s]
 90%| | 74.9M/83.3M [00:03<00:00, 10.1MB/s]
 91%| | 75.9M/83.3M [00:03<00:00, 9.66MB/s]
 92%|| 76.8M/83.3M [00:03<00:00, 9.44MB/s]
 93%|| 77.8M/83.3M [00:03<00:00, 9.01MB/s]
 95%|| 78.8M/83.3M [00:04<00:00, 9.40MB/s]
 96%|| 79.7M/83.3M [00:04<00:00, 9.23MB/s]
 97%|| 80.6M/83.3M [00:04<00:00, 9.03MB/s]
 98%|| 81.5M/83.3M [00:04<00:00, 9.02MB/s]
 99%|| 82.5M/83.3M [00:04<00:00, 9.41MB/s]
100%|| 83.3M/83.3M [00:04<00:00, 19.2MB/s]

 81%| | 67.8M/83.3M [00:02<00:01, 11.6MB/s]
 83%| | 69.1M/83.3M [00:03<00:01, 10.2MB/s]
 85%| | 70.5M/83.3M [00:03<00:01, 11.1MB/s]
 86%| | 71.6M/83.3M [00:03<00:01, 9.70MB/s]
 88%| | 73.2M/83.3M [00:03<00:00, 11.1MB/s]
 89%| | 74.4M/83.3M [00:03<00:00, 10.5MB/s]
 91%| | 75.5M/83.3M [00:03<00:00, 9.72MB/s]
 92%|| 76.6M/83.3M [00:04<00:01, 4.67MB/s]
 95%|| 79.3M/83.3M [00:04<00:00, 6.22MB/s]
 98%|| 81.7M/83.3M [00:04<00:00, 7.98MB/s]
100%|| 83.3M/83.3M [00:04<00:00, 19.1MB/s]
]
 84%| | 69.5M/83.3M [00:03<00:01, 10.1MB/s]
 85%| | 70.8M/83.3M [00:03<00:01, 10.8MB/s]
 86%| | 71.9M/83.3M [00:03<00:01, 11.1MB/s]
 88%| | 73.1M/83.3M [00:03<00:00, 10.8MB/s]
 89%| | 74.1M/83.3M [00:03<00:00, 10.2MB/s]
 90%| | 75.2M/83.3M [00:03<00:00, 10.1MB/s]
 91%|| 76.2M/83.3M [00:03<00:00, 9.53MB/s]
 93%|| 77.1M/83.3M [00:03<00:00, 9.40MB/s]
 94%|| 78.1M/83.3M [00:03<00:00, 9.61MB/s]
 95%|| 79.0M/83.3M [00:04<00:00, 9.10MB/s]
 96%|| 79.9M/83.3M [00:04<00:00, 9.16MB/s]
 97%|| 80.8M/83.3M [00:04<00:00, 8.97MB/s]
 98%|| 81.7M/83.3M [00:04<00:00, 9.07MB/s]
 99%|| 82.6M/83.3M [00:04<00:00, 9.25MB/s]
100%|| 83.3M/83.3M [00:04<00:00, 19.1MB/s]
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
:::MLLOG {"namespace": "", "time_ms": 1592669917757, "event_type": "POINT_IN_TIME", "key": "model_bn_span", "value": 114, "metadata": {"file": "train.py", "lineno": 170}}
:::MLLOG {"namespace": "", "time_ms": 1592669917758, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 912, "metadata": {"file": "train.py", "lineno": 171}}
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : 128.0
Delaying allreduces to the end of backward()
:::MLLOG {"namespace": "", "time_ms": 1592669917767, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.09, "metadata": {"file": "train.py", "lineno": 199}}
:::MLLOG {"namespace": "", "time_ms": 1592669917767, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_boundary_epochs", "value": [44, 55], "metadata": {"file": "train.py", "lineno": 200}}
:::MLLOG {"namespace": "", "time_ms": 1592669917767, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_steps", "value": [44, 55], "metadata": {"file": "train.py", "lineno": 201}}
:::MLLOG {"namespace": "", "time_ms": 1592669917767, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.00013, "metadata": {"file": "train.py", "lineno": 202}}
:::MLLOG {"namespace": "", "time_ms": 1592669917767, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 650, "metadata": {"file": "train.py", "lineno": 204}}
:::MLLOG {"namespace": "", "time_ms": 1592669917767, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_factor", "value": 0, "metadata": {"file": "train.py", "lineno": 205}}
epoch nbatch loss
:::MLLOG {"namespace": "", "time_ms": 1592669941023, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "train.py", "lineno": 267}}
:::MLLOG {"namespace": "", "time_ms": 1592669941031, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "train.py", "lineno": 274}}
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
:::MLLOG {"namespace": "", "time_ms": 1592669943097, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 117266, "metadata": {"file": "/workspace/single_stage_detector/data/build_pipeline.py", "lineno": 48}}
epoch size is:  117266  images
:::MLLOG {"namespace": "", "time_ms": 1592669943098, "event_type": "POINT_IN_TIME", "key": "max_samples", "value": 1, "metadata": {"file": "/workspace/single_stage_detector/utils.py", "lineno": 156}}
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
Done (t=0.12s)
creating index...
Done (t=0.11s)
creating index...
Done (t=0.11s)
creating index...
Done (t=0.12s)
creating index...
Done (t=0.11s)
creating index...
Done (t=0.11s)
creating index...
Done (t=0.12s)
creating index...
Done (t=0.12s)
creating index...
:::MLLOG {"namespace": "", "time_ms": 1592669943325, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 4952, "metadata": {"file": "/workspace/single_stage_detector/data/native_pipeline.py", "lineno": 97}}
:::MLLOG {"namespace": "", "time_ms": 1592669943326, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 293, "first_epoch_num": 1, "epoch_count": 40}}
:::MLLOG {"namespace": "", "time_ms": 1592669943327, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 1, "current_iter_num": 0}}
Iteration:      0, Loss function: 22.344, Average Loss: 0.022, avg. samples / sec: 35.79
Iteration:     20, Loss function: 20.744, Average Loss: 0.440, avg. samples / sec: 8164.84
Iteration:     40, Loss function: 17.063, Average Loss: 0.820, avg. samples / sec: 8882.75
Iteration:     60, Loss function: 12.645, Average Loss: 1.085, avg. samples / sec: 9055.78
Iteration:     80, Loss function: 11.347, Average Loss: 1.287, avg. samples / sec: 9249.67
Iteration:    100, Loss function: 9.658, Average Loss: 1.458, avg. samples / sec: 9268.70
Iteration:    120, Loss function: 9.090, Average Loss: 1.611, avg. samples / sec: 9274.43
:::MLLOG {"namespace": "", "time_ms": 1592669956589, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1592669956590, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 2, "current_iter_num": 129}}
Iteration:    140, Loss function: 9.107, Average Loss: 1.755, avg. samples / sec: 9324.93
Iteration:    160, Loss function: 8.376, Average Loss: 1.891, avg. samples / sec: 9398.31
Iteration:    180, Loss function: 8.197, Average Loss: 2.019, avg. samples / sec: 9433.54
Iteration:    200, Loss function: 8.036, Average Loss: 2.144, avg. samples / sec: 9458.80
Iteration:    220, Loss function: 7.697, Average Loss: 2.263, avg. samples / sec: 9437.37
Iteration:    240, Loss function: 7.735, Average Loss: 2.374, avg. samples / sec: 9353.80
:::MLLOG {"namespace": "", "time_ms": 1592669969077, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1592669969078, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 3, "current_iter_num": 258}}
Iteration:    260, Loss function: 7.395, Average Loss: 2.478, avg. samples / sec: 9503.57
Iteration:    280, Loss function: 7.088, Average Loss: 2.575, avg. samples / sec: 9537.68
Iteration:    300, Loss function: 7.288, Average Loss: 2.675, avg. samples / sec: 9510.79
Iteration:    320, Loss function: 6.827, Average Loss: 2.764, avg. samples / sec: 9561.14
Iteration:    340, Loss function: 7.148, Average Loss: 2.848, avg. samples / sec: 9490.29
Iteration:    360, Loss function: 7.114, Average Loss: 2.939, avg. samples / sec: 9569.91
Iteration:    380, Loss function: 6.669, Average Loss: 3.019, avg. samples / sec: 9566.59
:::MLLOG {"namespace": "", "time_ms": 1592669981312, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592669981313, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 4, "current_iter_num": 386}}
Iteration:    400, Loss function: 6.941, Average Loss: 3.094, avg. samples / sec: 9607.20
Iteration:    420, Loss function: 6.735, Average Loss: 3.167, avg. samples / sec: 9605.76
Iteration:    440, Loss function: 6.468, Average Loss: 3.234, avg. samples / sec: 9644.23
Iteration:    460, Loss function: 6.782, Average Loss: 3.301, avg. samples / sec: 9579.58
Iteration:    480, Loss function: 6.222, Average Loss: 3.364, avg. samples / sec: 9602.02
Iteration:    500, Loss function: 6.279, Average Loss: 3.422, avg. samples / sec: 9629.18
:::MLLOG {"namespace": "", "time_ms": 1592669993585, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592669993586, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 5, "current_iter_num": 515}}
Iteration:    520, Loss function: 6.435, Average Loss: 3.481, avg. samples / sec: 9653.11
Iteration:    540, Loss function: 5.983, Average Loss: 3.533, avg. samples / sec: 9617.69
Iteration:    560, Loss function: 6.146, Average Loss: 3.581, avg. samples / sec: 9658.46
Iteration:    580, Loss function: 5.872, Average Loss: 3.631, avg. samples / sec: 9655.28
Iteration:    600, Loss function: 6.040, Average Loss: 3.678, avg. samples / sec: 9711.60
Iteration:    620, Loss function: 5.950, Average Loss: 3.723, avg. samples / sec: 9690.73
Iteration:    640, Loss function: 6.310, Average Loss: 3.766, avg. samples / sec: 9705.70
:::MLLOG {"namespace": "", "time_ms": 1592670005628, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1592670005629, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 6, "current_iter_num": 643}}
Iteration:    660, Loss function: 5.888, Average Loss: 3.809, avg. samples / sec: 9657.64
Iteration:    680, Loss function: 5.774, Average Loss: 3.845, avg. samples / sec: 9669.01
Iteration:    700, Loss function: 5.482, Average Loss: 3.880, avg. samples / sec: 9708.81
Iteration:    720, Loss function: 5.824, Average Loss: 3.916, avg. samples / sec: 9729.97
Iteration:    740, Loss function: 5.585, Average Loss: 3.950, avg. samples / sec: 9716.25
Iteration:    760, Loss function: 5.465, Average Loss: 3.981, avg. samples / sec: 9752.45
:::MLLOG {"namespace": "", "time_ms": 1592670017752, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 6}}
:::MLLOG {"namespace": "", "time_ms": 1592670017752, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 7, "current_iter_num": 772}}
Iteration:    780, Loss function: 5.391, Average Loss: 4.009, avg. samples / sec: 9701.39
Iteration:    800, Loss function: 5.819, Average Loss: 4.036, avg. samples / sec: 9732.01
Iteration:    820, Loss function: 5.064, Average Loss: 4.061, avg. samples / sec: 9770.00
Iteration:    840, Loss function: 5.002, Average Loss: 4.085, avg. samples / sec: 9653.12
Iteration:    860, Loss function: 5.548, Average Loss: 4.109, avg. samples / sec: 9676.17
Iteration:    880, Loss function: 5.306, Average Loss: 4.130, avg. samples / sec: 9747.41
Iteration:    900, Loss function: 5.051, Average Loss: 4.151, avg. samples / sec: 9754.52
:::MLLOG {"namespace": "", "time_ms": 1592670029888, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1592670029889, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 8, "current_iter_num": 901}}
Iteration:    920, Loss function: 4.997, Average Loss: 4.169, avg. samples / sec: 9773.91
Iteration:    940, Loss function: 4.964, Average Loss: 4.186, avg. samples / sec: 9784.28
Iteration:    960, Loss function: 4.980, Average Loss: 4.206, avg. samples / sec: 9776.53
Iteration:    980, Loss function: 4.970, Average Loss: 4.223, avg. samples / sec: 9798.06
Iteration:   1000, Loss function: 4.922, Average Loss: 4.238, avg. samples / sec: 9781.37
Iteration:   1020, Loss function: 4.953, Average Loss: 4.254, avg. samples / sec: 9784.50
:::MLLOG {"namespace": "", "time_ms": 1592670041783, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 8}}
:::MLLOG {"namespace": "", "time_ms": 1592670041784, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 9, "current_iter_num": 1029}}
Iteration:   1040, Loss function: 5.007, Average Loss: 4.267, avg. samples / sec: 9755.05
Iteration:   1060, Loss function: 4.747, Average Loss: 4.280, avg. samples / sec: 9744.23
Iteration:   1080, Loss function: 4.648, Average Loss: 4.291, avg. samples / sec: 9790.16
Iteration:   1100, Loss function: 4.771, Average Loss: 4.303, avg. samples / sec: 9763.77
Iteration:   1120, Loss function: 4.929, Average Loss: 4.315, avg. samples / sec: 9779.84
Iteration:   1140, Loss function: 4.899, Average Loss: 4.326, avg. samples / sec: 9783.60
:::MLLOG {"namespace": "", "time_ms": 1592670053820, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 9}}
:::MLLOG {"namespace": "", "time_ms": 1592670053821, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 10, "current_iter_num": 1158}}
Iteration:   1160, Loss function: 4.770, Average Loss: 4.334, avg. samples / sec: 9814.84
Iteration:   1180, Loss function: 4.305, Average Loss: 4.344, avg. samples / sec: 9779.87
Iteration:   1200, Loss function: 4.697, Average Loss: 4.352, avg. samples / sec: 9780.82
Iteration:   1220, Loss function: 4.799, Average Loss: 4.360, avg. samples / sec: 9770.77
Iteration:   1240, Loss function: 4.985, Average Loss: 4.370, avg. samples / sec: 9831.33
Iteration:   1260, Loss function: 5.024, Average Loss: 4.377, avg. samples / sec: 9834.83
Iteration:   1280, Loss function: 4.719, Average Loss: 4.384, avg. samples / sec: 9862.39
:::MLLOG {"namespace": "", "time_ms": 1592670065713, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 10}}
:::MLLOG {"namespace": "", "time_ms": 1592670065714, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 11, "current_iter_num": 1286}}
Iteration:   1300, Loss function: 4.704, Average Loss: 4.389, avg. samples / sec: 9824.60
Iteration:   1320, Loss function: 4.966, Average Loss: 4.397, avg. samples / sec: 9857.64
Iteration:   1340, Loss function: 4.672, Average Loss: 4.400, avg. samples / sec: 9848.66
Iteration:   1360, Loss function: 4.594, Average Loss: 4.404, avg. samples / sec: 9862.62
Iteration:   1380, Loss function: 4.627, Average Loss: 4.408, avg. samples / sec: 9833.25
Iteration:   1400, Loss function: 4.677, Average Loss: 4.412, avg. samples / sec: 9811.94
:::MLLOG {"namespace": "", "time_ms": 1592670077673, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1592670077674, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 12, "current_iter_num": 1415}}
Iteration:   1420, Loss function: 4.591, Average Loss: 4.416, avg. samples / sec: 9826.27
Iteration:   1440, Loss function: 4.779, Average Loss: 4.419, avg. samples / sec: 9843.70
Iteration:   1460, Loss function: 4.647, Average Loss: 4.422, avg. samples / sec: 9836.12
Iteration:   1480, Loss function: 4.450, Average Loss: 4.424, avg. samples / sec: 9842.28
Iteration:   1500, Loss function: 4.657, Average Loss: 4.427, avg. samples / sec: 9847.66
Iteration:   1520, Loss function: 4.397, Average Loss: 4.431, avg. samples / sec: 9859.21
Iteration:   1540, Loss function: 4.486, Average Loss: 4.435, avg. samples / sec: 9824.39
:::MLLOG {"namespace": "", "time_ms": 1592670089534, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1592670089534, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 13, "current_iter_num": 1543}}
Iteration:   1560, Loss function: 4.434, Average Loss: 4.437, avg. samples / sec: 9837.11
Iteration:   1580, Loss function: 4.373, Average Loss: 4.439, avg. samples / sec: 9842.50
Iteration:   1600, Loss function: 4.270, Average Loss: 4.439, avg. samples / sec: 9837.86
Iteration:   1620, Loss function: 4.241, Average Loss: 4.440, avg. samples / sec: 9845.78
Iteration:   1640, Loss function: 4.551, Average Loss: 4.441, avg. samples / sec: 9856.33
Iteration:   1660, Loss function: 4.512, Average Loss: 4.441, avg. samples / sec: 9833.48
:::MLLOG {"namespace": "", "time_ms": 1592670101487, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 13}}
:::MLLOG {"namespace": "", "time_ms": 1592670101488, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 14, "current_iter_num": 1672}}
Iteration:   1680, Loss function: 4.346, Average Loss: 4.441, avg. samples / sec: 9830.31
Iteration:   1700, Loss function: 4.291, Average Loss: 4.440, avg. samples / sec: 9806.51
Iteration:   1720, Loss function: 4.078, Average Loss: 4.439, avg. samples / sec: 9850.76
Iteration:   1740, Loss function: 4.527, Average Loss: 4.440, avg. samples / sec: 9844.36
Iteration:   1760, Loss function: 4.619, Average Loss: 4.440, avg. samples / sec: 9833.77
Iteration:   1780, Loss function: 4.240, Average Loss: 4.439, avg. samples / sec: 9843.29
Iteration:   1800, Loss function: 4.340, Average Loss: 4.438, avg. samples / sec: 9863.78
:::MLLOG {"namespace": "", "time_ms": 1592670113488, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 14}}
:::MLLOG {"namespace": "", "time_ms": 1592670113489, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 15, "current_iter_num": 1801}}
Iteration:   1820, Loss function: 4.004, Average Loss: 4.436, avg. samples / sec: 9834.41
Iteration:   1840, Loss function: 4.512, Average Loss: 4.433, avg. samples / sec: 9853.24
Iteration:   1860, Loss function: 4.324, Average Loss: 4.432, avg. samples / sec: 9855.23
Iteration:   1880, Loss function: 4.571, Average Loss: 4.431, avg. samples / sec: 9838.89
Iteration:   1900, Loss function: 4.374, Average Loss: 4.430, avg. samples / sec: 9842.30
Iteration:   1920, Loss function: 4.750, Average Loss: 4.429, avg. samples / sec: 9861.79
:::MLLOG {"namespace": "", "time_ms": 1592670125298, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1592670125299, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 16, "current_iter_num": 1929}}
Iteration:   1940, Loss function: 4.414, Average Loss: 4.428, avg. samples / sec: 9862.73
Iteration:   1960, Loss function: 4.356, Average Loss: 4.425, avg. samples / sec: 9866.53
Iteration:   1980, Loss function: 4.321, Average Loss: 4.423, avg. samples / sec: 9858.01
Iteration:   2000, Loss function: 4.517, Average Loss: 4.422, avg. samples / sec: 9851.02
Iteration:   2020, Loss function: 4.490, Average Loss: 4.421, avg. samples / sec: 9860.79
Iteration:   2040, Loss function: 4.615, Average Loss: 4.419, avg. samples / sec: 9853.45
:::MLLOG {"namespace": "", "time_ms": 1592670137234, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1592670137235, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 17, "current_iter_num": 2058}}
Iteration:   2060, Loss function: 4.377, Average Loss: 4.417, avg. samples / sec: 9854.88
Iteration:   2080, Loss function: 4.078, Average Loss: 4.415, avg. samples / sec: 9860.25
Iteration:   2100, Loss function: 4.326, Average Loss: 4.413, avg. samples / sec: 9856.10
Iteration:   2120, Loss function: 4.304, Average Loss: 4.409, avg. samples / sec: 9861.62
Iteration:   2140, Loss function: 4.044, Average Loss: 4.405, avg. samples / sec: 9868.69
Iteration:   2160, Loss function: 4.342, Average Loss: 4.401, avg. samples / sec: 9835.76
Iteration:   2180, Loss function: 4.243, Average Loss: 4.398, avg. samples / sec: 9867.16
:::MLLOG {"namespace": "", "time_ms": 1592670149076, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 17}}
:::MLLOG {"namespace": "", "time_ms": 1592670149076, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 18, "current_iter_num": 2186}}
Iteration:   2200, Loss function: 4.137, Average Loss: 4.394, avg. samples / sec: 9857.55
Iteration:   2220, Loss function: 4.059, Average Loss: 4.391, avg. samples / sec: 9815.87
Iteration:   2240, Loss function: 4.071, Average Loss: 4.387, avg. samples / sec: 9861.13
Iteration:   2260, Loss function: 4.369, Average Loss: 4.386, avg. samples / sec: 9875.24
Iteration:   2280, Loss function: 4.020, Average Loss: 4.383, avg. samples / sec: 9869.53
Iteration:   2300, Loss function: 4.001, Average Loss: 4.380, avg. samples / sec: 9860.52
:::MLLOG {"namespace": "", "time_ms": 1592670161011, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1592670161012, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 19, "current_iter_num": 2315}}
Iteration:   2320, Loss function: 3.831, Average Loss: 4.375, avg. samples / sec: 9851.99
Iteration:   2340, Loss function: 4.431, Average Loss: 4.372, avg. samples / sec: 9849.37
Iteration:   2360, Loss function: 4.119, Average Loss: 4.368, avg. samples / sec: 9850.33
Iteration:   2380, Loss function: 4.252, Average Loss: 4.364, avg. samples / sec: 9850.18
Iteration:   2400, Loss function: 4.088, Average Loss: 4.359, avg. samples / sec: 9856.42
Iteration:   2420, Loss function: 4.146, Average Loss: 4.355, avg. samples / sec: 9860.23
Iteration:   2440, Loss function: 4.206, Average Loss: 4.352, avg. samples / sec: 9868.24
:::MLLOG {"namespace": "", "time_ms": 1592670172858, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1592670172859, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 20, "current_iter_num": 2443}}
Iteration:   2460, Loss function: 4.136, Average Loss: 4.347, avg. samples / sec: 9857.11
Iteration:   2480, Loss function: 4.354, Average Loss: 4.344, avg. samples / sec: 9853.21
Iteration:   2500, Loss function: 4.055, Average Loss: 4.341, avg. samples / sec: 9866.17
Iteration:   2520, Loss function: 3.865, Average Loss: 4.338, avg. samples / sec: 9855.42
Iteration:   2540, Loss function: 4.012, Average Loss: 4.334, avg. samples / sec: 9857.90
Iteration:   2560, Loss function: 4.398, Average Loss: 4.330, avg. samples / sec: 9854.61
:::MLLOG {"namespace": "", "time_ms": 1592670184796, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1592670184797, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 21, "current_iter_num": 2572}}
Iteration:   2580, Loss function: 3.962, Average Loss: 4.325, avg. samples / sec: 9841.49
Iteration:   2600, Loss function: 4.186, Average Loss: 4.321, avg. samples / sec: 9861.30
Iteration:   2620, Loss function: 4.334, Average Loss: 4.317, avg. samples / sec: 9841.79
Iteration:   2640, Loss function: 4.230, Average Loss: 4.313, avg. samples / sec: 9859.12
Iteration:   2660, Loss function: 4.178, Average Loss: 4.308, avg. samples / sec: 9767.26
Iteration:   2680, Loss function: 4.097, Average Loss: 4.304, avg. samples / sec: 9868.18
Iteration:   2700, Loss function: 3.693, Average Loss: 4.300, avg. samples / sec: 9869.64
:::MLLOG {"namespace": "", "time_ms": 1592670196789, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 21}}
:::MLLOG {"namespace": "", "time_ms": 1592670196790, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 22, "current_iter_num": 2701}}
Iteration:   2720, Loss function: 4.241, Average Loss: 4.296, avg. samples / sec: 9804.11
Iteration:   2740, Loss function: 4.018, Average Loss: 4.291, avg. samples / sec: 9868.63
Iteration:   2760, Loss function: 3.923, Average Loss: 4.287, avg. samples / sec: 9840.27
Iteration:   2780, Loss function: 3.911, Average Loss: 4.283, avg. samples / sec: 9794.37
Iteration:   2800, Loss function: 3.845, Average Loss: 4.280, avg. samples / sec: 9856.28
Iteration:   2820, Loss function: 3.872, Average Loss: 4.276, avg. samples / sec: 9865.53
:::MLLOG {"namespace": "", "time_ms": 1592670208609, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 22}}
:::MLLOG {"namespace": "", "time_ms": 1592670208610, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 23, "current_iter_num": 2829}}
Iteration:   2840, Loss function: 4.164, Average Loss: 4.271, avg. samples / sec: 9798.70
Iteration:   2860, Loss function: 3.833, Average Loss: 4.267, avg. samples / sec: 9861.20
Iteration:   2880, Loss function: 4.076, Average Loss: 4.263, avg. samples / sec: 9855.25
Iteration:   2900, Loss function: 3.682, Average Loss: 4.259, avg. samples / sec: 9759.14
Iteration:   2920, Loss function: 4.051, Average Loss: 4.254, avg. samples / sec: 9854.58
Iteration:   2940, Loss function: 4.052, Average Loss: 4.252, avg. samples / sec: 9848.71
:::MLLOG {"namespace": "", "time_ms": 1592670220595, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1592670220596, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 24, "current_iter_num": 2958}}
Iteration:   2960, Loss function: 4.188, Average Loss: 4.248, avg. samples / sec: 9759.55
Iteration:   2980, Loss function: 4.089, Average Loss: 4.244, avg. samples / sec: 9854.99
Iteration:   3000, Loss function: 4.124, Average Loss: 4.240, avg. samples / sec: 9849.97
Iteration:   3020, Loss function: 4.123, Average Loss: 4.238, avg. samples / sec: 9763.27
Iteration:   3040, Loss function: 3.953, Average Loss: 4.233, avg. samples / sec: 9857.02
Iteration:   3060, Loss function: 3.924, Average Loss: 4.229, avg. samples / sec: 9870.20
Iteration:   3080, Loss function: 4.046, Average Loss: 4.224, avg. samples / sec: 9795.99
:::MLLOG {"namespace": "", "time_ms": 1592670232468, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1592670232469, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 25, "current_iter_num": 3086}}
Iteration:   3100, Loss function: 3.854, Average Loss: 4.220, avg. samples / sec: 9856.49
Iteration:   3120, Loss function: 3.939, Average Loss: 4.215, avg. samples / sec: 9817.97
Iteration:   3140, Loss function: 4.197, Average Loss: 4.212, avg. samples / sec: 9727.17
Iteration:   3160, Loss function: 3.958, Average Loss: 4.208, avg. samples / sec: 9825.04
Iteration:   3180, Loss function: 4.254, Average Loss: 4.204, avg. samples / sec: 9833.70
Iteration:   3200, Loss function: 3.835, Average Loss: 4.199, avg. samples / sec: 9761.71
:::MLLOG {"namespace": "", "time_ms": 1592670244468, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 25}}
:::MLLOG {"namespace": "", "time_ms": 1592670244469, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 26, "current_iter_num": 3215}}
Iteration:   3220, Loss function: 3.971, Average Loss: 4.195, avg. samples / sec: 9832.27
Iteration:   3240, Loss function: 4.148, Average Loss: 4.193, avg. samples / sec: 9824.18
Iteration:   3260, Loss function: 3.661, Average Loss: 4.189, avg. samples / sec: 9832.74
Iteration:   3280, Loss function: 4.043, Average Loss: 4.186, avg. samples / sec: 9846.45
Iteration:   3300, Loss function: 4.246, Average Loss: 4.182, avg. samples / sec: 9867.74
Iteration:   3320, Loss function: 4.133, Average Loss: 4.177, avg. samples / sec: 9857.10
Iteration:   3340, Loss function: 3.966, Average Loss: 4.175, avg. samples / sec: 9852.41
:::MLLOG {"namespace": "", "time_ms": 1592670256416, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 26}}
:::MLLOG {"namespace": "", "time_ms": 1592670256417, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 27, "current_iter_num": 3344}}
Iteration:   3360, Loss function: 3.866, Average Loss: 4.171, avg. samples / sec: 9847.44
Iteration:   3380, Loss function: 3.945, Average Loss: 4.166, avg. samples / sec: 9852.12
Iteration:   3400, Loss function: 3.836, Average Loss: 4.159, avg. samples / sec: 9854.75
Iteration:   3420, Loss function: 3.966, Average Loss: 4.155, avg. samples / sec: 9870.50
Iteration:   3440, Loss function: 3.818, Average Loss: 4.151, avg. samples / sec: 9873.02
Iteration:   3460, Loss function: 4.069, Average Loss: 4.147, avg. samples / sec: 9859.90
:::MLLOG {"namespace": "", "time_ms": 1592670268257, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1592670268257, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 28, "current_iter_num": 3472}}
Iteration:   3480, Loss function: 4.152, Average Loss: 4.143, avg. samples / sec: 9853.68
Iteration:   3500, Loss function: 4.026, Average Loss: 4.139, avg. samples / sec: 9870.12
Iteration:   3520, Loss function: 4.003, Average Loss: 4.133, avg. samples / sec: 9859.15
Iteration:   3540, Loss function: 4.104, Average Loss: 4.130, avg. samples / sec: 9865.32
Iteration:   3560, Loss function: 4.344, Average Loss: 4.126, avg. samples / sec: 9866.12
Iteration:   3580, Loss function: 3.891, Average Loss: 4.123, avg. samples / sec: 9838.56
Iteration:   3600, Loss function: 3.404, Average Loss: 4.119, avg. samples / sec: 9846.49
:::MLLOG {"namespace": "", "time_ms": 1592670280235, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1592670280236, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 29, "current_iter_num": 3601}}
Iteration:   3620, Loss function: 4.107, Average Loss: 4.115, avg. samples / sec: 9861.18
Iteration:   3640, Loss function: 3.862, Average Loss: 4.111, avg. samples / sec: 9862.39
Iteration:   3660, Loss function: 3.976, Average Loss: 4.107, avg. samples / sec: 9862.24
Iteration:   3680, Loss function: 3.479, Average Loss: 4.104, avg. samples / sec: 9831.07
Iteration:   3700, Loss function: 3.937, Average Loss: 4.101, avg. samples / sec: 9859.26
Iteration:   3720, Loss function: 3.840, Average Loss: 4.098, avg. samples / sec: 9829.08
:::MLLOG {"namespace": "", "time_ms": 1592670292047, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 29}}
:::MLLOG {"namespace": "", "time_ms": 1592670292048, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 30, "current_iter_num": 3729}}
Iteration:   3740, Loss function: 3.787, Average Loss: 4.094, avg. samples / sec: 9851.69
Iteration:   3760, Loss function: 3.906, Average Loss: 4.090, avg. samples / sec: 9863.64
Iteration:   3780, Loss function: 3.946, Average Loss: 4.086, avg. samples / sec: 9865.15
Iteration:   3800, Loss function: 3.701, Average Loss: 4.082, avg. samples / sec: 9856.79
Iteration:   3820, Loss function: 4.115, Average Loss: 4.077, avg. samples / sec: 9855.83
Iteration:   3840, Loss function: 3.752, Average Loss: 4.073, avg. samples / sec: 9865.09
:::MLLOG {"namespace": "", "time_ms": 1592670303979, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 30}}
:::MLLOG {"namespace": "", "time_ms": 1592670303980, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 31, "current_iter_num": 3858}}
Iteration:   3860, Loss function: 4.201, Average Loss: 4.069, avg. samples / sec: 9860.87
Iteration:   3880, Loss function: 3.996, Average Loss: 4.065, avg. samples / sec: 9862.58
Iteration:   3900, Loss function: 4.120, Average Loss: 4.061, avg. samples / sec: 9850.81
Iteration:   3920, Loss function: 3.768, Average Loss: 4.059, avg. samples / sec: 9864.59
Iteration:   3940, Loss function: 3.997, Average Loss: 4.055, avg. samples / sec: 9861.45
Iteration:   3960, Loss function: 3.921, Average Loss: 4.052, avg. samples / sec: 9857.06
Iteration:   3980, Loss function: 4.016, Average Loss: 4.050, avg. samples / sec: 9861.55
:::MLLOG {"namespace": "", "time_ms": 1592670315820, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1592670315821, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 32, "current_iter_num": 3986}}
Iteration:   4000, Loss function: 3.857, Average Loss: 4.046, avg. samples / sec: 9845.04
Iteration:   4020, Loss function: 3.790, Average Loss: 4.041, avg. samples / sec: 9847.74
Iteration:   4040, Loss function: 4.004, Average Loss: 4.038, avg. samples / sec: 9873.84
Iteration:   4060, Loss function: 4.057, Average Loss: 4.036, avg. samples / sec: 9869.65
Iteration:   4080, Loss function: 3.841, Average Loss: 4.033, avg. samples / sec: 9857.97
Iteration:   4100, Loss function: 3.464, Average Loss: 4.029, avg. samples / sec: 9873.93
:::MLLOG {"namespace": "", "time_ms": 1592670327750, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1592670327751, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 33, "current_iter_num": 4115}}
Iteration:   4120, Loss function: 3.923, Average Loss: 4.025, avg. samples / sec: 9858.08
Iteration:   4140, Loss function: 3.725, Average Loss: 4.022, avg. samples / sec: 9863.55
Iteration:   4160, Loss function: 3.664, Average Loss: 4.020, avg. samples / sec: 9867.32
Iteration:   4180, Loss function: 3.841, Average Loss: 4.017, avg. samples / sec: 9860.29
Iteration:   4200, Loss function: 3.444, Average Loss: 4.014, avg. samples / sec: 9859.98
Iteration:   4220, Loss function: 4.171, Average Loss: 4.010, avg. samples / sec: 9857.93
Iteration:   4240, Loss function: 4.061, Average Loss: 4.008, avg. samples / sec: 9829.42
:::MLLOG {"namespace": "", "time_ms": 1592670339689, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 33}}
:::MLLOG {"namespace": "", "time_ms": 1592670339690, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 34, "current_iter_num": 4244}}
Iteration:   4260, Loss function: 3.950, Average Loss: 4.004, avg. samples / sec: 9834.34
Iteration:   4280, Loss function: 3.629, Average Loss: 4.000, avg. samples / sec: 9862.33
Iteration:   4300, Loss function: 4.178, Average Loss: 3.996, avg. samples / sec: 9868.99
Iteration:   4320, Loss function: 3.996, Average Loss: 3.993, avg. samples / sec: 9875.90
Iteration:   4340, Loss function: 3.954, Average Loss: 3.992, avg. samples / sec: 9851.80
Iteration:   4360, Loss function: 3.723, Average Loss: 3.989, avg. samples / sec: 9864.91
:::MLLOG {"namespace": "", "time_ms": 1592670351520, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 34}}
:::MLLOG {"namespace": "", "time_ms": 1592670351521, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 35, "current_iter_num": 4372}}
Iteration:   4380, Loss function: 3.636, Average Loss: 3.985, avg. samples / sec: 9861.69
Iteration:   4400, Loss function: 3.708, Average Loss: 3.982, avg. samples / sec: 9857.83
Iteration:   4420, Loss function: 3.957, Average Loss: 3.979, avg. samples / sec: 9863.17
Iteration:   4440, Loss function: 3.719, Average Loss: 3.977, avg. samples / sec: 9851.79
Iteration:   4460, Loss function: 3.759, Average Loss: 3.973, avg. samples / sec: 9867.57
Iteration:   4480, Loss function: 3.903, Average Loss: 3.971, avg. samples / sec: 9864.00
Iteration:   4500, Loss function: 3.952, Average Loss: 3.968, avg. samples / sec: 9854.25
:::MLLOG {"namespace": "", "time_ms": 1592670363497, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1592670363498, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 36, "current_iter_num": 4501}}
Iteration:   4520, Loss function: 3.549, Average Loss: 3.965, avg. samples / sec: 9860.15
Iteration:   4540, Loss function: 3.756, Average Loss: 3.962, avg. samples / sec: 9842.95
Iteration:   4560, Loss function: 4.126, Average Loss: 3.959, avg. samples / sec: 9852.45
Iteration:   4580, Loss function: 3.844, Average Loss: 3.955, avg. samples / sec: 9851.13
Iteration:   4600, Loss function: 4.035, Average Loss: 3.954, avg. samples / sec: 9851.23
Iteration:   4620, Loss function: 3.940, Average Loss: 3.951, avg. samples / sec: 9867.30
:::MLLOG {"namespace": "", "time_ms": 1592670375302, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 36}}
:::MLLOG {"namespace": "", "time_ms": 1592670375303, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 37, "current_iter_num": 4629}}
Iteration:   4640, Loss function: 3.855, Average Loss: 3.948, avg. samples / sec: 9862.28
Iteration:   4660, Loss function: 3.926, Average Loss: 3.944, avg. samples / sec: 9853.43
Iteration:   4680, Loss function: 3.807, Average Loss: 3.941, avg. samples / sec: 9863.71
Iteration:   4700, Loss function: 4.257, Average Loss: 3.939, avg. samples / sec: 9849.38
Iteration:   4720, Loss function: 3.563, Average Loss: 3.936, avg. samples / sec: 9849.20
Iteration:   4740, Loss function: 3.757, Average Loss: 3.935, avg. samples / sec: 9799.21
:::MLLOG {"namespace": "", "time_ms": 1592670387248, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 37}}
:::MLLOG {"namespace": "", "time_ms": 1592670387249, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 38, "current_iter_num": 4758}}
Iteration:   4760, Loss function: 3.895, Average Loss: 3.932, avg. samples / sec: 9862.20
Iteration:   4780, Loss function: 3.653, Average Loss: 3.927, avg. samples / sec: 9846.39
Iteration:   4800, Loss function: 3.851, Average Loss: 3.923, avg. samples / sec: 9858.64
Iteration:   4820, Loss function: 3.696, Average Loss: 3.920, avg. samples / sec: 9839.12
Iteration:   4840, Loss function: 3.606, Average Loss: 3.917, avg. samples / sec: 9853.88
Iteration:   4860, Loss function: 3.914, Average Loss: 3.913, avg. samples / sec: 9857.49
Iteration:   4880, Loss function: 3.793, Average Loss: 3.911, avg. samples / sec: 9855.82
:::MLLOG {"namespace": "", "time_ms": 1592670399098, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 38}}
:::MLLOG {"namespace": "", "time_ms": 1592670399099, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 39, "current_iter_num": 4886}}
Iteration:   4900, Loss function: 3.947, Average Loss: 3.908, avg. samples / sec: 9849.79
Iteration:   4920, Loss function: 3.908, Average Loss: 3.905, avg. samples / sec: 9847.48
Iteration:   4940, Loss function: 3.743, Average Loss: 3.903, avg. samples / sec: 9847.66
Iteration:   4960, Loss function: 3.616, Average Loss: 3.900, avg. samples / sec: 9855.04
Iteration:   4980, Loss function: 3.852, Average Loss: 3.898, avg. samples / sec: 9856.27
Iteration:   5000, Loss function: 3.514, Average Loss: 3.895, avg. samples / sec: 9842.47
:::MLLOG {"namespace": "", "time_ms": 1592670411043, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 39}}
:::MLLOG {"namespace": "", "time_ms": 1592670411044, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 40, "current_iter_num": 5015}}
Iteration:   5020, Loss function: 4.128, Average Loss: 3.893, avg. samples / sec: 9837.54
Iteration:   5040, Loss function: 3.857, Average Loss: 3.890, avg. samples / sec: 9846.46
Iteration:   5060, Loss function: 3.594, Average Loss: 3.887, avg. samples / sec: 9810.30
Iteration:   5080, Loss function: 3.678, Average Loss: 3.885, avg. samples / sec: 9851.55
Iteration:   5100, Loss function: 3.627, Average Loss: 3.883, avg. samples / sec: 9821.71
Iteration:   5120, Loss function: 3.901, Average Loss: 3.881, avg. samples / sec: 9838.69
Iteration:   5140, Loss function: 3.758, Average Loss: 3.879, avg. samples / sec: 9831.81
:::MLLOG {"namespace": "", "time_ms": 1592670423008, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 40}}
averaging bn running means and vars
Predicting Ended, total time: 4.40 s
:::MLLOG {"namespace": "", "time_ms": 1592670427444, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 331, "first_epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1592670427486, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 338, "first_epoch_num": 41, "epoch_count": 10}}
:::MLLOG {"namespace": "", "time_ms": 1592670427486, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 41, "current_iter_num": 5144}}
Loading and preparing results...
DONE (t=0.57s)
Running per image evaluation...
Evaluate annotation type *bbox*
Iteration:   5160, Loss function: 3.727, Average Loss: 3.875, avg. samples / sec: 2816.58
DONE (t=1.73s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.18051
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.33057
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.17998
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.26547
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.18931
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.27625
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.29063
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.29063
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
Current AP: 0.18051 AP goal: 0.23000
Iteration:   5180, Loss function: 3.685, Average Loss: 3.873, avg. samples / sec: 9815.87
:::MLLOG {"namespace": "", "time_ms": 1592670431065, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 85, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1592670431066, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.1805089927104569, "metadata": {"file": "train.py", "lineno": 88, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1592670431066, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 89, "epoch_num": 40}}
Iteration:   5200, Loss function: 3.965, Average Loss: 3.871, avg. samples / sec: 9810.86
Iteration:   5220, Loss function: 3.804, Average Loss: 3.866, avg. samples / sec: 9815.29
Iteration:   5240, Loss function: 3.780, Average Loss: 3.863, avg. samples / sec: 9811.03
Iteration:   5260, Loss function: 3.569, Average Loss: 3.862, avg. samples / sec: 9798.87
:::MLLOG {"namespace": "", "time_ms": 1592670439526, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1592670439527, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 42, "current_iter_num": 5272}}
Iteration:   5280, Loss function: 3.930, Average Loss: 3.858, avg. samples / sec: 9801.50
Iteration:   5300, Loss function: 3.569, Average Loss: 3.856, avg. samples / sec: 9811.62
Iteration:   5320, Loss function: 3.899, Average Loss: 3.853, avg. samples / sec: 9776.78
Iteration:   5340, Loss function: 3.837, Average Loss: 3.850, avg. samples / sec: 9781.39
Iteration:   5360, Loss function: 3.860, Average Loss: 3.848, avg. samples / sec: 9804.15
Iteration:   5380, Loss function: 3.740, Average Loss: 3.846, avg. samples / sec: 9818.46
Iteration:   5400, Loss function: 3.536, Average Loss: 3.843, avg. samples / sec: 9837.40
:::MLLOG {"namespace": "", "time_ms": 1592670451568, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 42}}
:::MLLOG {"namespace": "", "time_ms": 1592670451569, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 43, "current_iter_num": 5401}}
Iteration:   5420, Loss function: 3.876, Average Loss: 3.840, avg. samples / sec: 9841.39
Iteration:   5440, Loss function: 3.728, Average Loss: 3.837, avg. samples / sec: 9842.16
Iteration:   5460, Loss function: 3.831, Average Loss: 3.835, avg. samples / sec: 9835.86
Iteration:   5480, Loss function: 3.610, Average Loss: 3.834, avg. samples / sec: 9824.52
Iteration:   5500, Loss function: 3.965, Average Loss: 3.832, avg. samples / sec: 9819.94
Iteration:   5520, Loss function: 3.838, Average Loss: 3.830, avg. samples / sec: 9838.03
:::MLLOG {"namespace": "", "time_ms": 1592670463398, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 43}}
:::MLLOG {"namespace": "", "time_ms": 1592670463399, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 44, "current_iter_num": 5529}}
Iteration:   5540, Loss function: 3.846, Average Loss: 3.827, avg. samples / sec: 9825.79
Iteration:   5560, Loss function: 3.581, Average Loss: 3.824, avg. samples / sec: 9818.83
Iteration:   5580, Loss function: 3.697, Average Loss: 3.822, avg. samples / sec: 9831.28
Iteration:   5600, Loss function: 3.867, Average Loss: 3.818, avg. samples / sec: 9838.84
Iteration:   5620, Loss function: 3.882, Average Loss: 3.817, avg. samples / sec: 9826.37
Iteration:   5640, Loss function: 3.821, Average Loss: 3.816, avg. samples / sec: 9838.57
:::MLLOG {"namespace": "", "time_ms": 1592670475363, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 44}}
lr decay step #1
:::MLLOG {"namespace": "", "time_ms": 1592670475364, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 45, "current_iter_num": 5658}}
Iteration:   5660, Loss function: 3.482, Average Loss: 3.815, avg. samples / sec: 9855.27
Iteration:   5680, Loss function: 3.568, Average Loss: 3.810, avg. samples / sec: 9848.08
Iteration:   5700, Loss function: 3.580, Average Loss: 3.802, avg. samples / sec: 9825.82
Iteration:   5720, Loss function: 3.587, Average Loss: 3.795, avg. samples / sec: 9836.42
Iteration:   5740, Loss function: 3.384, Average Loss: 3.788, avg. samples / sec: 9841.12
Iteration:   5760, Loss function: 3.188, Average Loss: 3.780, avg. samples / sec: 9859.36
Iteration:   5780, Loss function: 3.437, Average Loss: 3.773, avg. samples / sec: 9844.34
:::MLLOG {"namespace": "", "time_ms": 1592670487316, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 45}}
:::MLLOG {"namespace": "", "time_ms": 1592670487317, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 46, "current_iter_num": 5787}}
Iteration:   5800, Loss function: 3.359, Average Loss: 3.766, avg. samples / sec: 9839.76
Iteration:   5820, Loss function: 3.003, Average Loss: 3.757, avg. samples / sec: 9852.60
Iteration:   5840, Loss function: 2.969, Average Loss: 3.748, avg. samples / sec: 9846.59
Iteration:   5860, Loss function: 3.245, Average Loss: 3.741, avg. samples / sec: 9814.79
Iteration:   5880, Loss function: 3.127, Average Loss: 3.732, avg. samples / sec: 9820.49
Iteration:   5900, Loss function: 3.158, Average Loss: 3.724, avg. samples / sec: 9814.92
:::MLLOG {"namespace": "", "time_ms": 1592670499191, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 46}}
:::MLLOG {"namespace": "", "time_ms": 1592670499192, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 47, "current_iter_num": 5915}}
Iteration:   5920, Loss function: 3.164, Average Loss: 3.718, avg. samples / sec: 9824.07
Iteration:   5940, Loss function: 3.312, Average Loss: 3.709, avg. samples / sec: 9818.91
Iteration:   5960, Loss function: 3.505, Average Loss: 3.702, avg. samples / sec: 9804.97
Iteration:   5980, Loss function: 3.264, Average Loss: 3.695, avg. samples / sec: 9821.89
Iteration:   6000, Loss function: 3.317, Average Loss: 3.687, avg. samples / sec: 9804.44
Iteration:   6020, Loss function: 3.635, Average Loss: 3.680, avg. samples / sec: 9817.50
Iteration:   6040, Loss function: 3.314, Average Loss: 3.674, avg. samples / sec: 9845.13
:::MLLOG {"namespace": "", "time_ms": 1592670511173, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 47}}
:::MLLOG {"namespace": "", "time_ms": 1592670511174, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 48, "current_iter_num": 6044}}
Iteration:   6060, Loss function: 3.164, Average Loss: 3.668, avg. samples / sec: 9849.37
Iteration:   6080, Loss function: 3.537, Average Loss: 3.660, avg. samples / sec: 9844.43
Iteration:   6100, Loss function: 3.190, Average Loss: 3.653, avg. samples / sec: 9858.14
Iteration:   6120, Loss function: 3.690, Average Loss: 3.647, avg. samples / sec: 9858.27
Iteration:   6140, Loss function: 3.013, Average Loss: 3.639, avg. samples / sec: 9857.66
Iteration:   6160, Loss function: 3.307, Average Loss: 3.633, avg. samples / sec: 9838.08
:::MLLOG {"namespace": "", "time_ms": 1592670523022, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 48}}
:::MLLOG {"namespace": "", "time_ms": 1592670523023, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 49, "current_iter_num": 6172}}
Iteration:   6180, Loss function: 3.261, Average Loss: 3.626, avg. samples / sec: 9849.78
Iteration:   6200, Loss function: 3.196, Average Loss: 3.620, avg. samples / sec: 9848.00
Iteration:   6220, Loss function: 3.246, Average Loss: 3.612, avg. samples / sec: 9844.82
Iteration:   6240, Loss function: 3.335, Average Loss: 3.605, avg. samples / sec: 9849.85
Iteration:   6260, Loss function: 2.878, Average Loss: 3.597, avg. samples / sec: 9849.49
Iteration:   6280, Loss function: 3.166, Average Loss: 3.591, avg. samples / sec: 9851.81
Iteration:   6300, Loss function: 2.960, Average Loss: 3.583, avg. samples / sec: 9846.35
:::MLLOG {"namespace": "", "time_ms": 1592670535012, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 49}}
:::MLLOG {"namespace": "", "time_ms": 1592670535013, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 50, "current_iter_num": 6301}}
Iteration:   6320, Loss function: 3.178, Average Loss: 3.578, avg. samples / sec: 9839.27
Iteration:   6340, Loss function: 3.165, Average Loss: 3.572, avg. samples / sec: 9855.43
Iteration:   6360, Loss function: 3.372, Average Loss: 3.566, avg. samples / sec: 9832.49
Iteration:   6380, Loss function: 3.455, Average Loss: 3.561, avg. samples / sec: 9823.74
Iteration:   6400, Loss function: 3.187, Average Loss: 3.557, avg. samples / sec: 9823.08
Iteration:   6420, Loss function: 3.260, Average Loss: 3.551, avg. samples / sec: 9826.23
:::MLLOG {"namespace": "", "time_ms": 1592670546839, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 50}}
averaging bn running means and vars
Predicting Ended, total time: 3.82 s
:::MLLOG {"namespace": "", "time_ms": 1592670550671, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 331, "first_epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1592670550707, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 338, "first_epoch_num": 51, "epoch_count": 5}}
:::MLLOG {"namespace": "", "time_ms": 1592670550707, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 51, "current_iter_num": 6429}}
Loading and preparing results...
DONE (t=0.57s)
Running per image evaluation...
Evaluate annotation type *bbox*
Iteration:   6440, Loss function: 3.562, Average Loss: 3.545, avg. samples / sec: 3208.91
DONE (t=1.82s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.23263
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.39973
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23493
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.31753
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22419
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32854
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.34484
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.34484
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
Current AP: 0.23263 AP goal: 0.23000
Iteration:   6460, Loss function: 3.282, Average Loss: 3.540, avg. samples / sec: 9808.50
:::MLLOG {"namespace": "", "time_ms": 1592670553642, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 85, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1592670553642, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.23263176812769892, "metadata": {"file": "train.py", "lineno": 88, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1592670553642, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 89, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1592670553925, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "train.py", "lineno": 449, "status": "success"}}
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2020-06-20 09:29:18 AM
RESULT,SINGLE_STAGE_DETECTOR,,656,nvidia,2020-06-20 09:18:22 AM
ENDING TIMING RUN AT 2020-06-20 09:29:18 AM
RESULT,SINGLE_STAGE_DETECTOR,,656,nvidia,2020-06-20 09:18:22 AM
ENDING TIMING RUN AT 2020-06-20 09:29:19 AM
RESULT,SINGLE_STAGE_DETECTOR,,657,nvidia,2020-06-20 09:18:22 AM
ENDING TIMING RUN AT 2020-06-20 09:29:19 AM
ENDING TIMING RUN AT 2020-06-20 09:29:19 AM
ENDING TIMING RUN AT 2020-06-20 09:29:19 AM
RESULT,SINGLE_STAGE_DETECTOR,,657,nvidia,2020-06-20 09:18:22 AM
RESULT,SINGLE_STAGE_DETECTOR,,657,nvidia,2020-06-20 09:18:22 AM
RESULT,SINGLE_STAGE_DETECTOR,,657,nvidia,2020-06-20 09:18:22 AM
ENDING TIMING RUN AT 2020-06-20 09:29:19 AM
RESULT,SINGLE_STAGE_DETECTOR,,657,nvidia,2020-06-20 09:18:22 AM
ENDING TIMING RUN AT 2020-06-20 09:29:19 AM
RESULT,SINGLE_STAGE_DETECTOR,,657,nvidia,2020-06-20 09:18:22 AM
