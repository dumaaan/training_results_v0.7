+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ srun --nodes=1 --ntasks=1 --container-name=single_stage_detector python -c '
import mlperf_log_utils
from mlperf_logging.mllog import constants
mlperf_log_utils.mlperf_submission_log(constants.SSD)'
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
:::MLLOG {"namespace": "", "time_ms": 1592669900510, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "ssd", "metadata": {"file": "/workspace/single_stage_detector/mlperf_log_utils.py", "lineno": 17}}
:::MLLOG {"namespace": "", "time_ms": 1592669900548, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "NVIDIA", "metadata": {"file": "/workspace/single_stage_detector/mlperf_log_utils.py", "lineno": 22}}
:::MLLOG {"namespace": "", "time_ms": 1592669900548, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/single_stage_detector/mlperf_log_utils.py", "lineno": 26}}
:::MLLOG {"namespace": "", "time_ms": 1592669900548, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/single_stage_detector/mlperf_log_utils.py", "lineno": 30}}
:::MLLOG {"namespace": "", "time_ms": 1592669900548, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "1xNVIDIA DGX A100", "metadata": {"file": "/workspace/single_stage_detector/mlperf_log_utils.py", "lineno": 34}}
+ '[' 1 -eq 1 ']'
+ srun --ntasks=1 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
Clearing cache on luna-0144
vm.drop_caches = 3
+ srun --ntasks=1 --container-name=single_stage_detector python -c '
from mlperf_logging.mllog import constants
from mlperf_logger import log_event
log_event(key=constants.CACHE_CLEAR, value=True)'
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
:::MLLOG {"namespace": "", "time_ms": 1592669906345, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
+ srun --mpi=none --ntasks=8 --ntasks-per-node=8 --container-name=single_stage_detector --container-mounts=/raid/datasets/coco/coco-2017:/data,/lustre/fsw/mlperf-ci/13964268/results:/results ./run_and_time.sh
slurmstepd: pyxis: reusing existing container filesystem
slurmstepd: pyxis: starting container ...
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
slurmstepd: task_p_pre_launch: Using sched_affinity for tasks
STARTING TIMING RUN AT 2020-06-20 09:18:28 AM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
STARTING TIMING RUN AT 2020-06-20 09:18:28 AM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
++ pwd
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 8 -gt 1 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
++ pwd
STARTING TIMING RUN AT 2020-06-20 09:18:28 AM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
STARTING TIMING RUN AT 2020-06-20 09:18:28 AM
+ '[' -n 7 ']'
+ NUMEPOCHS=80
+ '[' 8 -gt 1 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
++ pwd
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 8 -gt 1 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
++ pwd
STARTING TIMING RUN AT 2020-06-20 09:18:28 AM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
STARTING TIMING RUN AT 2020-06-20 09:18:28 AM
+ declare -a CMD
+ NUMEPOCHS=80
+ echo 'running benchmark'
STARTING TIMING RUN AT 2020-06-20 09:18:28 AM
+ '[' -n 5 ']'
+ '[' 8 -gt 1 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
++ pwd
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 8 -gt 1 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
++ pwd
++ pwd
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ '[' -n 2 ']'
+ '[' 8 -gt 1 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ declare -a CMD
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
+ '[' -n 4 ']'
STARTING TIMING RUN AT 2020-06-20 09:18:28 AM
+ '[' 8 -gt 1 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ NUMEPOCHS=80
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
++ pwd
+ export TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ TORCH_HOME=/workspace/single_stage_detector/torch-model-cache
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 8 -gt 1 ']'
+ CMD=('./bind.sh' '--' 'python' '-u')
+ ./bind.sh -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=1 --membind=1 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
+ exec numactl --cpunodebind=2 --membind=2 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=0 --membind=0 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=4 --membind=4 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=5 --membind=5 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --cpunodebind=6 --membind=6 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
+ exec numactl --cpunodebind=7 --membind=7 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
+ exec numactl --cpunodebind=3 --membind=3 -- python -u train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --batch-size=114 --warmup=650 --lr=3.2e-3 --wd=1.3e-4
:::MLLOG {"namespace": "", "time_ms": 1592669911285, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592669911294, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592669911304, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592669911321, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592669911325, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592669911335, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592669911343, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592669911432, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 434}}
:::MLLOG {"namespace": "", "time_ms": 1592669914022, "event_type": "POINT_IN_TIME", "key": "seed", "value": 669064800, "metadata": {"file": "/workspace/single_stage_detector/mlperf_logger.py", "lineno": 92}}
0 Using seed = 669064800
2 Using seed = 669064802
1 Using seed = 669064801
3 Using seed = 669064803
4 Using seed = 669064804
6 Using seed = 669064806
7 Using seed = 669064807
5 Using seed = 669064805
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /workspace/single_stage_detector/torch-model-cache/checkpoints/resnet34-333f7ec4.pth

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 35%|      | 29.2M/83.3M [00:00<00:00, 306MB/s]
 74%|  | 61.7M/83.3M [00:00<00:00, 316MB/s]
100%|| 83.3M/83.3M [00:00<00:00, 328MB/s]

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 31%|      | 26.2M/83.3M [00:00<00:00, 274MB/s]
 63%|   | 52.2M/83.3M [00:00<00:00, 274MB/s]
100%|| 83.3M/83.3M [00:00<00:00, 287MB/s]

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
  6%|         | 5.27M/83.3M [00:00<00:01, 55.2MB/s]
 23%|       | 19.5M/83.3M [00:00<00:00, 68.1MB/s]
 61%|    | 50.5M/83.3M [00:00<00:00, 89.3MB/s]
 93%|| 77.1M/83.3M [00:00<00:00, 112MB/s]
100%|| 83.3M/83.3M [00:00<00:00, 205MB/s]

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 18%|        | 15.4M/83.3M [00:00<00:00, 161MB/s]
 41%|      | 34.3M/83.3M [00:00<00:00, 171MB/s]
 63%|   | 52.7M/83.3M [00:00<00:00, 177MB/s]
 87%| | 72.2M/83.3M [00:00<00:00, 184MB/s]
100%|| 83.3M/83.3M [00:00<00:00, 190MB/s]

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 23%|       | 18.8M/83.3M [00:00<00:00, 197MB/s]
 41%|     | 34.4M/83.3M [00:00<00:00, 183MB/s]
 66%|   | 55.0M/83.3M [00:00<00:00, 192MB/s]
 81%|  | 67.1M/83.3M [00:00<00:00, 165MB/s]
100%|| 83.3M/83.3M [00:00<00:00, 186MB/s]

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 18%|        | 15.2M/83.3M [00:00<00:00, 159MB/s]
 37%|      | 30.9M/83.3M [00:00<00:00, 161MB/s]
 56%|    | 46.7M/83.3M [00:00<00:00, 162MB/s]
 77%|  | 64.3M/83.3M [00:00<00:00, 168MB/s]
100%|| 83.3M/83.3M [00:00<00:00, 176MB/s]

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
  7%|         | 5.95M/83.3M [00:00<00:01, 62.3MB/s]
 22%|       | 18.6M/83.3M [00:00<00:00, 74.2MB/s]
 40%|      | 33.4M/83.3M [00:00<00:00, 87.9MB/s]
 63%|   | 52.6M/83.3M [00:00<00:00, 106MB/s]
100%|| 83.3M/83.3M [00:00<00:00, 175MB/s]
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))

  0%|          | 0.00/83.3M [00:00<?, ?B/s]
 25%|       | 20.9M/83.3M [00:00<00:00, 218MB/s]
 46%|     | 38.4M/83.3M [00:00<00:00, 205MB/s]
 71%|   | 59.2M/83.3M [00:00<00:00, 209MB/s]
 87%| | 72.1M/83.3M [00:00<00:00, 106MB/s]
100%|| 83.3M/83.3M [00:00<00:00, 144MB/s]
:::MLLOG {"namespace": "", "time_ms": 1592669920611, "event_type": "POINT_IN_TIME", "key": "model_bn_span", "value": 114, "metadata": {"file": "train.py", "lineno": 170}}
:::MLLOG {"namespace": "", "time_ms": 1592669920611, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 912, "metadata": {"file": "train.py", "lineno": 171}}
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : 128.0
Delaying allreduces to the end of backward()
:::MLLOG {"namespace": "", "time_ms": 1592669920621, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.09, "metadata": {"file": "train.py", "lineno": 199}}
:::MLLOG {"namespace": "", "time_ms": 1592669920621, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_boundary_epochs", "value": [44, 55], "metadata": {"file": "train.py", "lineno": 200}}
:::MLLOG {"namespace": "", "time_ms": 1592669920621, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_steps", "value": [44, 55], "metadata": {"file": "train.py", "lineno": 201}}
:::MLLOG {"namespace": "", "time_ms": 1592669920621, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.00013, "metadata": {"file": "train.py", "lineno": 202}}
:::MLLOG {"namespace": "", "time_ms": 1592669920621, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 650, "metadata": {"file": "train.py", "lineno": 204}}
:::MLLOG {"namespace": "", "time_ms": 1592669920621, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_factor", "value": 0, "metadata": {"file": "train.py", "lineno": 205}}
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
epoch nbatch loss
:::MLLOG {"namespace": "", "time_ms": 1592669943996, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "train.py", "lineno": 267}}
:::MLLOG {"namespace": "", "time_ms": 1592669944004, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "train.py", "lineno": 274}}
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
[/opt/dali/dali/operators/image/crop/bbox_crop.cc:348] WARNING: `ltrb` is deprecated. Please use `bbox_layout` to specify the format of the bounding box. E.g. For 2D bounding boxes, `ltrb=True`` is equivalent to `bbox_layout="xyXY"`, and `ltrb=False` is equivalent to `bbox_layout="xyWH"`
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
:::MLLOG {"namespace": "", "time_ms": 1592669946089, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 117266, "metadata": {"file": "/workspace/single_stage_detector/data/build_pipeline.py", "lineno": 48}}
epoch size is:  117266  images
:::MLLOG {"namespace": "", "time_ms": 1592669946090, "event_type": "POINT_IN_TIME", "key": "max_samples", "value": 1, "metadata": {"file": "/workspace/single_stage_detector/utils.py", "lineno": 156}}
loading annotations into memory...
Done (t=0.12s)
creating index...
Done (t=0.12s)
creating index...
Done (t=0.12s)
creating index...
Done (t=0.11s)
creating index...
Done (t=0.12s)
creating index...
Done (t=0.12s)
creating index...
Done (t=0.12s)
creating index...
Done (t=0.12s)
creating index...
:::MLLOG {"namespace": "", "time_ms": 1592669946326, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 4952, "metadata": {"file": "/workspace/single_stage_detector/data/native_pipeline.py", "lineno": 97}}
:::MLLOG {"namespace": "", "time_ms": 1592669946327, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 293, "first_epoch_num": 1, "epoch_count": 40}}
:::MLLOG {"namespace": "", "time_ms": 1592669946328, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 1, "current_iter_num": 0}}
Iteration:      0, Loss function: 22.957, Average Loss: 0.023, avg. samples / sec: 35.60
Iteration:     20, Loss function: 20.781, Average Loss: 0.445, avg. samples / sec: 8174.46
Iteration:     40, Loss function: 19.503, Average Loss: 0.838, avg. samples / sec: 8927.20
Iteration:     60, Loss function: 13.395, Average Loss: 1.116, avg. samples / sec: 9159.67
Iteration:     80, Loss function: 10.571, Average Loss: 1.315, avg. samples / sec: 9263.31
Iteration:    100, Loss function: 9.606, Average Loss: 1.483, avg. samples / sec: 9317.77
Iteration:    120, Loss function: 9.243, Average Loss: 1.637, avg. samples / sec: 9378.21
:::MLLOG {"namespace": "", "time_ms": 1592669959526, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1592669959527, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 2, "current_iter_num": 129}}
Iteration:    140, Loss function: 8.896, Average Loss: 1.780, avg. samples / sec: 9370.53
Iteration:    160, Loss function: 8.501, Average Loss: 1.917, avg. samples / sec: 9348.58
Iteration:    180, Loss function: 8.016, Average Loss: 2.044, avg. samples / sec: 9399.78
Iteration:    200, Loss function: 8.275, Average Loss: 2.164, avg. samples / sec: 9405.20
Iteration:    220, Loss function: 8.371, Average Loss: 2.292, avg. samples / sec: 9463.24
Iteration:    240, Loss function: 7.781, Average Loss: 2.405, avg. samples / sec: 9508.10
:::MLLOG {"namespace": "", "time_ms": 1592669971980, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1592669971981, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 3, "current_iter_num": 258}}
Iteration:    260, Loss function: 7.292, Average Loss: 2.507, avg. samples / sec: 9538.24
Iteration:    280, Loss function: 6.970, Average Loss: 2.604, avg. samples / sec: 9542.36
Iteration:    300, Loss function: 7.681, Average Loss: 2.701, avg. samples / sec: 9526.36
Iteration:    320, Loss function: 6.927, Average Loss: 2.793, avg. samples / sec: 9570.38
Iteration:    340, Loss function: 6.687, Average Loss: 2.877, avg. samples / sec: 9580.04
Iteration:    360, Loss function: 6.921, Average Loss: 2.956, avg. samples / sec: 9593.51
Iteration:    380, Loss function: 7.182, Average Loss: 3.042, avg. samples / sec: 9663.35
:::MLLOG {"namespace": "", "time_ms": 1592669984168, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1592669984169, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 4, "current_iter_num": 386}}
Iteration:    400, Loss function: 6.620, Average Loss: 3.119, avg. samples / sec: 9654.88
Iteration:    420, Loss function: 6.864, Average Loss: 3.189, avg. samples / sec: 9650.16
Iteration:    440, Loss function: 6.801, Average Loss: 3.258, avg. samples / sec: 9636.53
Iteration:    460, Loss function: 6.918, Average Loss: 3.325, avg. samples / sec: 9650.99
Iteration:    480, Loss function: 6.462, Average Loss: 3.389, avg. samples / sec: 9607.98
Iteration:    500, Loss function: 6.146, Average Loss: 3.447, avg. samples / sec: 9659.42
:::MLLOG {"namespace": "", "time_ms": 1592669996364, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1592669996364, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 5, "current_iter_num": 515}}
Iteration:    520, Loss function: 6.281, Average Loss: 3.505, avg. samples / sec: 9695.19
Iteration:    540, Loss function: 5.991, Average Loss: 3.557, avg. samples / sec: 9668.51
Iteration:    560, Loss function: 6.431, Average Loss: 3.605, avg. samples / sec: 9748.22
Iteration:    580, Loss function: 5.935, Average Loss: 3.655, avg. samples / sec: 9663.50
Iteration:    600, Loss function: 6.253, Average Loss: 3.706, avg. samples / sec: 9701.98
Iteration:    620, Loss function: 6.125, Average Loss: 3.752, avg. samples / sec: 9725.62
Iteration:    640, Loss function: 5.901, Average Loss: 3.793, avg. samples / sec: 9737.40
:::MLLOG {"namespace": "", "time_ms": 1592670008389, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1592670008390, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 6, "current_iter_num": 643}}
Iteration:    660, Loss function: 5.710, Average Loss: 3.831, avg. samples / sec: 9708.79
Iteration:    680, Loss function: 5.783, Average Loss: 3.867, avg. samples / sec: 9696.20
Iteration:    700, Loss function: 5.477, Average Loss: 3.900, avg. samples / sec: 9747.85
Iteration:    720, Loss function: 5.302, Average Loss: 3.933, avg. samples / sec: 9748.61
Iteration:    740, Loss function: 5.597, Average Loss: 3.964, avg. samples / sec: 9764.86
Iteration:    760, Loss function: 5.490, Average Loss: 3.993, avg. samples / sec: 9784.93
:::MLLOG {"namespace": "", "time_ms": 1592670020460, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 6}}
:::MLLOG {"namespace": "", "time_ms": 1592670020461, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 7, "current_iter_num": 772}}
Iteration:    780, Loss function: 5.437, Average Loss: 4.021, avg. samples / sec: 9811.19
Iteration:    800, Loss function: 5.606, Average Loss: 4.049, avg. samples / sec: 9742.33
Iteration:    820, Loss function: 5.471, Average Loss: 4.075, avg. samples / sec: 9807.13
Iteration:    840, Loss function: 5.369, Average Loss: 4.098, avg. samples / sec: 9779.73
Iteration:    860, Loss function: 5.418, Average Loss: 4.121, avg. samples / sec: 9739.20
Iteration:    880, Loss function: 5.480, Average Loss: 4.142, avg. samples / sec: 9790.24
Iteration:    900, Loss function: 4.915, Average Loss: 4.162, avg. samples / sec: 9801.85
:::MLLOG {"namespace": "", "time_ms": 1592670032533, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1592670032534, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 8, "current_iter_num": 901}}
Iteration:    920, Loss function: 5.056, Average Loss: 4.181, avg. samples / sec: 9798.02
Iteration:    940, Loss function: 4.844, Average Loss: 4.197, avg. samples / sec: 9766.09
Iteration:    960, Loss function: 4.873, Average Loss: 4.215, avg. samples / sec: 9821.94
Iteration:    980, Loss function: 5.103, Average Loss: 4.231, avg. samples / sec: 9778.55
Iteration:   1000, Loss function: 5.002, Average Loss: 4.244, avg. samples / sec: 9828.46
Iteration:   1020, Loss function: 5.032, Average Loss: 4.259, avg. samples / sec: 9843.11
:::MLLOG {"namespace": "", "time_ms": 1592670044395, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 8}}
:::MLLOG {"namespace": "", "time_ms": 1592670044396, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 9, "current_iter_num": 1029}}
Iteration:   1040, Loss function: 4.893, Average Loss: 4.273, avg. samples / sec: 9830.69
Iteration:   1060, Loss function: 4.757, Average Loss: 4.284, avg. samples / sec: 9828.72
Iteration:   1080, Loss function: 4.882, Average Loss: 4.296, avg. samples / sec: 9817.76
Iteration:   1100, Loss function: 4.765, Average Loss: 4.308, avg. samples / sec: 9839.67
Iteration:   1120, Loss function: 4.936, Average Loss: 4.319, avg. samples / sec: 9830.89
Iteration:   1140, Loss function: 4.989, Average Loss: 4.332, avg. samples / sec: 9836.71
:::MLLOG {"namespace": "", "time_ms": 1592670056364, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 9}}
:::MLLOG {"namespace": "", "time_ms": 1592670056365, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 10, "current_iter_num": 1158}}
Iteration:   1160, Loss function: 4.622, Average Loss: 4.340, avg. samples / sec: 9797.83
Iteration:   1180, Loss function: 4.544, Average Loss: 4.349, avg. samples / sec: 9818.25
Iteration:   1200, Loss function: 4.814, Average Loss: 4.357, avg. samples / sec: 9832.21
Iteration:   1220, Loss function: 4.711, Average Loss: 4.365, avg. samples / sec: 9794.88
Iteration:   1240, Loss function: 4.699, Average Loss: 4.372, avg. samples / sec: 9807.14
Iteration:   1260, Loss function: 4.891, Average Loss: 4.380, avg. samples / sec: 9822.79
Iteration:   1280, Loss function: 4.674, Average Loss: 4.387, avg. samples / sec: 9831.28
:::MLLOG {"namespace": "", "time_ms": 1592670068260, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 10}}
:::MLLOG {"namespace": "", "time_ms": 1592670068261, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 11, "current_iter_num": 1286}}
Iteration:   1300, Loss function: 4.884, Average Loss: 4.392, avg. samples / sec: 9788.06
Iteration:   1320, Loss function: 4.810, Average Loss: 4.399, avg. samples / sec: 9864.53
Iteration:   1340, Loss function: 4.977, Average Loss: 4.403, avg. samples / sec: 9819.51
Iteration:   1360, Loss function: 4.602, Average Loss: 4.407, avg. samples / sec: 9895.53
Iteration:   1380, Loss function: 4.717, Average Loss: 4.411, avg. samples / sec: 9852.04
Iteration:   1400, Loss function: 4.900, Average Loss: 4.415, avg. samples / sec: 9874.25
:::MLLOG {"namespace": "", "time_ms": 1592670080200, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1592670080201, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 12, "current_iter_num": 1415}}
Iteration:   1420, Loss function: 4.615, Average Loss: 4.417, avg. samples / sec: 9871.63
Iteration:   1440, Loss function: 4.659, Average Loss: 4.421, avg. samples / sec: 9851.69
Iteration:   1460, Loss function: 4.607, Average Loss: 4.425, avg. samples / sec: 9847.75
Iteration:   1480, Loss function: 4.270, Average Loss: 4.428, avg. samples / sec: 9862.73
Iteration:   1500, Loss function: 4.669, Average Loss: 4.431, avg. samples / sec: 9870.58
Iteration:   1520, Loss function: 4.402, Average Loss: 4.436, avg. samples / sec: 9870.48
Iteration:   1540, Loss function: 4.236, Average Loss: 4.439, avg. samples / sec: 9888.39
:::MLLOG {"namespace": "", "time_ms": 1592670092034, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1592670092035, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 13, "current_iter_num": 1543}}
Iteration:   1560, Loss function: 4.548, Average Loss: 4.439, avg. samples / sec: 9849.59
Iteration:   1580, Loss function: 4.369, Average Loss: 4.440, avg. samples / sec: 9890.21
Iteration:   1600, Loss function: 4.407, Average Loss: 4.440, avg. samples / sec: 9853.43
Iteration:   1620, Loss function: 4.404, Average Loss: 4.442, avg. samples / sec: 9884.11
Iteration:   1640, Loss function: 4.392, Average Loss: 4.443, avg. samples / sec: 9880.66
Iteration:   1660, Loss function: 4.246, Average Loss: 4.444, avg. samples / sec: 9889.56
:::MLLOG {"namespace": "", "time_ms": 1592670103949, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 13}}
:::MLLOG {"namespace": "", "time_ms": 1592670103949, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 14, "current_iter_num": 1672}}
Iteration:   1680, Loss function: 4.345, Average Loss: 4.444, avg. samples / sec: 9838.46
Iteration:   1700, Loss function: 4.286, Average Loss: 4.443, avg. samples / sec: 9819.50
Iteration:   1720, Loss function: 4.291, Average Loss: 4.443, avg. samples / sec: 9840.53
Iteration:   1740, Loss function: 4.491, Average Loss: 4.443, avg. samples / sec: 9846.98
Iteration:   1760, Loss function: 4.732, Average Loss: 4.443, avg. samples / sec: 9841.48
Iteration:   1780, Loss function: 4.352, Average Loss: 4.442, avg. samples / sec: 9849.43
Iteration:   1800, Loss function: 4.055, Average Loss: 4.441, avg. samples / sec: 9825.11
:::MLLOG {"namespace": "", "time_ms": 1592670115953, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 14}}
:::MLLOG {"namespace": "", "time_ms": 1592670115953, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 15, "current_iter_num": 1801}}
Iteration:   1820, Loss function: 4.098, Average Loss: 4.439, avg. samples / sec: 9829.26
Iteration:   1840, Loss function: 4.328, Average Loss: 4.436, avg. samples / sec: 9844.72
Iteration:   1860, Loss function: 4.477, Average Loss: 4.435, avg. samples / sec: 9854.28
Iteration:   1880, Loss function: 4.544, Average Loss: 4.434, avg. samples / sec: 9850.63
Iteration:   1900, Loss function: 4.385, Average Loss: 4.432, avg. samples / sec: 9834.21
Iteration:   1920, Loss function: 4.656, Average Loss: 4.431, avg. samples / sec: 9857.00
:::MLLOG {"namespace": "", "time_ms": 1592670127769, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1592670127770, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 16, "current_iter_num": 1929}}
Iteration:   1940, Loss function: 4.412, Average Loss: 4.428, avg. samples / sec: 9839.61
Iteration:   1960, Loss function: 4.489, Average Loss: 4.426, avg. samples / sec: 9850.91
Iteration:   1980, Loss function: 4.215, Average Loss: 4.423, avg. samples / sec: 9827.70
Iteration:   2000, Loss function: 4.251, Average Loss: 4.421, avg. samples / sec: 9856.80
Iteration:   2020, Loss function: 4.416, Average Loss: 4.419, avg. samples / sec: 9833.70
Iteration:   2040, Loss function: 4.437, Average Loss: 4.417, avg. samples / sec: 9840.05
:::MLLOG {"namespace": "", "time_ms": 1592670139723, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1592670139724, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 17, "current_iter_num": 2058}}
Iteration:   2060, Loss function: 4.485, Average Loss: 4.416, avg. samples / sec: 9840.36
Iteration:   2080, Loss function: 4.135, Average Loss: 4.413, avg. samples / sec: 9853.12
Iteration:   2100, Loss function: 4.428, Average Loss: 4.412, avg. samples / sec: 9844.94
Iteration:   2120, Loss function: 4.214, Average Loss: 4.410, avg. samples / sec: 9853.66
Iteration:   2140, Loss function: 4.167, Average Loss: 4.407, avg. samples / sec: 9856.31
Iteration:   2160, Loss function: 4.244, Average Loss: 4.402, avg. samples / sec: 9862.33
Iteration:   2180, Loss function: 4.213, Average Loss: 4.399, avg. samples / sec: 9876.47
:::MLLOG {"namespace": "", "time_ms": 1592670151565, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 17}}
:::MLLOG {"namespace": "", "time_ms": 1592670151566, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 18, "current_iter_num": 2186}}
Iteration:   2200, Loss function: 4.323, Average Loss: 4.396, avg. samples / sec: 9851.29
Iteration:   2220, Loss function: 4.189, Average Loss: 4.393, avg. samples / sec: 9886.69
Iteration:   2240, Loss function: 4.277, Average Loss: 4.390, avg. samples / sec: 9855.60
Iteration:   2260, Loss function: 4.351, Average Loss: 4.387, avg. samples / sec: 9885.02
Iteration:   2280, Loss function: 4.242, Average Loss: 4.384, avg. samples / sec: 9877.53
Iteration:   2300, Loss function: 4.112, Average Loss: 4.380, avg. samples / sec: 9884.54
:::MLLOG {"namespace": "", "time_ms": 1592670163481, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1592670163482, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 19, "current_iter_num": 2315}}
Iteration:   2320, Loss function: 4.153, Average Loss: 4.376, avg. samples / sec: 9873.37
Iteration:   2340, Loss function: 4.236, Average Loss: 4.373, avg. samples / sec: 9866.13
Iteration:   2360, Loss function: 4.194, Average Loss: 4.368, avg. samples / sec: 9840.66
Iteration:   2380, Loss function: 4.315, Average Loss: 4.365, avg. samples / sec: 9850.33
Iteration:   2400, Loss function: 4.146, Average Loss: 4.360, avg. samples / sec: 9871.14
Iteration:   2420, Loss function: 4.132, Average Loss: 4.357, avg. samples / sec: 9870.87
Iteration:   2440, Loss function: 4.185, Average Loss: 4.353, avg. samples / sec: 9882.90
:::MLLOG {"namespace": "", "time_ms": 1592670175316, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1592670175317, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 20, "current_iter_num": 2443}}
Iteration:   2460, Loss function: 4.015, Average Loss: 4.348, avg. samples / sec: 9881.88
Iteration:   2480, Loss function: 4.097, Average Loss: 4.343, avg. samples / sec: 9864.87
Iteration:   2500, Loss function: 4.201, Average Loss: 4.340, avg. samples / sec: 9883.34
Iteration:   2520, Loss function: 3.881, Average Loss: 4.336, avg. samples / sec: 9868.33
Iteration:   2540, Loss function: 3.969, Average Loss: 4.332, avg. samples / sec: 9874.66
Iteration:   2560, Loss function: 4.382, Average Loss: 4.327, avg. samples / sec: 9862.17
:::MLLOG {"namespace": "", "time_ms": 1592670187237, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1592670187238, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 21, "current_iter_num": 2572}}
Iteration:   2580, Loss function: 3.861, Average Loss: 4.323, avg. samples / sec: 9844.66
Iteration:   2600, Loss function: 4.169, Average Loss: 4.319, avg. samples / sec: 9852.41
Iteration:   2620, Loss function: 4.323, Average Loss: 4.315, avg. samples / sec: 9867.63
Iteration:   2640, Loss function: 4.221, Average Loss: 4.311, avg. samples / sec: 9867.58
Iteration:   2660, Loss function: 4.100, Average Loss: 4.307, avg. samples / sec: 9873.30
Iteration:   2680, Loss function: 3.906, Average Loss: 4.301, avg. samples / sec: 9878.16
Iteration:   2700, Loss function: 3.679, Average Loss: 4.297, avg. samples / sec: 9860.27
:::MLLOG {"namespace": "", "time_ms": 1592670199204, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 21}}
:::MLLOG {"namespace": "", "time_ms": 1592670199205, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 22, "current_iter_num": 2701}}
Iteration:   2720, Loss function: 4.344, Average Loss: 4.293, avg. samples / sec: 9851.15
Iteration:   2740, Loss function: 3.881, Average Loss: 4.288, avg. samples / sec: 9854.43
Iteration:   2760, Loss function: 3.907, Average Loss: 4.284, avg. samples / sec: 9845.89
Iteration:   2780, Loss function: 4.020, Average Loss: 4.280, avg. samples / sec: 9836.11
Iteration:   2800, Loss function: 3.847, Average Loss: 4.277, avg. samples / sec: 9829.30
Iteration:   2820, Loss function: 3.959, Average Loss: 4.273, avg. samples / sec: 9829.06
:::MLLOG {"namespace": "", "time_ms": 1592670211026, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 22}}
:::MLLOG {"namespace": "", "time_ms": 1592670211027, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 23, "current_iter_num": 2829}}
Iteration:   2840, Loss function: 4.068, Average Loss: 4.267, avg. samples / sec: 9836.10
Iteration:   2860, Loss function: 3.772, Average Loss: 4.263, avg. samples / sec: 9835.39
Iteration:   2880, Loss function: 4.060, Average Loss: 4.259, avg. samples / sec: 9848.64
Iteration:   2900, Loss function: 3.974, Average Loss: 4.255, avg. samples / sec: 9846.51
Iteration:   2920, Loss function: 3.849, Average Loss: 4.250, avg. samples / sec: 9844.61
Iteration:   2940, Loss function: 3.979, Average Loss: 4.247, avg. samples / sec: 9835.69
:::MLLOG {"namespace": "", "time_ms": 1592670222986, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1592670222987, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 24, "current_iter_num": 2958}}
Iteration:   2960, Loss function: 4.016, Average Loss: 4.241, avg. samples / sec: 9800.54
Iteration:   2980, Loss function: 3.844, Average Loss: 4.237, avg. samples / sec: 9843.75
Iteration:   3000, Loss function: 3.955, Average Loss: 4.232, avg. samples / sec: 9822.35
Iteration:   3020, Loss function: 4.099, Average Loss: 4.228, avg. samples / sec: 9820.49
Iteration:   3040, Loss function: 3.944, Average Loss: 4.223, avg. samples / sec: 9843.82
Iteration:   3060, Loss function: 4.156, Average Loss: 4.219, avg. samples / sec: 9857.03
Iteration:   3080, Loss function: 4.063, Average Loss: 4.216, avg. samples / sec: 9847.28
:::MLLOG {"namespace": "", "time_ms": 1592670234851, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1592670234852, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 25, "current_iter_num": 3086}}
Iteration:   3100, Loss function: 3.978, Average Loss: 4.212, avg. samples / sec: 9847.92
Iteration:   3120, Loss function: 3.810, Average Loss: 4.207, avg. samples / sec: 9829.29
Iteration:   3140, Loss function: 4.011, Average Loss: 4.203, avg. samples / sec: 9862.36
Iteration:   3160, Loss function: 4.015, Average Loss: 4.198, avg. samples / sec: 9840.11
Iteration:   3180, Loss function: 4.147, Average Loss: 4.194, avg. samples / sec: 9824.23
Iteration:   3200, Loss function: 3.942, Average Loss: 4.190, avg. samples / sec: 9815.47
:::MLLOG {"namespace": "", "time_ms": 1592670246813, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 25}}
:::MLLOG {"namespace": "", "time_ms": 1592670246814, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 26, "current_iter_num": 3215}}
Iteration:   3220, Loss function: 4.114, Average Loss: 4.186, avg. samples / sec: 9828.17
Iteration:   3240, Loss function: 3.974, Average Loss: 4.182, avg. samples / sec: 9805.69
Iteration:   3260, Loss function: 3.702, Average Loss: 4.178, avg. samples / sec: 9821.89
Iteration:   3280, Loss function: 3.999, Average Loss: 4.176, avg. samples / sec: 9841.86
Iteration:   3300, Loss function: 4.226, Average Loss: 4.171, avg. samples / sec: 9840.25
Iteration:   3320, Loss function: 4.131, Average Loss: 4.166, avg. samples / sec: 9840.82
Iteration:   3340, Loss function: 3.873, Average Loss: 4.164, avg. samples / sec: 9826.40
:::MLLOG {"namespace": "", "time_ms": 1592670258781, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 26}}
:::MLLOG {"namespace": "", "time_ms": 1592670258782, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 27, "current_iter_num": 3344}}
Iteration:   3360, Loss function: 3.959, Average Loss: 4.159, avg. samples / sec: 9822.57
Iteration:   3380, Loss function: 4.022, Average Loss: 4.155, avg. samples / sec: 9827.05
Iteration:   3400, Loss function: 3.971, Average Loss: 4.149, avg. samples / sec: 9830.52
Iteration:   3420, Loss function: 4.087, Average Loss: 4.145, avg. samples / sec: 9833.15
Iteration:   3440, Loss function: 3.839, Average Loss: 4.141, avg. samples / sec: 9838.33
Iteration:   3460, Loss function: 4.129, Average Loss: 4.138, avg. samples / sec: 9833.63
:::MLLOG {"namespace": "", "time_ms": 1592670270658, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1592670270659, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 28, "current_iter_num": 3472}}
Iteration:   3480, Loss function: 3.860, Average Loss: 4.133, avg. samples / sec: 9812.66
Iteration:   3500, Loss function: 4.160, Average Loss: 4.129, avg. samples / sec: 9825.27
Iteration:   3520, Loss function: 4.017, Average Loss: 4.124, avg. samples / sec: 9832.26
Iteration:   3540, Loss function: 3.962, Average Loss: 4.121, avg. samples / sec: 9815.12
Iteration:   3560, Loss function: 4.113, Average Loss: 4.116, avg. samples / sec: 9833.80
Iteration:   3580, Loss function: 3.965, Average Loss: 4.112, avg. samples / sec: 9847.30
Iteration:   3600, Loss function: 3.779, Average Loss: 4.109, avg. samples / sec: 9871.74
:::MLLOG {"namespace": "", "time_ms": 1592670282664, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1592670282665, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 29, "current_iter_num": 3601}}
Iteration:   3620, Loss function: 4.000, Average Loss: 4.105, avg. samples / sec: 9854.39
Iteration:   3640, Loss function: 3.826, Average Loss: 4.103, avg. samples / sec: 9873.39
Iteration:   3660, Loss function: 4.064, Average Loss: 4.099, avg. samples / sec: 9875.65
Iteration:   3680, Loss function: 3.756, Average Loss: 4.095, avg. samples / sec: 9855.14
Iteration:   3700, Loss function: 3.918, Average Loss: 4.093, avg. samples / sec: 9843.31
Iteration:   3720, Loss function: 3.982, Average Loss: 4.089, avg. samples / sec: 9854.42
:::MLLOG {"namespace": "", "time_ms": 1592670294464, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 29}}
:::MLLOG {"namespace": "", "time_ms": 1592670294465, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 30, "current_iter_num": 3729}}
Iteration:   3740, Loss function: 3.773, Average Loss: 4.085, avg. samples / sec: 9824.24
Iteration:   3760, Loss function: 3.903, Average Loss: 4.081, avg. samples / sec: 9861.60
Iteration:   3780, Loss function: 4.013, Average Loss: 4.078, avg. samples / sec: 9866.12
Iteration:   3800, Loss function: 3.882, Average Loss: 4.075, avg. samples / sec: 9867.39
Iteration:   3820, Loss function: 4.357, Average Loss: 4.070, avg. samples / sec: 9855.10
Iteration:   3840, Loss function: 3.967, Average Loss: 4.066, avg. samples / sec: 9846.40
:::MLLOG {"namespace": "", "time_ms": 1592670306402, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 30}}
:::MLLOG {"namespace": "", "time_ms": 1592670306403, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 31, "current_iter_num": 3858}}
Iteration:   3860, Loss function: 4.053, Average Loss: 4.063, avg. samples / sec: 9846.00
Iteration:   3880, Loss function: 3.689, Average Loss: 4.059, avg. samples / sec: 9857.55
Iteration:   3900, Loss function: 3.814, Average Loss: 4.055, avg. samples / sec: 9862.11
Iteration:   3920, Loss function: 3.813, Average Loss: 4.052, avg. samples / sec: 9856.06
Iteration:   3940, Loss function: 4.189, Average Loss: 4.048, avg. samples / sec: 9863.16
Iteration:   3960, Loss function: 3.833, Average Loss: 4.044, avg. samples / sec: 9864.46
Iteration:   3980, Loss function: 3.874, Average Loss: 4.042, avg. samples / sec: 9855.16
:::MLLOG {"namespace": "", "time_ms": 1592670318244, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1592670318245, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 32, "current_iter_num": 3986}}
Iteration:   4000, Loss function: 3.554, Average Loss: 4.038, avg. samples / sec: 9830.38
Iteration:   4020, Loss function: 3.742, Average Loss: 4.034, avg. samples / sec: 9828.77
Iteration:   4040, Loss function: 4.031, Average Loss: 4.031, avg. samples / sec: 9846.56
Iteration:   4060, Loss function: 4.071, Average Loss: 4.028, avg. samples / sec: 9834.61
Iteration:   4080, Loss function: 3.897, Average Loss: 4.026, avg. samples / sec: 9834.03
Iteration:   4100, Loss function: 3.584, Average Loss: 4.023, avg. samples / sec: 9837.85
:::MLLOG {"namespace": "", "time_ms": 1592670330206, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1592670330207, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 33, "current_iter_num": 4115}}
Iteration:   4120, Loss function: 4.054, Average Loss: 4.020, avg. samples / sec: 9835.82
Iteration:   4140, Loss function: 3.964, Average Loss: 4.016, avg. samples / sec: 9838.27
Iteration:   4160, Loss function: 3.496, Average Loss: 4.015, avg. samples / sec: 9846.66
Iteration:   4180, Loss function: 4.001, Average Loss: 4.013, avg. samples / sec: 9872.21
Iteration:   4200, Loss function: 3.679, Average Loss: 4.010, avg. samples / sec: 9866.08
Iteration:   4220, Loss function: 4.148, Average Loss: 4.006, avg. samples / sec: 9875.32
Iteration:   4240, Loss function: 3.921, Average Loss: 4.004, avg. samples / sec: 9880.61
:::MLLOG {"namespace": "", "time_ms": 1592670342135, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 33}}
:::MLLOG {"namespace": "", "time_ms": 1592670342136, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 34, "current_iter_num": 4244}}
Iteration:   4260, Loss function: 3.781, Average Loss: 3.999, avg. samples / sec: 9871.34
Iteration:   4280, Loss function: 3.594, Average Loss: 3.996, avg. samples / sec: 9858.51
Iteration:   4300, Loss function: 3.914, Average Loss: 3.992, avg. samples / sec: 9884.17
Iteration:   4320, Loss function: 3.752, Average Loss: 3.988, avg. samples / sec: 9861.02
Iteration:   4340, Loss function: 3.648, Average Loss: 3.985, avg. samples / sec: 9835.81
Iteration:   4360, Loss function: 3.276, Average Loss: 3.981, avg. samples / sec: 9878.24
:::MLLOG {"namespace": "", "time_ms": 1592670353968, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 34}}
:::MLLOG {"namespace": "", "time_ms": 1592670353969, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 35, "current_iter_num": 4372}}
Iteration:   4380, Loss function: 3.657, Average Loss: 3.979, avg. samples / sec: 9863.73
Iteration:   4400, Loss function: 3.579, Average Loss: 3.975, avg. samples / sec: 9838.47
Iteration:   4420, Loss function: 3.871, Average Loss: 3.971, avg. samples / sec: 9836.11
Iteration:   4440, Loss function: 3.710, Average Loss: 3.969, avg. samples / sec: 9844.92
Iteration:   4460, Loss function: 3.939, Average Loss: 3.966, avg. samples / sec: 9825.09
Iteration:   4480, Loss function: 3.682, Average Loss: 3.963, avg. samples / sec: 9837.19
Iteration:   4500, Loss function: 3.711, Average Loss: 3.960, avg. samples / sec: 9822.09
:::MLLOG {"namespace": "", "time_ms": 1592670365977, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1592670365978, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 36, "current_iter_num": 4501}}
Iteration:   4520, Loss function: 3.736, Average Loss: 3.956, avg. samples / sec: 9825.73
Iteration:   4540, Loss function: 3.705, Average Loss: 3.952, avg. samples / sec: 9833.45
Iteration:   4560, Loss function: 3.852, Average Loss: 3.950, avg. samples / sec: 9826.18
Iteration:   4580, Loss function: 3.849, Average Loss: 3.947, avg. samples / sec: 9835.73
Iteration:   4600, Loss function: 4.131, Average Loss: 3.945, avg. samples / sec: 9832.91
Iteration:   4620, Loss function: 3.683, Average Loss: 3.943, avg. samples / sec: 9842.74
:::MLLOG {"namespace": "", "time_ms": 1592670377806, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 36}}
:::MLLOG {"namespace": "", "time_ms": 1592670377806, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 37, "current_iter_num": 4629}}
Iteration:   4640, Loss function: 3.803, Average Loss: 3.940, avg. samples / sec: 9809.14
Iteration:   4660, Loss function: 3.906, Average Loss: 3.936, avg. samples / sec: 9847.94
Iteration:   4680, Loss function: 3.856, Average Loss: 3.933, avg. samples / sec: 9841.07
Iteration:   4700, Loss function: 4.055, Average Loss: 3.932, avg. samples / sec: 9836.73
Iteration:   4720, Loss function: 3.621, Average Loss: 3.929, avg. samples / sec: 9849.44
Iteration:   4740, Loss function: 3.870, Average Loss: 3.928, avg. samples / sec: 9786.92
:::MLLOG {"namespace": "", "time_ms": 1592670389770, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 37}}
:::MLLOG {"namespace": "", "time_ms": 1592670389771, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 38, "current_iter_num": 4758}}
Iteration:   4760, Loss function: 3.901, Average Loss: 3.926, avg. samples / sec: 9852.82
Iteration:   4780, Loss function: 3.839, Average Loss: 3.923, avg. samples / sec: 9839.52
Iteration:   4800, Loss function: 3.893, Average Loss: 3.919, avg. samples / sec: 9833.85
Iteration:   4820, Loss function: 3.611, Average Loss: 3.915, avg. samples / sec: 9827.12
Iteration:   4840, Loss function: 3.719, Average Loss: 3.913, avg. samples / sec: 9857.13
Iteration:   4860, Loss function: 3.945, Average Loss: 3.910, avg. samples / sec: 9877.74
Iteration:   4880, Loss function: 3.756, Average Loss: 3.908, avg. samples / sec: 9866.70
:::MLLOG {"namespace": "", "time_ms": 1592670401622, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 38}}
:::MLLOG {"namespace": "", "time_ms": 1592670401623, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 39, "current_iter_num": 4886}}
Iteration:   4900, Loss function: 3.733, Average Loss: 3.906, avg. samples / sec: 9857.88
Iteration:   4920, Loss function: 3.763, Average Loss: 3.903, avg. samples / sec: 9868.76
Iteration:   4940, Loss function: 3.466, Average Loss: 3.901, avg. samples / sec: 9878.52
Iteration:   4960, Loss function: 3.828, Average Loss: 3.898, avg. samples / sec: 9874.67
Iteration:   4980, Loss function: 4.064, Average Loss: 3.896, avg. samples / sec: 9885.31
Iteration:   5000, Loss function: 3.798, Average Loss: 3.894, avg. samples / sec: 9883.30
:::MLLOG {"namespace": "", "time_ms": 1592670413538, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 39}}
:::MLLOG {"namespace": "", "time_ms": 1592670413539, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 40, "current_iter_num": 5015}}
Iteration:   5020, Loss function: 4.020, Average Loss: 3.891, avg. samples / sec: 9847.20
Iteration:   5040, Loss function: 3.782, Average Loss: 3.888, avg. samples / sec: 9864.99
Iteration:   5060, Loss function: 3.550, Average Loss: 3.886, avg. samples / sec: 9876.02
Iteration:   5080, Loss function: 3.741, Average Loss: 3.884, avg. samples / sec: 9878.32
Iteration:   5100, Loss function: 3.647, Average Loss: 3.882, avg. samples / sec: 9849.79
Iteration:   5120, Loss function: 3.765, Average Loss: 3.880, avg. samples / sec: 9861.35
Iteration:   5140, Loss function: 3.742, Average Loss: 3.877, avg. samples / sec: 9874.48
:::MLLOG {"namespace": "", "time_ms": 1592670425464, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 40}}
averaging bn running means and vars
Predicting Ended, total time: 4.31 s
:::MLLOG {"namespace": "", "time_ms": 1592670429814, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 331, "first_epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1592670429857, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 338, "first_epoch_num": 41, "epoch_count": 10}}
:::MLLOG {"namespace": "", "time_ms": 1592670429857, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 41, "current_iter_num": 5144}}
Loading and preparing results...
DONE (t=0.51s)
Running per image evaluation...
Evaluate annotation type *bbox*
Iteration:   5160, Loss function: 3.698, Average Loss: 3.873, avg. samples / sec: 2860.39
DONE (t=1.71s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.18569
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.33944
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.18660
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.27463
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.19342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.28318
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.29850
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.29850
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
Current AP: 0.18569 AP goal: 0.23000
Iteration:   5180, Loss function: 3.610, Average Loss: 3.872, avg. samples / sec: 9835.22
:::MLLOG {"namespace": "", "time_ms": 1592670433418, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 85, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1592670433418, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.1856862622899764, "metadata": {"file": "train.py", "lineno": 88, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1592670433419, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 89, "epoch_num": 40}}
Iteration:   5200, Loss function: 3.745, Average Loss: 3.867, avg. samples / sec: 9852.29
Iteration:   5220, Loss function: 3.756, Average Loss: 3.864, avg. samples / sec: 9848.66
Iteration:   5240, Loss function: 3.880, Average Loss: 3.861, avg. samples / sec: 9835.99
Iteration:   5260, Loss function: 3.789, Average Loss: 3.860, avg. samples / sec: 9838.58
:::MLLOG {"namespace": "", "time_ms": 1592670441852, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1592670441853, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 42, "current_iter_num": 5272}}
Iteration:   5280, Loss function: 3.724, Average Loss: 3.857, avg. samples / sec: 9824.66
Iteration:   5300, Loss function: 3.677, Average Loss: 3.855, avg. samples / sec: 9831.04
Iteration:   5320, Loss function: 3.672, Average Loss: 3.851, avg. samples / sec: 9835.84
Iteration:   5340, Loss function: 3.645, Average Loss: 3.849, avg. samples / sec: 9829.97
Iteration:   5360, Loss function: 3.875, Average Loss: 3.848, avg. samples / sec: 9831.14
Iteration:   5380, Loss function: 3.699, Average Loss: 3.845, avg. samples / sec: 9834.16
Iteration:   5400, Loss function: 3.540, Average Loss: 3.842, avg. samples / sec: 9827.50
:::MLLOG {"namespace": "", "time_ms": 1592670453862, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 42}}
:::MLLOG {"namespace": "", "time_ms": 1592670453863, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 43, "current_iter_num": 5401}}
Iteration:   5420, Loss function: 4.021, Average Loss: 3.840, avg. samples / sec: 9833.28
Iteration:   5440, Loss function: 3.732, Average Loss: 3.838, avg. samples / sec: 9842.32
Iteration:   5460, Loss function: 3.820, Average Loss: 3.835, avg. samples / sec: 9830.26
Iteration:   5480, Loss function: 3.659, Average Loss: 3.834, avg. samples / sec: 9838.91
Iteration:   5500, Loss function: 3.848, Average Loss: 3.832, avg. samples / sec: 9839.53
Iteration:   5520, Loss function: 3.656, Average Loss: 3.830, avg. samples / sec: 9840.28
:::MLLOG {"namespace": "", "time_ms": 1592670465685, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 43}}
:::MLLOG {"namespace": "", "time_ms": 1592670465686, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 44, "current_iter_num": 5529}}
Iteration:   5540, Loss function: 3.892, Average Loss: 3.829, avg. samples / sec: 9848.11
Iteration:   5560, Loss function: 3.469, Average Loss: 3.826, avg. samples / sec: 9853.70
Iteration:   5580, Loss function: 3.598, Average Loss: 3.822, avg. samples / sec: 9854.79
Iteration:   5600, Loss function: 3.692, Average Loss: 3.819, avg. samples / sec: 9852.66
Iteration:   5620, Loss function: 3.868, Average Loss: 3.819, avg. samples / sec: 9831.90
Iteration:   5640, Loss function: 3.660, Average Loss: 3.818, avg. samples / sec: 9864.34
:::MLLOG {"namespace": "", "time_ms": 1592670477624, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 44}}
lr decay step #1
:::MLLOG {"namespace": "", "time_ms": 1592670477624, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 45, "current_iter_num": 5658}}
Iteration:   5660, Loss function: 3.550, Average Loss: 3.816, avg. samples / sec: 9873.72
Iteration:   5680, Loss function: 3.656, Average Loss: 3.811, avg. samples / sec: 9861.61
Iteration:   5700, Loss function: 3.464, Average Loss: 3.803, avg. samples / sec: 9866.99
Iteration:   5720, Loss function: 3.578, Average Loss: 3.795, avg. samples / sec: 9883.69
Iteration:   5740, Loss function: 3.182, Average Loss: 3.787, avg. samples / sec: 9856.94
Iteration:   5760, Loss function: 3.335, Average Loss: 3.779, avg. samples / sec: 9873.08
Iteration:   5780, Loss function: 3.365, Average Loss: 3.771, avg. samples / sec: 9875.85
:::MLLOG {"namespace": "", "time_ms": 1592670489547, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 45}}
:::MLLOG {"namespace": "", "time_ms": 1592670489548, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 46, "current_iter_num": 5787}}
Iteration:   5800, Loss function: 3.297, Average Loss: 3.763, avg. samples / sec: 9856.46
Iteration:   5820, Loss function: 3.107, Average Loss: 3.754, avg. samples / sec: 9868.18
Iteration:   5840, Loss function: 3.252, Average Loss: 3.746, avg. samples / sec: 9877.17
Iteration:   5860, Loss function: 3.026, Average Loss: 3.739, avg. samples / sec: 9861.94
Iteration:   5880, Loss function: 3.309, Average Loss: 3.731, avg. samples / sec: 9864.84
Iteration:   5900, Loss function: 3.229, Average Loss: 3.722, avg. samples / sec: 9861.98
:::MLLOG {"namespace": "", "time_ms": 1592670501378, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 46}}
:::MLLOG {"namespace": "", "time_ms": 1592670501379, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 47, "current_iter_num": 5915}}
Iteration:   5920, Loss function: 3.388, Average Loss: 3.715, avg. samples / sec: 9868.69
Iteration:   5940, Loss function: 3.169, Average Loss: 3.706, avg. samples / sec: 9861.61
Iteration:   5960, Loss function: 3.435, Average Loss: 3.700, avg. samples / sec: 9872.83
Iteration:   5980, Loss function: 3.335, Average Loss: 3.692, avg. samples / sec: 9867.09
Iteration:   6000, Loss function: 3.264, Average Loss: 3.685, avg. samples / sec: 9862.35
Iteration:   6020, Loss function: 3.404, Average Loss: 3.677, avg. samples / sec: 9874.84
Iteration:   6040, Loss function: 3.267, Average Loss: 3.670, avg. samples / sec: 9870.59
:::MLLOG {"namespace": "", "time_ms": 1592670513300, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 47}}
:::MLLOG {"namespace": "", "time_ms": 1592670513301, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 48, "current_iter_num": 6044}}
Iteration:   6060, Loss function: 3.268, Average Loss: 3.663, avg. samples / sec: 9865.00
Iteration:   6080, Loss function: 3.364, Average Loss: 3.655, avg. samples / sec: 9879.74
Iteration:   6100, Loss function: 3.180, Average Loss: 3.648, avg. samples / sec: 9869.24
Iteration:   6120, Loss function: 3.596, Average Loss: 3.641, avg. samples / sec: 9861.77
Iteration:   6140, Loss function: 3.029, Average Loss: 3.634, avg. samples / sec: 9873.67
Iteration:   6160, Loss function: 3.343, Average Loss: 3.628, avg. samples / sec: 9854.25
:::MLLOG {"namespace": "", "time_ms": 1592670525130, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 48}}
:::MLLOG {"namespace": "", "time_ms": 1592670525131, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 49, "current_iter_num": 6172}}
Iteration:   6180, Loss function: 3.210, Average Loss: 3.620, avg. samples / sec: 9863.73
Iteration:   6200, Loss function: 3.216, Average Loss: 3.614, avg. samples / sec: 9861.16
Iteration:   6220, Loss function: 3.277, Average Loss: 3.607, avg. samples / sec: 9875.90
Iteration:   6240, Loss function: 3.435, Average Loss: 3.600, avg. samples / sec: 9869.91
Iteration:   6260, Loss function: 3.111, Average Loss: 3.594, avg. samples / sec: 9862.68
Iteration:   6280, Loss function: 3.080, Average Loss: 3.587, avg. samples / sec: 9870.85
Iteration:   6300, Loss function: 3.101, Average Loss: 3.581, avg. samples / sec: 9861.05
:::MLLOG {"namespace": "", "time_ms": 1592670537099, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 49}}
:::MLLOG {"namespace": "", "time_ms": 1592670537100, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 50, "current_iter_num": 6301}}
Iteration:   6320, Loss function: 3.202, Average Loss: 3.575, avg. samples / sec: 9838.50
Iteration:   6340, Loss function: 3.317, Average Loss: 3.569, avg. samples / sec: 9852.88
Iteration:   6360, Loss function: 3.365, Average Loss: 3.563, avg. samples / sec: 9856.53
Iteration:   6380, Loss function: 3.424, Average Loss: 3.558, avg. samples / sec: 9840.31
Iteration:   6400, Loss function: 2.990, Average Loss: 3.553, avg. samples / sec: 9854.33
Iteration:   6420, Loss function: 3.225, Average Loss: 3.548, avg. samples / sec: 9812.69
:::MLLOG {"namespace": "", "time_ms": 1592670548915, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 427, "epoch_num": 50}}
averaging bn running means and vars
Predicting Ended, total time: 3.75 s
:::MLLOG {"namespace": "", "time_ms": 1592670552675, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 331, "first_epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1592670552711, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 338, "first_epoch_num": 51, "epoch_count": 5}}
:::MLLOG {"namespace": "", "time_ms": 1592670552711, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 348, "epoch_num": 51, "current_iter_num": 6429}}
Loading and preparing results...
DONE (t=0.52s)
Running per image evaluation...
Evaluate annotation type *bbox*
Iteration:   6440, Loss function: 3.360, Average Loss: 3.541, avg. samples / sec: 3249.03
DONE (t=1.77s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.23251
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.39762
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23872
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.31521
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22364
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32762
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.34325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.34325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.00000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.00000
Current AP: 0.23251 AP goal: 0.23000
Iteration:   6460, Loss function: 3.219, Average Loss: 3.536, avg. samples / sec: 9819.36
:::MLLOG {"namespace": "", "time_ms": 1592670555646, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 85, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1592670555647, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.23251402882315678, "metadata": {"file": "train.py", "lineno": 88, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1592670555647, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 89, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1592670555944, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "train.py", "lineno": 449, "status": "success"}}
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2020-06-20 09:29:20 AM
RESULT,SINGLE_STAGE_DETECTOR,,652,nvidia,2020-06-20 09:18:28 AM
ENDING TIMING RUN AT 2020-06-20 09:29:20 AM
RESULT,SINGLE_STAGE_DETECTOR,,652,nvidia,2020-06-20 09:18:28 AM
ENDING TIMING RUN AT 2020-06-20 09:29:21 AM
RESULT,SINGLE_STAGE_DETECTOR,,653,nvidia,2020-06-20 09:18:28 AM
ENDING TIMING RUN AT 2020-06-20 09:29:21 AM
RESULT,SINGLE_STAGE_DETECTOR,,653,nvidia,2020-06-20 09:18:28 AM
ENDING TIMING RUN AT 2020-06-20 09:29:21 AM
RESULT,SINGLE_STAGE_DETECTOR,,653,nvidia,2020-06-20 09:18:28 AM
slurmstepd: error: _is_a_lwp: open() /proc/228744/status failed: No such file or directory
ENDING TIMING RUN AT 2020-06-20 09:29:21 AM
RESULT,SINGLE_STAGE_DETECTOR,,653,nvidia,2020-06-20 09:18:28 AM
ENDING TIMING RUN AT 2020-06-20 09:29:21 AM
RESULT,SINGLE_STAGE_DETECTOR,,653,nvidia,2020-06-20 09:18:28 AM
ENDING TIMING RUN AT 2020-06-20 09:29:22 AM
RESULT,SINGLE_STAGE_DETECTOR,,654,nvidia,2020-06-20 09:18:28 AM
